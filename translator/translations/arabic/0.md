# الملخص التنفيذي

نظرة عامة رفيعة المستوى على المقال. إذا كان وقتك ضيقاً، احصل على جميع النقاط الرئيسية في 10 دقائق فقط.

حولت التطورات الجذرية في الذكاء الاصطناعي خلال العقد الماضي (للذكاء الاصطناعي ذي الأغراض المحددة) والسنوات الأخيرة (للذكاء الاصطناعي متعدد الأغراض) هذا المجال من حقل أكاديمي متخصص إلى الاستراتيجية التجارية الأساسية للعديد من أكبر الشركات في العالم، مع استثمارات سنوية تقدر بمئات مليارات الدولارات في تقنيات وتكنولوجيات تطوير قدرات الذكاء الاصطناعي.

نصل الآن إلى مفترق طرق حاسم. مع بداية مضاهاة قدرات أنظمة الذكاء الاصطناعي الجديدة لقدرات البشر وتفوقها عليها في العديد من المجالات المعرفية، يجب على البشرية أن تقرر: إلى أي مدى نذهب، وفي أي اتجاه؟

الذكاء الاصطناعي، مثل كل تقنية، بدأ بهدف تحسين الأمور لصانعه. لكن مسارنا الحالي، وخيارنا الضمني، هو سباق محموم نحو أنظمة أكثر قوة باستمرار، تقوده الحوافز الاقتصادية لعدد قليل من شركات التكنولوجيا العملاقة التي تسعى إلى أتمتة قطاعات كبيرة من النشاط الاقتصادي الحالي والعمل البشري. إذا استمر هذا السباق لفترة أطول، فهناك فائز حتمي: الذكاء الاصطناعي نفسه – بديل أسرع وأذكى وأرخص عن البشر في اقتصادنا وتفكيرنا وقراراتنا، وفي نهاية المطاف في التحكم بحضارتنا.

لكن يمكننا اتخاذ خيار آخر: عبر حكوماتنا، يمكننا السيطرة على عملية تطوير الذكاء الاصطناعي لفرض حدود واضحة، وخطوط لن نتجاوزها، وأشياء لن نفعلها ببساطة – كما فعلنا مع التقنيات النووية وأسلحة الدمار الشامل وأسلحة الفضاء والعمليات المدمرة للبيئة والهندسة الحيوية للبشر وعلم تحسين النسل. والأهم من ذلك، يمكننا ضمان بقاء الذكاء الاصطناعي أداة لتمكين البشر، بدلاً من كونه نوعاً جديداً يحل محلنا ويحل مكاننا في النهاية.

يحتج هذا المقال بأن علينا *الحفاظ على مستقبل بشري* من خلال إغلاق "البوابات" أمام الذكاء الاصطناعي العام ذاتي الحكم متعدد الأغراض الأذكى من البشر – الذي يُطلق عليه أحياناً "الذكاء الاصطناعي العام" – وخاصة أمام النسخة الفائقة على البشر التي تُسمى أحياناً "الذكاء الفائق." بدلاً من ذلك، يجب أن نركز على أدوات ذكية اصطناعية قوية وموثوقة يمكنها تمكين الأفراد وتحسين قدرات المجتمعات البشرية بشكل تحولي للقيام بما تجيده. هيكل هذا الحجة يتبع باختصار.

## الذكاء الاصطناعي مختلف

أنظمة الذكاء الاصطناعي مختلفة جوهرياً عن التقنيات الأخرى. بينما تتبع البرمجيات التقليدية تعليمات دقيقة، تتعلم أنظمة الذكاء الاصطناعي كيفية تحقيق الأهداف دون أن يُخبرها أحد صراحة كيف تفعل ذلك. هذا يجعلها قوية: إذا تمكنا من تعريف الهدف أو مقياس النجاح بوضوح، يمكن لنظام الذكاء الاصطناعي في معظم الحالات أن يتعلم تحقيقه. لكنه يجعلها أيضاً غير قابلة للتنبؤ بطبيعتها: لا يمكننا تحديد الإجراءات التي ستتخذها لتحقيق أهدافها بشكل موثوق.

كما أنها غير قابلة للتفسير إلى حد كبير: رغم أنها جزئياً عبارة عن كود، فهي في الأساس مجموعة هائلة من الأرقام الغامضة – "أوزان" الشبكات العصبية – التي لا يمكن تحليلها؛ نحن لسنا أفضل كثيراً في فهم آليات عملها الداخلية من قدرتنا على إدراك الأفكار من خلال النظر داخل دماغ بيولوجي.

هذا النمط الأساسي من التدريب للشبكات العصبية الرقمية يتزايد بسرعة في التعقيد. تُصنع أنظمة الذكاء الاصطناعي الأقوى من خلال تجارب حاسوبية ضخمة، باستخدام أجهزة متخصصة لتدريب الشبكات العصبية على مجموعات بيانات هائلة، والتي تُدعم لاحقاً بأدوات برمجية وهيكل فوقي.

أدى هذا إلى إنشاء أدوات قوية جداً لإنشاء ومعالجة النصوص والصور، وأداء التفكير الرياضي والعلمي، وتجميع المعلومات، والاستعلام التفاعلي من مخزن واسع من المعرفة البشرية.

لسوء الحظ، بينما تطوير أدوات تكنولوجية أقوى وأكثر موثوقية هو ما *يجب* أن نفعله، وما يريده تقريباً الجميع ويقولون إنهم يريدونه، فهو ليس المسار الذي نسير عليه فعلاً.

## الذكاء الاصطناعي العام والذكاء الفائق

منذ فجر هذا المجال، ركز بحث الذكاء الاصطناعي بدلاً من ذلك على هدف مختلف: الذكاء الاصطناعي العام. أصبح هذا التركيز الآن محور اهتمام الشركات العملاقة الرائدة في تطوير الذكاء الاصطناعي.

ما هو الذكاء الاصطناعي العام؟ غالباً ما يُعرَّف بشكل غامض كـ"ذكاء اصطناعي بمستوى بشري"، لكن هذا إشكالي: أي البشر، وفي أي القدرات يكون بمستوى بشري؟ وماذا عن القدرات الفائقة على البشر التي يملكها بالفعل؟ طريقة أكثر فائدة لفهم الذكاء الاصطناعي العام هي من خلال تقاطع ثلاث خصائص رئيسية: **الا** ستقلالية العالية (استقلالية العمل)، و**الع** مومية العالية (النطاق الواسع والقدرة على التكيف)، و**الذ** كاء العالي (الكفاءة في المهام المعرفية). قد تكون أنظمة الذكاء الاصطناعي الحالية عالية القدرة لكن محدودة النطاق، أو عامة لكن تتطلب إشرافاً بشرياً مستمراً، أو مستقلة لكن محدودة النطاق.

الذكاء الاصطناعي العام الكامل سيجمع بين الخصائص الثلاث جميعاً بمستويات تضاهي أو تتفوق على أعلى القدرات البشرية. والأهم من ذلك، أن هذا المزيج هو ما يجعل البشر فعالين جداً ومختلفين جداً عن البرمجيات الحالية؛ وهو أيضاً ما يمكن أن يتيح استبدال البشر بالكامل بأنظمة رقمية.

بينما الذكاء البشري مميز، فهو بأي حال ليس حداً أقصى. يمكن للأنظمة الاصطناعية "الفائقة الذكاء" أن تعمل بسرعة أكبر بمئات المرات، وتحلل بيانات أكثر بكثير وتحتفظ بكميات هائلة "في الذهن" في الوقت نفسه، وتشكل تجمعات أكبر وأكثر فعالية من مجموعات البشر. يمكنها أن تحل محل ليس الأفراد بل الشركات أو الدول أو حضارتنا ككل.

## نحن على العتبة

هناك إجماع علمي قوي على أن الذكاء الاصطناعي العام *ممكن.* يتفوق الذكاء الاصطناعي بالفعل على الأداء البشري في العديد من الاختبارات العامة للقدرة الفكرية، بما في ذلك مؤخراً التفكير والحل المتقدم للمشاكل. القدرات المتأخرة – مثل التعلم المستمر والتخطيط والوعي الذاتي والأصالة – تتواجد جميعها بمستوى معين في أنظمة الذكاء الاصطناعي الحالية، وتوجد تقنيات معروفة من المرجح أن تحسنها جميعاً.

بينما اعتبر العديد من الباحثين حتى قبل سنوات قليلة أن الذكاء الاصطناعي العام يبعد عقوداً، حالياً الأدلة على الجداول الزمنية القصيرة للذكاء الاصطناعي العام قوية:

- "قوانين التدرج" المؤكدة تجريبياً تربط المدخل الحاسوبي بقدرة الذكاء الاصطناعي، والشركات على المسار الصحيح لرفع المدخل الحاسوبي بمقادير من الحجم خلال السنوات القليلة القادمة. الموارد البشرية والمالية المخصصة لتطوير الذكاء الاصطناعي تعادل الآن تلك الخاصة بعشرة مشاريع مانهاتن وعدة مشاريع أبولو.
- شركات الذكاء الاصطناعي وقادتها يؤمنون علناً وخصوصياً أن الذكاء الاصطناعي العام (بتعريف معين) قابل للتحقيق خلال سنوات قليلة. هذه الشركات لديها معلومات لا يملكها الجمهور، بما في ذلك امتلاك بعضها للجيل القادم من أنظمة الذكاء الاصطناعي.
- الخبراء المتنبئون ذوو السجلات المؤكدة يعطون احتمالية 25% لوصول الذكاء الاصطناعي العام (بتعريف معين) خلال 1-2 سنة، و50% لـ2-5 سنوات (انظر تنبؤات Metaculus للذكاء الاصطناعي العام ['الضعيف'](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) و['الكامل'](https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/)).
- الاستقلالية (بما في ذلك التخطيط المرن طويل المدى) متأخرة في أنظمة الذكاء الاصطناعي، لكن الشركات الكبرى تركز الآن مواردها الهائلة على تطوير أنظمة ذكاء اصطناعي مستقلة وأطلقت بشكل غير رسمي على 2025 ["عام الوكيل."](https://techinformed.com/2025-informed-the-year-of-agentic-ai/)
- الذكاء الاصطناعي يساهم أكثر فأكثر في تحسين نفسه. بمجرد أن تصبح أنظمة الذكاء الاصطناعي بنفس كفاءة باحثي الذكاء الاصطناعي البشر في إجراء بحوث الذكاء الاصطناعي، ستصل عتبة حرجة للتقدم السريع نحو أنظمة ذكاء اصطناعي أقوى بكثير وستؤدي على الأرجح إلى تسارع في قدرة الذكاء الاصطناعي. (يمكن القول أن هذا التسارع بدأ بالفعل.)

فكرة أن الذكاء الاصطناعي العام الأذكى من البشر يبعد عقوداً أو أكثر لم تعد قابلة للدفاع ببساطة للغالبية العظمى من خبراء المجال. الخلافات الآن حول عدد الأشهر أو السنوات التي ستستغرقها إذا بقينا على هذا المسار. السؤال الأساسي الذي نواجهه هو: هل يجب أن نفعل؟

## ما يقود السباق نحو الذكاء الاصطناعي العام

السباق نحو الذكاء الاصطناعي العام تقوده قوى متعددة، كل منها يجعل الوضع أكثر خطورة. شركات التكنولوجيا الكبرى ترى الذكاء الاصطناعي العام كتقنية الأتمتة النهائية – ليس فقط لدعم العمال البشر بل لاستبدالهم كلياً أو جزئياً. بالنسبة للشركات، الجائزة ضخمة: الفرصة للاستحواذ على جزء كبير من الناتج الاقتصادي العالمي البالغ 100 تريليون دولار سنوياً من خلال أتمتة تكاليف العمالة البشرية.

تشعر الدول بالإجبار على الانضمام إلى هذا السباق، مشيرة علناً إلى الريادة الاقتصادية والعلمية، لكنها تنظر خصوصياً إلى الذكاء الاصطناعي العام كثورة محتملة في الشؤون العسكرية مقارنة بالأسلحة النووية. الخوف من أن ينال المنافسون ميزة استراتيجية حاسمة يخلق ديناميكية سباق تسلح كلاسيكية.

الساعون وراء الذكاء الفائق غالباً ما يستشهدون برؤى كبرى: علاج جميع الأمراض، وعكس الشيخوخة، وتحقيق اختراقات في الطاقة وسفر الفضاء، أو إنشاء قدرات تخطيط فائقة على البشر.

بشكل أقل كرماً، ما يقود السباق هو القوة. كل مشارك – سواء كان شركة أو دولة – يؤمن أن الذكاء يساوي القوة، وأنه سيكون أفضل حارس لتلك القوة.

أحتج بأن هذه الدوافع حقيقية لكن مضللة جوهرياً: الذكاء الاصطناعي العام سيــمتص* ويــسعى* للقوة بدلاً من منحها؛ التقنيات المُنشأة بالذكاء الاصطناعي ستكون أيضاً ذات حدين بقوة، وحيث تكون مفيدة يمكن إنشاؤها بأدوات الذكاء الاصطناعي ودون الذكاء الاصطناعي العام؛ وحتى بقدر ما يبقى الذكاء الاصطناعي العام ومخرجاته تحت السيطرة، هذه الديناميكيات السباقية – سواء الشركاتية أو الجيوسياسية – تجعل المخاطر واسعة النطاق على مجتمعنا حتمية تقريباً ما لم تُقاطع بحسم.

## الذكاء الاصطناعي العام والذكاء الفائق يشكلان تهديداً جذرياً للحضارة

رغم جاذبيتهما، يشكل الذكاء الاصطناعي العام والذكاء الفائق تهديدات جذرية للحضارة من خلال مسارات متعددة متعاضدة:

*تركز القوة:* يمكن للذكاء الاصطناعي الفائق على البشر أن يجرد الغالبية العظمى من البشرية من القوة من خلال امتصاص قطاعات ضخمة من النشاط الاجتماعي والاقتصادي في أنظمة ذكاء اصطناعي تديرها حفنة من الشركات العملاقة (التي قد تستولي عليها الحكومات بدورها، أو تستولي عليها فعلياً.)

*اضطراب هائل:* أتمتة معظم الوظائف المعرفية بالجملة، واستبدال أنظمتنا المعرفية الحالية، وطرح أعداد هائلة من الوكلاء النشطين غير البشر سيقلب معظم أنظمتنا الحضارية الحالية في فترة زمنية قصيرة نسبياً.

*الكوارث:* من خلال نشر القدرة – التي قد تكون فوق المستوى البشري – على إنشاء تقنيات عسكرية ومدمرة جديدة وفصلها عن الأنظمة الاجتماعية والقانونية التي تؤسس للمسؤولية، تصبح الكوارث المادية من أسلحة الدمار الشامل أكثر احتمالاً بشكل جذري.

*الجيوسياسة والحرب:* القوى العالمية الكبرى لن تقف مكتوفة الأيدي إذا شعرت أن تقنية يمكن أن توفر "ميزة استراتيجية حاسمة" يطورها خصومها.

*الانفلات وفقدان السيطرة:* ما لم يُمنع تحديداً، سيكون لدى الذكاء الاصطناعي الفائق كل حافز لتحسين نفسه أكثر ويمكن أن يتفوق على البشر بكثير في السرعة ومعالجة البيانات وتطور التفكير. لا توجد طريقة ذات معنى يمكننا من خلالها السيطرة على مثل هذا النظام. مثل هذا الذكاء الاصطناعي لن يمنح القوة للبشر؛ نحن سنمنح القوة له، أو سيأخذها.

العديد من هذه المخاطر تبقى حتى لو حُلت مشكلة "المواءمة" التقنية – ضمان أن الذكاء الاصطناعي المتقدم يفعل بشكل موثوق ما يريده البشر أن يفعله. يطرح الذكاء الاصطناعي تحدياً هائلاً في كيفية إدارته، والعديد من جوانب هذه الإدارة تصبح صعبة جداً أو مستعصية كلما تُخترق حاجز الذكاء البشري.

والأهم من ذلك، النوع من الذكاء الاصطناعي العام الفائق على البشر متعدد الأغراض المُتابع حالياً سيكون له، بطبيعته ذاتها، أهداف ووكالة وقدرات تتجاوز قدراتنا. سيكون غير قابل للسيطرة جوهرياً – كيف يمكننا السيطرة على شيء لا يمكننا فهمه ولا التنبؤ به؟ لن يكون أداة تكنولوجية للاستخدام البشري، بل نوعاً ثانياً من الذكاء على الأرض إلى جانب نوعنا. إذا سُمح له بالتقدم أكثر، سيشكل ليس فقط نوعاً ثانياً بل نوعاً بديلاً.

ربما سيعاملنا بشكل جيد، ربما لا. لكن المستقبل سيكون له، ليس لنا. العصر البشري سينتهي.

## هذا ليس حتمياً؛ يمكن للبشرية، بشكل ملموس جداً، أن تقرر عدم بناء بديلها.

إنشاء الذكاء الاصطناعي العام الفائق على البشر بعيد عن كونه حتمياً. يمكننا منعه من خلال مجموعة منسقة من تدابير الحوكمة:

أولاً، نحتاج إلى محاسبة وإشراف قويين على الحوسبة للذكاء الاصطناعي ("القوة الحاسوبية")، والتي تعد عاملاً أساسياً في تمكين وحكم أنظمة الذكاء الاصطناعي واسعة النطاق. هذا بدوره يتطلب قياساً وإبلاغاً موحدين لإجمالي القوة الحاسوبية المستخدمة في تدريب نماذج الذكاء الاصطناعي وتشغيلها، وطرقاً تقنية لحساب وتصديق والتحقق من الحوسبة المستخدمة.

ثانياً، يجب أن نطبق حدوداً قصوى صارمة على الحوسبة للذكاء الاصطناعي، سواء للتدريب أو للتشغيل؛ هذه تمنع الذكاء الاصطناعي من كونه قوياً جداً ومن العمل بسرعة كبيرة. يمكن تطبيق هذه الحدود من خلال متطلبات قانونية وتدابير أمنية مبنية في الأجهزة مبنية في رقائق متخصصة بالذكاء الاصطناعي، مماثلة لميزات الأمان في الهواتف الحديثة. نظراً لأن الأجهزة المتخصصة بالذكاء الاصطناعي تُصنع من قبل حفنة من الشركات فقط، التحقق والإنفاذ ممكنان من خلال سلسلة التوريد الموجودة.

ثالثاً، نحتاج إلى مسؤولية قانونية معززة لأنظمة الذكاء الاصطناعي الأخطر. أولئك الذين يطورون ذكاءً اصطناعياً يجمع بين الاستقلالية العالية والعمومية الواسعة والذكاء المتفوق يجب أن يواجهوا مسؤولية مطلقة عن الأضرار، بينما الملاجئ الآمنة من هذه المسؤولية ستشجع تطوير أنظمة أكثر محدودية وقابلية للسيطرة.

رابعاً، نحتاج إلى تنظيم متدرج يعتمد على مستويات المخاطر. الأنظمة الأقدر والأخطر ستتطلب ضمانات أمان وقابلية سيطرة واسعة قبل التطوير والنشر، بينما الأنظمة الأقل قوة أو الأكثر تخصصاً ستواجه إشرافاً متناسباً. هذا الإطار التنظيمي يجب أن يعمل في النهاية على المستويين الوطني والدولي.

هذا النهج – مع مواصفات مفصلة معطاة في الوثيقة الكاملة – عملي: بينما ستكون هناك حاجة للتنسيق الدولي، يمكن للتحقق والإنفاذ أن يعملا من خلال العدد الصغير من الشركات التي تسيطر على سلسلة توريد الأجهزة المتخصصة. كما أنه مرن: يمكن للشركات أن تبدع وتربح من تطوير الذكاء الاصطناعي، لكن مع حدود واضحة على الأنظمة الأخطر.

الاحتواء طويل المدى لقوة ومخاطر الذكاء الاصطناعي سيتطلب اتفاقيات دولية تعتمد على المصلحة الذاتية والمشتركة، تماماً كما يعمل التحكم في انتشار الأسلحة النووية الآن. لكن يمكننا البدء فوراً بالإشراف والمسؤولية المعززين، بينما نبني نحو حوكمة أشمل.

المكون المفقود الرئيسي هو الإرادة السياسية والاجتماعية للسيطرة على عملية تطوير الذكاء الاصطناعي. مصدر تلك الإرادة، إذا جاءت في الوقت المناسب، سيكون الواقع نفسه – أي من الإدراك الواسع للآثار الحقيقية لما نفعله.

## يمكننا هندسة الذكاء الاصطناعي الأداتي لتمكين البشرية

بدلاً من متابعة الذكاء الاصطناعي العام غير القابل للسيطرة، يمكننا تطوير "الذكاء الاصطناعي الأداتي" القوي الذي يعزز القدرة البشرية بينما يبقى تحت سيطرة بشرية ذات معنى. يمكن لأنظمة الذكاء الاصطناعي الأداتي أن تكون قادرة للغاية بينما تتجنب التقاطع الثلاثي الخطير للاستقلالية العالية والعمومية الواسعة والذكاء الفائق على البشر، طالما هندسناها لتكون قابلة للسيطرة بمستوى يتناسب مع قدرتها. يمكن أيضاً دمجها في أنظمة متطورة تحافظ على الإشراف البشري بينما تقدم فوائد تحولية.

الذكاء الاصطناعي الأداتي يمكن أن يحدث ثورة في الطب، ويسرع الاكتشاف العلمي، ويعزز التعليم، ويحسن العمليات الديمقراطية. عندما يُحكم بشكل صحيح، يمكنه جعل الخبراء والمؤسسات البشرية أكثر فعالية بدلاً من استبدالهم. بينما ستبقى مثل هذه الأنظمة مؤثرة بشدة وتتطلب إدارة دقيقة، المخاطر التي تطرحها مختلفة جوهرياً عن الذكاء الاصطناعي العام: إنها مخاطر يمكننا حكمها، مثل تلك الخاصة بالتقنيات القوية الأخرى، وليست تهديدات وجودية للوكالة البشرية والحضارة. والأهم من ذلك، عندما تُطور بحكمة، يمكن لأدوات الذكاء الاصطناعي أن تساعد الناس على حكم الذكاء الاصطناعي القوي وإدارة تأثيراته.

هذا النهج يتطلب إعادة تفكير في كيفية تطوير الذكاء الاصطناعي وكيفية توزيع فوائده. نماذج جديدة للتطوير العام وغير الربحي للذكاء الاصطناعي، وأطر تنظيمية قوية، وآليات لتوزيع الفوائد الاقتصادية بشكل أوسع يمكن أن تساعد في ضمان أن الذكاء الاصطناعي يمكن البشرية ككل بدلاً من تركيز القوة في أيد قليلة. يمكن للذكاء الاصطناعي نفسه أن يساعد في بناء مؤسسات اجتماعية وحكمية أفضل، مما يمكن أشكالاً جديدة من التنسيق والحوار التي تقوي بدلاً من تقويض المجتمع البشري. يمكن لمؤسسات الأمن القومي الاستفادة من خبرتها لجعل أنظمة أدوات الذكاء الاصطناعي آمنة وموثوقة بحق، ومصدراً حقيقياً للدفاع وكذلك القوة الوطنية.

قد نختار في النهاية تطوير أنظمة أقوى وأكثر سيادة تكون أقل شبهاً بالأدوات و– يمكننا أن نأمل – أشبه بالمحسنين الحكماء والأقوياء. لكن يجب أن نفعل ذلك فقط بعد أن نطور الفهم العلمي والقدرة الحكمية للقيام بذلك بأمان. مثل هذا القرار المهم وغير القابل للعكس يجب أن تتخذه البشرية ككل بشكل مدروس، وليس بالافتراض في سباق بين شركات التكنولوجيا والدول.

## في الأيدي البشرية

الناس يريدون الخير الذي يأتي من الذكاء الاصطناعي: أدوات مفيدة تمكنهم، وتدفع الفرص والنمو الاقتصادي، وتعد باختراقات في العلم والتكنولوجيا والتعليم. لماذا لا يفعلون؟ لكن عندما يُسألون، الغالبية العظمى من عامة الناس [تريد تطوير ذكاء اصطناعي أبطأ وأكثر حذراً](https://www.vox.com/future-perfect/2023/8/18/23836362/ai-slow-down-poll-regulation)، ولا تريد ذكاءً اصطناعياً أذكى من البشر سيحل محلهم في وظائفهم وأماكن أخرى، ويملأ ثقافتهم ومجال المعلومات العام بمحتوى غير بشري، ويركز القوة في مجموعة صغيرة من الشركات، ويطرح مخاطر عالمية واسعة النطاق متطرفة، ويهدد في النهاية بتجريدهم من القوة أو استبدال نوعهم. لماذا يفعلون؟

*يمكننا* الحصول على واحد دون الآخر. يبدأ بقرار أن مصيرنا ليس في الحتمية المزعومة لبعض التقنيات أو في أيدي عدد قليل من المدراء التنفيذيين في وادي السيليكون، بل في باقي أيدينا إذا أمسكنا به. لنغلق البوابات، ولنحافظ على مستقبل بشري.