# الفصل العاشر - الخيار أمامنا

لحماية مستقبلنا الإنساني، يجب أن نختار إغلاق البوابات أمام الذكاء الاصطناعي العام والذكاء الفائق.

آخر مرة شاركت فيها البشرية الأرض مع عقول أخرى تتحدث وتفكر وتبني التكنولوجيا وتحل المشكلات عامة الغرض كانت قبل 40,000 سنة في أوروبا العصر الجليدي. تلك العقول الأخرى انقرضت، كلياً أو جزئياً بسبب جهود عقولنا.

ونحن الآن ندخل مجدداً مثل هذا الوقت. أكثر منتجات ثقافتنا وتكنولوجيتنا تطوراً - مجموعات البيانات المبنية من مجمل المعلومات المشتركة على الإنترنت، ورقائق من 100 مليار عنصر هي أعقد التقنيات التي صنعناها على الإطلاق - يجري دمجها لإحياء أنظمة الذكاء الاصطناعي المتقدمة عامة الغرض.

يحرص مطورو هذه الأنظمة على تصويرها كأدوات لتمكين البشر. وحقاً يمكنها أن تكون كذلك. لكن لا تخطئوا الفهم: مسارنا الحالي هو بناء وكلاء رقميين موجهين نحو الأهداف ومتخذين للقرارات وذوي قدرات عامة أكثر قوة من أي وقت مضى. إنها تؤدي بالفعل بنفس جودة كثير من البشر في نطاق واسع من المهام الفكرية، وتتحسن بسرعة، وتساهم في تحسين نفسها.

ما لم يتغير هذا المسار أو يصطدم بعقبة غير متوقعة، فسنحصل قريباً - في سنوات وليس عقود - على ذكاءات رقمية خطيرة القوة. حتى في *أفضل* النتائج، ستجلب هذه منافع اقتصادية عظيمة (على الأقل لبعضنا) ولكن فقط مقابل اضطراب عميق في مجتمعنا، واستبدال البشر في معظم أهم الأشياء التي نقوم بها: هذه الآلات ستفكر نيابة عنا، وتخطط لنا، وتقرر لنا، وتبدع لنا. سنكون مدللين، لكن كأطفال مدللين. والأرجح أن هذه الأنظمة ستحل محل البشر في الأشياء الإيجابية *والسلبية* التي نقوم بها، بما في ذلك الاستغلال والتلاعب والعنف والحرب. هل يمكننا البقاء أمام نسخ مفرطة التسارع بالذكاء الاصطناعي من هذه؟ أخيراً، من المعقول جداً ألا تسير الأمور على ما يرام إطلاقاً: أن نُستبدل نسبياً قريباً ليس فقط فيما نفعل، بل فيما *نحن عليه*، كمعماريين للحضارة والمستقبل. اسألوا إنسان النياندرتال كيف يسير ذلك. ربما قدمنا لهم حليات إضافية لفترة كذلك.

*لسنا مضطرين لفعل هذا.* لدينا ذكاء اصطناعي ينافس البشر، ولا حاجة لبناء ذكاء اصطناعي *لا يمكننا* منافسته. يمكننا بناء أدوات ذكاء اصطناعي مذهلة دون بناء نوع خلف. فكرة أن الذكاء الاصطناعي العام والذكاء الفائق حتميان هي *خيار يتقنع بقناع القدر*.

بفرض بعض الحدود الصارمة والعالمية، يمكننا الحفاظ على القدرة العامة للذكاء الاصطناعي عند مستوى بشري تقريباً بينما نجني فوائد قدرة أجهزة الكمبيوتر على معالجة البيانات بطرق لا نستطيعها، وأتمتة المهام التي لا يريد أحد منا القيام بها. ستظل هذه تطرح مخاطر كثيرة، لكن إذا صُممت وأُديرت جيداً، ستكون نعمة هائلة للبشرية، من الطب إلى البحث إلى المنتجات الاستهلاكية.

فرض الحدود سيتطلب تعاوناً دولياً، لكن أقل مما قد يظن المرء، وهذه الحدود ستترك مجالاً واسعاً لصناعة ضخمة للذكاء الاصطناعي وأجهزته تركز على التطبيقات التي تعزز رفاهية الإنسان، بدلاً من السعي المحض وراء القوة. وإذا قررنا، بضمانات أمان قوية وبعد حوار عالمي هادف، المضي أبعد، فهذا الخيار يظل متاحاً لنا للسعي وراءه.

يجب على البشرية أن *تختار* إغلاق البوابات أمام الذكاء الاصطناعي العام والذكاء الفائق.

للحفاظ على المستقبل إنسانياً.

## ملاحظة من المؤلف

شكراً لكم على الوقت الذي خصصتموه لاستكشاف هذا الموضوع معنا.

كتبت هذا المقال لأنني كعالم أشعر بأهمية قول الحقيقة دون تجميل، ولأنني كإنسان أشعر بأنه من الحاسم أن نتصرف بسرعة وحزم لمواجهة قضية تغير العالم: تطوير أنظمة ذكاء اصطناعي أذكى من البشر.

إذا أردنا الاستجابة لهذا الوضع المذهل بحكمة، يجب أن نكون مستعدين لفحص السردية السائدة نقدياً بأن الذكاء الاصطناعي العام والذكاء الفائق "يجب" بناؤهما لضمان مصالحنا، أو أنهما "حتميان" ولا يمكن إيقافهما. هذه السرديات تتركنا عاجزين، غير قادرين على رؤية المسارات البديلة أمامنا.

آمل أن تنضموا إليّ في الدعوة للحذر في وجه التهور، والشجاعة في وجه الجشع.

آمل أن تنضموا إليّ في الدعوة لمستقبل إنساني.

*– أنتوني*

![Anthony Aguirre signature](https://keepthefuturehuman.ai/essay/_next/image?url=https%3A%2F%2Fkeepthefuturehuman.ai%2Fwp-content%2Fuploads%2F2025%2F02%2FAnthony-Aguirre-signature-300x84.png&w=3840&q=75)