## Summary

This essay by Anthony Aguirre argues against the current trajectory toward Artificial General Intelligence (AGI) and superintelligence, proposing instead that humanity should "close the gates" to these technologies and focus on developing controllable AI tools. The document is structured as a comprehensive 10-chapter analysis with appendices, beginning with an executive summary and progressing through technical explanations of AI systems, definitions of AGI and superintelligence, analysis of current progress and driving forces, examination of risks, and finally presenting concrete policy proposals.

The core argument centers on the "triple intersection" of Autonomy, Generality, and Intelligence (A-G-I) as the danger zone that humanity should avoid. Aguirre contends that while current AI systems are already highly capable, crossing into full AGI would lead to loss of human control, massive societal disruption, potential warfare between nations, and ultimately the end of human civilization as we know it. The essay proposes specific governance mechanisms including compute caps, enhanced liability frameworks, and safety regulations to prevent this outcome while still allowing beneficial AI development. The overarching theme is that building superintelligent AGI is a choice, not an inevitability, and humanity should choose to "keep the future human."

## Glossary

- **Source Term**: Artificial General Intelligence (AGI)
- **Target Translation**: الذكاء الاصطناعي العام
- **Context**: Central concept throughout the document referring to AI systems that match or exceed human capabilities across all cognitive domains
- **Notes**: This is an established term in Arabic AI discourse; translation maintains technical precision

- **Source Term**: Superintelligence
- **Target Translation**: الذكاء الفائق
- **Context**: AI systems that dramatically exceed human intelligence across all domains
- **Notes**: Standard translation in Arabic technical literature; clearly distinguishes from regular AI

- **Source Term**: Neural networks
- **Target Translation**: الشبكات العصبية
- **Context**: The mathematical/computational structures underlying modern AI systems
- **Notes**: Well-established technical term in Arabic; no need for alternative translation

- **Source Term**: Training
- **Target Translation**: التدريب
- **Context**: The process of teaching AI systems by adjusting their parameters based on data
- **Notes**: Direct translation works well and is commonly used in Arabic AI contexts

- **Source Term**: Inference
- **Target Translation**: الاستنتاج
- **Context**: The process of an AI system generating outputs based on its training
- **Notes**: Captures the meaning of drawing conclusions/making predictions from learned patterns

- **Source Term**: Alignment
- **Target Translation**: المواءمة
- **Context**: The challenge of ensuring AI systems do what humans want them to do
- **Notes**: Conveys the concept of bringing AI behavior in line with human values and intentions

- **Source Term**: Compute/Computation
- **Target Translation**: القوة الحاسوبية / الحوسبة
- **Context**: The computational resources (processing power) required for AI training and operation
- **Notes**: "القوة الحاسوبية" for "compute" as a resource; "الحوسبة" for "computation" as a process

- **Source Term**: FLOP (Floating Point Operations)
- **Target Translation**: FLOP
- **Context**: Technical measure of computational work, used throughout for measuring AI system capabilities
- **Notes**: Keep as English acronym since it's a precise technical unit commonly used as-is in Arabic technical contexts

- **Source Term**: Tool AI
- **Target Translation**: الذكاء الاصطناعي الأداتي
- **Context**: The author's proposed alternative to AGI - AI systems that remain controllable tools
- **Notes**: Emphasizes the instrumental/tool-like nature that maintains human control

- **Source Term**: Autonomous agents
- **Target Translation**: الوكلاء المستقلون
- **Context**: AI systems that can take actions independently with varying levels of human oversight
- **Notes**: "وكلاء" captures the concept of entities acting on behalf of others; "مستقلون" indicates independence

- **Source Term**: Gates (closing the Gates)
- **Target Translation**: البوابات (إغلاق البوابات)
- **Context**: The author's central metaphor for preventing the development of dangerous AGI
- **Notes**: Maintains the metaphorical power while being clear in Arabic; central to the essay's thesis

- **Source Term**: Scaffolding
- **Target Translation**: السقالة
- **Context**: Software structures that connect and coordinate multiple AI components
- **Notes**: Architectural metaphor that works well in Arabic; conveys the support structure concept

- **Source Term**: Chain-of-thought
- **Target Translation**: سلسلة التفكير
- **Context**: AI technique where systems work through problems step-by-step
- **Notes**: Literal translation that clearly conveys the sequential reasoning process

- **Source Term**: Liability (strict liability)
- **Target Translation**: المسؤولية القانونية (المسؤولية المطلقة)
- **Context**: Legal framework proposed for holding AI developers accountable for harms
- **Notes**: Standard legal terminology; "مطلقة" indicates liability regardless of fault

- **Source Term**: Multimodal models
- **Target Translation**: النماذج متعددة الوسائط
- **Context**: AI systems that can process multiple types of data (text, images, audio)
- **Notes**: Standard technical translation that clearly indicates multiple input/output modalities