# Kapitel 1 - Indledning

Hvordan vi vil reagere på udsigten til AI, der er klogere end mennesker, er det mest presserende spørgsmål i vores tid. Dette essay giver en vej fremad.

Vi befinder os måske ved afslutningen af den menneskelige æra.

Noget er begyndt i løbet af de seneste ti år, som er unikt i vores arts historie. Konsekvenserne vil i høj grad afgøre menneskehedens fremtid. Fra omkring 2015 er forskere lykkedes med at udvikle *snæver* kunstig intelligens (AI) – systemer der kan vinde i spil som Go, genkende billeder og tale, og så videre, bedre end noget menneske.[^1]

Dette er en fantastisk succes, og det giver ekstrem nyttige systemer og produkter, som vil styrke menneskeheden. Men snæver kunstig intelligens har aldrig været feltets egentlige mål. I stedet har formålet været at skabe AI-systemer til *generel* anvendelse, især dem der ofte kaldes "AGI (Artificial General Intelligence)" eller "superintelligens", som samtidigt er lige så gode eller bedre end mennesker på tværs af næsten *alle* opgaver, præcis som AI nu er overmenneskelig til Go, skak, poker, drone-racing, osv. Dette er det erklærede mål for mange store AI-virksomheder.[^2]

*Disse bestræbelser lykkes også.* Generelle AI-systemer som ChatGPT, Gemini, Llama, Grok, Claude og Deepseek, baseret på massive beregninger og bjerge af data, har nået samme niveau som typiske mennesker på tværs af en bred vifte af opgaver, og matcher endda menneskelige eksperter på nogle områder. Nu kapløber AI-ingeniører hos nogle af de største teknologivirksomheder om at skubbe disse gigantiske eksperimenter i maskinelligens til de næste niveauer, hvor de matcher og derefter overgår hele spektret af menneskelige evner, ekspertise og autonomi.

*Dette er umiddelbart forestående.* I løbet af de sidste ti år er eksperternes estimater for, hvor lang tid dette vil tage – hvis vi fortsætter vores nuværende kurs – faldet fra årtier (eller århundreder) til et enkelt antal år.

Det har også epokegørende betydning og transcendent risiko. Tilhængere af AGI ser det som en positiv transformation, der vil løse videnskabelige problemer, helbrede sygdomme, udvikle nye teknologier og automatisere slidsomme opgaver. Og AI kunne bestemt hjælpe med at opnå alle disse ting – det gør det faktisk allerede. Men gennem årtier har mange omhyggelige tænkere, fra Alan Turing til Stephen Hawking til nutidens Geoffrey Hinton og Yoshua Bengio [^3] udsendt en skarp advarsel: at bygge virkelig klogere-end-menneskelig, generel, autonom AI vil som minimum fuldstændigt og uigenkaldeligt vælte samfundet, og som maksimum resultere i menneskelig udryddelse.[^4]

Superintelligent AI nærmer sig hurtigt på vores nuværende vej, men er langt fra uundgåelig. Dette essay er et udvidet argument for, hvorfor og hvordan vi bør *lukke Portene* til denne nærmende umenneskelige fremtid, og hvad vi i stedet bør gøre.


[^1]: Dette [diagram](https://time.com/6300942/ai-progress-charts/) viser et sæt opgaver; mange lignende kurver kunne tilføjes til denne graf. Disse hurtige fremskridt inden for snæver AI har overrasket selv eksperter på området, hvor benchmarks er blevet overgået år før forudsigelserne.

[^2]: Deepmind, OpenAI, Anthropic og X.ai blev alle grundlagt med det specifikke mål at udvikle AGI. For eksempel erklærer OpenAI's charter eksplicit sit mål som at udvikle "artificial general intelligence der gavner hele menneskeheden," mens DeepMinds mission er "at løse intelligens, og derefter bruge det til at løse alt andet." Meta, Microsoft og andre forfølger nu væsentligt lignende veje. Meta har sagt, at det [planlægger at udvikle AGI og frigive det åbent.](https://www.forbes.com/sites/johnkoetsier/2024/01/18/zuckerberg-on-ai-meta-building-agi-for-everyone-and-open-sourcing-it/)

[^3]: Hinton og Bengio er to af de mest citerede AI-forskere, har begge vundet AI-feltets Nobel, Turing-prisen, og Hinton har vundet en Nobelpris (i fysik) oven i købet.

[^4]: At bygge noget med denne risiko, under kommercielle incitamenter og næsten nul statsligt tilsyn, er fuldstændigt uden fortilfælde. Der er ikke engang kontrovers om risikoen blandt dem, der bygger det! Lederne af Deepmind, OpenAI og Anthropic, blandt mange andre eksperter, har alle bogstaveligt talt underskrevet en [erklæring](https://www.safe.ai/work/statement-on-ai-risk) om, at avanceret AI udgør en *udryddelsesrisiko for menneskeheden.* Alarmklokkerne kunne ikke ringe hårdere, og man kan kun konkludere, at dem der ignorerer dem, simpelthen ikke tager AGI og superintelligens seriøst. Et mål med dette essay er at hjælpe dem med at forstå, hvorfor de burde.