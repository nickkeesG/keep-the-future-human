# Kapitel 5 - På tærsklen

Vejen fra nutidens AI-systemer til fuldstændig udviklede AGI virker chokerende kort og forudsigelig.

De seneste ti år har budt på dramatiske fremskridt inden for AI drevet af enorme [beregnings-](https://epoch.ai/blog/training-compute-of-frontier-ai-models-grows-by-4-5x-per-year), menneskelige og [finansielle](https://arxiv.org/abs/2405.21015) ressourcer. Mange snævre AI-anvendelser klarer sig bedre end mennesker på deres tildelte opgaver og er bestemt langt hurtigere og billigere.[^1] Og der findes også snævre overmenneskelige agenter, som kan slå alle mennesker i spil inden for begrænsede domæner som [Go](https://www.nature.com/articles/nature16961), [skak](https://arxiv.org/abs/1712.01815) og [poker](https://www.deepstack.ai/), såvel som mere [generelle agenter](https://deepmind.google/discover/blog/a-generalist-agent/), der kan planlægge og udføre handlinger i forenklede simulerede miljøer lige så effektivt som mennesker.

Mest fremtrædende er nutidens generelle AI-systemer fra OpenAI/Microsoft, Google/Deepmind, Anthropic/Amazon, Facebook/Meta, X.ai/Tesla og andre[^2] opstået siden begyndelsen af 2023 og støt (om end ujævnt) øget deres kapaciteter siden da. Alle disse er blevet skabt via token-forudsigelse på enorme tekst- og multimediedatasæt kombineret med omfattende forstærkende feedback fra mennesker og andre AI-systemer. Nogle af dem inkluderer også omfattende værktøjs- og stilladseringssystemer.

## Styrker og svagheder ved nuværende generelle systemer

Disse systemer klarer sig godt på et stadig bredere spektrum af tests designet til at måle intelligens og ekspertise, med fremskridt der har overrasket selv eksperter på området:

- Da GPT-4 først blev frigivet, [matchede eller oversteg den typisk menneskelig præstation](https://arxiv.org/abs/2303.08774) på standardiserede akademiske tests inklusive SAT, GRE, optagelsesprøver og advokateksamen. Nyere modeller klarer sig sandsynligvis betydeligt bedre, selvom resultaterne ikke er offentligt tilgængelige.
- Turing-testen – længe betragtet som et nøglebenchmark for "sand" AI – bestås nu rutinemæssigt i nogle former af moderne sprogmodeller, både uformelt og i [formelle studier](https://arxiv.org/abs/2405.08007).[^3]
- På det omfattende MMLU benchmark, der spænder over 57 akademiske fag, [opnår nyere modeller ekspertniveauresultater](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu) (∼90%)[^4]
- Teknisk ekspertise har udviklet sig dramatisk: GPQA benchmarket for fysik på kandidatniveau så [præstationen springe](https://epoch.ai/data/ai-benchmarking-dashboard) fra næsten tilfældige gæt (GPT-4, 2022) til ekspertniveau (o1-preview, 2024).
- Selv tests specifikt designet til at være AI-resistente falder: OpenAIs O3 [løser angiveligt](https://www.nextbigfuture.com/2024/12/openai-releases-o3-model-with-high-performance-and-high-cost.html) ARC-AGI abstrakte problemløsningsbenchmark på menneskeniveau, opnår topekspert-programmeringsydelse og scorer 25% på Epoch AIs "frontier math"-problemer designet til at udfordre elitematematikere.[^5]
- Tendensen er så klar, at MMLUs udvikler nu har skabt ["Menneskehedens Sidste Eksamen"](https://agi.safe.ai/) – et ildevarslende navn, der reflekterer muligheden for, at AI snart vil overgå menneskelig præstation på enhver meningsfuld test. På skrivende tidspunkt er der påstande om AI-systemer, der opnår 27% (ifølge [Sam Altman](https://x.com/sama/status/1886220281565381078)) og 35% (ifølge [dette papir](https://arxiv.org/abs/2502.09955)) på denne ekstremt svære eksamen. Det er højst usandsynligt, at nogen individuel person kunne gøre det samme.

På trods af disse imponerende tal (og deres åbenlyse intelligens, når man interagerer med dem)[^6] er der mange ting, som (i det mindste de frigivne versioner af) disse neurale netværk *ikke kan* gøre. I øjeblikket er de fleste ikke-kropslige – eksisterer kun på servere – og behandler højst tekst, lyd og stilbilleder (men ikke video). Afgørende er det, at de fleste ikke kan udføre komplekse planlagte aktiviteter, der kræver høj nøjagtighed.[^7] Og der er en række andre kvaliteter, der er stærke i menneskelig kognition på højt niveau, som i øjeblikket er lave i frigivne AI-systemer.

Den følgende tabel opremser en række af disse baseret på AI-systemer fra midten af 2024 som GPT-4o, Claude 3.5 Sonnet og Google Gemini 1.5.[^8] Nøglespørgsmålet for hvor hurtigt generel AI vil blive mere kraftfuld er: i hvilken grad vil det bare at gøre *mere af det samme* producere resultater, versus tilføjelse af yderligere men *kendte* teknikker, versus udvikling eller implementering af *virkelig nye* AI-forskningsretninger. Mine egne forudsigelser for dette er givet i tabellen med hensyn til hvor sandsynligt hvert af disse scenarier er til at få den kapacitet til og ud over menneskeniveau.

<table><tbody><tr><th>Kapacitet</th><th>Beskrivelse af kapacitet</th><th>Status/prognose</th><th>Skalering/kendt/ny</th></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td colspan="4"><em>Centrale Kognitive Kapaciteter</em></td></tr><tr><td>Ræsonnement</td><td>Mennesker kan udføre nøjagtig, flertrinsforbigående, følge regler og kontrollere nøjagtighed.</td><td>Dramatiske nylige fremskridt ved brug af udvidet tankegang og gentræning</td><td>95/5/5</td></tr><tr><td>Planlægning</td><td>Mennesker udviser langsigtet og hierarkisk planlægning.</td><td>Forbedres med skala; kan styrkes kraftigt ved hjælp af stilladsering og bedre træningsmetoder.</td><td>10/85/5</td></tr><tr><td>Sandhedsforankring</td><td>GPAIer konfabulerer uforankret information for at tilfredsstille forespørgsler.</td><td>Forbedres med skala; kalibreringsdata tilgængelige i modellen; kan kontrolleres/forbedres via stilladsering.</td><td>30/65/5</td></tr><tr><td>Fleksibel problemløsning</td><td>Mennesker kan genkende nye mønstre og opfinde nye løsninger til komplekse problemer; nuværende ML-modeller kæmper.</td><td>Forbedres med skala men svagt; kan løses med neurosymbolske eller generaliserede "søge"-teknikker.</td><td>15/75/10</td></tr><tr><td colspan="4"><em>Læring og Viden</em></td></tr><tr><td>Læring & hukommelse</td><td>Mennesker har arbejds-, korttids- og langtidshukommelse, som alle er dynamiske og indbyrdes relaterede.</td><td>Alle modeller lærer under træning; GPAIer lærer inden for kontekstvindue og under finjustering; "kontinuert læring" og andre teknikker eksisterer men endnu ikke integreret i store GPAIer.</td><td>5/80/15</td></tr><tr><td>Abstraktion & rekursion</td><td>Mennesker kan kortlægge og overføre relationssæt til mere abstrakte for ræsonnement og manipulation, inklusive rekursivt "meta" ræsonnement.</td><td>Forbedres svagt med skala; kunne opstå i neurosymbolske systemer.</td><td>30/50/20</td></tr><tr><td>Verdensmodel(ler)</td><td>Mennesker har og opdaterer kontinuerligt en forudsigelig verdensmodel, inden for hvilken de kan løse problemer og foretage fysisk ræsonnement</td><td>Forbedres med skala; opdatering knyttet til læring; GPAIer svage i virkelighedsforudsigelse.</td><td>20/50/30</td></tr><tr><td colspan="4"><em>Selv og Agens</em></td></tr><tr><td>Agens</td><td>Mennesker kan handle for at forfølge mål baseret på planlægning/forudsigelse.</td><td>Mange ML-systemer er agentiske; LLMer kan gøres til agenter via wrappers.</td><td>5/90/5</td></tr><tr><td>Selvledelse</td><td>Mennesker udvikler og forfølger deres egne mål med internt genereret motivation og drivkraft.</td><td>Består stort set af agens plus originalitet; vil sandsynligvis opstå i komplekse agentiske systemer med abstrakte mål.</td><td>40/45/15</td></tr><tr><td>Selvreference</td><td>Mennesker forstår og ræsonnerer om sig selv som situeret i et miljø/kontekst.</td><td>Forbedres med skala og kunne forøges med træningsbelønning.</td><td>70/15/15</td></tr><tr><td>Selvbevidsthed</td><td>Mennesker har viden om og kan ræsonnere angående deres egne tanker og mentale tilstande.</td><td>Eksisterer på en måde i GPAIer, som nok kan bestå den klassiske "spejltest" for selvbevidsthed. Kan forbedres med stilladsering; men uklart om dette er nok.</td><td>20/55/25</td></tr><tr><td colspan="4"><em>Interface og Miljø</em></td></tr><tr><td>Kropsliggjort intelligens</td><td>Mennesker forstår og interagerer aktivt med deres virkelige miljø.</td><td>Forstærkende læring fungerer godt i simulerede og virkelige (robotiske) miljøer og kan integreres i multimodale transformere.</td><td>5/85/10</td></tr><tr><td>Multi-sans behandling</td><td>Mennesker integrerer og behandler visuelle, auditive og andre sensoriske strømme i realtid.</td><td>Træning i flere modaliteter synes at "bare virke" og forbedres med skala. Realtids videobehandling er vanskelig, men f.eks. selvkørende systemer forbedres hurtigt.</td><td>30/60/10</td></tr><tr><td colspan="4"><em>Kapaciteter af Højere Orden</em></td></tr><tr><td>Originalitet</td><td>Nuværende ML-modeller er kreative i at transformere og kombinere eksisterende ideer/værker, men mennesker kan bygge nye rammer og strukturer, nogle gange knyttet til deres identitet.</td><td>Kan være svært at skelne fra "kreativitet," som måske skalerer ind i den; kan opstå fra kreativitet plus selvbevidsthed.</td><td>50/40/10</td></tr><tr><td>Følsomhed</td><td>Mennesker oplever qualia; disse kan være af positiv, negativ eller neutral valens; det er "som noget" at være et menneske.</td><td>Meget vanskeligt og filosofisk problematisk at afgøre, om et givet system har dette.</td><td>5/10/85</td></tr></tbody></table>

Nøglekapaciteter i øjeblikket under menneskeligt ekspertniveau i moderne GPAI-systemer, grupperet efter type. Den tredje kolonne opsummerer nuværende status. Sidste kolonne viser forudsagt sandsynlighed (%) for, at menneskeniveau vil opnås gennem: skalering af nuværende teknikker / kombination med kendte teknikker / udvikling af nye teknikker. Disse kapaciteter er ikke uafhængige, og stigning i en går typisk sammen med stigninger i andre. Bemærk at ikke alle (især følsomhed) er nødvendige for AI-systemer, der kan fremme AI-udvikling, hvilket fremhæver muligheden for kraftfuld men ikke-følsom AI.

At opdele det der "mangler" på denne måde gør det ret klart, at vi er godt på vej mod bredt overmenneskelig intelligens ved at skalere eksisterende eller kendte teknikker.[^9]

Der kunne stadig være overraskelser. Selv hvis vi ser bort fra "følsomhed," kunne der være nogle af de oplistede centrale kognitive kapaciteter, der virkelig ikke kan gøres med nuværende teknikker og kræver nye. Men overvej dette. Den nuværende indsats, der ydes af mange af verdens største virksomheder, svarer til flere gange Apollo-projektets og titusinder af gange Manhattan-projektets udgifter,[^10] og ansætter tusinder af de allerførende tekniske folk til uhørte lønninger. Dynamikken fra de seneste år har nu bragt mere menneskelig intellektuel ildkraft til dette (med AI nu tilføjet) end nogen bestræbelse i historien. Vi bør ikke satse på fiasko.

## Det store mål: generaliserede autonome agenter

Udviklingen af generel AI gennem de seneste år har fokuseret på at skabe generel og kraftfuld men værktøjsagtig AI: den fungerer primært som en (ret) loyal assistent og tager generelt ikke handlinger på egen hånd. Dette er delvis ved design, men hovedsagelig fordi disse systemer simpelthen ikke har været kompetente nok til de relevante færdigheder til at blive betroet komplekse handlinger.[^11]

AI-virksomheder og forskere [skifter dog i stigende grad fokus](https://www.axios.com/2025/01/23/davos-2025-ai-agents) mod *autonome* ekspertniveau-generelle-formål agenter.[^12] Dette ville tillade systemerne at agere mere som en menneskelig assistent, som brugeren kan delegere virkelige handlinger til.[^13] Hvad vil det kræve? En række af kapaciteterne i "hvad der mangler"-tabellen er implicerede, inklusive stærk sandhedsforankring, læring og hukommelse, abstraktion og rekursion samt verdensmodellering (for intelligens), planlægning, agens, originalitet, selvledelse, selvreference og selvbevidsthed (for autonomi), og multi-sans-behandling, kropsliggjort intelligens og fleksibel problemløsning (for generalitet).[^14]

Dette triple-kryds af høj autonomi (uafhængighed af handling), høj generalitet (omfang og opgavebredde) og høj intelligens (kompetence til kognitive opgaver) er i øjeblikket unikt for mennesker. Det er implicit, hvad mange sandsynligvis har i tankerne, når de tænker på AGI – både med hensyn til dens værdi såvel som dens risici.

Dette giver en anden måde at definere A-G-I som ***A*** utonom- ***G*** enerel- ***I*** ntelligens, og vi vil se, at dette triple kryds giver en meget værdifuld linse for høj-kapacitets systemer både i forståelsen af deres risici og belønninger og i styring af AI.

![](https://keepthefuturehuman.ai/essay/_next/image?url=https%3A%2F%2Fkeepthefuturehuman.ai%2Fwp-content%2Fuploads%2F2025%2F02%2FAGI-Venn-Diagram-Simple-1024x1024.png&w=3840&q=75) Den transformative A-G-I kraft- og risikozone opstår fra krydsfeltet mellem tre nøgleegenskaber: høj Autonomi, høj Intelligens til opgaver og høj Generalitet.

## AI-(selv-)forbedrings-cyklusen

En sidste afgørende faktor i forståelsen af AI-fremskridt er AIs unikke teknologiske feedback-loop. I udviklingen af AI bringer succes – i både demonstrerede systemer og deployerede produkter – yderligere investering, talent og konkurrence, og vi befinder os i øjeblikket midt i en enorm AI-hype-plus-virkelighed feedback-loop, der driver hundredvis af milliarder eller endda billioner af dollars i investering.

Denne type feedback-cyklus kunne ske med enhver teknologi, og vi har set det i mange, hvor markedssucces avler investering, som avler forbedring og bedre markedssucces. Men AI-udvikling går længere, idet AI-systemer nu hjælper med at udvikle nye og mere kraftfulde AI-systemer.[^15] Vi kan tænke på denne feedback-loop i fem stadier, hver med en kortere tidsskala end den sidste, som vist i tabellen.

*AI-forbedrings-cyklusen opererer på tværs af flere tidsskalaer, hvor hvert stadie potentielt kan accelerere efterfølgende stadier. Tidligere stadier er godt i gang, mens senere stadier forbliver spekulative men kunne forløbe meget hurtigt, når de først er låst op.*

Flere af disse stadier er allerede i gang, og et par er klart ved at komme i gang. Det sidste stadie, hvor AI-systemer autonomt forbedrer sig selv, har været en fast bestanddel af litteraturen om risikoen ved meget kraftfulde AI-systemer, og af god grund.[^16] Men det er vigtigt at bemærke, at det blot er den mest drastiske form af en feedback-cyklus, der allerede er begyndt og kunne føre til flere overraskelser i den hurtige udvikling af teknologien.


[^1]: Du bruger meget mere af denne AI, end du sandsynligvis tror, til at drive taleoprettelse og -genkendelse, billedbehandling, nyhedsfeed-algoritmer osv.

[^2]: Mens forholdet mellem disse par af virksomheder er ret komplekse og nuancerede, har jeg eksplicit opført dem for at indikere både den enorme samlede markedsværdi af firmaer, der nu er engageret i AI-udvikling, og også at selv bag "mindre" virksomheder som Anthropic sidder enormt dybe lommer via investeringer og større partnerskabsaftaler.

[^3]: Det er blevet fashionabelt at nedgøre Turing-testen, men den er ret kraftfuld og generel. I svage versioner indikerer den, om typiske mennesker, der interagerer med en AI (som er trænet til at agere menneskeligt) på typiske måder i korte perioder, kan fortælle, om det er en AI. Det kan de ikke. For det andet kan en stærkt modstridende Turing-test undersøge grundlæggende ethvert element af menneskelig kapacitet og intelligens – ved f.eks. at sammenligne et AI-system med en menneskelig ekspert, evalueret af andre menneskelige eksperter. Der er en forstand på hvilken, at meget af AI-evaluering er en generaliseret form for Turing-test.

[^4]: Dette er per domæne – intet menneske kunne plausibelt opnå sådanne scores på tværs af alle fag samtidigt.

[^5]: Dette er problemer, der ville tage selv fremragende matematikere betydelig tid at løse, hvis de overhovedet kunne løse dem.

[^6]: Hvis du er skeptisk af sind, bevar din skepsis men prøv virkelig de mest aktuelle modeller, såvel som prøv selv nogle af de testspørgsmål, de kan bestå. Som fysilkprofessor ville jeg forudsige med næsten sikkerhed, at f.eks. topmodellerne ville bestå kandidateksamen i vores afdeling.

[^7]: Dette og andre svagheder som konfabulation har bremset markedsadoptionen og ført til et gab mellem opfattede og påståede kapaciteter (som også skal ses gennem linsen af intens markedskonkurrence og behovet for at tiltrække investering). Dette har forvirret både offentligheden og politiske beslutningstagere om den faktiske tilstand af AI-fremskridt. Mens det måske ikke matcher hypen, er fremskridtet meget reelt.

[^8]: Det store fremskridt siden da har været udviklingen af systemer trænet til topkvalitets ræsonnement, der udnytter mere beregning under inferens og større forstærkende læring. Fordi disse modeller er nye og deres kapaciteter mindre testede, har jeg ikke helt omdannet denne tabel undtagen for "ræsonnement," som jeg betragter som grundlæggende løst. Men jeg har opdateret forudsigelser baseret på erfarne og rapporterede kapaciteter af disse systemer.

[^9]: Tidligere bølger af AI-optimisme i 1960erne og 1980erne endte i "AI-vintre," når lovede kapaciteter ikke materialiserede sig. Den nuværende bølge adskiller sig dog fundamentalt ved at have opnået overmenneskelig præstation i mange domæner, understøttet af massive beregningsressourcer og kommerciel succes.

[^10]: Det fulde Apollo-projekt [kostede omkring 250 milliarder USD i 2020-dollars](https://www.planetary.org/space-policy/cost-of-apollo), og Manhattan-projektet [mindre end en tiendedel deraf](https://www.brookings.edu/the-costs-of-the-manhattan-project/). Goldman Sachs [projekterer en billion dollars udgifter bare på AI-datacentre](https://www.datacenterdynamics.com/en/news/goldman-sachs-1tn-to-be-spent-on-ai-data-centers-chips-and-utility-upgrades-with-little-to-show-for-it-so-far/) over de næste år.

[^11]: Selvom mennesker laver masser af fejl, undervurderer vi bare hvor pålidelige vi kan være! Fordi sandsynligheder multipliceres, kræver en opgave der kræver 20 trin at udføre korrekt, at hvert trin er 97% pålideligt bare for at få det gjort rigtigt halvdelen af tiden. Vi laver sådanne opgaver hele tiden.

[^12]: Et stærkt skridt i denne retning er for ganske nylig blevet taget med OpenAIs ["Deep Research"](https://openai.com/index/introducing-deep-research/) assistent, der autonomt udfører generel forskning, beskrevet som "en ny agentisk kapacitet, der udfører flertrinsforskning på internettet for komplekse opgaver."

[^13]: Ting som at udfylde det besværlige PDF-formular, booke flyvninger osv. Men med en PhD i 20 fag! Så også: skrive det speciale for dig, forhandle den kontrakt for dig, bevise det teorem for dig, skabe den reklamekampagne for dig osv. Hvad gør *du*? Du fortæller det, hvad det skal gøre, selvfølgelig.

[^14]: Bemærk at følsomhed *ikke* er klart påkrævet, og at AI i dette triple-kryds ikke nødvendigvis indebærer det.

[^15]: Den nærmeste analogi her er måske chip-teknologi, hvor udvikling har opretholdt Moores lov i årtier, da computerteknologier hjælper folk med at designe næste generation af chip-teknologi. Men AI vil være langt mere direkte.

[^16]: Det er vigtigt at lade det synke ind et øjeblik, at AI kunne – snart – forbedre sig selv på en tidsskala af dage eller uger. Eller mindre. Husk dette, når nogen fortæller dig, at en AI-kapacitet bestemt er langt væk.