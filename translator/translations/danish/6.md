# Kapitel 6 - Kapløbet om AGI

Hvad er drivkræfterne bag kapløbet om at bygge AGI, både for virksomheder og lande?

De seneste hurtige fremskridt inden for AI har både resulteret fra og skabt et ekstraordinært niveau af opmærksomhed og investering. Dette er delvist drevet af succes i AI-udvikling, men der foregår mere. Hvorfor kappes nogle af Jordens største virksomheder, og endda lande, om at bygge ikke bare AI, men AGI og superintelligens?

## Hvad har drevet AI-forskning mod menneskelignende AI

Indtil de seneste fem år eller deromkring har AI hovedsageligt været et akademisk og videnskabeligt forskningsproblem, og derfor primært drevet af nysgerrighed og trangen til at forstå intelligens og hvordan man skaber den på et nyt substrat.

I denne fase var der relativt lidt opmærksomhed på fordelene eller farerne ved AI blandt de fleste forskere. Når man spurgte, hvorfor AI skulle udvikles, kunne et almindeligt svar være at opstille, noget vagt, problemer som AI kunne hjælpe med: nye lægemidler, nye materialer, ny videnskab, smartere processer, og generelt forbedre tingene for mennesker.[^1]

Dette er beundringsværdige mål![^2] Selvom vi kan og vil stille spørgsmålstegn ved, om AGI – snarere end AI generelt – er nødvendig for disse mål, viser de den idealisme, som mange AI-forskere startede med.

I løbet af de seneste fem år er AI dog blevet transformeret fra et relativt rent forskningsfelt til meget mere et ingeniør- og produktfelt, primært drevet af nogle af verdens største virksomheder.[^3] Forskere er, selvom de stadig er relevante, ikke længere dem, der styrer processen.

## Hvorfor prøver virksomheder at bygge AGI?

Så hvorfor hælder gigantiske selskaber (og endnu mere investorer) enorme ressourcer i at bygge AGI? Der er to drivkræfter, som de fleste virksomheder er ganske ærlige omkring: de ser AI som drivere af produktivitet for samfundet og af profit for dem selv. Fordi generel AI per definition er generel, er der en kæmpe gevinst: i stedet for at vælge en sektor, hvor man skal skabe produkter og tjenester, kan man prøve *alle på én gang.* Store teknologivirksomheder er vokset enorme ved at producere digitale varer og tjenester, og i det mindste nogle ledere ser sikkert AI som blot det næste skridt i at levere dem ordentligt, med risici og fordele der udvider, men gentager, dem som søgemaskiner, sociale medier, bærbare computere, telefoner osv. giver.

Men hvorfor AGI? Der er et meget simpelt svar på dette, som de fleste virksomheder og investorer skyr at diskutere offentligt.[^4]

Det er, at AGI direkte, en-til-en, kan *erstatte arbejdere.*

Ikke supplere, ikke styrke, ikke gøre mere produktive. Ikke engang *fortrænge.* Alt dette kan og vil blive gjort af ikke-AGI. AGI er specifikt det, der fuldt ud kan *erstatte* tankearbejdere (og med robotteknologi mange fysiske også.) Som støtte for dette synspunkt behøver man ikke se længere end til OpenAI's [(offentligt erklærede) definition](https://openai.com/our-structure/) af AGI, som er "et højt autonomt system, der overgår mennesker i det meste økonomisk værdifulde arbejde."

Gevinsten her (for virksomheder!) er enorm. Lønomkostninger udgør en væsentlig procentdel af verdens ∼100 billioner dollars globale økonomi. Selv hvis kun en brøkdel af dette fanges ved erstatning af menneskelig arbejdskraft med AI-arbejdskraft, er dette billioner af dollars i årlig indtægt. AI-virksomheder er også bevidste om, hvem der er villige til at betale. Som de ser det, vil du ikke betale tusindvis af dollars om året for produktivitetsværktøjer. Men en virksomhed *vil* betale tusindvis af dollars om året for at erstatte din arbejdskraft, hvis de kan.

## Hvorfor lande føler, de er nødt til at kappes om AGI

Landes erklærede motivationer for at forfølge AGI fokuserer på økonomisk og videnskabeligt lederskab. Argumentet er overbevisende: AGI kunne dramatisk accelerere videnskabelig forskning, teknologisk udvikling og økonomisk vækst. Set i lyset af, hvad der står på spil, argumenterer de, kan ingen stormagt have råd til at falde bagud.[^5]

Men der er også yderligere og stort set ustilede drivkræfter. Der er ingen tvivl om, at når visse militære og nationale sikkerhedsledere mødes bag lukkede døre for at diskutere en ekstraordinært potent og katastrofalt risikabel teknologi, er deres fokus ikke på "hvordan undgår vi disse risici", men snarere "hvordan får vi dette først?" Militære og efterretningsledere ser AGI som en potentiel revolution i militære anliggender, måske den mest betydningsfulde siden atomvåben. Frygten er, at det første land, der udvikler AGI, kunne opnå en uoverkommelig strategisk fordel. Dette skaber en klassisk våbenkapløbsdynamik.

Vi vil se, at denne "kapløb om AGI"-tankegang,[^6] selvom den er overbevisende, er dybt fejlbehæftet. Dette er ikke fordi kapløb er farligt og risikabelt – selvom det er det – men på grund af teknologiens natur. Den usagte antagelse er, at AGI, ligesom andre teknologier, kan kontrolleres af den stat, der udvikler den, og er en magtgivende velsignelse for det samfund, der har mest af den. Som vi vil se, vil den sandsynligvis ikke være nogen af delene.

## Hvorfor superintelligens?

Mens virksomheder offentligt fokuserer på produktivitet, og lande på økonomisk og teknologisk vækst, er disse blot begyndelsen for dem, der bevidst forfølger fuld AGI og superintelligens. Hvad har de virkelig i tankerne? Selvom det sjældent siges højt, inkluderer det:

1. Kure mod mange eller alle sygdomme;
2. Stopning og vending af aldring;
3. Nye bæredygtige energikilder som fusion;
4. Menneskelige opgraderinger eller designerorganismer via genmanipulation;
5. Nanoteknologi og molekylær fremstilling;
6. Sind-uploads;
7. Eksotisk fysik eller rumteknologier;
8. Overmenneskelig rådgivning og beslutningsstøtte;
9. Overmenneskelig planlægning og koordination.

De første tre er hovedsageligt "enkeltsidet" teknologier – dvs. sandsynligvis ganske stærkt netto positive. Det er svært at argumentere imod at helbrede sygdomme eller at kunne leve længere, hvis man vælger det. Og vi har allerede høstet den negative side af fusion (i form af atomvåben); det ville være dejligt nu at få den positive side. Spørgsmålet med denne første kategori er, om det at få disse teknologier hurtigere kompenserer for risikoen.

De næste fire er klart tveæggede: transformative teknologier med både potentielt enorme fordele og immense risici, meget ligesom AI. Alle disse, hvis de sprang ud af en sort boks i morgen og blev implementeret, ville være utroligt svære at håndtere.[^7]

De sidste to drejer sig om den overmenneskelige AI, der gør ting selv frem for blot at opfinde teknologi. Mere præcist, ved at lægge eufemismer til side, involverer disse kraftfulde AI-systemer, der fortæller folk, hvad de skal gøre. At kalde dette "rådgivning" er uredelig, hvis systemet, der giver råd, er langt mere kraftfuldt end den rådgivne, som ikke meningsfuldt kan forstå grundlaget for beslutningen (eller selvom dette gives, stole på at rådgiveren ikke ville give en tilsvarende overbevisende begrundelse for en anden beslutning.)

Dette peger på en vigtig ting, der mangler på ovenstående liste:

10. Magt.

Det er overdrevent klart, at meget af det, der ligger til grund for det nuværende kapløb om overmenneskelig AI, er ideen om, at *intelligens = magt*. Hver deltager satser på at være den bedste indehaver af denne magt, og at de vil være i stand til at udøve den af tilsyneladende velgørende årsager uden at den glider eller bliver taget fra deres kontrol.

Det vil sige, det virksomheder og nationer virkelig jager, er ikke blot frugterne af AGI og superintelligens, men magten til at kontrollere, hvem der får adgang til dem, og hvordan de bruges. Virksomheder ser sig selv som ansvarlige forvaltere af denne magt i service af aktionærer og menneskeheden; nationer ser sig selv som nødvendige vogtere, der forhindrer fjendtlige magter i at opnå afgørende fordel. Begge tager farligt fejl og anerkender ikke, at superintelligens per sin natur ikke kan kontrolleres pålideligt af nogen menneskelig institution. Vi vil se, at superintelligente systemers natur og dynamikker gør menneskelig kontrol ekstremt vanskelig, hvis ikke umulig.

Disse kapløbsdynamikker – både erhvervsmæssige og geopolitiske – gør visse risici næsten uundgåelige, medmindre de afgørende afbrydes. Vi vender os nu til at undersøge disse risici og hvorfor de ikke kan afbødes tilstrækkeligt inden for et konkurrencepræget [^8] udviklingsparadigme.


[^1]: En mere præcis liste over værdige mål er FN's [Bæredygtighedsmål.](https://sdgs.un.org/goals) Disse er i en forstand det tætteste, vi kommer på et sæt globale konsensusmål for, hvad vi gerne vil se forbedret i verden. AI kunne hjælpe.

[^2]: Teknologi generelt har en transformativ økonomisk og social kraft til menneskelig forbedring, som tusindvis af år vidner om. I denne ånd kan en lang og overbevisende forklaring af en positiv AGI-vision findes i [dette essay](https://darioamodei.com/machines-of-loving-grace) af Anthropic-grundlægger Dario Amodei.

[^3]: Private AI-investeringer [begyndte at boome i 2018-19, hvor de krydsede offentlige investeringer omkring da,](https://cset.georgetown.edu/publication/tracking-ai-investment/) og har enormt overgået dem siden.

[^4]: Jeg kan bekræfte, at bag mere lukkede døre har de ingen sådan skrupler. Og det bliver mere offentligt; se for eksempel Y-combinators nye ["request for startups"](https://www.ycombinator.com/rfs), hvor mange dele eksplicit opfordrer til fuldstændig erstatning af menneskelige arbejdere. For at citere dem: "Værdiforslaget for B2B SaaS var at gøre menneskelige arbejdere trinvist mere effektive. Værdiforslaget for vertikale AI-agenter er at automatisere arbejdet fuldstændigt...Det er helt muligt, at denne mulighed er stor nok til at præge yderligere 100 enhjørninger." (For dem, der ikke er vandt til Silicon Valley-sprog, er "B2B" business-to-business og en enhjørning er en virksomhed til 1 milliard dollars. Det vil sige, de taler om mere end hundrede milliard-plus-dollar-forretninger, der erstatter arbejdere for andre virksomheder.)

[^5]: Se for eksempel en nylig [US-China Economic and Security Review Commission-rapport](https://www.uscc.gov/sites/default/files/2024-11/2024_Executive_Summary.pdf). Selvom der var overraskende lidt begrundelse i selve rapporten, var topanbefalingen, at USA "Kongressen etablerer og finansierer et Manhattan Project-lignende program dedikeret til at kappes om og erhverve en Artificial General Intelligence (AGI) kapacitet."

[^6]: Virksomheder adopterer nu denne geopolitiske indramning som et skjold mod enhver begrænsning på deres AI-udvikling, generelt på måder der er åbenlyst selvtjenende, og nogle gange på måder der ikke engang giver grundlæggende mening. Overvej Metas [Approach to Frontier AI](https://about.fb.com/news/2025/02/meta-approach-frontier-ai/), som samtidig argumenterer for, at Amerika skal "[Cementere sin] position som leder i teknologisk innovation, økonomisk vækst og national sikkerhed" og også at det skal gøre det ved åbent at frigive sine mest kraftfulde AI-systemer – hvilket inkluderer at give dem direkte til sine geopolitiske rivaler og modstandere.

[^7]: Derfor ville vi sandsynligvis være nødt til at overlade håndteringen af disse teknologier til AI'erne. Men dette ville være en meget problematisk delegation af kontrol, som vi vil vende tilbage til nedenfor.

[^8]: Konkurrence i teknologiudvikling bringer ofte vigtige fordele: forhindrer monopolistisk kontrol, driver innovation og omkostningsreduktion, muliggør forskellige tilgange og skaber gensidig overvågning. Men med AGI skal disse fordele vejes mod unikke risici fra kapløbsdynamikker og pres for at reducere sikkerhedsforanstaltninger.