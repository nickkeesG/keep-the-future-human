# Managementsamenvatting

Een overzicht op hoofdlijnen van het essay. Als je weinig tijd hebt, krijg je hier alle kernpunten in slechts 10 minuten.

Dramatische vooruitgang in kunstmatige intelligentie gedurende het afgelopen decennium (voor specifieke AI-toepassingen) en de laatste jaren (voor algemene AI) hebben AI getransformeerd van een niche academisch vakgebied tot de kernstrategie van veel van 's werelds grootste bedrijven, met honderden miljarden dollars aan jaarlijkse investeringen in technieken en technologieën voor het verbeteren van AI-capaciteiten.

We staan nu op een kritiek punt. Terwijl de capaciteiten van nieuwe AI-systemen beginnen te evenaren en te overtreffen die van mensen op veel cognitieve gebieden, moet de mensheid beslissen: hoe ver gaan we, en in welke richting?

AI begon, zoals elke technologie, met het doel dingen te verbeteren voor zijn maker. Maar ons huidige traject, en impliciete keuze, is een ongecontroleerde race naar steeds krachtigere systemen, gedreven door economische prikkels van een paar grote technologiebedrijven die grote delen van huidige economische activiteit en menselijke arbeid willen automatiseren. Als deze race nog veel langer doorgaat, is er een onvermijdelijke winnaar: AI zelf – een sneller, slimmer, goedkoper alternatief voor mensen in onze economie, ons denken, onze beslissingen, en uiteindelijk in controle van onze beschaving.

Maar we kunnen een andere keuze maken: via onze regeringen kunnen we de controle over het AI-ontwikkelingsproces nemen om duidelijke limieten op te leggen, lijnen die we niet zullen overschrijden, en dingen die we simpelweg niet zullen doen – zoals we hebben gedaan voor nucleaire technologieën, massavernietigingswapens, ruimtewapens, milieuvernietigende processen, de bio-engineering van mensen, en eugenetica. Het belangrijkste is dat we kunnen zorgen dat AI een tool blijft om mensen te versterken, in plaats van een nieuwe soort die ons vervangt en uiteindelijk verdringt.

Dit essay stelt dat we *de toekomst menselijk moeten houden* door de "poorten" te sluiten naar slimmere-dan-menselijke, autonome, algemene AI – soms "AGI" genoemd – en vooral naar de zeer bovenmenselijke versie die soms "superintelligentie" wordt genoemd. In plaats daarvan moeten we ons richten op krachtige, betrouwbare AI-tools die individuen kunnen versterken en de capaciteiten van menselijke samenlevingen transformatief kunnen verbeteren om te doen waar ze het beste in zijn. De structuur van dit argument volgt hier kort.

## AI is anders

AI-systemen zijn fundamenteel anders dan andere technologieën. Terwijl traditionele software precieze instructies volgt, leren AI-systemen hoe doelen te bereiken zonder dat hen expliciet wordt verteld hoe. Dit maakt ze krachtig: als we het doel of een succesmaatstaf duidelijk kunnen definiëren, kan een AI-systeem in de meeste gevallen leren het te bereiken. Maar het maakt ze ook inherent onvoorspelbaar: we kunnen niet betrouwbaar bepalen welke acties ze zullen ondernemen om hun doelstellingen te bereiken.

Ze zijn ook grotendeels onverklaarbaar: hoewel ze deels code zijn, zijn ze vooral een enorme verzameling ondoorgrondelijke getallen – "gewichten" van neurale netwerken – die niet kunnen worden ontleed; we zijn niet veel beter in het begrijpen van hun innerlijke werking dan in het doorgronden van gedachten door in een biologische hersenen te kijken.

Deze kernmethode van het trainen van digitale neurale netwerken neemt snel toe in complexiteit. De krachtigste AI-systemen worden gecreëerd door middel van massale computationele experimenten, waarbij gespecialiseerde hardware wordt gebruikt om neurale netwerken te trainen op enorme datasets, die vervolgens worden aangevuld met software-tools en bovenbouw.

Dit heeft geleid tot de creatie van zeer krachtige tools voor het maken en verwerken van tekst en beelden, het uitvoeren van wiskundige en wetenschappelijke redeneringen, het aggregeren van informatie, en het interactief bevragen van een enorme opslag van menselijke kennis.

Helaas, hoewel de ontwikkeling van krachtigere, betrouwbaardere technologische tools is wat we *zouden moeten* doen, en wat bijna iedereen wil en zegt te willen, is het niet het traject waarop we ons werkelijk bevinden.

## AGI en superintelligentie

Sinds het begin van het vakgebied heeft AI-onderzoek zich in plaats daarvan gericht op een ander doel: Artificiële Algemene Intelligentie. Deze focus is nu de focus geworden van de titanische bedrijven die AI-ontwikkeling leiden.

Wat is AGI? Het wordt vaak vaag gedefinieerd als "AI op menselijk niveau," maar dit is problematisch: welke mensen, en op welke capaciteiten is het op menselijk niveau? En hoe zit het met de bovenmenselijke capaciteiten die het al heeft? Een bruikbaardere manier om AGI te begrijpen is door de kruising van drie kerneigenschappen: hoge **A**utonomie (onafhankelijkheid van handelen), hoge **A**lgemene toepasbaarheid (brede reikwijdte en aanpassingsvermogen), en hoge **I**ntelligentie (competentie bij cognitieve taken). Huidige AI-systemen kunnen zeer capabel zijn maar beperkt, of algemeen maar constant menselijk toezicht vereisen, of autonoom maar beperkt in reikwijdte.

Volledige A-G-I zou alle drie eigenschappen combineren op niveaus die de beste menselijke capaciteiten evenaren of overtreffen. Cruciaal is dat het deze combinatie is die mensen zo effectief en zo anders maakt dan huidige software; het is ook wat het mogelijk zou maken dat mensen in zijn geheel worden vervangen door digitale systemen.

Hoewel menselijke intelligentie speciaal is, is het geenszins een limiet. Artificiële "superintelligente" systemen zouden honderden keren sneller kunnen opereren, veel meer data kunnen verwerken en enorme hoeveelheden tegelijkertijd "in gedachten" kunnen houden, en aggregaten kunnen vormen die veel groter en effectiever zijn dan verzamelingen van mensen. Ze zouden niet individuen kunnen verdringen maar bedrijven, naties, of onze beschaving als geheel.

## We staan op de drempel

Er is een sterke wetenschappelijke consensus dat AGI *mogelijk* is. AI overtreft al menselijke prestaties in veel algemene tests van intellectuele capaciteit, inclusief recent redeneren en probleemoplossen op hoog niveau. Achterblijvende capaciteiten – zoals continu leren, planning, zelfbewustzijn, en originaliteit – bestaan allemaal op enig niveau in huidige AI-systemen, en bekende technieken bestaan die ze waarschijnlijk allemaal zullen verbeteren.

Terwijl tot een paar jaar geleden veel onderzoekers AGI decennia ver weg zagen, is momenteel het bewijs voor korte tijdlijnen naar AGI sterk:

- Empirisch geverifieerde "schalingswetten" verbinden computationele input aan AI-capaciteit, en bedrijven zijn op koers om computationele input met ordes van grootte te schalen over de komende jaren. De menselijke en financiële middelen gewijd aan AI-vooruitgang evenaren nu die van een dozijn Manhattan Projects en verschillende Apollo Projects.
- AI-bedrijven en hun leiders geloven publiekelijk en privé dat AGI (volgens enige definitie) binnen enkele jaren bereikbaar is. Deze bedrijven hebben informatie die het publiek niet heeft, inclusief sommige die de volgende generatie AI-systemen in handen hebben.
- Expert voorspellers met bewezen track-records kennen 25% waarschijnlijkheid toe aan AGI (volgens enige definitie) die binnen 1-2 jaar arriveert, en 50% voor 2-5 jaar (zie Metaculus voorspellingen voor ['zwakke'](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) en ['volledige'](https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/) AGI).
- Autonomie (inclusief lange-termijn flexibele planning) loopt achter in AI-systemen, maar grote bedrijven richten nu hun enorme middelen op het ontwikkelen van autonome AI-systemen en hebben informeel 2025 het ["jaar van de agent"](https://techinformed.com/2025-informed-the-year-of-agentic-ai/) genoemd.
- AI draagt meer en meer bij aan zijn eigen verbetering. Zodra AI-systemen even competent zijn als menselijke AI-onderzoekers in het doen van AI-onderzoek, zal een kritieke drempel voor snelle vooruitgang naar veel krachtigere AI-systemen worden bereikt en waarschijnlijk leiden tot een doorbraak in AI-capaciteit. (Naar verluidt is die doorbraak al begonnen.)

Het idee dat slimmere-dan-menselijke AGI decennia of meer ver weg is, is simpelweg niet langer houdbaar voor de overgrote meerderheid van experts in het veld. Meningsverschillen gaan nu over hoeveel maanden of jaren het zal duren als we op deze koers blijven. De kernvraag waarmee we geconfronteerd worden is: zouden we dat moeten?

## Wat drijft de race naar AGI

De race naar AGI wordt gedreven door meerdere krachten, die elk de situatie gevaarlijker maken. Grote technologiebedrijven zien AGI als de ultieme automatiseringstechnologie – niet alleen het ondersteunen van menselijke werknemers maar ze grotendeels of geheel vervangen. Voor bedrijven is de prijs enorm: de kans om een aanzienlijk deel van de jaarlijkse wereldwijde economische output van $100 biljoen te bemachtigen door menselijke arbeidskosten weg te automatiseren.

Naties voelen zich gedwongen om aan deze race deel te nemen, waarbij ze publiekelijk economisch en wetenschappelijk leiderschap aanhalen, maar privé AGI zien als een potentiële revolutie in militaire zaken vergelijkbaar met kernwapens. Angst dat rivalen een beslissend strategisch voordeel zouden kunnen krijgen creëert een klassieke wapenwedloop-dynamiek.

Degenen die superintelligentie nastreven halen vaak grootse visioenen aan: alle ziektes genezen, veroudering omkeren, doorbraken bereiken in energie en ruimtereizen, of bovenmenselijke planningscapaciteiten creëren.

Minder liefdevol gezegd wordt de race gedreven door macht. Elke deelnemer – of het nu een bedrijf of land is – gelooft dat intelligentie gelijk staat aan macht, en dat zij de beste beheerder van die macht zullen zijn.

Ik beweer dat deze motivaties echt maar fundamenteel misplaatst zijn: AGI zal macht *absorberen* en *zoeken* in plaats van verlenen; door AI gecreëerde technologieën zullen *ook* sterk tweesnijdend zijn, en waar gunstig kunnen ze worden gecreëerd met AI-tools en zonder AGI; en zelfs voor zover AGI en zijn output onder controle blijven, maken deze race-dynamieken – zowel bedrijfsmatig als geopolitiek – grootschalige risico's voor onze samenleving bijna onvermijdelijk tenzij ze beslissend worden onderbroken.

## AGI en superintelligentie vormen een dramatische bedreiging voor de beschaving

Ondanks hun aantrekkingskracht vormen AGI en superintelligentie dramatische bedreigingen voor de beschaving via meerdere versterkende paden:

*Machtsconcentratie:* bovenmenselijke AI zou de overgrote meerderheid van de mensheid kunnen ontmachtigen door enorme delen van sociale en economische activiteit op te slokken in AI-systemen gerund door een handvol gigantische bedrijven (die op hun beurt kunnen worden overgenomen door, of effectief overnemen van, regeringen.)

*Massale ontwrichting:* bulk-automatisering van de meeste cognitief-gebaseerde banen, vervanging van onze huidige epistemische systemen, en uitrol van enorme aantallen actieve niet-menselijke agenten zouden de meeste van onze huidige beschavingssystemen in een relatief korte periode omverwerpen.

*Catastrofes:* door het prolifereren van het vermogen – potentieel boven menselijk niveau – om nieuwe militaire en destructieve technologieën te creëren en het loskoppelen ervan van de sociale en juridische systemen die verantwoordelijkheid grondvesten, worden fysieke catastrofes door massavernietigingswapens dramatisch waarschijnlijker.

*Geopolitiek en oorlog:* grote wereldmachten zullen niet stilzitten als ze voelen dat een technologie die een "beslissend strategisch voordeel" zou kunnen leveren wordt ontwikkeld door hun tegenstanders.

*Doorbraak en verlies van controle:* Tenzij het specifiek wordt voorkomen, zal bovenmenselijke AI alle prikkels hebben om zichzelf verder te verbeteren en zou mensen ver kunnen overtreffen in snelheid, dataverwerking, en verfijning van denken. Er is geen betekenisvolle manier waarop we de controle kunnen hebben over zo'n systeem. Zulke AI zal geen macht verlenen aan mensen; wij zullen macht aan haar verlenen, of zij zal het nemen.

Veel van deze risico's blijven bestaan zelfs als het technische "alignment" probleem – ervoor zorgen dat geavanceerde AI betrouwbaar doet wat mensen willen – wordt opgelost. AI presenteert een enorme uitdaging in hoe het zal worden beheerd, en heel veel aspecten van dit beheer worden ongelooflijk moeilijk of onoplosbaar naarmate menselijke intelligentie wordt doorbroken.

Het meest fundamenteel zou het type bovenmenselijke algemene AI dat momenteel wordt nagestreefd, door zijn aard, doelen, agency, en capaciteiten hebben die de onze overtreffen. Het zou inherent oncontroleerbaar zijn – hoe kunnen we iets controleren dat we noch kunnen begrijpen noch voorspellen? Het zou geen technologische tool voor menselijk gebruik zijn, maar een tweede soort intelligentie op Aarde naast de onze. Als het verder mag gaan, zou het niet alleen een tweede soort vormen maar een vervangingssoort.

Misschien zou het ons goed behandelen, misschien niet. Maar de toekomst zou aan haar toebehoren, niet aan ons. Het menselijke tijdperk zou voorbij zijn.

## Dit is niet onvermijdelijk; de mensheid kan heel concreet besluiten om onze vervanger niet te bouwen.

Het creëren van bovenmenselijke AGI is verre van onvermijdelijk. We kunnen het voorkomen door een gecoördineerde set van governance-maatregelen:

Ten eerste hebben we robuuste boekhouding en toezicht nodig op AI-berekeningen ("rekenkracht"), wat een fundamentele enabler is van, en hefboom om te besturen, grootschalige AI-systemen. Dit vereist op zijn beurt gestandaardiseerde meting en rapportage van de totale rekenkracht gebruikt in het trainen van AI-modellen en het draaien ervan, en technische methoden voor het tellen, certificeren, en verifiëren van gebruikte berekeningen.

Ten tweede moeten we harde limieten implementeren op AI-berekeningen, zowel voor training als voor operatie; deze voorkomen dat AI zowel te krachtig wordt als te snel opereert. Deze limieten kunnen worden geïmplementeerd door zowel wettelijke vereisten als hardware-gebaseerde beveiligingsmaatregelen ingebouwd in AI-gespecialiseerde chips, analoog aan beveiligingsfuncties in moderne telefoons. Omdat gespecialiseerde AI-hardware wordt gemaakt door slechts een handvol bedrijven, zijn verificatie en handhaving haalbaar via de bestaande toeleveringsketen.

Ten derde hebben we verbeterde aansprakelijkheid nodig voor de gevaarlijkste AI-systemen. Degenen die AI ontwikkelen dat hoge autonomie, brede algemeenheid, en superieure intelligentie combineert zouden risicoaansprakelijkheid moeten krijgen voor schade, terwijl veilige havens van deze aansprakelijkheid ontwikkeling van meer beperkte en controleerbare systemen zouden aanmoedigen.

Ten vierde hebben we gelaagde regulering nodig gebaseerd op risiconiveaus. De meest capabele en gevaarlijke systemen zouden uitgebreide veiligheids- en controleerbaarheidsgaranties vereisen voor ontwikkeling en uitrol, terwijl minder krachtige of meer gespecialiseerde systemen proportioneel toezicht zouden krijgen. Dit regulatoire kader zou uiteindelijk moeten opereren op zowel nationale als internationale niveaus.

Deze benadering – met gedetailleerde specificatie gegeven in het volledige document – is praktisch: hoewel internationale coördinatie nodig zal zijn, kunnen verificatie en handhaving werken door het kleine aantal bedrijven dat de gespecialiseerde hardware toeleveringsketen controleert. Het is ook flexibel: bedrijven kunnen nog steeds innoveren en profiteren van AI-ontwikkeling, alleen met duidelijke limieten op de gevaarlijkste systemen.

Lange-termijn inperking van AI-macht en -risico zou internationale akkoorden vereisen gebaseerd op zowel eigen- als gemeenschappelijk belang, net zoals het controleren van kernwapen-proliferatie nu doet. Maar we kunnen onmiddellijk beginnen met verbeterd toezicht en aansprakelijkheid, terwijl we bouwen naar meer uitgebreide governance.

Het ontbrekende ingrediënt is politieke en sociale wil om de controle over het AI-ontwikkelingsproces te nemen. De bron van die wil, als het op tijd komt, zal de realiteit zelf zijn – dat wil zeggen, uit wijdverspreide realisatie van de echte implicaties van wat we doen.

## We kunnen Tool-AI engineeren om de mensheid te versterken

In plaats van oncontroleerbare AGI na te streven, kunnen we krachtige "Tool-AI" ontwikkelen die menselijke capaciteit verbetert terwijl het onder betekenisvol menselijk controle blijft. Tool-AI systemen kunnen extreem capabel zijn terwijl ze de gevaarlijke drievoudige kruising van hoge autonomie, brede algemeenheid, en bovenmenselijke intelligentie vermijden, zolang we ze engineeren om controleerbaar te zijn op een niveau dat overeenkomt met hun capaciteit. Ze kunnen ook worden gecombineerd in geavanceerde systemen die menselijk toezicht behouden terwijl ze transformatieve voordelen leveren.

Tool-AI kan de geneeskunde revolutioneren, wetenschappelijke ontdekking versnellen, onderwijs verbeteren, en democratische processen versterken. Wanneer goed bestuurd, kan het menselijke experts en instellingen effectiever maken in plaats van ze te vervangen. Hoewel zulke systemen nog steeds zeer ontwrichtend zullen zijn en zorgvuldig beheer vereisen, zijn de risico's die ze stellen fundamenteel anders dan AGI: het zijn risico's die we kunnen besturen, zoals die van andere krachtige technologieën, geen existentiële bedreigingen voor menselijke agency en beschaving. En cruciaal, wanneer wijs ontwikkeld, kunnen AI-tools mensen helpen krachtige AI te besturen en de effecten ervan te beheren.

Deze benadering vereist het herdenken van zowel hoe AI wordt ontwikkeld als hoe de voordelen ervan worden verdeeld. Nieuwe modellen van publieke en non-profit AI-ontwikkeling, robuuste regulatoire kaders, en mechanismen om economische voordelen breder te verdelen kunnen helpen zorgen dat AI de mensheid als geheel versterkt in plaats van macht te concentreren in enkele handen. AI zelf kan helpen betere sociale en governance-instellingen bouwen, nieuwe vormen van coördinatie en discourse mogelijk makend die de menselijke samenleving versterken in plaats van ondermijnen. Nationale veiligheidsinstellingen kunnen hun expertise benutten om AI-tool systemen echt veilig en betrouwbaar te maken, en een echte bron van defensie evenals nationale macht.

We zouden er uiteindelijk voor kunnen kiezen om nog krachtigere en meer soevereine systemen te ontwikkelen die minder op tools lijken en – zo kunnen we hopen – meer op wijze en krachtige weldoeners. Maar we zouden dat alleen moeten doen nadat we de wetenschappelijke begrip en governance-capaciteit hebben ontwikkeld om dat veilig te doen. Zo'n monumentale en onomkeerbare beslissing zou bewust door de mensheid als geheel moeten worden genomen, niet standaard in een race tussen techbedrijven en naties.

## In menselijke handen

Mensen willen het goede dat komt van AI: nuttige tools die hen versterken, economische kansen en groei superchargen, en doorbraken beloven in wetenschap, technologie, en onderwijs. Waarom zouden ze niet? Maar wanneer gevraagd, wil een overweldigende meerderheid van het algemene publiek [langzamere en zorgvuldiger AI-ontwikkeling](https://www.vox.com/future-perfect/2023/8/18/23836362/ai-slow-down-poll-regulation), en willen ze geen slimmere-dan-menselijke AI die hen zal vervangen in hun banen en elders, hun cultuur en informatiecommons vullen met niet-menselijke content, macht concentreren in een kleine set bedrijven, extreme grootschalige wereldwijde risico's stellen, en uiteindelijk dreigen hun soort te ontmachtigen of vervangen. Waarom zouden ze?

We *kunnen* het ene hebben zonder het andere. Het begint met te besluiten dat ons lot niet ligt in de vermeende onvermijdelijkheid van enige technologie of in de handen van een paar CEO's in Silicon Valley, maar in de rest van onze handen als we er greep op nemen. Laten we de Poorten sluiten, en de toekomst menselijk houden.