# Hoofdstuk 1 - Inleiding

Hoe we zullen reageren op het vooruitzicht van AI die slimmer is dan mensen, is de meest urgente kwestie van onze tijd. Dit essay biedt een weg voorwaarts.

We bevinden ons mogelijk aan het einde van het menselijke tijdperk.

In de afgelopen tien jaar is er iets begonnen dat uniek is in de geschiedenis van onze soort. De gevolgen daarvan zullen grotendeels de toekomst van de mensheid bepalen. Vanaf ongeveer 2015 zijn onderzoekers erin geslaagd *smalle* kunstmatige intelligentie (AI) te ontwikkelen – systemen die beter dan welke mens dan ook kunnen winnen bij spellen zoals Go, beelden en spraak kunnen herkennen, enzovoort.[^1]

Dit is een verbazingwekkend succes, en het levert uiterst nuttige systemen en producten op die de mensheid zullen versterken. Maar smalle kunstmatige intelligentie is nooit het werkelijke doel van het vakgebied geweest. Het doel is juist geweest om AI-systemen voor *algemene* doeleinden te creëren, met name die welke vaak "artificiële algemene intelligentie" (AGI) of "superintelligentie" worden genoemd, die tegelijkertijd net zo goed of beter zijn dan mensen bij vrijwel *alle* taken, net zoals AI nu superhuman is bij Go, schaken, poker, droneracen, etc. Dit is het verklaarde doel van veel grote AI-bedrijven.[^2]

*Deze inspanningen slagen ook.* AI-systemen voor algemene doeleinden zoals ChatGPT, Gemini, Llama, Grok, Claude en Deepseek, gebaseerd op enorme berekeningen en bergen aan data, hebben gelijkwaardigheid bereikt met gewone mensen bij een grote verscheidenheid aan taken, en evenaren zelfs menselijke experts op sommige gebieden. Nu racen AI-ingenieurs bij enkele van de grootste technologiebedrijven om deze gigantische experimenten in machine-intelligentie naar de volgende niveaus te brengen, waarbij ze het volledige spectrum aan menselijke capaciteiten, expertise en autonomie eerst evenaren en vervolgens overtreffen.

*Dit staat voor de deur.* In de afgelopen tien jaar zijn expertschattingen voor hoe lang dit zal duren – als we onze huidige koers voortzetten – gedaald van decennia (of eeuwen) naar enkele jaren.

Het is ook van epochaal belang en van transcendent risico. Voorstanders van AGI zien het als een positieve transformatie die wetenschappelijke problemen zal oplossen, ziekten zal genezen, nieuwe technologieën zal ontwikkelen en sleur zal automatiseren. En AI zou zeker kunnen helpen bij het bereiken van al deze dingen – sterker nog, dat doet het al. Maar door de decennia heen hebben veel zorgvuldige denkers, van Alan Turing tot Stephen Hawking tot de hedendaagse Geoffrey Hinton en Yoshua Bengio[^3], een scherpe waarschuwing gegeven: het bouwen van werkelijk slimmer-dan-menselijke, algemene, autonome AI zal minimaal de samenleving volledig en onherroepelijk op zijn kop zetten, en maximaal resulteren in het uitsterven van de mens.[^4]

Superintelligente AI nadert snel op onze huidige weg, maar is verre van onvermijdelijk. Dit essay is een uitgebreid argument voor waarom en hoe we de *Poorten* naar deze naderende onmenselijke toekomst moeten *sluiten*, en wat we in plaats daarvan zouden moeten doen.

[^1]: Deze [grafiek](https://time.com/6300942/ai-progress-charts/) toont een reeks taken; veel vergelijkbare curves zouden aan deze grafiek kunnen worden toegevoegd. Deze snelle vooruitgang in smalle AI heeft zelfs experts op dit gebied verrast, waarbij benchmarks jaren eerder werden overtroffen dan voorspeld.

[^2]: Deepmind, OpenAI, Anthropic en X.ai werden allemaal opgericht met het specifieke doel AGI te ontwikkelen. OpenAI's charter stelt bijvoorbeeld expliciet als doel het ontwikkelen van "artificiële algemene intelligentie die de hele mensheid ten goede komt", terwijl DeepMind's missie is "intelligentie oplossen, en dat vervolgens gebruiken om alles op te lossen." Meta, Microsoft en anderen volgen nu substantieel vergelijkbare paden. Meta heeft gezegd dat het [van plan is AGI te ontwikkelen en het open vrij te geven.](https://www.forbes.com/sites/johnkoetsier/2024/01/18/zuckerberg-on-ai-meta-building-agi-for-everyone-and-open-sourcing-it/)

[^3]: Hinton en Bengio zijn twee van de meest geciteerde AI-onderzoekers, hebben beiden de Nobel van het AI-vakgebied gewonnen, de Turing Prize, en Hinton heeft ook nog eens een Nobelprijs gewonnen (in de natuurkunde).

[^4]: Het bouwen van iets met dit risico, onder commerciële prikkels en vrijwel geen overheidtoezicht, is volkomen ongekend. Er is niet eens controverse over het risico onder degenen die het bouwen! De leiders van Deepmind, OpenAI en Anthropic, naast vele andere experts, hebben allemaal letterlijk een [verklaring](https://www.safe.ai/work/statement-on-ai-risk) ondertekend dat geavanceerde AI een *uitstervingsrisico voor de mensheid* vormt. De alarmbellen kunnen niet harder rinkelen, en men kan alleen concluderen dat degenen die ze negeren AGI en superintelligentie simpelweg niet serieus nemen. Een doel van dit essay is hen te helpen begrijpen waarom dat wel zou moeten.
