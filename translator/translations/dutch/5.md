# Hoofdstuk 5 - Op de drempel

De weg van de huidige AI-systemen naar volwaardige AGI lijkt schokkend kort en voorspelbaar.

De afgelopen tien jaar hebben dramatische vooruitgang in AI laten zien, aangedreven door enorme [computationele](https://epoch.ai/blog/training-compute-of-frontier-ai-models-grows-by-4-5x-per-year), menselijke en [financiële](https://arxiv.org/abs/2405.21015) middelen. Veel smalle AI-toepassingen presteren beter dan mensen bij hun toegewezen taken, en zijn zeker veel sneller en goedkoper.[^1] En er zijn ook smalle superhumane agenten die alle mensen kunnen verslaan in smalle domeinspellen zoals [Go](https://www.nature.com/articles/nature16961), [Schaken](https://arxiv.org/abs/1712.01815) en [Poker](https://www.deepstack.ai/), evenals meer [algemene agenten](https://deepmind.google/discover/blog/a-generalist-agent/) die kunnen plannen en acties uitvoeren in vereenvoudigde gesimuleerde omgevingen net zo effectief als mensen.

Het meest prominent zijn de huidige algemene AI-systemen van OpenAI/Microsoft, Google/Deepmind, Anthropic/Amazon, Facebook/Meta, X.ai/Tesla en anderen [^2] die sinds begin 2023 zijn ontstaan en sindsdien gestaag (hoewel ongelijkmatig) hun capaciteiten hebben vergroot. Al deze zijn gecreëerd via token-voorspelling op enorme tekst- en multimediadatasets, gecombineerd met uitgebreide versterkingsfeedback van mensen en andere AI-systemen. Sommige bevatten ook uitgebreide tool- en scaffolding-systemen.

## Sterke punten en zwakke punten van huidige algemene systemen

Deze systemen presteren goed bij een steeds bredere reeks tests die ontworpen zijn om intelligentie en expertise te meten, met vooruitgang die zelfs experts op het gebied heeft verrast:

- Bij de eerste release presteerde GPT-4 [op het niveau van of beter dan typische menselijke prestaties](https://arxiv.org/abs/2303.08774) bij standaard academische tests inclusief SATs, GRE, toelatingexamens en juridische examens. Meer recente modellen presteren waarschijnlijk aanzienlijk beter, hoewel resultaten niet publiek beschikbaar zijn.
- De Turing-test – lang beschouwd als een belangrijke benchmark voor "echte" AI – wordt nu routinematig doorstaan in sommige vormen door moderne taalmodellen, zowel informeel als in [formele studies](https://arxiv.org/abs/2405.08007).[^3]
- Op de uitgebreide MMLU-benchmark die 57 academische vakgebieden omvat, [behalen recente modellen scores op domeinexpertniveau](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu) (∼90%) [^4]
- Technische expertise is dramatisch vooruitgegaan: De GPQA-benchmark van natuurkundevragen op graduate-niveau zag [prestaties springen](https://epoch.ai/data/ai-benchmarking-dashboard) van bijna willekeurig raden (GPT-4, 2022) naar expertniveau (o1-preview, 2024).
- Zelfs tests die specifiek ontworpen zijn om AI-resistent te zijn, vallen: OpenAI's O3 [lost naar verluidt](https://www.nextbigfuture.com/2024/12/openai-releases-o3-model-with-high-performance-and-high-cost.html) de ARC-AGI abstracte probleemoplossing benchmark op menselijk niveau op, behaalt top-expert programmeerpreestaties, en scoort 25% op Epoch AI's "frontier math" problemen die ontworpen zijn om elite-wiskundigen uit te dagen.[^5]
- De trend is zo duidelijk dat MMLU's ontwikkelaar nu ["Humanity's Last Exam"](https://agi.safe.ai/) heeft gecreëerd – een onheilspellende naam die de mogelijkheid weergeeft dat AI binnenkort menselijke prestaties bij elke betekenisvolle test zal overtreffen. Op het moment van schrijven zijn er beweringen dat AI-systemen 27% (volgens [Sam Altman](https://x.com/sama/status/1886220281565381078)) en 35% (volgens [dit paper](https://arxiv.org/abs/2502.09955)) behalen op dit extreem moeilijke examen. Het is hoogst onwaarschijnlijk dat een individuele mens dit zou kunnen.

Ondanks deze indrukwekkende cijfers (en hun duidelijke intelligentie wanneer je ermee interacteert) [^6] zijn er veel dingen die (tenminste de uitgebrachte versies van) deze neurale netwerken *niet kunnen* doen. Momenteel zijn de meeste ontlichaamd – bestaand alleen op servers – en verwerken hooguit tekst, geluid en stilstaande beelden (maar geen video). Cruciaal is dat de meeste geen complexe geplande activiteiten kunnen uitvoeren die hoge nauwkeurigheid vereisen.[^7] En er zijn een aantal andere kwaliteiten die sterk zijn in hoogwaardige menselijke cognitie maar momenteel laag in uitgebrachte AI-systemen.

De volgende tabel somt er een aantal op, gebaseerd op midden-2024 AI-systemen zoals GPT-4o, Claude 3.5 Sonnet en Google Gemini 1.5.[^8] De sleutelvraag voor hoe snel algemene AI krachtiger zal worden is: in welke mate zal alleen *meer van hetzelfde* doen resultaten opleveren, versus het toevoegen van additionele maar *bekende* technieken, versus het ontwikkelen of implementeren van *echt nieuwe* AI-onderzoeksrichtingen. Mijn eigen voorspellingen hiervoor staan in de tabel, in termen van hoe waarschijnlijk elk van deze scenario's is om die capaciteit tot en boven menselijk niveau te krijgen.

<table><tbody><tr><th>Capaciteit</th><th>Beschrijving van capaciteit</th><th>Status/prognose</th><th>Schaling/bekend/nieuw</th></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td colspan="4"><em>Kerncompetenties Cognitie</em></td></tr><tr><td>Redenering</td><td>Menschen kunnen nauwkeurige, meerstappige redenering doen, regels volgen en nauwkeurigheid controleren.</td><td>Dramatische recente vooruitgang met uitgebreide chain-of-thought en hertraining</td><td>95/5/5</td></tr><tr><td>Planning</td><td>Menschen vertonen langetermijn- en hiërarchische planning.</td><td>Verbetert met schaling; kan sterk worden geholpen met scaffolding en betere trainingstechnieken.</td><td>10/85/5</td></tr><tr><td>Waarheidsgrondslag</td><td>GPAI's verzinnen ongegronde informatie om vragen te beantwoorden.</td><td>Verbetert met schaling; kalibratiedata beschikbaar binnen model; kan worden gecontroleerd/verbeterd via scaffolding.</td><td>30/65/5</td></tr><tr><td>Flexibele probleemoplossing</td><td>Menschen kunnen nieuwe patronen herkennen en nieuwe oplossingen bedenken voor complexe problemen; huidige ML-modellen hebben moeite hiermee.</td><td>Verbetert met schaling maar zwak; kan oplosbaar zijn met neurosymbolische of gegeneraliseerde "zoek"-technieken.</td><td>15/75/10</td></tr><tr><td colspan="4"><em>Leren en Kennis</em></td></tr><tr><td>Leren & geheugen</td><td>Menschen hebben werkgeheugen, kortetermijn- en langetermijngeheugen, die allemaal dynamisch en onderling gerelateerd zijn.</td><td>Alle modellen leren tijdens training; GPAI's leren binnen contextvenster en tijdens fine-tuning; "continual learning" en andere technieken bestaan maar zijn nog niet geïntegreerd in grote GPAI's.</td><td>5/80/15</td></tr><tr><td>Abstractie & recursie</td><td>Menschen kunnen relatiesets toewijzen en overdragen naar meer abstracte voor redenering en manipulatie, inclusief recursieve "meta" redenering.</td><td>Verbetert zwak met schaling; zou kunnen ontstaan in neurosymbolische systemen.</td><td>30/50/20</td></tr><tr><td>Wereldmodel(len)</td><td>Menschen hebben en updaten voortdurend een voorspellend wereldmodel waarbinnen zij problemen kunnen oplossen en fysieke redenering kunnen doen</td><td>Verbetert met schaling; updaten gekoppeld aan leren; GPAI's zwak in echte-wereld voorspelling.</td><td>20/50/30</td></tr><tr><td colspan="4"><em>Zelf en Agentschap</em></td></tr><tr><td>Agentschap</td><td>Menschen kunnen acties ondernemen om doelen na te streven, gebaseerd op planning/voorspelling.</td><td>Veel ML-systemen zijn agentisch; LLM's kunnen agenten worden gemaakt via wrappers.</td><td>5/90/5</td></tr><tr><td>Zelfsturing</td><td>Menschen ontwikkelen en streven hun eigen doelen na, met intern gegenereerde motivatie en drijfveer.</td><td>Grotendeels samengesteld uit agentschap plus originaliteit; waarschijnlijk ontstaan in complexe agentische systemen met abstracte doelen.</td><td>40/45/15</td></tr><tr><td>Zelfreferentie</td><td>Menschen begrijpen en redeneren over zichzelf als gesitueerd binnen een omgeving/context.</td><td>Verbetert met schaling en kan worden versterkt met trainingsbeloning.</td><td>70/15/15</td></tr><tr><td>Zelfbewustzijn</td><td>Menschen hebben kennis van en kunnen redeneren over hun eigen gedachten en mentale toestanden.</td><td>Bestaat in zekere zin in GPAI's, die naar verluidt de klassieke "spiegeltest" voor zelfbewustzijn kunnen doorstaan. Kan worden verbeterd met scaffolding; maar onduidelijk of dit genoeg is.</td><td>20/55/25</td></tr><tr><td colspan="4"><em>Interface en Omgeving</em></td></tr><tr><td>Belichaamde intelligentie</td><td>Menschen begrijpen en interacteren actief met hun echte-wereld omgeving.</td><td>Reinforcement learning werkt goed in gesimuleerde en echte-wereld (robotische) omgevingen en kan worden geïntegreerd in multimodale transformers.</td><td>5/85/10</td></tr><tr><td>Multizintuiglijke verwerking</td><td>Menschen integreren en verwerken real-time visuele, audio en andere sensorische stromen.</td><td>Training in meerdere modaliteiten lijkt "gewoon te werken" en verbetert met schaling. Real-time videoverwerking is moeilijk maar bijv. zelfrijdende systemen verbeteren snel.</td><td>30/60/10</td></tr><tr><td colspan="4"><em>Hogere-orde Capaciteiten</em></td></tr><tr><td>Originaliteit</td><td>Huidige ML-modellen zijn creatief in het transformeren en combineren van bestaande ideeën/werken, maar menschen kunnen nieuwe kaders en structuren bouwen, soms gekoppeld aan hun identiteit.</td><td>Kan moeilijk te onderscheiden zijn van "creativiteit," die erin kan schalen; kan ontstaan uit creativiteit plus zelfbewustzijn.</td><td>50/40/10</td></tr><tr><td>Bewustzijn</td><td>Menschen ervaren qualia; deze kunnen positieve, negatieve of neutrale valentie hebben; het is "iets om" een persoon te zijn.</td><td>Zeer moeilijk en filosofisch beladen om te bepalen of een gegeven systeem dit heeft.</td><td>5/10/85</td></tr></tbody></table>

Belangrijke capaciteiten die momenteel onder menselijk expertniveau zijn in moderne GPAI-systemen, gegroepeerd per type. De derde kolom vat de huidige status samen. De laatste kolom toont voorspelde waarschijnlijkheid (%) dat menselijk niveau wordt bereikt door: schaling van huidige technieken / combinatie met bekende technieken / ontwikkeling van nieuwe technieken. Deze capaciteiten zijn niet onafhankelijk, en toename in een ervan gaat typisch samen met toenames in anderen. Merk op dat niet alle (vooral bewustzijn) nodig zijn voor AI-systemen die in staat zijn AI-ontwikkeling te bevorderen, wat de mogelijkheid benadrukt van krachtige maar niet-bewuste AI.

Door op deze manier uit te splitsen wat "ontbreekt", wordt het vrij duidelijk dat we behoorlijk op koers zijn voor breed boven-menselijke intelligentie door het schalen van bestaande of bekende technieken.[^9]

Er kunnen nog steeds verrassingen zijn. Zelfs afgezien van "bewustzijn" zouden er van de genoemde cognitieve kerncompetenties enkele kunnen zijn die echt niet gedaan kunnen worden met huidige technieken en nieuwe vereisen. Maar overweeg dit. De huidige inspanning door veel van 's werelds grootste bedrijven bedraagt meerdere malen de uitgaven van het Apollo-project en tientallen malen die van het Manhattan-project,[^10] en stelt duizenden van de allerbeste technische mensen te werk tegen ongekende salarissen. De dynamiek van de afgelopen jaren heeft nu meer menselijke intellectuele kracht (met AI die nu wordt toegevoegd) hierop gericht dan enige onderneming in de geschiedenis. We zouden niet moeten wedden op mislukking.

## Het grote doel: generalistische autonome agenten

De ontwikkeling van algemene AI in de afgelopen jaren heeft zich gericht op het creëren van algemene en krachtige maar tool-achtige AI: het functioneert primair als een (redelijk) loyale assistent, en onderneemt over het algemeen niet zelf acties. Dit is deels bewust ontwerp, maar grotendeels omdat deze systemen simpelweg niet bekwaam genoeg zijn geweest in de relevante vaardigheden om toevertrouwd te worden met complexe acties.[^11]

AI-bedrijven en onderzoekers [verschuiven echter steeds meer de focus](https://www.axios.com/2025/01/23/davos-2025-ai-agents) naar *autonome* generalistische agenten op expertniveau.[^12] Dit zou de systemen in staat stellen meer te handelen als een menselijke assistent aan wie de gebruiker echte acties kan delegeren.[^13] Wat is daarvoor nodig? Een aantal van de capaciteiten in de "wat ontbreekt"-tabel zijn hierbij betrokken, waaronder sterke waarheidsgrondslag, leren en geheugen, abstractie en recursie, en wereldmodellering (voor intelligentie), planning, agentschap, originaliteit, zelfsturing, zelfreferentie en zelfbewustzijn (voor autonomie), en multizintuiglijke verwerking, belichaamde intelligentie en flexibele probleemoplossing (voor generaliteit).[^14]

Deze drievoudige kruising van hoge autonomie (onafhankelijkheid van actie), hoge generaliteit (bereik en taakbreedte) en hoge intelligentie (competentie bij cognitieve taken) is momenteel uniek voor mensen. Het is impliciet wat velen waarschijnlijk voor ogen hebben wanneer ze denken aan AGI – zowel in termen van waarde als risico's.

Dit biedt een andere manier om A-G-I te definiëren als ***A*** utonome- ***G*** enerale- ***I*** ntelligentie, en we zullen zien dat deze drievoudige kruising een zeer waardevolle lens biedt voor systemen met hoge capaciteiten, zowel in het begrijpen van hun risico's en beloningen als in de governance van AI.

![](https://keepthefuturehuman.ai/essay/_next/image?url=https%3A%2F%2Fkeepthefuturehuman.ai%2Fwp-content%2Fuploads%2F2025%2F02%2FAGI-Venn-Diagram-Simple-1024x1024.png&w=3840&q=75) De transformatieve A-G-I kracht- en risicozone ontstaat uit de kruising van drie belangrijke eigenschappen: hoge Autonomie, hoge Intelligentie bij taken, en hoge Generaliteit.

## De AI (zelf-)verbeteringscyclus

Een laatste cruciale factor in het begrijpen van AI-vooruitgang is AI's unieke technologische feedbackloop. Bij het ontwikkelen van AI brengt succes – zowel in gedemonstreerde systemen als ingezette producten – extra investering, talent en concurrentie met zich mee, en we bevinden ons momenteel midden in een enorme AI hype-plus-realiteit feedbackloop die honderden miljarden, of zelfs biljoenen dollars aan investeringen aanstuurt.

Dit type feedbackcyclus zou kunnen gebeuren bij elke technologie, en we hebben het bij veel gezien, waar marktsucces investering bevordert, wat verbetering en beter marktsucces bevordert. Maar AI-ontwikkeling gaat verder, doordat nu AI-systemen helpen bij het ontwikkelen van nieuwe en krachtigere AI-systemen.[^15] We kunnen deze feedbackloop zien in vijf stadia, elk met een kortere tijdschaal dan de vorige, zoals getoond in de tabel.

*De AI-verbeteringscyclus werkt op meerdere tijdschalen, waarbij elk stadium mogelijk volgende stadia versnelt. Eerdere stadia zijn goed onderweg, terwijl latere stadia speculatief blijven maar zeer snel zouden kunnen verlopen zodra ze ontgrendeld zijn.*

Verschillende van deze stadia zijn al onderweg, en een paar beginnen duidelijk. Het laatste stadium, waarin AI-systemen zichzelf autonoom verbeteren, is een hoofdbestanddeel geweest van de literatuur over het risico van zeer krachtige AI-systemen, en terecht.[^16] Maar het is belangrijk op te merken dat het slechts de meest drastische vorm is van een feedbackcyclus die al is begonnen en zou kunnen leiden tot meer verrassingen in de snelle vooruitgang van de technologie.

[^1]: Je gebruikt veel meer van deze AI dan je waarschijnlijk denkt, bij spraakgeneratie en -herkenning, beeldverwerking, nieuwsfeed-algoritmes, enz.

[^2]: Hoewel de relaties tussen deze bedrijfsparen vrij complex en genuanceerd zijn, heb ik ze expliciet genoemd om zowel de enorme totale marktkapitalisatie van bedrijven die nu betrokken zijn bij AI-ontwikkeling aan te geven, als ook dat er achter zelfs "kleinere" bedrijven zoals Anthropic enorm diepe zakken zitten via investeringen en grote partnerschapsdeals.

[^3]: Het is mode geworden om de Turing-test te kleineren, maar hij is vrij krachtig en algemeen. In zwakke versies geeft hij aan of typische mensen die interacteren met een AI (die getraind is om menselijk te handelen) op typische manieren voor korte periodes kunnen zeggen of het een AI is. Dat kunnen ze niet. Ten tweede kan een zeer adversariële Turing-test in wezen elk element van menselijke capaciteit en intelligentie onderzoeken – door bijv. een AI-systeem te vergelijken met een menselijke expert, geëvalueerd door andere menselijke experts. Er is een zin waarin veel AI-evaluatie een gegeneraliseerde vorm van Turing-test is.

[^4]: Dit is per domein – geen mens zou plausibel zulke scores kunnen behalen over alle vakken tegelijkertijd.

[^5]: Dit zijn problemen die zelfs uitstekende wiskundigen aanzienlijke tijd zouden kosten om op te lossen, als ze ze überhaupt zouden kunnen oplossen.

[^6]: Als je van een sceptische inslag bent, behoud dan je scepsis maar probeer echt de meest actuele modellen uit, en probeer ook zelf enkele van de testvragen die ze kunnen doorstaan. Als natuurkundeprofessor zou ik met bijna zekerheid voorspellen dat bijvoorbeeld de topmodellen zouden slagen voor het graduate-kwalificatie-examen op onze afdeling.

[^7]: Dit en andere zwakke punten zoals verzinnen hebben marktacceptatie vertraagd en geleid tot een kloof tussen waargenomen en beweerde capaciteiten (wat ook bekeken moet worden door de lens van intense marktconcurrentie en de noodzaak om investering aan te trekken). Dit heeft zowel het publiek als beleidsmakers verward over de werkelijke staat van AI-vooruitgang. Hoewel misschien niet overeenstemmend met de hype, is de vooruitgang zeer reëel.

[^8]: De belangrijkste vooruitgang sindsdien is de ontwikkeling van systemen getraind voor topkwaliteit redenering, gebruik makend van meer berekening tijdens inferentie en meer reinforcement learning. Omdat deze modellen nieuw zijn en hun capaciteiten minder getest, heb ik deze tabel niet volledig herzien behalve voor "redenering", wat ik beschouw als in wezen opgelost. Maar ik heb voorspellingen bijgewerkt gebaseerd op ervaren en gerapporteerde capaciteiten van die systemen.

[^9]: Eerdere golven van AI-optimisme in de jaren 1960 en 1980 eindigden in "AI-winters" toen beloofde capaciteiten faalden te materialiseren. De huidige golf verschilt echter fundamenteel doordat superhumane prestaties in veel domeinen zijn behaald, gesteund door massale computationele middelen en commercieel succes.

[^10]: Het volledige Apollo-project [kostte ongeveer $250 miljard USD in 2020 dollars](https://www.planetary.org/space-policy/cost-of-apollo), en het Manhattan-project [minder dan een tiende daarvan](https://www.brookings.edu/the-costs-of-the-manhattan-project/). Goldman Sachs [projecteert een biljoen dollar uitgaven alleen al aan AI-datacenters](https://www.datacenterdynamics.com/en/news/goldman-sachs-1tn-to-be-spent-on-ai-data-centers-chips-and-utility-upgrades-with-little-to-show-for-it-so-far/) in de komende jaren.

[^11]: Hoewel mensen genoeg fouten maken, onderschatten we hoe betrouwbaar we kunnen zijn! Omdat kansen zich vermenigvuldigen, vereist een taak die 20 stappen correct moet doen dat elke stap 97% betrouwbaar is om het de helft van de tijd goed te doen. We doen zulke taken voortdurend.

[^12]: Een sterke beweging in deze richting is zeer recentelijk ondernomen met OpenAI's ["Deep Research"](https://openai.com/index/introducing-deep-research/) assistent die autonoom algemeen onderzoek uitvoert, beschreven als "een nieuwe agentische capaciteit die meerstaps-onderzoek op internet uitvoert voor complexe taken."

[^13]: Dingen zoals dat vervelende PDF-formulier invullen, vluchten boeken, enz. Maar met een PhD in 20 vakgebieden! Dus ook: die scriptie voor je schrijven, dat contract voor je onderhandelen, die stelling voor je bewijzen, die reclamecampagne voor je creëren, enz. Wat doe *jij*? Je vertelt het wat te doen, natuurlijk.

[^14]: Merk op dat bewustzijn *niet* duidelijk vereist is, noch impliceert AI in deze drievoudige kruising dit noodzakelijk.

[^15]: De dichtstbijzijnde analogie hier is misschien chiptechnologie, waar ontwikkeling Moore's wet decennia heeft volgehouden, terwijl computertechnologieën mensen helpen de volgende generatie chiptechnologie te ontwerpen. Maar AI zal veel directer zijn.

[^16]: Het is belangrijk om het even te laten bezinken dat AI – binnenkort – zichzelf zou kunnen verbeteren op een tijdschaal van dagen of weken. Of minder. Houd dit in gedachten wanneer iemand je vertelt dat een AI-capaciteit zeker ver weg is.
