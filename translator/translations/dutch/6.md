# Hoofdstuk 6 - De race naar AGI

Wat zijn de drijvende krachten achter de race om AGI te bouwen, voor zowel bedrijven als landen?

De recente snelle vooruitgang in AI heeft zowel geleid tot als geresulteerd in een buitengewoon niveau van aandacht en investeringen. Dit wordt deels gedreven door succes in AI-ontwikkeling, maar er speelt meer. Waarom racen enkele van de grootste bedrijven ter wereld, en zelfs landen, om niet alleen AI te bouwen, maar AGI en superintelligentie?

## Wat heeft AI-onderzoek richting menselijk-niveau AI gedreven

Tot ongeveer de laatste vijf jaar was AI grotendeels een academisch en wetenschappelijk onderzoeksprobleem, dus grotendeels gedreven door nieuwsgierigheid en de drang om intelligentie te begrijpen en hoe deze in een nieuw substraat te creëren.

In deze fase werd er relatief weinig aandacht besteed aan de voordelen of gevaren van AI onder de meeste onderzoekers. Wanneer gevraagd waarom AI zou moeten worden ontwikkeld, zou een veelvoorkomend antwoord zijn om enigszins vaag problemen op te sommen waar AI mee zou kunnen helpen: nieuwe geneesmiddelen, nieuwe materialen, nieuwe wetenschap, slimmere processen, en in het algemeen dingen verbeteren voor mensen.[^1]

Dit zijn bewonderenswaardige doelen![^2] Hoewel we kunnen en zullen vragen of AGI – in plaats van AI in het algemeen – noodzakelijk is voor deze doelen, tonen ze het idealisme waarmee veel AI-onderzoekers begonnen.

In de afgelopen vijf jaar is AI echter getransformeerd van een relatief puur onderzoeksveld naar veel meer een engineering- en productveld, grotendeels gedreven door enkele van 's werelds grootste bedrijven.[^3] Onderzoekers zijn, hoewel relevant, niet langer de leiding over het proces.

## Waarom proberen bedrijven AGI te bouwen?

Dus waarom storten gigantische bedrijven (en nog meer investeerders) enorme middelen in het bouwen van AGI? Er zijn twee drijfveren waar de meeste bedrijven vrij eerlijk over zijn: zij zien AI als drijvers van productiviteit voor de samenleving, en van winst voor henzelf. Omdat algemene AI van nature algemeen toepasbaar is, is er een enorme prijs: in plaats van een sector te kiezen waarin producten en diensten te creëren, kan men *ze allemaal tegelijk* proberen. Big Tech-bedrijven zijn enorm gegroeid door digitale goederen en diensten te produceren, en minstens enkele leidinggevenden zien AI zeker gewoon als de volgende stap in het goed leveren ervan, met risico's en voordelen die uitbreiden op maar een echo zijn van die geboden door zoekmachines, sociale media, laptops, telefoons, enz.

Maar waarom AGI? Er is een heel eenvoudig antwoord hierop, waar de meeste bedrijven en investeerders schuw van wegblijven om publiekelijk te bespreken.[^4]

Het is dat AGI direct, één-op-één, *werknemers kan vervangen.*

Niet versterken, niet empoweren, niet productiever maken. Niet eens *verdringen.* Dit alles kan en zal gedaan worden door non-AGI. AGI is specifiek wat volledig denkende werknemers kan *vervangen* (en met robotica, ook veel fysieke werknemers.) Als ondersteuning voor dit standpunt hoeft men niet verder te kijken dan OpenAI's [(publiek verklaarde) definitie](https://openai.com/our-structure/) van AGI, namelijk "een zeer autonoom systeem dat beter presteert dan mensen bij het meeste economisch waardevolle werk."

De prijs hier (voor bedrijven!) is enorm. Arbeidskosten zijn een substantieel percentage van 's werelds ∼$100 biljoen mondiale economie. Zelfs als slechts een fractie hiervan wordt veroverd door vervanging van menselijke arbeid door AI-arbeid, gaat dit om biljoenen dollars aan jaarlijkse omzet. AI-bedrijven zijn zich ook bewust van wie bereid is te betalen. Zoals zij het zien, ga jij niet duizenden dollars per jaar betalen voor productiviteitstools. Maar een bedrijf *zal* duizenden dollars per jaar betalen om jouw arbeid te vervangen, als ze dat kunnen.

## Waarom landen het gevoel hebben dat ze moeten racen naar AGI

Landen stellen motivaties voor het nastreven van AGI die zich richten op economisch en wetenschappelijk leiderschap. Het argument is overtuigend: AGI zou wetenschappelijk onderzoek, technologische ontwikkeling en economische groei dramatisch kunnen versnellen. Gezien wat er op het spel staat, beweren zij, kan geen grote mogendheid zich veroorloven achter te blijven.[^5]

Maar er zijn ook aanvullende en grotendeels onuitgesproken drijfveren. Er is geen twijfel dat wanneer bepaalde militaire en nationale veiligheidsleiders achter gesloten deuren bijeenkomen om een buitengewoon krachtige en catastrophaal risicovolle technologie te bespreken, hun focus niet ligt op "hoe vermijden we die risico's" maar eerder "hoe krijgen we dit eerst?" Militaire en inlichtingenleiders zien AGI als een potentiële revolutie in militaire aangelegenheden, misschien wel de meest significante sinds kernwapens. De vrees is dat het eerste land dat AGI ontwikkelt een onoverkoomelijk strategisch voordeel zou kunnen krijgen. Dit creëert een klassieke wapenwedloop-dynamiek.

We zullen zien dat dit "race naar AGI"-denken,[^6] hoewel overtuigend, diep gebrekkig is. Dit is niet omdat racen gevaarlijk en riskant is – hoewel het dat is – maar vanwege de aard van de technologie. De onuitgesproken aanname is dat AGI, zoals andere technologieën, controleerbaar is door de staat die het ontwikkelt, en een macht-verlenende zegen is voor de samenleving die er het meest van heeft. Zoals we zullen zien, zal het waarschijnlijk geen van beide zijn.

## Waarom superintelligentie?

Terwijl bedrijven publiekelijk focussen op productiviteit, en landen op economische en technologische groei, zijn dit voor degenen die bewust volledige AGI en superintelligentie nastreven slechts het begin. Wat hebben zij werkelijk voor ogen? Hoewel zelden hardop gezegd, omvatten zij:

1. Geneesmiddelen voor veel of alle ziektes;
2. Stoppen en omkering van veroudering;
3. Nieuwe duurzame energiebronnen zoals fusie;
4. Menselijke upgrades, of ontworpen organismen via genetische manipulatie;
5. Nanotechnologie en moleculaire fabricage;
6. Mind uploads;
7. Exotische fysica of ruimtetechnologieën;
8. Super-menselijk advies en beslissingsondersteuning;
9. Super-menselijke planning en coördinatie.

De eerste drie zijn grotendeels "enkelzijdige" technologieën – d.w.z. waarschijnlijk vrij sterk netto positief. Het is moeilijk te argumenteren tegen het genezen van ziektes of langer kunnen leven als men dat kiest. En we hebben al de negatieve kant van fusie geoogst (in de vorm van kernwapens); het zou mooi zijn nu de positieve kant te krijgen. De vraag bij deze eerste categorie is of het eerder krijgen van deze technologieën het risico compenseert.

De volgende vier zijn duidelijk tweesnijdend: transformatieve technologieën met zowel potentieel enorme voordelen als immense risico's, net als AI. Al deze zouden, als ze morgen uit een zwarte doos zouden springen en ingezet werden, ongelooflijk moeilijk te beheren zijn.[^7]

De laatste twee betreffen de super-menselijke AI die zelf dingen doet in plaats van alleen technologie uitvinden. Meer precies, eufemismen terzijde latend, behelzen deze krachtige AI-systemen die mensen vertellen wat te doen. Dit "advies" noemen is onoprecht als het systeem dat adviseert veel machtiger is dan de geadviseerde, die de basis van de beslissing niet betekenisvol kan begrijpen (of zelfs als dit wordt verstrekt, er niet op kan vertrouwen dat de adviseur niet een even overtuigende rationale zou verstrekken voor een andere beslissing.)

Dit wijst naar een belangrijk item dat ontbreekt in bovenstaande lijst:

10. Macht.

Het is overduidelijk dat veel van wat ten grondslag ligt aan de huidige race voor super-menselijke AI het idee is dat *intelligentie = macht*. Elke racer zet erop in de beste houder van die macht te zijn, en dat zij deze zullen kunnen hanteren voor ogenschijnlijk welwillende redenen zonder dat het uit hun controle glipt of wordt weggenomen.

Dat wil zeggen, wat bedrijven en naties werkelijk najagen is niet alleen de vruchten van AGI en superintelligentie, maar de macht om te controleren wie er toegang toe krijgt en hoe ze worden gebruikt. Bedrijven zien zichzelf als verantwoordelijke beheerders van deze macht ten dienste van aandeelhouders en de mensheid; naties zien zichzelf als noodzakelijke bewakers die voorkomen dat vijandige machten beslissend voordeel verkrijgen. Beiden hebben gevaarlijk ongelijk, falen erin te erkennen dat superintelligentie, door haar aard, niet betrouwbaar gecontroleerd kan worden door enige menselijke instelling. We zullen zien dat de aard en dynamiek van superintelligente systemen menselijke controle extreem moeilijk, zo niet onmogelijk maken.

Deze race-dynamieken – zowel bedrijfsmatig als geopolitiek – maken bepaalde risico's bijna onvermijdelijk tenzij ze beslist worden onderbroken. We keren ons nu naar het onderzoeken van deze risico's en waarom ze niet adequaat kunnen worden beperkt binnen een competitief [^8] ontwikkelingsparadigma.

[^1]: Een preciezere lijst van waardige doelen zijn de VN [Duurzame Ontwikkelingsdoelen.](https://sdgs.un.org/goals) Dit zijn, in zekere zin, het dichtst wat we hebben bij een set van mondiale consensusdoelen voor wat we graag verbeterd zouden zien in de wereld. AI zou kunnen helpen.

[^2]: Technologie in het algemeen heeft een transformatieve economische en sociale kracht voor menselijke verbetering, zoals duizenden jaren betuigen. In deze geest kan een lange en overtuigende uiteenzetting van een positieve AGI-visie worden gevonden in [dit essay](https://darioamodei.com/machines-of-loving-grace) door Anthropic-oprichter Dario Amodei.

[^3]: Private AI-investeringen [begonnen te boomen in 2018-19, kruisten publieke investeringen rond die tijd,](https://cset.georgetown.edu/publication/tracking-ai-investment/) en hebben deze sindsdien enorm overtroffen.

[^4]: Ik kan betuigen dat achter meer gesloten deuren, zij geen dergelijke schroom hebben. En het wordt publiekelijker; zie bijvoorbeeld Y-combinator's nieuwe ["request for startups"](https://www.ycombinator.com/rfs), waarvan vele delen expliciet oproepen tot grootschalige vervanging van menselijke werknemers. Om hen te citeren, "De waardepropositie van B2B SaaS was om menselijke werknemers incrementeel efficiënter te maken. De waardepropositie van verticale AI-agenten is om het werk geheel te automatiseren...Het is volledig mogelijk dat deze kans groot genoeg is om nog eens 100 eenhoorns te slaan." (Voor degenen niet thuis in Silicon Valley-spreektaal, "B2B" is business-to-business en een eenhoorn is een $1 miljard bedrijf. Dat wil zeggen ze praten over meer dan honderd miljard-plus-dollar bedrijven die werknemers vervangen voor andere bedrijven.)

[^5]: Zie bijvoorbeeld een recent [US-China Economic and Security Review Commission rapport](https://www.uscc.gov/sites/default/files/2024-11/2024_Executive_Summary.pdf). Hoewel er verrassend weinig rechtvaardiging binnen het rapport zelf was, was de toplijn-aanbeveling dat de VS "Congres een Manhattan Project-achtig programma moet oprichten en financieren gewijd aan het racen naar en verwerven van een Artificiële Algemene Intelligentie (AGI) capaciteit."

[^6]: Bedrijven nemen nu deze geopolitieke framing over als schild tegen elke beperking op hun AI-ontwikkeling, over het algemeen op manieren die schaamteloos eigenbelang dienen, en soms op manieren die niet eens elementaire zin maken. Overweeg Meta's [Approach to Frontier AI](https://about.fb.com/news/2025/02/meta-approach-frontier-ai/), die tegelijkertijd argumenteert dat Amerika zijn "\[positie moet cementen\] als leider in technologische innovatie, economische groei en nationale veiligheid" en ook dat het dit moet doen door openlijk zijn krachtigste AI-systemen vrij te geven – wat inhoudt ze direct te geven aan zijn geopolitieke rivalen en tegenstanders.

[^7]: Dus zouden we waarschijnlijk het beheer van deze technologieën aan de AI's moeten overlaten. Maar dit zou een zeer problematische delegatie van controle zijn, waar we hieronder op terugkomen.

[^8]: Competitie in technologieontwikkeling brengt vaak belangrijke voordelen: voorkomen van monopolistische controle, innovatie en kostenreductie stimuleren, diverse benaderingen mogelijk maken, en wederzijds toezicht creëren. Bij AGI moeten deze voordelen echter worden afgewogen tegen unieke risico's van race-dynamieken en druk om veiligheidsvoorzorgen te verminderen.
