# Chapitre 1 - Introduction

La façon dont nous réagirons à la perspective d'une IA plus intelligente que l'humain est l'enjeu le plus pressant de notre époque. Cet essai propose une voie à suivre.

Nous nous trouvons peut-être à la fin de l'ère humaine.

Quelque chose a commencé au cours des dix dernières années qui est unique dans l'histoire de notre espèce. Ses conséquences détermineront, dans une large mesure, l'avenir de l'humanité. À partir de 2015 environ, les chercheurs ont réussi à développer une intelligence artificielle (IA) *spécialisée* – des systèmes capables de gagner à des jeux comme le Go, de reconnaître des images et la parole, et bien d'autres choses, mieux que n'importe quel humain.[^1]

C'est un succès remarquable, qui produit des systèmes et des produits extrêmement utiles qui renforceront les capacités humaines. Mais l'intelligence artificielle spécialisée n'a jamais été le véritable objectif du domaine. L'ambition a plutôt été de créer des systèmes d'IA *polyvalents*, notamment ceux souvent appelés « intelligence artificielle générale » (IAG) ou « superintelligence », qui sont simultanément aussi performants ou meilleurs que les humains dans presque *toutes* les tâches, tout comme l'IA surpasse aujourd'hui l'humain au Go, aux échecs, au poker, aux courses de drones, etc. C'est l'objectif déclaré de nombreuses grandes entreprises d'IA.[^2]

*Ces efforts réussissent également.* Les systèmes d'IA polyvalents comme ChatGPT, Gemini, Llama, Grok, Claude et Deepseek, basés sur des calculs massifs et des montagnes de données, ont atteint la parité avec les humains ordinaires dans une grande variété de tâches, et égalent même les experts humains dans certains domaines. Aujourd'hui, les ingénieurs en IA de quelques-unes des plus grandes entreprises technologiques s'efforcent de pousser ces expériences géantes d'intelligence artificielle vers les niveaux suivants, où elles égaleront puis dépasseront toute la gamme des capacités, expertises et autonomie humaines.

*Cela est imminent.* Au cours des dix dernières années, les estimations d'experts sur le temps que cela prendra – si nous poursuivons notre trajectoire actuelle – sont passées de décennies (ou de siècles) à quelques années seulement.

C'est aussi d'une importance historique et représente un risque transcendant. Les partisans de l'IAG y voient une transformation positive qui résoudra les problèmes scientifiques, guérira les maladies, développera de nouvelles technologies et automatisera les corvées. Et l'IA pourrait certainement contribuer à réaliser tout cela – d'ailleurs, elle le fait déjà. Mais au fil des décennies, de nombreux penseurs attentifs, d'Alan Turing à Stephen Hawking en passant par Geoffrey Hinton et Yoshua Bengio d'aujourd'hui[^3], ont lancé un avertissement sévère : construire une IA véritablement plus intelligente que l'humain, générale et autonome bouleversera au minimum complètement et irréversiblement la société, et au maximum entraînera l'extinction humaine.[^4]

La superintelligence artificielle approche rapidement sur notre trajectoire actuelle, mais elle est loin d'être inévitable. Cet essai est un argument développé expliquant pourquoi et comment nous devrions *fermer les Portes* à cet avenir inhumain qui approche, et ce que nous devrions faire à la place.


[^1]: Ce [graphique](https://time.com/6300942/ai-progress-charts/) montre un ensemble de tâches ; de nombreuses courbes similaires pourraient être ajoutées à ce graphique. Ces progrès rapides de l'IA spécialisée ont surpris même les experts du domaine, avec des références dépassées des années avant les prédictions.

[^2]: Deepmind, OpenAI, Anthropic et X.ai ont tous été fondés avec l'objectif spécifique de développer l'IAG. Par exemple, la charte d'OpenAI énonce explicitement son objectif comme développer « une intelligence artificielle générale qui profite à toute l'humanité », tandis que la mission de DeepMind est « résoudre l'intelligence, puis l'utiliser pour tout résoudre ». Meta, Microsoft et d'autres poursuivent désormais des voies substantiellement similaires. Meta a déclaré qu'elle [prévoit de développer l'IAG et de la diffuser ouvertement.](https://www.forbes.com/sites/johnkoetsier/2024/01/18/zuckerberg-on-ai-meta-building-agi-for-everyone-and-open-sourcing-it/)

[^3]: Hinton et Bengio sont deux des chercheurs en IA les plus cités, ont tous deux remporté le Nobel de l'IA, le prix Turing, et Hinton a en plus remporté un prix Nobel (en physique).

[^4]: Construire quelque chose de ce niveau de risque, sous des incitations commerciales et une surveillance gouvernementale quasi nulle, est absolument sans précédent. Il n'y a même pas de controverse sur le risque parmi ceux qui le construisent ! Les dirigeants de Deepmind, OpenAI et Anthropic, parmi de nombreux autres experts, ont tous littéralement signé une [déclaration](https://www.safe.ai/work/statement-on-ai-risk) affirmant que l'IA avancée pose un *risque d'extinction pour l'humanité.* Les signaux d'alarme ne pourraient pas sonner plus fort, et on ne peut que conclure que ceux qui les ignorent ne prennent tout simplement pas l'IAG et la superintelligence au sérieux. L'un des objectifs de cet essai est de les aider à comprendre pourquoi ils le devraient.