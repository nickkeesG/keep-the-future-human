# Chapitre 10 - Le choix qui s'offre à nous

Pour préserver notre avenir humain, nous devons choisir de fermer les Portes à l'IAG et à la superintelligence.

La dernière fois que l'humanité a partagé la Terre avec d'autres esprits qui parlaient, pensaient, construisaient des technologies et résolvaient des problèmes de manière polyvalente, c'était il y a 40 000 ans dans l'Europe de l'ère glaciaire. Ces autres esprits se sont éteints, en partie ou entièrement à cause des efforts des nôtres.

Nous entrons à nouveau dans une telle époque. Les produits les plus avancés de notre culture et de notre technologie – des jeux de données construits à partir de l'ensemble de notre patrimoine informationnel d'internet, et des puces de 100 milliards d'éléments qui sont les technologies les plus complexes que nous ayons jamais créées – sont combinés pour donner naissance à des systèmes d'IA polyvalents avancés.

Les développeurs de ces systèmes sont soucieux de les présenter comme des outils d'autonomisation humaine. Et en effet, ils pourraient l'être. Mais ne nous y trompons pas : notre trajectoire actuelle consiste à construire des agents numériques de plus en plus puissants, orientés vers des objectifs, capables de prendre des décisions et généralement compétents. Ils performent déjà aussi bien que de nombreux humains dans un large éventail de tâches intellectuelles, s'améliorent rapidement, et contribuent à leur propre amélioration.

À moins que cette trajectoire ne change ou ne rencontre un obstacle imprévu, nous aurons bientôt – en années, pas en décennies – des intelligences numériques dangereusement puissantes. Même dans le *meilleur* des scénarios, celles-ci apporteraient de grands bénéfices économiques (du moins à certains d'entre nous) mais seulement au prix d'une profonde perturbation de notre société, et du remplacement des humains dans la plupart des choses les plus importantes que nous faisons : ces machines penseraient pour nous, planifieraient pour nous, décideraient pour nous, et créeraient pour nous. Nous serions gâtés, mais comme des enfants gâtés. Il est bien plus probable que ces systèmes remplacent les humains aussi bien dans les choses positives *que* négatives que nous faisons, notamment l'exploitation, la manipulation, la violence et la guerre. Pouvons-nous survivre à des versions suralimentées par l'IA de ces fléaux ? Enfin, il est plus que plausible que les choses ne se passent pas bien du tout : que relativement vite nous soyons remplacés non seulement dans ce que nous faisons, mais dans ce que nous *sommes*, en tant qu'architectes de la civilisation et de l'avenir. Demandez aux néandertaliens comment cela se passe. Peut-être leur avons-nous fourni des babioles supplémentaires pendant un moment également.

*Nous n'avons pas à faire cela.* Nous avons une IA compétitive par rapport aux humains, et il n'y a aucune nécessité de construire une IA avec laquelle nous *ne pouvons pas* rivaliser. Nous pouvons construire des outils d'IA extraordinaires sans construire une espèce successeur. L'idée que l'IAG et la superintelligence sont inévitables est un *choix qui se déguise en fatalité*.

En imposant certaines limites strictes et mondiales, nous pouvons maintenir la capacité générale de l'IA à approximativement le niveau humain tout en récoltant les bénéfices de la capacité des ordinateurs à traiter les données de manières que nous ne pouvons pas, et à automatiser des tâches qu'aucun de nous ne veut faire. Ceux-ci présenteraient encore de nombreux risques, mais s'ils sont bien conçus et bien gérés, seraient un énorme bienfait pour l'humanité, de la médecine à la recherche en passant par les produits de consommation.

Imposer des limites nécessiterait une coopération internationale, mais moins qu'on pourrait le penser, et ces limites laisseraient encore largement place à une énorme industrie de l'IA et du matériel IA axée sur des applications qui améliorent le bien-être humain, plutôt que sur la poursuite pure du pouvoir. Et si, avec de solides garanties de sécurité et après un dialogue mondial significatif, nous décidons d'aller plus loin, cette option continue d'être nôtre à poursuivre.

L'humanité doit *choisir* de fermer les Portes à l'IAG et à la superintelligence.

Pour garder l'avenir humain.

## Note de l'auteur

Merci d'avoir pris le temps d'explorer ce sujet avec nous.

J'ai écrit cet essai parce qu'en tant que scientifique, je pense qu'il est important de dire la vérité sans fard, et parce qu'en tant que personne, je pense qu'il est crucial pour nous d'agir rapidement et de manière décisive face à un enjeu qui change le monde : le développement de systèmes d'IA plus intelligents que les humains.

Si nous devons répondre à cet état de fait remarquable avec sagesse, nous devons être prêts à examiner de manière critique le narratif dominant selon lequel l'IAG et la superintelligence « doivent » être construites pour sécuriser nos intérêts, ou sont « inévitables » et ne peuvent être arrêtées. Ces narratifs nous privent de notre pouvoir, nous empêchent de voir les voies alternatives qui s'ouvrent devant nous.

J'espère que vous vous joindrez à moi pour appeler à la prudence face à l'imprudence, et au courage face à la cupidité.

J'espère que vous vous joindrez à moi pour appeler à un avenir humain.

*– Anthony*

![Anthony Aguirre signature](https://keepthefuturehuman.ai/essay/_next/image?url=https%3A%2F%2Fkeepthefuturehuman.ai%2Fwp-content%2Fuploads%2F2025%2F02%2FAnthony-Aguirre-signature-300x84.png&w=3840&q=75)