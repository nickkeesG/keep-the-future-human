# Chapitre 5 - Au seuil

Le chemin qui nous mène des systèmes d'IA actuels à une IAG pleinement développée semble d'une brièveté et d'une prévisibilité saisissantes.

Les dix dernières années ont été témoins d'avancées spectaculaires en IA, alimentées par des ressources [computationnelles](https://epoch.ai/blog/training-compute-of-frontier-ai-models-grows-by-4-5x-per-year), humaines et [financières](https://arxiv.org/abs/2405.21015) considérables. De nombreuses applications d'IA spécialisée surpassent les humains dans leurs tâches assignées, et sont certainement bien plus rapides et économiques.[^1] Il existe aussi des agents spécialisés surhumains qui écrasent tous les humains dans des jeux à domaine restreint comme le [Go](https://www.nature.com/articles/nature16961), les [échecs](https://arxiv.org/abs/1712.01815) et le [poker](https://www.deepstack.ai/), ainsi que des [agents plus généralistes](https://deepmind.google/discover/blog/a-generalist-agent/) capables de planifier et d'exécuter des actions dans des environnements simulés simplifiés avec autant d'efficacité que les humains.

Plus remarquables encore, les systèmes d'IA générale actuels d'OpenAI/Microsoft, Google/Deepmind, Anthropic/Amazon, Facebook/Meta, X.ai/Tesla et autres [^2] ont émergé depuis le début 2023 et ont régulièrement (bien qu'inégalement) accru leurs capacités depuis. Tous ont été créés par prédiction de tokens sur d'immenses ensembles de données textuelles et multimédias, combinée à un retour de renforcement extensif de la part d'humains et d'autres systèmes d'IA. Certains incluent également de vastes systèmes d'outils et d'architectures de support.

## Forces et faiblesses des systèmes généralistes actuels

Ces systèmes performent bien dans une gamme de plus en plus large de tests conçus pour mesurer l'intelligence et l'expertise, avec des progrès qui ont surpris même les experts du domaine :

- Lors de sa première sortie, GPT-4 [égalait ou dépassait les performances humaines typiques](https://arxiv.org/abs/2303.08774) aux tests académiques standards incluant les SAT, GRE, examens d'entrée et examens du barreau. Les modèles plus récents performent probablement significativement mieux, bien que les résultats ne soient pas publiquement disponibles.
- Le test de Turing – longtemps considéré comme un critère clé pour une IA « véritable » – est désormais régulièrement réussi sous certaines formes par les modèles de langage modernes, tant informellement que dans des [études formelles](https://arxiv.org/abs/2405.08007).[^3]
- Sur le benchmark MMLU couvrant 57 matières académiques, [les modèles récents atteignent des scores au niveau d'experts du domaine](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu) (∼90%) [^4]
- L'expertise technique a progressé de manière spectaculaire : Le benchmark GPQA de physique de niveau universitaire a vu [ses performances bondir](https://epoch.ai/data/ai-benchmarking-dashboard) de quasi-aléatoires (GPT-4, 2022) au niveau expert (o1-preview, 2024).
- Même les tests spécifiquement conçus pour résister à l'IA tombent : O3 d'OpenAI [résoudrait](https://www.nextbigfuture.com/2024/12/openai-releases-o3-model-with-high-performance-and-high-cost.html) le benchmark de résolution de problèmes abstraits ARC-AGI au niveau humain, atteint des performances de programmation au niveau des meilleurs experts, et obtient 25% sur les problèmes de « mathématiques de pointe » d'Epoch AI conçus pour défier les mathématiciens d'élite.[^5]
- La tendance est si claire que le développeur de MMLU a maintenant créé [« Le dernier examen de l'humanité »](https://agi.safe.ai/) – un nom inquiétant reflétant la possibilité que l'IA dépasse bientôt les performances humaines sur tout test significatif. Au moment de la rédaction, il y a des affirmations de systèmes d'IA atteignant 27% (selon [Sam Altman](https://x.com/sama/status/1886220281565381078)) et 35% (selon [cet article](https://arxiv.org/abs/2502.09955)) sur cet examen extrêmement difficile. Il est très improbable qu'un humain individuel puisse le faire.

Malgré ces chiffres impressionnants (et leur intelligence évidente quand on interagit avec eux) [^6] il y a beaucoup de choses que (du moins les versions publiées de) ces réseaux de neurones *ne peuvent pas* faire. Actuellement, la plupart sont désincarnés – n'existant que sur des serveurs – et ne traitent au mieux que du texte, du son et des images fixes (mais pas de vidéo). Crucialement, la plupart ne peuvent pas mener d'activités complexes planifiées nécessitant une haute précision.[^7] Et il y a un certain nombre d'autres qualités fortes dans la cognition humaine de haut niveau actuellement faibles dans les systèmes d'IA publiés.

Le tableau suivant en énumère un certain nombre, basé sur les systèmes d'IA de mi-2024 tels que GPT-4o, Claude 3.5 Sonnet, et Google Gemini 1.5.[^8] La question clé pour déterminer à quelle vitesse l'IA générale deviendra plus puissante est : dans quelle mesure faire simplement *plus de la même chose* produira-t-il des résultats, par opposition à ajouter des techniques supplémentaires mais *connues*, par opposition à développer ou implémenter des directions de recherche en IA *vraiment nouvelles*. Mes propres prédictions à ce sujet sont données dans le tableau, en termes de probabilité que chacun de ces scénarios amène cette capacité au niveau humain et au-delà.

<table><tbody><tr><th>Capacité</th><th>Description de la capacité</th><th>Statut/pronostic</th><th>Échelle/connu/nouveau</th></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td colspan="4"><em>Capacités cognitives fondamentales</em></td></tr><tr><td>Raisonnement</td><td>Les gens peuvent faire un raisonnement précis, multi-étapes, suivant des règles et vérifiant la précision.</td><td>Progrès récents spectaculaires utilisant les chaînes de raisonnement étendues et le réentraînement</td><td>95/5/5</td></tr><tr><td>Planification</td><td>Les gens présentent une planification à long terme et hiérarchique.</td><td>S'améliore avec l'échelle ; peut être fortement aidée par l'architecture de support et de meilleures techniques d'entraînement.</td><td>10/85/5</td></tr><tr><td>Ancrage dans la vérité</td><td>Les IA générales confabulent des informations non fondées pour satisfaire les requêtes.</td><td>S'améliore avec l'échelle ; données de calibrage disponibles dans le modèle ; peut être vérifié/amélioré via l'architecture de support.</td><td>30/65/5</td></tr><tr><td>Résolution flexible de problèmes</td><td>Les humains peuvent reconnaître de nouveaux motifs et inventer de nouvelles solutions à des problèmes complexes ; les modèles d'apprentissage automatique actuels peinent.</td><td>S'améliore avec l'échelle mais faiblement ; peut être résolvable avec des techniques neurosymboliques ou de « recherche » généralisée.</td><td>15/75/10</td></tr><tr><td colspan="4"><em>Apprentissage et connaissance</em></td></tr><tr><td>Apprentissage et mémoire</td><td>Les gens ont une mémoire de travail, à court terme et à long terme, toutes dynamiques et interreliées.</td><td>Tous les modèles apprennent pendant l'entraînement ; les IA générales apprennent dans la fenêtre contextuelle et pendant l'ajustement fin ; l'« apprentissage continu » et autres techniques existent mais ne sont pas encore intégrés dans les grandes IA générales.</td><td>5/80/15</td></tr><tr><td>Abstraction et récursion</td><td>Les gens peuvent mapper et transférer des ensembles de relations en d'autres plus abstraits pour le raisonnement et la manipulation, incluant le raisonnement « méta » récursif.</td><td>S'améliore faiblement avec l'échelle ; pourrait émerger dans les systèmes neurosymboliques.</td><td>30/50/20</td></tr><tr><td>Modèle(s) du monde</td><td>Les gens ont et mettent continuellement à jour un modèle prédictif du monde dans lequel ils peuvent résoudre des problèmes et faire du raisonnement physique</td><td>S'améliore avec l'échelle ; la mise à jour liée à l'apprentissage ; les IA générales faibles en prédiction du monde réel.</td><td>20/50/30</td></tr><tr><td colspan="4"><em>Soi et agentivité</em></td></tr><tr><td>Agentivité</td><td>Les gens peuvent prendre des actions pour poursuivre des objectifs, basées sur la planification/prédiction.</td><td>Beaucoup de systèmes d'apprentissage automatique sont agentiques ; les LLM peuvent devenir agents via des enveloppes.</td><td>5/90/5</td></tr><tr><td>Auto-direction</td><td>Les gens développent et poursuivent leurs propres objectifs, avec motivation et élan générés intérieurement.</td><td>Largement composée d'agentivité plus originalité ; susceptible d'émerger dans des systèmes agentiels complexes avec des objectifs abstraits.</td><td>40/45/15</td></tr><tr><td>Auto-référence</td><td>Les gens se comprennent et raisonnent sur eux-mêmes comme situés dans un environnement/contexte.</td><td>S'améliore avec l'échelle et pourrait être augmentée avec une récompense d'entraînement.</td><td>70/15/15</td></tr><tr><td>Conscience de soi</td><td>Les gens ont connaissance et peuvent raisonner sur leurs propres pensées et états mentaux.</td><td>Existe dans un certain sens dans les IA générales, qui peuvent sans doute réussir le « test du miroir » classique de conscience de soi. Peut être améliorée avec l'architecture de support ; mais incertain si c'est suffisant.</td><td>20/55/25</td></tr><tr><td colspan="4"><em>Interface et environnement</em></td></tr><tr><td>Intelligence incarnée</td><td>Les gens comprennent et interagissent activement avec leur environnement du monde réel.</td><td>L'apprentissage par renforcement fonctionne bien dans des environnements simulés et du monde réel (robotique) et peut être intégré dans des transformateurs multimodaux.</td><td>5/85/10</td></tr><tr><td>Traitement multi-sensoriel</td><td>Les gens intègrent et traitent en temps réel des flux visuels, audio et autres flux sensoriels.</td><td>L'entraînement en modalités multiples semble « simplement fonctionner » et s'améliore avec l'échelle. Le traitement vidéo en temps réel est difficile mais par ex. les systèmes de conduite autonome s'améliorent rapidement.</td><td>30/60/10</td></tr><tr><td colspan="4"><em>Capacités d'ordre supérieur</em></td></tr><tr><td>Originalité</td><td>Les modèles d'apprentissage automatique actuels sont créatifs pour transformer et combiner des idées/œuvres existantes, mais les gens peuvent construire de nouveaux cadres et structures, parfois liés à leur identité.</td><td>Peut être difficile à discerner de la « créativité », qui peut évoluer vers cela ; peut émerger de la créativité plus la conscience de soi.</td><td>50/40/10</td></tr><tr><td>Sentience</td><td>Les gens expérimentent des qualia ; ceux-ci peuvent avoir une valence positive, négative ou neutre ; c'est « comme quelque chose » d'être une personne.</td><td>Très difficile et philosophiquement épineux de déterminer si un système donné possède cela.</td><td>5/10/85</td></tr></tbody></table>

Capacités clés actuellement sous le niveau d'expert humain dans les systèmes d'IA générale modernes, groupées par type. La troisième colonne résume le statut actuel. La dernière colonne montre la probabilité prédite (%) que la performance de niveau humain soit atteinte par : mise à l'échelle des techniques actuelles / combinaison avec des techniques connues / développement de nouvelles techniques. Ces capacités ne sont pas indépendantes, et l'augmentation de l'une s'accompagne typiquement d'augmentations des autres. Notez que toutes (particulièrement la sentience) ne sont pas nécessaires pour des systèmes d'IA capables de faire progresser le développement de l'IA, soulignant la possibilité d'une IA puissante mais non sentiente.

Décomposer ce qui « manque » de cette façon rend assez clair que nous sommes tout à fait sur la voie d'une intelligence largement supra-humaine en mettant à l'échelle les techniques existantes ou connues.[^9]

Il pourrait encore y avoir des surprises. Même en mettant de côté la « sentience », il pourrait y avoir certaines des capacités cognitives fondamentales listées qui ne peuvent vraiment pas être accomplies avec les techniques actuelles et nécessitent des nouvelles. Mais considérons ceci. L'effort actuel déployé par bon nombre des plus grandes entreprises mondiales équivaut à plusieurs fois les dépenses du projet Apollo et à des dizaines de fois celles du projet Manhattan,[^10] et emploie des milliers des meilleurs techniciens au monde à des salaires inouïs. La dynamique de ces dernières années a maintenant mobilisé plus de puissance intellectuelle humaine (avec l'IA maintenant ajoutée) que tout autre effort dans l'histoire. Nous ne devrions pas parier sur l'échec.

## La grande cible : les agents autonomes généralistes

Le développement de l'IA générale au cours des dernières années s'est concentré sur la création d'IA générale et puissante mais ressemblant à un outil : elle fonctionne principalement comme un assistant (assez) loyal, et généralement ne prend pas d'actions de son propre chef. C'est en partie par conception, mais largement parce que ces systèmes n'ont simplement pas été assez compétents dans les compétences pertinentes pour être chargés d'actions complexes.[^11]

Les entreprises d'IA et les chercheurs [déplacent cependant de plus en plus l'attention](https://www.axios.com/2025/01/23/davos-2025-ai-agents) vers des agents généralistes *autonomes* de niveau expert.[^12] Cela permettrait aux systèmes d'agir plus comme un assistant humain à qui l'utilisateur peut déléguer de vraies actions.[^13] Que faudra-t-il pour cela ? Un certain nombre des capacités du tableau « ce qui manque » sont impliquées, incluant un fort ancrage dans la vérité, l'apprentissage et la mémoire, l'abstraction et la récursion, et la modélisation du monde (pour l'intelligence), la planification, l'agentivité, l'originalité, l'auto-direction, l'auto-référence, et la conscience de soi (pour l'autonomie), et le traitement multi-sensoriel, l'intelligence incarnée, et la résolution flexible de problèmes (pour la généralité).[^14]

Cette triple intersection de haute autonomie (indépendance d'action), haute généralité (portée et étendue des tâches) et haute intelligence (compétence aux tâches cognitives) est actuellement unique aux humains. C'est implicitement ce que beaucoup ont probablement à l'esprit quand ils pensent à l'IAG – tant en termes de valeur que de risques.

Cela fournit une autre façon de définir I-A-G comme Intelligence ***A***utonome- ***G***énérale, et nous verrons que cette triple intersection fournit une perspective très précieuse pour les systèmes de haute capacité tant pour comprendre leurs risques et récompenses que pour la gouvernance de l'IA.

![](https://keepthefuturehuman.ai/essay/_next/image?url=https%3A%2F%2Fkeepthefuturehuman.ai%2Fwp-content%2Fuploads%2F2025%2F02%2FAGI-Venn-Diagram-Simple-1024x1024.png&w=3840&q=75) La zone transformatrice de puissance et de risque I-A-G émerge de l'intersection de trois propriétés clés : haute Autonomie, haute Intelligence aux tâches, et haute Généralité.

## Le cycle d'amélioration (auto-)amélioration de l'IA

Un facteur final crucial pour comprendre le progrès de l'IA est la boucle de rétroaction technologique unique de l'IA. Dans le développement de l'IA, le succès – tant dans les systèmes démontrés que dans les produits déployés – apporte investissement, talent et concurrence supplémentaires, et nous sommes actuellement au milieu d'une énorme boucle de rétroaction battage-plus-réalité de l'IA qui drive des centaines de milliards, voire des billions, de dollars d'investissement.

Ce type de cycle de rétroaction pourrait arriver avec n'importe quelle technologie, et nous l'avons vu dans beaucoup, où le succès commercial engendre l'investissement, qui engendre l'amélioration et un meilleur succès commercial. Mais le développement de l'IA va plus loin, en ce que maintenant les systèmes d'IA aident à développer des systèmes d'IA nouveaux et plus puissants.[^15] Nous pouvons penser à cette boucle de rétroaction en cinq étapes, chacune avec une échelle de temps plus courte que la précédente, comme montré dans le tableau.

*Le cycle d'amélioration de l'IA opère à travers de multiples échelles de temps, avec chaque étape accélérant potentiellement les étapes suivantes. Les étapes antérieures sont bien engagées, tandis que les étapes ultérieures restent spéculatives mais pourraient procéder très rapidement une fois débloquées.*

Plusieurs de ces étapes sont déjà en cours, et quelques-unes commencent clairement. La dernière étape, dans laquelle les systèmes d'IA s'améliorent autonomement eux-mêmes, a été un pilier de la littérature sur le risque de systèmes d'IA très puissants, et pour de bonnes raisons.[^16] Mais il est important de noter que c'est juste la forme la plus drastique d'un cycle de rétroaction qui a déjà commencé et pourrait mener à plus de surprises dans l'avancement rapide de la technologie.


[^1]: Vous utilisez beaucoup plus de cette IA que vous ne le pensez probablement, alimentant la génération et reconnaissance vocale, le traitement d'images, les algorithmes de flux d'actualités, etc.

[^2]: Bien que les relations entre ces paires d'entreprises soient assez complexes et nuancées, je les ai explicitement listées pour indiquer à la fois la vaste capitalisation boursière globale des firmes maintenant engagées dans le développement de l'IA, et aussi que derrière même des entreprises « plus petites » comme Anthropic se trouvent des poches énormément profondes via des investissements et des accords de partenariat majeurs.

[^3]: Il est devenu à la mode de dénigrer le test de Turing, mais il est assez puissant et général. Dans les versions faibles, il indique si des gens typiques interagissant avec une IA (qui est entraînée à agir humainement) de manières typiques pendant de brèves périodes peuvent dire si c'est une IA. Ils ne peuvent pas. Deuxièmement, un test de Turing hautement adversarial peut sonder essentiellement tout élément de capacité et d'intelligence humaines – par ex. en comparant un système d'IA à un expert humain, évalué par d'autres experts humains. Il y a un sens dans lequel une grande partie de l'évaluation de l'IA est une forme généralisée de test de Turing.

[^4]: C'est par domaine – aucun humain ne pourrait plausiblement atteindre de tels scores à travers toutes les matières simultanément.

[^5]: Ce sont des problèmes qui prendraient même à d'excellents mathématiciens un temps substantiel à résoudre, s'ils pouvaient les résoudre du tout.

[^6]: Si vous êtes d'un tempérament sceptique, gardez votre scepticisme mais essayez vraiment les modèles les plus actuels, ainsi que tentez par vous-même quelques-unes des questions de test qu'ils peuvent réussir. En tant que professeur de physique, je prédirais avec quasi-certitude que, par exemple, les meilleurs modèles réussiraient l'examen de qualification diplômant dans notre département.

[^7]: Ceci et d'autres faiblesses comme la confabulation ont ralenti l'adoption commerciale et mené à un écart entre les capacités perçues et revendiquées (qui doivent aussi être vues à travers le prisme de la concurrence de marché intense et le besoin d'attirer l'investissement). Cela a confondu tant le public que les décideurs politiques sur l'état réel du progrès de l'IA. Bien que peut-être ne correspondant pas au battage, le progrès est très réel.

[^8]: L'avancée majeure depuis lors a été le développement de systèmes entraînés pour un raisonnement de qualité supérieure, tirant parti de plus de calcul pendant l'inférence et d'un apprentissage par renforcement plus grand. Parce que ces modèles sont nouveaux et leurs capacités moins testées, je n'ai pas entièrement remanié ce tableau sauf pour le « raisonnement », que je considère comme essentiellement résolu. Mais j'ai mis à jour les prédictions basées sur les capacités expérimentées et rapportées de ces systèmes.

[^9]: Les vagues précédentes d'optimisme de l'IA dans les années 1960 et 1980 se sont terminées en « hivers de l'IA » quand les capacités promises ont échoué à se matérialiser. Cependant, la vague actuelle diffère fondamentalement en ayant atteint des performances surhumaines dans de nombreux domaines, soutenues par des ressources computationnelles massives et un succès commercial.

[^10]: Le projet Apollo complet [a coûté environ 250 milliards USD en dollars 2020](https://www.planetary.org/space-policy/cost-of-apollo), et le projet Manhattan [moins d'un dixième de cela](https://www.brookings.edu/the-costs-of-the-manhattan-project/). Goldman Sachs [projette mille milliards de dollars de dépenses juste sur les centres de données IA](https://www.datacenterdynamics.com/en/news/goldman-sachs-1tn-to-be-spent-on-ai-data-centers-chips-and-utility-upgrades-with-little-to-show-for-it-so-far/) dans les prochaines années.

[^11]: Bien que les humains fassent beaucoup d'erreurs, nous sous-estimons à quel point nous pouvons être fiables ! Parce que les probabilités se multiplient, une tâche nécessitant 20 étapes pour être faite correctement exige que chaque étape soit fiable à 97% juste pour la faire bien la moitié du temps. Nous faisons de telles tâches tout le temps.

[^12]: Un mouvement fort dans cette direction a très récemment été pris avec l'assistant [« Recherche Profonde »](https://openai.com/index/introducing-deep-research/) d'OpenAI qui effectue autonomement une recherche générale, décrit comme « une nouvelle capacité agentique qui conduit une recherche multi-étapes sur internet pour des tâches complexes ».

[^13]: Des choses comme remplir ce PDF embêtant, réserver des vols, etc. Mais avec un doctorat dans 20 domaines ! Donc aussi : écrire cette thèse pour vous, négocier ce contrat pour vous, prouver ce théorème pour vous, créer cette campagne publicitaire pour vous, etc. Que faites-*vous* ? Vous lui dites quoi faire, bien sûr.

[^14]: Notez que la sentience n'est *pas* clairement requise, ni l'IA dans cette triple intersection n'implique nécessairement cela.

[^15]: L'analogie la plus proche ici est peut-être la technologie des puces, où le développement a maintenu la loi de Moore pendant des décennies, alors que les technologies informatiques aident les gens à concevoir la prochaine génération de technologie de puce. Mais l'IA sera bien plus directe.

[^16]: Il est important de laisser cela s'imprégner un moment que l'IA pourrait – bientôt – s'améliorer elle-même sur une échelle de temps de jours ou semaines. Ou moins. Gardez cela à l'esprit quand quelqu'un vous dit qu'une capacité de l'IA est définitivement loin.