# Chapitre 6 - La course à l'IAG

Quelles sont les forces motrices derrière la course à la construction de l'IAG, tant pour les entreprises que pour les pays ?

Les progrès rapides récents de l'IA ont résulté d'un niveau extraordinaire d'attention et d'investissement, et ont également contribué à les alimenter. Cela s'explique en partie par les succès du développement de l'IA, mais il y a d'autres enjeux. Pourquoi certaines des plus grandes entreprises de la planète, et même des pays entiers, se livrent-ils une course pour construire non seulement de l'IA, mais spécifiquement l'IAG et la superintelligence ?

## Ce qui a orienté la recherche en IA vers l'intelligence de niveau humain

Jusqu'à ces cinq dernières années environ, l'IA était largement un problème de recherche académique et scientifique, donc principalement motivée par la curiosité et la volonté de comprendre l'intelligence et comment la créer dans un nouveau substrat.

Durant cette phase, la plupart des chercheurs accordaient relativement peu d'attention aux avantages ou aux périls de l'IA. Lorsqu'on leur demandait pourquoi l'IA devrait être développée, une réponse courante consistait à énumérer, de manière quelque peu vague, les problèmes que l'IA pourrait aider à résoudre : nouveaux médicaments, nouveaux matériaux, nouvelles sciences, processus plus intelligents, et en général améliorer les choses pour les gens.[^1]

Ce sont des objectifs admirables ![^2] Bien que nous puissions et allons nous demander si l'IAG – plutôt que l'IA en général – est nécessaire pour ces objectifs, ils témoignent de l'idéalisme avec lequel de nombreux chercheurs en IA ont commencé.

Au cours des cinq dernières années, cependant, l'IA s'est transformée d'un domaine de recherche relativement pure en un domaine beaucoup plus orienté vers l'ingénierie et les produits, largement porté par certaines des plus grandes entreprises mondiales.[^3] Les chercheurs, bien que toujours pertinents, ne dirigent plus le processus.

## Pourquoi les entreprises essaient-elles de construire l'IAG ?

Alors pourquoi les corporations géantes (et plus encore les investisseurs) investissent-elles des ressources considérables dans la construction de l'IAG ? Il y a deux moteurs dont la plupart des entreprises parlent assez ouvertement : elles voient l'IA comme un moteur de productivité pour la société, et de profits pour elles. Parce que l'IA générale est par nature polyvalente, il y a un enjeu énorme : plutôt que de choisir un secteur dans lequel créer des produits et services, on peut essayer de *tous les faire à la fois.* Les grandes entreprises technologiques ont atteint une taille énorme en produisant des biens et services numériques, et au moins certains dirigeants voient sûrement l'IA comme simplement la prochaine étape pour bien les fournir, avec des risques et avantages qui étendent mais font écho à ceux fournis par la recherche, les réseaux sociaux, les ordinateurs portables, les téléphones, etc.

Mais pourquoi l'IAG ? Il y a une réponse très simple à cela, dont la plupart des entreprises et investisseurs évitent de discuter publiquement.[^4]

C'est que l'IAG peut directement, un pour un, *remplacer les travailleurs.*

Pas augmenter, pas autonomiser, pas rendre plus productif. Pas même *déplacer.* Tout cela peut être et sera fait par de l'IA non générale. L'IAG est spécifiquement ce qui peut entièrement *remplacer* les travailleurs intellectuels (et avec la robotique, beaucoup de travailleurs physiques également). Pour soutenir cette vision, il suffit de regarder la [définition (publiquement déclarée)](https://openai.com/our-structure/) de l'IAG par OpenAI, qui est « un système hautement autonome qui surpasse les humains dans la plupart des tâches économiquement valorisables. »

L'enjeu ici (pour les entreprises !) est énorme. Les coûts de main-d'œuvre représentent un pourcentage substantiel des ~100 000 milliards de dollars de l'économie mondiale. Même si seulement une fraction de cela est capturée par le remplacement du travail humain par le travail de l'IA, cela représente des milliers de milliards de dollars de revenus annuels. Les entreprises d'IA sont également conscientes de qui est prêt à payer. Selon elles, vous n'allez pas payer des milliers de dollars par an pour des outils de productivité. Mais une entreprise *paiera* des milliers de dollars par an pour remplacer votre travail, si elle le peut.

## Pourquoi les pays se sentent obligés de faire la course à l'IAG

Les motivations officielles des pays pour poursuivre l'IAG se concentrent sur le leadership économique et scientifique. L'argument est convaincant : l'IAG pourrait considérablement accélérer la recherche scientifique, le développement technologique et la croissance économique. Compte tenu des enjeux, argumentent-ils, aucune grande puissance ne peut se permettre de prendre du retard.[^5]

Mais il y a aussi des moteurs supplémentaires et largement non déclarés. Il ne fait aucun doute que lorsque certains dirigeants militaires et de sécurité nationale se réunissent à huis clos pour discuter d'une technologie extraordinairement puissante et catastrophiquement risquée, leur attention ne se porte pas sur « comment éviter ces risques » mais plutôt sur « comment l'obtenir en premier ? » Les dirigeants militaires et du renseignement voient l'IAG comme une révolution potentielle dans les affaires militaires, peut-être la plus significative depuis les armes nucléaires. La crainte est que le premier pays à développer l'IAG pourrait obtenir un avantage stratégique insurmontable. Cela crée une dynamique classique de course aux armements.

Nous verrons que cette pensée de « course à l'IAG »,[^6] bien que convaincante, est profondément défaillante. Ce n'est pas parce que faire la course est dangereux et risqué – bien que ce soit le cas – mais à cause de la nature de la technologie. L'hypothèse implicite est que l'IAG, comme les autres technologies, est contrôlable par l'État qui la développe, et constitue un avantage générateur de pouvoir pour la société qui en a le plus. Comme nous le verrons, elle ne sera probablement ni l'un ni l'autre.

## Pourquoi la superintelligence ?

Tandis que les entreprises se concentrent publiquement sur la productivité, et les pays sur la croissance économique et technologique, pour ceux qui poursuivent délibérément l'IAG complète et la superintelligence, ce ne sont que le début. Qu'ont-ils vraiment en tête ? Bien que rarement dit à voix haute, cela inclut :

1. Des remèdes à de nombreuses ou toutes les maladies ;
2. L'arrêt et l'inversion du vieillissement ;
3. De nouvelles sources d'énergie durable comme la fusion ;
4. Des améliorations humaines, ou des organismes conçus via l'ingénierie génétique ;
5. La nanotechnologie et la fabrication moléculaire ;
6. Le téléchargement d'esprits ;
7. La physique exotique ou les technologies spatiales ;
8. Des conseils et un soutien à la décision surhumains ;
9. Une planification et une coordination surhumaines.

Les trois premiers sont largement des technologies « à effet unique » – c'est-à-dire susceptibles d'être assez fortement positives nettes. Il est difficile d'argumenter contre guérir les maladies ou pouvoir vivre plus longtemps si on le choisit. Et nous avons déjà récolté le côté négatif de la fusion (sous forme d'armes nucléaires) ; il serait formidable maintenant d'obtenir le côté positif. La question avec cette première catégorie est de savoir si obtenir ces technologies plus tôt compense le risque.

Les quatre suivantes sont clairement à double tranchant : des technologies transformatrices avec à la fois des avantages potentiellement énormes et des risques immenses, un peu comme l'IA. Toutes ces technologies, si elles sortaient d'une boîte noire demain et étaient déployées, seraient incroyablement difficiles à gérer.[^7]

Les deux dernières concernent l'IA surhumaine faisant des choses elle-même plutôt que d'inventer simplement de la technologie. Plus précisément, en laissant les euphémismes de côté, celles-ci impliquent des systèmes d'IA puissants disant aux gens quoi faire. Appeler cela des « conseils » est malhonnête si le système qui conseille est bien plus puissant que celui qui est conseillé, qui ne peut pas comprendre de manière significative la base de la décision (ou même si cela est fourni, faire confiance que le conseiller ne fournirait pas une justification également convaincante pour une décision différente).

Cela indique un élément clé manquant dans la liste ci-dessus :

10. Le pouvoir.

Il est parfaitement clair qu'une grande partie de ce qui sous-tend la course actuelle vers l'IA surhumaine est l'idée que *intelligence = pouvoir*. Chaque concurrent mise sur le fait d'être le meilleur détenteur de ce pouvoir, et qu'il sera capable de l'exercer pour des raisons ostensiblement bienveillantes sans qu'il leur échappe ou leur soit retiré de leur contrôle.

C'est-à-dire que ce que les entreprises et nations poursuivent vraiment, ce ne sont pas seulement les fruits de l'IAG et de la superintelligence, mais le pouvoir de contrôler qui y a accès et comment ils sont utilisés. Les entreprises se voient comme des gardiens responsables de ce pouvoir au service des actionnaires et de l'humanité ; les nations se voient comme des gardiens nécessaires empêchant les puissances hostiles d'obtenir un avantage décisif. Les deux ont dangereusement tort, échouant à reconnaître que la superintelligence, par sa nature, ne peut pas être contrôlée de manière fiable par aucune institution humaine. Nous verrons que la nature et les dynamiques des systèmes superintelligents rendent le contrôle humain extrêmement difficile, sinon impossible.

Ces dynamiques de course – à la fois corporatives et géopolitiques – rendent certains risques quasi inévitables sauf s'ils sont interrompus de manière décisive. Nous nous tournons maintenant vers l'examen de ces risques et pourquoi ils ne peuvent pas être adéquatement atténués dans un paradigme de développement compétitif.[^8]


[^1]: Une liste plus précise d'objectifs dignes est celle des [Objectifs de développement durable](https://sdgs.un.org/goals) de l'ONU. Ce sont, en un sens, ce qui se rapproche le plus d'un ensemble d'objectifs de consensus mondial pour ce que nous aimerions voir s'améliorer dans le monde. L'IA pourrait aider.

[^2]: La technologie en général a un pouvoir transformateur économique et social pour le bien-être humain, comme en attestent des milliers d'années. Dans cette veine, une explication longue et convaincante d'une vision positive de l'IAG peut être trouvée dans [cet essai](https://darioamodei.com/machines-of-loving-grace) du fondateur d'Anthropic, Dario Amodei.

[^3]: L'investissement privé en IA [a commencé à exploser en 2018-19, dépassant l'investissement public vers cette période,](https://cset.georgetown.edu/publication/tracking-ai-investment/) et l'a largement distancé depuis.

[^4]: Je peux attester que derrière des portes plus fermées, ils n'ont pas de tels scrupules. Et cela devient plus public ; voir par exemple la nouvelle [« demande de startups »](https://www.ycombinator.com/rfs) de Y-combinator, dont de nombreuses parties appellent explicitement au remplacement complet des travailleurs humains. Pour les citer, « La proposition de valeur du SaaS B2B était de rendre les travailleurs humains progressivement plus efficaces. La proposition de valeur des agents d'IA verticaux est d'automatiser entièrement le travail... Il est tout à fait possible que cette opportunité soit assez grande pour créer une centaine d'autres licornes. » (Pour ceux qui ne connaissent pas le jargon de la Silicon Valley, « B2B » signifie business-to-business et une licorne est une entreprise d'un milliard de dollars. C'est-à-dire qu'ils parlent de plus d'une centaine d'entreprises d'un milliard de dollars et plus qui remplacent les travailleurs pour d'autres entreprises.)

[^5]: Voir par exemple un récent [rapport de la Commission de révision économique et sécuritaire États-Unis-Chine](https://www.uscc.gov/sites/default/files/2024-11/2024_Executive_Summary.pdf). Bien qu'il y ait eu étonnamment peu de justification dans le rapport lui-même, la recommandation principale était que le Congrès américain « établisse et finance un programme de type Projet Manhattan dédié à faire la course pour acquérir une capacité d'Intelligence artificielle générale (IAG). »

[^6]: Les entreprises adoptent maintenant ce cadrage géopolitique comme un bouclier contre toute contrainte sur leur développement d'IA, généralement de manières qui sont manifestement intéressées, et parfois de manières qui n'ont même pas de sens basique. Considérez l'[Approche de l'IA de frontière](https://about.fb.com/news/2025/02/meta-approach-frontier-ai/) de Meta, qui argue simultanément que l'Amérique doit « [Consolider sa] position de leader dans l'innovation technologique, la croissance économique et la sécurité nationale » et aussi qu'elle doit le faire en publiant ouvertement ses systèmes d'IA les plus puissants – ce qui inclut les donner directement à ses rivaux et adversaires géopolitiques.

[^7]: Ainsi nous devrions probablement laisser la gestion de ces technologies aux IA. Mais ce serait une délégation de contrôle très problématique, à laquelle nous reviendrons ci-dessous.

[^8]: La concurrence dans le développement technologique apporte souvent des avantages importants : prévenir le contrôle monopolistique, stimuler l'innovation et la réduction des coûts, permettre des approches diverses, et créer une surveillance mutuelle. Cependant, avec l'IAG, ces avantages doivent être pesés contre les risques uniques des dynamiques de course et de la pression à réduire les précautions de sécurité.