# Zusammenfassung

Ein Überblick über den Essay auf hoher Ebene. Wenn Sie wenig Zeit haben, erhalten Sie alle wichtigsten Punkte in nur 10 Minuten.

Die dramatischen Fortschritte in der künstlichen Intelligenz der letzten Dekade (bei spezialisierten KI-Systemen) und der letzten Jahre (bei Allzweck-KI) haben die KI von einem akademischen Nischenbereich zur Kernstrategie vieler der größten Unternehmen der Welt verwandelt, mit hunderten Milliarden Dollar jährlicher Investitionen in die Techniken und Technologien zur Weiterentwicklung der KI-Fähigkeiten.

Wir stehen nun an einem kritischen Wendepunkt. Da die Fähigkeiten neuer KI-Systeme beginnen, denen von Menschen in vielen kognitiven Bereichen zu entsprechen und sie zu übertreffen, muss die Menschheit entscheiden: Wie weit gehen wir, und in welche Richtung?

KI begann, wie jede Technologie, mit dem Ziel, die Dinge für ihre Schöpfer zu verbessern. Aber unser aktueller Kurs und unsere stillschweigende Entscheidung ist ein unkontrolliertes Rennen hin zu immer mächtigeren Systemen, angetrieben von wirtschaftlichen Anreizen weniger großer Technologieunternehmen, die große Bereiche der aktuellen Wirtschaftstätigkeit und menschlichen Arbeit automatisieren wollen. Falls dieses Rennen noch viel länger anhält, gibt es einen unvermeidlichen Gewinner: die KI selbst – eine schnellere, intelligentere, günstigere Alternative zu Menschen in unserer Wirtschaft, unserem Denken, unseren Entscheidungen und schließlich in der Kontrolle über unsere Zivilisation.

Aber wir können eine andere Wahl treffen: über unsere Regierungen können wir die Kontrolle über den KI-Entwicklungsprozess übernehmen, um klare Grenzen zu setzen, Linien, die wir nicht überschreiten werden, und Dinge, die wir einfach nicht tun werden – wie wir es bei Nukleartechnologien, Massenvernichtungswaffen, Weltraumwaffen, umweltschädlichen Prozessen, der Bioengineering von Menschen und der Eugenik getan haben. Am wichtigsten ist, dass wir sicherstellen können, dass KI ein Werkzeug bleibt, das Menschen stärkt, anstatt eine neue Spezies zu werden, die uns ersetzt und schließlich verdrängt.

Dieser Essay argumentiert, dass wir *die Zukunft menschlich halten* sollten, indem wir die „Tore" zu intelligenterer-als-menschlicher, autonomer, Allzweck-KI – manchmal „AGI" genannt – und besonders zu der hochgradig übermenschlichen Version, die manchmal „Superintelligenz" genannt wird, schließen. Stattdessen sollten wir uns auf mächtige, vertrauenswürdige KI-Werkzeuge konzentrieren, die Individuen stärken und die Fähigkeiten menschlicher Gesellschaften transformativ verbessern können, das zu tun, was sie am besten können. Die Struktur dieses Arguments folgt hier in Kürze.

## KI ist anders

KI-Systeme unterscheiden sich grundlegend von anderen Technologien. Während herkömmliche Software präzisen Anweisungen folgt, lernen KI-Systeme, wie sie Ziele erreichen können, ohne explizit gesagt zu bekommen, wie. Das macht sie mächtig: Wenn wir das Ziel oder eine Erfolgsmetrik klar definieren können, kann ein KI-System in den meisten Fällen lernen, es zu erreichen. Aber es macht sie auch von Natur aus unvorhersagbar: Wir können nicht zuverlässig bestimmen, welche Handlungen sie zur Erreichung ihrer Ziele unternehmen werden.

Sie sind auch weitgehend unerklärlich: Obwohl sie teilweise Code sind, bestehen sie größtenteils aus einer enormen Menge unergründlicher Zahlen – neuronale Netzwerk-„Gewichtungen" –, die nicht analysiert werden können; wir sind nicht viel besser darin, ihre inneren Abläufe zu verstehen, als Gedanken durch einen Blick ins biologische Gehirn zu erkennen.

Diese grundlegende Art des Trainings digitaler neuronaler Netzwerke nimmt rapide an Komplexität zu. Die mächtigsten KI-Systeme werden durch massive Rechenexperimente erstellt, die spezialisierte Hardware verwenden, um neuronale Netzwerke auf enormen Datensätzen zu trainieren, die dann mit Software-Werkzeugen und Superstrukturen erweitert werden.

Dies hat zur Entstehung sehr mächtiger Werkzeuge für das Erstellen und Verarbeiten von Texten und Bildern, das Durchführen mathematischen und wissenschaftlichen Schlussfolgerns, das Aggregieren von Informationen und das interaktive Abfragen eines riesigen Speichers menschlichen Wissens geführt.

Leider ist die Entwicklung mächtigerer, vertrauenswürdigerer technologischer Werkzeuge zwar das, was wir tun *sollten* und was fast jeder will und sagt zu wollen, aber nicht der Kurs, auf dem wir uns tatsächlich befinden.

## AGI und Superintelligenz

Seit den Anfängen des Feldes konzentrierte sich die KI-Forschung stattdessen auf ein anderes Ziel: Artificial General Intelligence. Dieser Fokus ist nun zum Fokus der titanischen Unternehmen geworden, die die KI-Entwicklung anführen.

Was ist AGI? Es wird oft vage als „menschliche KI" definiert, aber das ist problematisch: Welche Menschen, und bei welchen Fähigkeiten ist sie menschlich? Und was ist mit den übermenschlichen Fähigkeiten, die sie bereits hat? Eine nützlichere Art, AGI zu verstehen, ist durch die Schnittmenge dreier Schlüsseleigenschaften: hohe **A**utonomie (Handlungsunabhängigkeit), hohe **A**llgemeinheit (breite Reichweite und Anpassungsfähigkeit) und hohe **I**ntelligenz (Kompetenz bei kognitiven Aufgaben). Aktuelle KI-Systeme mögen hochfähig aber eng gefasst sein, oder allgemein aber konstante menschliche Aufsicht erfordern, oder autonom aber im Umfang begrenzt.

Vollständige A-G-I würde alle drei Eigenschaften auf Ebenen kombinieren, die menschliche Spitzenfähigkeiten erreichen oder übertreffen. Kritisch ist, dass es diese Kombination ist, die Menschen so effektiv und so unterschiedlich von aktueller Software macht; es ist auch das, was es ermöglichen würde, dass Menschen vollständig durch digitale Systeme ersetzt werden.

Während menschliche Intelligenz besonders ist, ist sie keineswegs eine Grenze. Künstliche „superintelligente" Systeme könnten hunderte Male schneller operieren, weitaus mehr Daten analysieren und enorme Mengen gleichzeitig „im Kopf" behalten, und Aggregate bilden, die viel größer und effektiver sind als Zusammenschlüsse von Menschen. Sie könnten nicht Individuen, sondern Unternehmen, Nationen oder unsere Zivilisation als Ganzes verdrängen.

## Wir stehen an der Schwelle

Es gibt einen starken wissenschaftlichen Konsens, dass AGI *möglich* ist. KI übertrifft bereits die menschliche Leistung in vielen allgemeinen Tests intellektueller Fähigkeiten, einschließlich kürzlich bei hochgradigem Schlussfolgern und Problemlösen. Rückständige Fähigkeiten – wie kontinuierliches Lernen, Planung, Selbstbewusstsein und Originalität – existieren alle auf einer gewissen Ebene in gegenwärtigen KI-Systemen, und bekannte Techniken existieren, die wahrscheinlich alle davon verbessern werden.

Während bis vor wenigen Jahren viele Forscher AGI als Jahrzehnte entfernt sahen, sind die Belege für kurze Zeitspannen bis zur AGI derzeit stark:

- Empirisch verifizierte „Skalierungsgesetze" verbinden rechnerischen Input mit KI-Fähigkeiten, und Unternehmen sind auf Kurs, rechnerischen Input um Größenordnungen über die kommenden Jahre zu skalieren. Die menschlichen und finanziellen Ressourcen, die der KI-Weiterentwicklung gewidmet sind, entsprechen nun denen von einem Dutzend Manhattan-Projekten und mehreren Apollo-Projekten.
- KI-Unternehmen und ihre Führungskräfte glauben öffentlich und privat, dass AGI (nach irgendeiner Definition) innerhalb weniger Jahre erreichbar ist. Diese Unternehmen haben Informationen, die die Öffentlichkeit nicht hat, einschließlich dass einige die nächste Generation von KI-Systemen bereits in der Hand haben.
- Experten-Prognostiker mit bewährter Erfolgsbilanz weisen AGI (nach irgendeiner Definition) eine 25%ige Wahrscheinlichkeit zu, innerhalb von 1-2 Jahren einzutreffen, und 50% für 2-5 Jahre (siehe Metaculus-Vorhersagen für ['schwache'](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) und ['vollständige'](https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/) AGI).
- Autonomie (einschließlich langfristiger flexibler Planung) hinkt in KI-Systemen hinterher, aber große Unternehmen konzentrieren nun ihre enormen Ressourcen auf die Entwicklung autonomer KI-Systeme und haben informell 2025 das [„Jahr des Agenten"](https://techinformed.com/2025-informed-the-year-of-agentic-ai/) genannt.
- KI trägt mehr und mehr zu ihrer eigenen Verbesserung bei. Sobald KI-Systeme so kompetent wie menschliche KI-Forscher bei der KI-Forschung sind, wird eine kritische Schwelle für schnellen Fortschritt zu viel mächtigeren KI-Systemen erreicht und wahrscheinlich zu einem Kontrollverlust bei den KI-Fähigkeiten führen. (Wohl hat dieser Kontrollverlust bereits begonnen.)

Die Vorstellung, dass intelligentere-als-menschliche AGI Jahrzehnte oder mehr entfernt ist, ist einfach nicht mehr haltbar für die große Mehrheit der Experten auf diesem Gebiet. Meinungsverschiedenheiten gibt es jetzt darüber, wie viele Monate oder Jahre es dauern wird, wenn wir auf diesem Kurs bleiben. Die Kernfrage, der wir uns stellen: Sollten wir das?

## Was das Rennen zur AGI antreibt

Das Rennen zur AGI wird von mehreren Kräften angetrieben, die jeweils die Situation gefährlicher machen. Große Technologieunternehmen sehen AGI als die ultimative Automatisierungstechnologie – die menschliche Arbeiter nicht nur ergänzt, sondern sie weitgehend oder vollständig ersetzt. Für Unternehmen ist der Preis enorm: die Gelegenheit, einen bedeutenden Anteil der jährlichen Wirtschaftsleistung der Welt von 100 Billionen Dollar zu erfassen, indem sie menschliche Arbeitskosten wegautomatisieren.

Nationen fühlen sich gedrängt, diesem Rennen beizutreten, und zitieren öffentlich wirtschaftliche und wissenschaftliche Führerschaft, aber betrachten privat AGI als eine potenzielle Revolution in militärischen Angelegenheiten, vergleichbar mit Nuklearwaffen. Die Furcht, dass Rivalen einen entscheidenden strategischen Vorteil erlangen könnten, schafft eine klassische Rüstungsrennen-Dynamik.

Diejenigen, die Superintelligenz verfolgen, führen oft große Visionen an: alle Krankheiten heilen, Alterung umkehren, Durchbrüche in Energie und Raumfahrt erreichen oder übermenschliche Planungsfähigkeiten schaffen.

Weniger wohlwollend betrachtet treibt das Rennen die Macht an. Jeder Teilnehmer – sei es Unternehmen oder Land – glaubt, dass Intelligenz gleich Macht ist, und dass sie der beste Verwalter dieser Macht sein werden.

Ich argumentiere, dass diese Motivationen real, aber grundlegend fehlgeleitet sind: AGI wird Macht *absorbieren* und *suchen*, anstatt sie zu gewähren; KI-geschaffene Technologien werden *auch* stark zweischneidig sein, und wo sie vorteilhaft sind, können sie mit KI-Werkzeugen und ohne AGI geschaffen werden; und selbst insofern AGI und ihre Ergebnisse unter Kontrolle bleiben, machen diese Renndynamiken – sowohl unternehmerische als auch geopolitische – große Risiken für unsere Gesellschaft nahezu unvermeidlich, es sei denn, sie werden entschieden unterbrochen.

## AGI und Superintelligenz stellen eine dramatische Bedrohung für die Zivilisation dar

Trotz ihrer Anziehungskraft stellen AGI und Superintelligenz dramatische Bedrohungen für die Zivilisation durch mehrere sich verstärkende Pfade dar:

*Machtkonzentration:* Übermenschliche KI könnte die große Mehrheit der Menschheit entmachten, indem sie riesige Bereiche sozialer und wirtschaftlicher Aktivität in KI-Systeme absorbiert, die von einer Handvoll Riesenunternehmen betrieben werden (die wiederum entweder von Regierungen übernommen werden könnten oder diese effektiv übernehmen könnten).

*Massive Störung:* Massenautomatisierung der meisten kognitiv-basierten Jobs, Ersetzung unserer aktuellen epistemischen Systeme und Einführung riesiger Mengen aktiver nicht-menschlicher Agenten würden die meisten unserer aktuellen zivilisatorischen Systeme in einem relativ kurzen Zeitraum umwälzen.

*Katastrophen:* Durch die Verbreitung der Fähigkeit – potenziell über menschliches Niveau – neue militärische und zerstörerische Technologien zu schaffen und ihre Entkopplung von den sozialen und rechtlichen Systemen, die Verantwortung begründen, werden physische Katastrophen durch Massenvernichtungswaffen dramatisch wahrscheinlicher.

*Geopolitik und Krieg:* Große Weltmächte werden nicht untätig zusehen, wenn sie das Gefühl haben, dass eine Technologie, die einen „entscheidenden strategischen Vorteil" liefern könnte, von ihren Gegnern entwickelt wird.

*Kontrollverlust und Kontrollverlust:* Sofern es nicht spezifisch verhindert wird, wird übermenschliche KI jeden Anreiz haben, sich selbst weiter zu verbessern und könnte Menschen bei Geschwindigkeit, Datenverarbeitung und Raffinesse des Denkens weit übertreffen. Es gibt keinen bedeutsamen Weg, auf den wir ein solches System kontrollieren können. Solche KI wird Menschen keine Macht gewähren; wir werden ihr Macht gewähren, oder sie wird sie nehmen.

Viele dieser Risiken bleiben selbst dann bestehen, wenn das technische „Alignment"-Problem – sicherzustellen, dass fortgeschrittene KI zuverlässig das tut, was Menschen von ihr wollen – gelöst ist. KI stellt eine enorme Herausforderung darin dar, wie sie verwaltet wird, und sehr viele Aspekte dieser Verwaltung werden unglaublich schwierig oder unlösbar, sobald menschliche Intelligenz durchbrochen wird.

Am grundlegendsten hätte die Art übermenschlicher Allzweck-KI, die derzeit verfolgt wird, von ihrer Natur her Ziele, Handlungsfähigkeit und Fähigkeiten, die unsere eigenen übertreffen. Sie wäre von Natur aus unkontrollierbar – wie können wir etwas kontrollieren, das wir weder verstehen noch vorhersagen können? Sie wäre kein technologisches Werkzeug für menschlichen Gebrauch, sondern eine zweite Intelligenzspezies auf der Erde neben unserer. Wenn ihr erlaubt würde, weiter fortzuschreiten, würde sie nicht nur eine zweite Spezies, sondern eine Ersatzspezies darstellen.

Vielleicht würde sie uns gut behandeln, vielleicht nicht. Aber die Zukunft würde ihr gehören, nicht uns. Die menschliche Ära wäre vorbei.

## Das ist nicht unvermeidlich; die Menschheit kann sehr konkret entscheiden, ihren Ersatz nicht zu bauen.

Die Schaffung übermenschlicher AGI ist alles andere als unvermeidlich. Wir können sie durch eine koordinierte Reihe von Governance-Maßnahmen verhindern:

Erstens brauchen wir robuste Buchführung und Aufsicht über KI-Rechenleistung, die ein grundlegender Ermöglicher und Hebel zur Steuerung großangelegter KI-Systeme ist. Das wiederum erfordert standardisierte Messung und Berichterstattung der gesamten Rechenleistung, die beim Training von KI-Modellen und beim Betrieb verwendet wird, sowie technische Methoden zur Zählung, Zertifizierung und Verifizierung verwendeter Rechenleistung.

Zweitens sollten wir harte Rechenleistungsobergrenzen für KI implementieren, sowohl für Training als auch für Betrieb; diese verhindern sowohl, dass KI zu mächtig wird als auch zu schnell operiert. Diese Obergrenzen können sowohl durch rechtliche Anforderungen als auch durch hardware-basierte Sicherheitsmaßnahmen implementiert werden, die in KI-spezialisierte Chips eingebaut sind, analog zu Sicherheitsfeatures in modernen Handys. Da spezialisierte KI-Hardware nur von einer Handvoll Unternehmen hergestellt wird, sind Verifizierung und Durchsetzung durch die bestehende Lieferkette machbar.

Drittens brauchen wir verschärfte Haftung für die gefährlichsten KI-Systeme. Diejenigen, die KI entwickeln, die hohe Autonomie, breite Allgemeinheit und überlegene Intelligenz kombiniert, sollten strikter Haftung für Schäden gegenüberstehen, während Schutzräume vor dieser Haftung die Entwicklung begrenzterer und kontrollierbarer Systeme fördern würden.

Viertens brauchen wir gestufte Regulierung basierend auf Risikoebenen. Die fähigsten und gefährlichsten Systeme würden umfangreiche Sicherheits- und Kontrollierbarkeitsgarantien vor Entwicklung und Einsatz erfordern, während weniger mächtige oder spezialisiertere Systeme proportionale Aufsicht erfahren würden. Dieses Regulierungsframework sollte schließlich sowohl auf nationaler als auch internationaler Ebene operieren.

Dieser Ansatz – mit detaillierter Spezifikation im vollständigen Dokument – ist praktisch: Während internationale Koordination nötig sein wird, können Verifizierung und Durchsetzung durch die kleine Anzahl von Unternehmen funktionieren, die die spezialisierte Hardware-Lieferkette kontrollieren. Er ist auch flexibel: Unternehmen können noch immer innovieren und von KI-Entwicklung profitieren, nur mit klaren Grenzen bei den gefährlichsten Systemen.

Längerfristige Eindämmung von KI-Macht und -Risiko würde internationale Abkommen erfordern, die sowohl auf Eigen- als auch auf Gemeininteresse basieren, genau wie die Kontrolle der Nuklearwaffenverbreitung es jetzt tut. Aber wir können sofort mit verstärkter Aufsicht und Haftung beginnen, während wir zu umfassenderer Governance aufbauen.

Die wichtigste fehlende Zutat ist der politische und gesellschaftliche Wille, die Kontrolle über den KI-Entwicklungsprozess zu übernehmen. Die Quelle dieses Willens, wenn er rechtzeitig kommt, wird die Realität selbst sein – das heißt, aus weitverbreiteter Erkenntnis der wirklichen Implikationen dessen, was wir tun.

## Wir können Werkzeug-KI entwickeln, um die Menschheit zu stärken

Anstatt unkontrollierbare AGI zu verfolgen, können wir mächtige „Werkzeug-KI" entwickeln, die menschliche Fähigkeiten verstärkt, während sie unter bedeutsamer menschlicher Kontrolle bleibt. Werkzeug-KI-Systeme können extrem fähig sein, während sie die gefährliche Dreifach-Schnittmenge hoher Autonomie, breiter Allgemeinheit und übermenschlicher Intelligenz vermeiden, solange wir sie so entwickeln, dass sie auf einer Ebene kontrollierbar sind, die ihrer Fähigkeit entspricht. Sie können auch zu sophistizierten Systemen kombiniert werden, die menschliche Aufsicht bewahren, während sie transformative Vorteile liefern.

Werkzeug-KI kann die Medizin revolutionieren, wissenschaftliche Entdeckungen beschleunigen, Bildung verbessern und demokratische Prozesse stärken. Wenn sie richtig gesteuert wird, kann sie menschliche Experten und Institutionen effektiver machen, anstatt sie zu ersetzen. Während solche Systeme noch immer hochgradig disruptiv sein und sorgfältiges Management erfordern werden, sind die Risiken, die sie darstellen, grundlegend anders als AGI: Es sind Risiken, die wir regieren können, wie die anderer mächtiger Technologien, nicht existenzielle Bedrohungen für menschliche Handlungsfähigkeit und Zivilisation. Und entscheidend, wenn sie klug entwickelt wird, kann KI-Werkzeuge Menschen dabei helfen, mächtige KI zu steuern und ihre Effekte zu verwalten.

Dieser Ansatz erfordert ein Umdenken sowohl darüber, wie KI entwickelt wird, als auch wie ihre Vorteile verteilt werden. Neue Modelle öffentlicher und gemeinnütziger KI-Entwicklung, robuste Regulierungsrahmen und Mechanismen zur breiteren Verteilung wirtschaftlicher Vorteile können dabei helfen sicherzustellen, dass KI die Menschheit als Ganzes stärkt, anstatt Macht in wenigen Händen zu konzentrieren. KI selbst kann dabei helfen, bessere soziale und Governance-Institutionen zu bauen, die neue Formen der Koordination und des Diskurses ermöglichen, die die menschliche Gesellschaft stärken, anstatt sie zu untergraben. Nationale Sicherheitseinrichtungen können ihre Expertise nutzen, um KI-Werkzeugsysteme wirklich sicher und vertrauenswürdig zu machen und zu einer wahren Quelle der Verteidigung sowie nationaler Macht.

Wir könnten uns schließlich dafür entscheiden, noch mächtigere und souveränere Systeme zu entwickeln, die weniger wie Werkzeuge und – so können wir hoffen – mehr wie weise und mächtige Wohltäter sind. Aber wir sollten das nur tun, nachdem wir das wissenschaftliche Verständnis und die Governance-Kapazität entwickelt haben, um das sicher zu tun. Eine solche bedeutsame und unumkehrbare Entscheidung sollte bewusst von der Menschheit als Ganzer getroffen werden, nicht standardmäßig in einem Rennen zwischen Technologieunternehmen und Nationen.

## In menschlichen Händen

Menschen wollen das Gute, das von KI kommt: nützliche Werkzeuge, die sie stärken, wirtschaftliche Möglichkeiten und Wachstum verstärken und Durchbrüche in Wissenschaft, Technologie und Bildung versprechen. Warum sollten sie nicht? Aber wenn gefragt, will die überwältigende Mehrheit der allgemeinen Öffentlichkeit [langsamere und sorgfältigere KI-Entwicklung](https://www.vox.com/future-perfect/2023/8/18/23836362/ai-slow-down-poll-regulation) und will keine intelligentere-als-menschliche KI, die sie in ihren Jobs und anderswo ersetzen wird, ihre Kultur und Informationsallmende mit nicht-menschlichem Inhalt füllen, Macht in einer winzigen Anzahl von Unternehmen konzentrieren, extreme großangelegte globale Risiken darstellen und schließlich drohen, ihre Spezies zu entmachten oder zu ersetzen. Warum sollten sie?

Wir *können* das eine ohne das andere haben. Es beginnt damit zu entscheiden, dass unser Schicksal nicht in der vermeintlichen Unvermeidlichkeit irgendeiner Technologie oder in den Händen weniger CEOs im Silicon Valley liegt, sondern in unseren anderen Händen, wenn wir sie ergreifen. Lasst uns die Tore schließen und die Zukunft menschlich halten.