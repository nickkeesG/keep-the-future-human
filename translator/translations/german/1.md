# Kapitel 1 - Einleitung

Die Frage, wie wir auf die Aussicht auf übermenschliche KI reagieren werden, ist das drängendste Thema unserer Zeit. Dieser Essay zeigt einen Weg nach vorn auf.

Wir stehen möglicherweise am Ende des menschlichen Zeitalters.

In den letzten zehn Jahren hat etwas begonnen, das in der Geschichte unserer Spezies einzigartig ist. Die Konsequenzen werden zu einem großen Teil die Zukunft der Menschheit bestimmen. Seit etwa 2015 ist es Forschern gelungen, *spezialisierte* künstliche Intelligenz (KI) zu entwickeln – Systeme, die Spiele wie Go gewinnen, Bilder und Sprache erkennen können und so weiter, besser als jeder Mensch.[^1]

Das ist ein erstaunlicher Erfolg und führt zu äußerst nützlichen Systemen und Produkten, die die Menschheit stärken werden. Doch spezialisierte künstliche Intelligenz war nie das wahre Ziel des Forschungsfelds. Vielmehr bestand das Ziel darin, KI-Systeme für *allgemeine* Zwecke zu schaffen, insbesondere solche, die oft als „Artificial General Intelligence" (AGI) oder „Superintelligenz" bezeichnet werden und gleichzeitig genauso gut oder besser als Menschen in nahezu *allen* Aufgaben sind, so wie KI heute bereits übermenschlich beim Go, Schach, Poker, Drohnenrennen usw. ist. Das ist das erklärte Ziel vieler großer KI-Unternehmen.[^2]

*Diese Bemühungen sind ebenfalls erfolgreich.* Allzweck-KI-Systeme wie ChatGPT, Gemini, Llama, Grok, Claude und Deepseek, die auf massiven Berechnungen und Bergen von Daten basieren, haben bei einer Vielzahl von Aufgaben Gleichstand mit durchschnittlichen Menschen erreicht und entsprechen sogar menschlichen Experten in einigen Bereichen. Nun wetteifern KI-Ingenieure bei einigen der größten Technologieunternehmen darum, diese gigantischen Experimente mit maschineller Intelligenz auf die nächsten Stufen zu bringen, auf denen sie das gesamte Spektrum menschlicher Fähigkeiten, Expertise und Autonomie erreichen und dann übertreffen.

*Das steht unmittelbar bevor.* In den letzten zehn Jahren sind die Schätzungen von Experten dafür, wie lange das dauern wird – wenn wir unseren gegenwärtigen Kurs fortsetzen –, von Jahrzehnten (oder Jahrhunderten) auf einstellige Jahreszahlen gefallen.

Es ist auch von epochaler Bedeutung und birgt außergewöhnliche Risiken. Befürworter von AGI sehen darin eine positive Transformation, die wissenschaftliche Probleme lösen, Krankheiten heilen, neue Technologien entwickeln und mühselige Arbeiten automatisieren wird. Und KI könnte sicherlich dabei helfen, all diese Dinge zu erreichen – tatsächlich tut sie das bereits. Doch über die Jahrzehnte hinweg haben viele sorgfältige Denker, von Alan Turing über Stephen Hawking bis hin zu den heutigen Geoffrey Hinton und Yoshua Bengio [^3], eine eindringliche Warnung ausgesprochen: Der Bau einer wirklich übermenschlichen, allgemeinen, autonomen KI wird die Gesellschaft mindestens vollständig und unwiderruflich umwälzen und höchstens zum Aussterben der Menschheit führen.[^4]

Superintelligente KI rückt auf unserem gegenwärtigen Pfad schnell näher, ist aber keineswegs unvermeidlich. Dieser Essay ist ein ausführliches Argument dafür, warum und wie wir die *Tore* zu dieser sich nähernden unmenschlichen Zukunft *schließen* sollten und was wir stattdessen tun sollten.


[^1]: Diese [Grafik](https://time.com/6300942/ai-progress-charts/) zeigt eine Reihe von Aufgaben; viele ähnliche Kurven könnten zu diesem Diagramm hinzugefügt werden. Dieser schnelle Fortschritt in der spezialisierten KI hat sogar Experten auf diesem Gebiet überrascht, da Benchmarks Jahre früher als vorhergesagt übertroffen wurden.

[^2]: Deepmind, OpenAI, Anthropic und X.ai wurden alle mit dem spezifischen Ziel gegründet, AGI zu entwickeln. OpenAIs Gründungsurkunde etwa erklärt explizit als Ziel die Entwicklung „künstlicher allgemeiner Intelligenz, die der gesamten Menschheit zugute kommt", während DeepMinds Mission lautet: „Intelligenz zu lösen und sie dann zu nutzen, um alles andere zu lösen." Meta, Microsoft und andere verfolgen nun im Wesentlichen ähnliche Wege. Meta hat erklärt, [AGI entwickeln und offen zugänglich machen zu wollen.](https://www.forbes.com/sites/johnkoetsier/2024/01/18/zuckerberg-on-ai-meta-building-agi-for-everyone-and-open-sourcing-it/)

[^3]: Hinton und Bengio gehören zu den meistzitierten KI-Forschern, haben beide den Nobel des KI-Bereichs, den Turing-Preis, gewonnen, und Hinton hat obendrein einen Nobelpreis (in Physik) erhalten.

[^4]: Etwas mit diesem Risiko unter kommerziellen Anreizen und nahezu ohne staatliche Aufsicht zu entwickeln, ist völlig beispiellos. Es gibt nicht einmal Kontroversen über das Risiko unter denen, die es entwickeln! Die Leiter von Deepmind, OpenAI und Anthropic haben zusammen mit vielen anderen Experten alle buchstäblich eine [Erklärung](https://www.safe.ai/work/statement-on-ai-risk) unterzeichnet, dass fortgeschrittene KI ein *Existenzrisiko für die Menschheit* darstellt. Die Alarmglocken könnten nicht lauter läuten, und man kann nur schlussfolgern, dass diejenigen, die sie ignorieren, AGI und Superintelligenz einfach nicht ernst nehmen. Ein Ziel dieses Essays ist es, ihnen zu helfen zu verstehen, warum sie das tun sollten.