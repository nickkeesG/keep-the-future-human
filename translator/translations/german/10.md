# Kapitel 10 - Die Entscheidung vor uns

Um unsere menschliche Zukunft zu bewahren, müssen wir uns dafür entscheiden, die Tore zu AGI und Superintelligenz zu schließen.

Das letzte Mal, dass die Menschheit die Erde mit anderen denkenden Wesen teilte, die sprechen, denken, Technologie entwickeln und allgemeine Problemlösung betreiben konnten, war vor 40.000 Jahren im eiszeitlichen Europa. Diese anderen Geister starben aus, ganz oder teilweise durch die Bemühungen der unseren.

Wir treten nun wieder in eine solche Zeit ein. Die fortschrittlichsten Erzeugnisse unserer Kultur und Technologie – Datensätze, die aus unserem gesamten Internet-Informationsbestand erstellt wurden, und Chips mit 100 Milliarden Elementen, die zu den komplexesten Technologien gehören, die wir je entwickelt haben – werden kombiniert, um fortschrittliche Allzweck-KI-Systeme zu erschaffen.

Die Entwickler dieser Systeme sind darauf bedacht, sie als Werkzeuge zur menschlichen Ermächtigung darzustellen. Und das könnten sie durchaus sein. Aber täuschen wir uns nicht: Unser gegenwärtiger Kurs führt zum Bau immer mächtigerer, zielorientierter, entscheidungsfähiger und allgemein leistungsfähiger digitaler Agenten. Sie erbringen bereits bei einer breiten Palette intellektueller Aufgaben Leistungen, die mit denen vieler Menschen vergleichbar sind, verbessern sich rasant und tragen zu ihrer eigenen Verbesserung bei.

Sollte sich dieser Kurs nicht ändern oder auf ein unerwartetes Hindernis stoßen, werden wir bald – in Jahren, nicht Jahrzehnten – über digitale Intelligenzen verfügen, die gefährlich mächtig sind. Selbst im *besten* Fall brächten diese große wirtschaftliche Vorteile (zumindest für einige von uns), aber nur um den Preis einer tiefgreifenden gesellschaftlichen Erschütterung und der Ablösung der Menschen in den meisten der wichtigsten Dinge, die wir tun: Diese Maschinen würden für uns denken, für uns planen, für uns entscheiden und für uns erschaffen. Wir wären verwöhnt, aber verwöhnte Kinder. Viel wahrscheinlicher ist, dass diese Systeme Menschen sowohl bei den positiven *als auch* bei den negativen Dingen ersetzen würden, die wir tun, einschließlich Ausbeutung, Manipulation, Gewalt und Krieg. Können wir KI-verstärkte Versionen davon überleben? Schließlich ist es mehr als plausibel, dass die Dinge überhaupt nicht gut laufen würden: dass wir relativ bald nicht nur in dem ersetzt würden, was wir tun, sondern in dem, was wir *sind* – als Architekten der Zivilisation und der Zukunft. Fragt die Neandertaler, wie das ausgeht. Vielleicht haben wir ihnen auch eine Zeit lang zusätzliche Schmuckstücke verschafft.

*Das müssen wir nicht tun.* Wir haben menschenvergleichbare KI, und es besteht keine Notwendigkeit, KI zu bauen, mit der wir *nicht* konkurrieren können. Wir können erstaunliche KI-Werkzeuge bauen, ohne eine Nachfolgerspezies zu erschaffen. Die Vorstellung, dass AGI und Superintelligenz unvermeidlich seien, ist eine *Wahl, die sich als Schicksal tarnt*.

Durch die Durchsetzung einiger harter, globaler Grenzen können wir die allgemeine Leistungsfähigkeit der KI ungefähr auf menschlichem Niveau halten und dabei trotzdem von der Fähigkeit der Computer profitieren, Daten auf eine Weise zu verarbeiten, die wir nicht können, und Aufgaben zu automatisieren, die niemand von uns machen will. Diese würden immer noch viele Risiken bergen, aber wenn sie gut entwickelt und verwaltet werden, wären sie ein enormer Segen für die Menschheit, von der Medizin über die Forschung bis hin zu Konsumprodukten.

Die Durchsetzung von Grenzen würde internationale Zusammenarbeit erfordern, aber weniger als man denken könnte, und diese Grenzen würden immer noch viel Raum für eine enorme KI- und KI-Hardware-Industrie lassen, die sich auf Anwendungen konzentriert, die das menschliche Wohlbefinden fördern, anstatt auf das reine Streben nach Macht. Und wenn wir uns nach starken Sicherheitsgarantien und einem sinnvollen globalen Dialog dafür entscheiden, weiter zu gehen, bleibt diese Option weiterhin in unserer Hand.

Die Menschheit muss sich *entscheiden*, die Tore zu AGI und Superintelligenz zu schließen.

Um die Zukunft menschlich zu halten.

## Eine Notiz des Autors

Vielen Dank, dass Sie sich die Zeit genommen haben, dieses Thema mit uns zu erkunden.

Ich habe diesen Essay geschrieben, weil ich als Wissenschaftler das Gefühl habe, dass es wichtig ist, die ungeschminkte Wahrheit zu sagen, und weil ich als Mensch das Gefühl habe, dass es entscheidend ist, dass wir schnell und entschlossen handeln, um ein weltveränderndes Problem anzugehen: die Entwicklung intelligenterer KI-Systeme als Menschen.

Wenn wir auf diesen bemerkenswerten Zustand der Dinge mit Weisheit reagieren wollen, müssen wir bereit sein, das vorherrschende Narrativ kritisch zu hinterfragen, dass AGI und Superintelligenz gebaut werden „müssen", um unsere Interessen zu sichern, oder „unvermeidlich" seien und nicht gestoppt werden könnten. Diese Narrative entmachten uns und machen uns unfähig, die alternativen Wege vor uns zu sehen.

Ich hoffe, Sie werden sich mir anschließen und zur Vorsicht im Angesicht von Rücksichtslosigkeit und zu Mut im Angesicht von Gier aufrufen.

Ich hoffe, Sie werden sich mir anschließen und zu einer menschlichen Zukunft aufrufen.

*– Anthony*

![Anthony Aguirre signature](https://keepthefuturehuman.ai/essay/_next/image?url=https%3A%2F%2Fkeepthefuturehuman.ai%2Fwp-content%2Fuploads%2F2025%2F02%2FAnthony-Aguirre-signature-300x84.png&w=3840&q=75)