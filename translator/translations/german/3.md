# Kapitel 3 - Zentrale Aspekte der Entwicklung moderner allgemeiner KI-Systeme

Die meisten der weltweit modernsten KI-Systeme werden mit überraschend ähnlichen Methoden entwickelt. Hier sind die Grundlagen.

Um einen Menschen wirklich zu verstehen, muss man etwas über Biologie, Evolution, Kindererziehung und mehr wissen; um KI zu verstehen, muss man ebenfalls wissen, wie sie entwickelt wird. In den letzten fünf Jahren haben sich KI-Systeme sowohl in ihrer Leistungsfähigkeit als auch in ihrer Komplexität enorm weiterentwickelt. Ein entscheidender Erfolgsfaktor war die Verfügbarkeit sehr großer Mengen an Rechenleistung (umgangssprachlich „Compute", wenn es auf KI angewendet wird).

Die Zahlen sind verblüffend. Etwa 10<sup>25</sup>-10<sup>26</sup> „Gleitkommaoperationen" (FLOP) [^1] werden für das Training von Modellen wie der GPT-Serie, Claude, Gemini usw. verwendet.[^2] (Zum Vergleich: Wenn jeder Mensch auf der Erde ununterbrochen arbeiten und alle fünf Sekunden eine Berechnung durchführen würde, bräuchte es etwa eine Milliarde Jahre, um dies zu schaffen.) Diese enorme Menge an Rechenleistung ermöglicht das Training von Modellen mit bis zu Billionen von Modellgewichten auf Terabytes von Daten – einem großen Teil aller jemals geschriebenen qualitativ hochwertigen Texte sowie umfangreichen Bibliotheken von Tönen, Bildern und Videos. Ergänzt durch zusätzliches umfassendes Training, das menschliche Präferenzen und gute Aufgabenleistung verstärkt, zeigen auf diese Weise trainierte Modelle menschlich vergleichbare Leistung bei einer beträchtlichen Bandbreite grundlegender intellektueller Aufgaben, einschließlich Reasoning und Problemlösung.

Wir wissen auch (sehr, sehr grob), wie viel Rechengeschwindigkeit, in Operationen pro Sekunde, ausreicht, damit die *Inferenz*-Geschwindigkeit [^3] eines solchen Systems der *Geschwindigkeit* menschlicher Textverarbeitung entspricht. Es sind etwa 10<sup>15</sup>-10<sup>16</sup> FLOP pro Sekunde.[^4]

Obwohl diese Modelle mächtig sind, sind sie von Natur aus in wichtigen Aspekten begrenzt, ganz ähnlich wie ein einzelner Mensch begrenzt wäre, wenn er gezwungen wäre, einfach Text mit einer festen Rate von Wörtern pro Minute auszugeben, ohne anzuhalten zum Nachdenken oder zusätzliche Werkzeuge zu verwenden. Neuere KI-Systeme gehen diese Einschränkungen durch einen komplexeren Prozess und eine Architektur an, die mehrere Schlüsselelemente kombiniert:

- Ein oder mehrere neuronale Netzwerke, wobei ein Modell die Kernkognition bereitstellt und bis zu mehrere andere spezialisiertere Aufgaben übernehmen;
- *Werkzeuge*, die dem Modell zur Verfügung gestellt und von ihm verwendet werden können – beispielsweise die Fähigkeit, im Web zu suchen, Dokumente zu erstellen oder zu bearbeiten, Programme auszuführen usw.
- *Gerüstsysteme*, die Ein- und Ausgaben neuronaler Netzwerke verbinden. Ein sehr einfaches Gerüstsystem könnte nur zwei „Instanzen" eines KI-Modells miteinander sprechen lassen oder eine die Arbeit der anderen überprüfen lassen.[^5]
- *Chain-of-Thought* und verwandte Prompting-Techniken tun etwas Ähnliches und veranlassen ein Modell beispielsweise dazu, viele Ansätze für ein Problem zu generieren und diese Ansätze dann für eine aggregierte Antwort zu verarbeiten.
- *Retraining* von Modellen, um Werkzeuge, Gerüstsysteme und Chain-of-Thought besser zu nutzen.

Da diese Erweiterungen sehr mächtig sein können (und KI-Systeme selbst einschließen), können diese zusammengesetzten Systeme ziemlich ausgereift sein und die KI-Fähigkeiten dramatisch verbessern.[^6] Und kürzlich wurden Techniken in Gerüstsystemen und besonders Chain-of-Thought-Prompting (und die Einspeisung der Ergebnisse zurück in das Retraining von Modellen, um diese besser zu nutzen) in [o1](https://openai.com/o1/), [o3](https://openai.com/index/openai-o3-mini/) und [DeepSeek R1](https://api-docs.deepseek.com/news/news250120) entwickelt und eingesetzt, um viele Inferenzdurchläufe als Antwort auf eine gegebene Anfrage durchzuführen.[^7] Dies ermöglicht es dem Modell effektiv, über seine Antwort „nachzudenken" und steigert die Fähigkeit dieser Modelle dramatisch, hochwertiges Reasoning bei Wissenschafts-, Mathematik- und Programmieraufgaben durchzuführen.[^8]

Für eine gegebene KI-Architektur können Erhöhungen der Trainingsrechenleistung [zuverlässig übersetzt werden](https://arxiv.org/abs/2405.10938) in Verbesserungen bei einer Reihe klar definierter Metriken. Für weniger scharf definierte allgemeine Fähigkeiten (wie die unten diskutierten) ist die Übersetzung weniger klar und vorhersagbar, aber es ist fast sicher, dass größere Modelle mit mehr Trainingsrechenleistung neue und bessere Fähigkeiten haben werden, auch wenn es schwer vorherzusagen ist, welche das sein werden.

Ähnlich haben zusammengesetzte Systeme und besonders Fortschritte in „Chain of Thought" (und Training von Modellen, die gut damit funktionieren) Skalierung in der *Inferenz*-Rechenleistung freigeschaltet: Für ein gegebenes trainiertes Kernmodell steigen zumindest einige KI-Systemfähigkeiten, wenn mehr Rechenleistung angewendet wird, die es ihnen ermöglicht, „härter und länger" über komplexe Probleme zu „denken". Dies geht mit steilen Kosten bei der Rechengeschwindigkeit einher und erfordert Hunderte oder Tausende mehr FLOP/s, um menschliche Leistung zu erreichen.[^9]

Obwohl die Rolle der Rechenleistung nur ein Teil dessen ist, was zu raschem KI-Fortschritt führt,[^10] werden die Rechenleistung und die Möglichkeit zusammengesetzter Systeme sich als entscheidend sowohl für die Verhinderung unkontrollierbarer AGI als auch für die Entwicklung sichererer Alternativen erweisen.

[^1]: 10<sup>27</sup> bedeutet 1 gefolgt von 25 Nullen, oder zehn Billionen Billionen. Ein FLOP ist einfach eine arithmetische Addition oder Multiplikation von Zahlen mit einer bestimmten Genauigkeit. Beachten Sie, dass die Leistung von KI-Hardware je nach Genauigkeit der Arithmetik und der Architektur des Computers um einen Faktor von zehn variieren kann. Das Zählen von Logikgatter-Operationen (ANDS, ORS, AND NOTS) wäre fundamental, aber diese sind nicht allgemein verfügbar oder benchmarked; für gegenwärtige Zwecke ist es nützlich, auf 16-Bit-Operationen (FP16) zu standardisieren, obwohl angemessene Konversionsfaktoren etabliert werden sollten.

[^2]: Eine Sammlung von Schätzungen und harten Daten ist von [Epoch AI](https://epochai.org/data/large-scale-ai-models) verfügbar und zeigt etwa 2×10<sup>25</sup> 16-Bit FLOP für GPT-4; dies entspricht ungefähr [Zahlen, die durchgesickert sind](https://mpost.io/gpt-4s-leaked-details-shed-light-on-its-massive-scale-and-impressive-architecture/) für GPT-4. Schätzungen für andere Modelle aus Mitte 2024 liegen alle innerhalb eines Faktors von wenigen von GPT-4.

[^3]: Inferenz ist einfach der Prozess der Generierung einer Ausgabe aus einem neuronalen Netzwerk. Training kann als eine Abfolge vieler Inferenzen und Modellgewichtsanpassungen betrachtet werden.

[^4]: Für Textproduktion benötigte das ursprüngliche GPT-4 560 TFLOP pro generiertem Token. Etwa 7 Tokens/s sind nötig, um mit menschlichem Denken Schritt zu halten, das ergibt ≈3×10<sup>15</sup> FLOP/s. Aber Effizienzsteigerungen haben dies reduziert; [diese NVIDIA-Broschüre](https://developer.nvidia.com/blog/supercharging-llama-3-1-across-nvidia-platforms/) beispielsweise zeigt nur 3×10<sup>14</sup> FLOP/s für ein vergleichbar leistungsfähiges Llama 405B-Modell.

[^5]: Als etwas komplexeres Beispiel könnte ein KI-System zunächst mehrere mögliche Lösungen für ein Mathematikproblem generieren, dann eine andere Instanz verwenden, um jede Lösung zu überprüfen, und schließlich eine dritte verwenden, um die Ergebnisse in eine klare Erklärung zu synthetisieren. Dies ermöglicht eine gründlichere und zuverlässigere Problemlösung als ein einziger Durchgang.

[^6]: Siehe zum Beispiel Details zu [OpenAIs „Operator"](https://openai.com/index/introducing-operator/), [Claudes Werkzeugfähigkeiten](https://docs.anthropic.com/en/docs/build-with-claude/computer-use) und [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT). OpenAIs [Deep Research](https://openai.com/index/introducing-deep-research/) hat wahrscheinlich eine ziemlich ausgeklügelte Architektur, aber Details sind nicht verfügbar.

[^7]: Deepseek R1 stützt sich auf iteratives Training und Prompting des Modells, sodass das final trainierte Modell umfangreiches Chain-of-Thought-Reasoning erstellt. Architekturdetails sind für o1 oder o3 nicht verfügbar, jedoch hat Deepseek enthüllt, dass keine besondere „Geheimzutat" erforderlich ist, um Fähigkeitsskalierung mit Inferenz freizuschalten. Aber trotz großer Medienaufmerksamkeit als Umwälzung des „Status quo" in der KI beeinflusst es nicht die Kernaussagen dieses Essays.

[^8]: Diese Modelle übertreffen Standard-Modelle bei Reasoning-Benchmarks erheblich. Zum Beispiel erreichte GPT-4o beim GPQA Diamond Benchmark – einem rigorosen Test von PhD-Niveau-Wissenschaftsfragen – [56%](https://openai.com/index/learning-to-reason-with-llms/), während o1 und o3 78% bzw. 88% erreichten und damit den durchschnittlichen 70%-Score menschlicher Experten weit übertrafen.

[^9]: OpenAIs O3 wendete wahrscheinlich ∼10<sup>21</sup>-10<sup>22</sup> FLOP [für jede der ARC-AGI-Challenge-Fragen](https://www.interconnects.ai/p/openais-o3-the-2024-finale-of-ai) auf, die kompetente Menschen in (sagen wir) 10-100 Sekunden lösen können, was eine Zahl von eher ∼10<sup>20</sup> FLOP/s ergibt.

[^10]: Während Rechenleistung ein Schlüsselmaß für KI-Systemfähigkeiten ist, interagiert sie sowohl mit Datenqualität als auch algorithmischen Verbesserungen. Bessere Daten oder Algorithmen können Rechenanforderungen reduzieren, während mehr Rechenleistung manchmal schwächere Daten oder Algorithmen kompensieren kann.