# Kapitel 5 - An der Schwelle

Der Weg von den heutigen KI-Systemen zu vollständiger AGI erscheint schockierend kurz und vorhersagbar.

Die vergangenen zehn Jahre haben dramatische Fortschritte in der KI erlebt, angetrieben von enormen [Rechenleistungs-](https://epoch.ai/blog/training-compute-of-frontier-ai-models-grows-by-4-5x-per-year), personellen und [finanziellen](https://arxiv.org/abs/2405.21015) Ressourcen. Viele spezialisierte KI-Anwendungen übertreffen Menschen bei ihren zugewiesenen Aufgaben und sind dabei sicherlich deutlich schneller und günstiger.[^1] Zudem gibt es spezialisierte übermenschliche Agenten, die alle Menschen in abgegrenzten Spielbereichen wie [Go](https://www.nature.com/articles/nature16961), [Schach](https://arxiv.org/abs/1712.01815) und [Poker](https://www.deepstack.ai/) besiegen können, sowie [generalistischere Agenten](https://deepmind.google/discover/blog/a-generalist-agent/), die in vereinfachten simulierten Umgebungen so effektiv planen und handeln können wie Menschen.

Am prominentesten sind die aktuellen allgemeinen KI-Systeme von OpenAI/Microsoft, Google/Deepmind, Anthropic/Amazon, Facebook/Meta, X.ai/Tesla und anderen,[^2] die seit Anfang 2023 entstanden sind und seither stetig (wenn auch ungleichmäßig) ihre Fähigkeiten ausgebaut haben. Alle wurden durch Token-Vorhersage auf riesigen Text- und Multimedia-Datensätzen erstellt, kombiniert mit umfangreichem Verstärkungsfeedback von Menschen und anderen KI-Systemen. Einige enthalten auch umfangreiche Werkzeug- und Gerüstsysteme.

## Stärken und Schwächen aktueller genereller Systeme

Diese Systeme erbringen gute Leistungen bei einer zunehmend breiten Palette von Tests zur Messung von Intelligenz und Expertise, mit Fortschritten, die sogar Experten auf diesem Gebiet überrascht haben:

- Bei seiner Erstveröffentlichung [erreichte oder übertraf GPT-4 die typische menschliche Leistung](https://arxiv.org/abs/2303.08774) bei standardisierten akademischen Tests wie SATs, GRE, Aufnahmeprüfungen und Anwaltsprüfungen. Neuere Modelle schneiden wahrscheinlich deutlich besser ab, obwohl die Ergebnisse nicht öffentlich verfügbar sind.
- Der Turing-Test – lange als Schlüssel-Benchmark für „echte" KI betrachtet – wird nun routinemäßig in einigen Formen von modernen Sprachmodellen bestanden, sowohl informell als auch in [formellen Studien](https://arxiv.org/abs/2405.08007).[^3]
- Beim umfassenden MMLU-Benchmark, der 57 akademische Fächer umfasst, [erreichen aktuelle Modelle Punktzahlen auf Experteniveau](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu) (∼90%)[^4]
- Die technische Expertise hat sich dramatisch verbessert: Der GPQA-Benchmark für Physik auf Graduiertenebene verzeichnete einen [Leistungssprung](https://epoch.ai/data/ai-benchmarking-dashboard) von nahezu zufälligen Vermutungen (GPT-4, 2022) auf Expertenniveau (o1-preview, 2024).
- Selbst Tests, die speziell darauf ausgelegt waren, KI-resistent zu sein, fallen: OpenAIs O3 [löst angeblich](https://www.nextbigfuture.com/2024/12/openai-releases-o3-model-with-high-performance-and-high-cost.html) den ARC-AGI-Benchmark für abstrakte Problemlösung auf menschlichem Niveau, erreicht Spitzen-Expertenleistung beim Programmieren und erzielt 25% bei Epoch AIs „Frontier Math"-Problemen, die Elite-Mathematiker herausfordern sollen.[^5]
- Der Trend ist so deutlich, dass der Entwickler von MMLU nun [„Humanity's Last Exam"](https://agi.safe.ai/) erstellt hat – ein ominöser Name, der die Möglichkeit widerspiegelt, dass KI bald die menschliche Leistung bei jedem sinnvollen Test übertreffen wird. Zum Zeitpunkt der Erstellung gibt es Behauptungen, KI-Systeme erreichten 27% (laut [Sam Altman](https://x.com/sama/status/1886220281565381078)) und 35% (laut [diesem Paper](https://arxiv.org/abs/2502.09955)) bei dieser extrem schwierigen Prüfung. Es ist äußerst unwahrscheinlich, dass ein einzelner Mensch das schaffen könnte.

Trotz dieser beeindruckenden Zahlen (und ihrer offensichtlichen Intelligenz bei der Interaktion mit ihnen)[^6] gibt es viele Dinge, die (zumindest die veröffentlichten Versionen) dieser neuronalen Netzwerke *nicht* können. Derzeit sind die meisten körperlos – existieren nur auf Servern – und verarbeiten höchstens Text, Ton und Standbilder (aber keine Videos). Entscheidend ist, dass die meisten keine komplexen geplanten Aktivitäten durchführen können, die hohe Genauigkeit erfordern.[^7] Und es gibt eine Reihe anderer Eigenschaften, die in hochstufiger menschlicher Kognition stark ausgeprägt, in veröffentlichten KI-Systemen jedoch schwach entwickelt sind.

Die folgende Tabelle führt eine Reihe davon auf, basierend auf KI-Systemen von Mitte 2024 wie GPT-4o, Claude 3.5 Sonnet und Google Gemini 1.5.[^8] Die Schlüsselfrage dafür, wie schnell allgemeine KI mächtiger wird, lautet: In welchem Maße wird *mehr desselben* Ergebnisse hervorbringen, versus das Hinzufügen zusätzlicher, aber *bekannter* Techniken, versus die Entwicklung oder Implementierung *wirklich neuer* KI-Forschungsrichtungen. Meine eigenen Vorhersagen dazu sind in der Tabelle angegeben, in Bezug darauf, wie wahrscheinlich jedes dieser Szenarien ist, diese Fähigkeit auf und über das menschliche Niveau zu bringen.

<table><tbody><tr><th>Fähigkeit</th><th>Beschreibung der Fähigkeit</th><th>Status/Prognose</th><th>Skalierung/bekannt/neu</th></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td colspan="4"><em>Zentrale kognitive Fähigkeiten</em></td></tr><tr><td>Reasoning</td><td>Menschen können präzise, mehrstufige Schlussfolgerungen ziehen, Regeln befolgen und Genauigkeit überprüfen.</td><td>Dramatische jüngste Fortschritte durch erweiterte Chain-of-Thought und erneutes Training</td><td>95/5/5</td></tr><tr><td>Planung</td><td>Menschen zeigen langfristige und hierarchische Planung.</td><td>Verbessert sich mit der Skalierung; kann durch Gerüstsysteme und bessere Trainingstechniken stark unterstützt werden.</td><td>10/85/5</td></tr><tr><td>Wahrheitsverankerung</td><td>Allzweck-KIs erfinden unbegründete Informationen, um Anfragen zu erfüllen.</td><td>Verbessert sich mit der Skalierung; Kalibrierungsdaten im Modell verfügbar; kann durch Gerüstsysteme überprüft/verbessert werden.</td><td>30/65/5</td></tr><tr><td>Flexible Problemlösung</td><td>Menschen können neue Muster erkennen und neue Lösungen für komplexe Probleme erfinden; aktuelle ML-Modelle haben Schwierigkeiten damit.</td><td>Verbessert sich mit der Skalierung, aber schwach; könnte mit neurosymbolischen oder verallgemeinerten „Such"-Techniken lösbar sein.</td><td>15/75/10</td></tr><tr><td colspan="4"><em>Lernen und Wissen</em></td></tr><tr><td>Lernen & Gedächtnis</td><td>Menschen haben Arbeits-, Kurzzeit- und Langzeitgedächtnis, die alle dynamisch und miteinander verbunden sind.</td><td>Alle Modelle lernen während des Trainings; Allzweck-KIs lernen innerhalb des Kontextfensters und während der Feinabstimmung; „kontinuierliches Lernen" und andere Techniken existieren, sind aber noch nicht in große Allzweck-KIs integriert.</td><td>5/80/15</td></tr><tr><td>Abstraktion & Rekursion</td><td>Menschen können Beziehungsmengen in abstraktere überführen für Reasoning und Manipulation, einschließlich rekursivem „Meta"-Reasoning.</td><td>Schwache Verbesserung mit der Skalierung; könnte in neurosymbolischen Systemen entstehen.</td><td>30/50/20</td></tr><tr><td>Weltmodell(e)</td><td>Menschen haben und aktualisieren kontinuierlich ein prädiktives Weltmodell, innerhalb dessen sie Probleme lösen und physikalisches Reasoning betreiben können</td><td>Verbessert sich mit der Skalierung; Aktualisierung mit Lernen verknüpft; Allzweck-KIs schwach in realer Weltvorhersage.</td><td>20/50/30</td></tr><tr><td colspan="4"><em>Selbst und Handlungsfähigkeit</em></td></tr><tr><td>Handlungsfähigkeit</td><td>Menschen können Handlungen ausführen, um Ziele zu verfolgen, basierend auf Planung/Vorhersage.</td><td>Viele ML-Systeme sind handlungsfähig; LLMs können durch Wrapper zu Agenten gemacht werden.</td><td>5/90/5</td></tr><tr><td>Selbststeuerung</td><td>Menschen entwickeln und verfolgen ihre eigenen Ziele mit intern erzeugter Motivation und Antrieb.</td><td>Besteht größtenteils aus Handlungsfähigkeit plus Originalität; wird wahrscheinlich in komplexen handlungsfähigen Systemen mit abstrakten Zielen entstehen.</td><td>40/45/15</td></tr><tr><td>Selbstbezug</td><td>Menschen verstehen und denken über sich selbst als situiert innerhalb einer Umgebung/eines Kontexts nach.</td><td>Verbessert sich mit der Skalierung und könnte durch Trainingsbelohnung erweitert werden.</td><td>70/15/15</td></tr><tr><td>Selbstbewusstsein</td><td>Menschen haben Wissen über ihre eigenen Gedanken und geistigen Zustände und können darüber nachdenken.</td><td>Existiert in gewissem Sinne in Allzweck-KIs, die wohl den klassischen „Spiegeltest" für Selbstbewusstsein bestehen können. Kann mit Gerüstsystemen verbessert werden; aber unklar, ob das ausreicht.</td><td>20/55/25</td></tr><tr><td colspan="4"><em>Schnittstelle und Umgebung</em></td></tr><tr><td>Verkörperte Intelligenz</td><td>Menschen verstehen ihre reale Umgebung und interagieren aktiv mit ihr.</td><td>Verstärkungslernen funktioniert gut in simulierten und realen (robotischen) Umgebungen und kann in multimodale Transformer integriert werden.</td><td>5/85/10</td></tr><tr><td>Multisensorische Verarbeitung</td><td>Menschen integrieren und verarbeiten in Echtzeit visuelle, auditive und andere Sinnesdatenströme.</td><td>Training in mehreren Modalitäten scheint „einfach zu funktionieren" und verbessert sich mit der Skalierung. Echtzeit-Videoverarbeitung ist schwierig, aber z.B. selbstfahrende Systeme verbessern sich rasch.</td><td>30/60/10</td></tr><tr><td colspan="4"><em>Höherrangige Fähigkeiten</em></td></tr><tr><td>Originalität</td><td>Aktuelle ML-Modelle sind kreativ im Transformieren und Kombinieren existierender Ideen/Werke, aber Menschen können neue Rahmenwerke und Strukturen entwickeln, manchmal verknüpft mit ihrer Identität.</td><td>Kann schwer von „Kreativität" zu unterscheiden sein, die sich dazu skalieren könnte; könnte aus Kreativität plus Selbstbewusstsein entstehen.</td><td>50/40/10</td></tr><tr><td>Empfindungsfähigkeit</td><td>Menschen erleben Qualia; diese können positive, negative oder neutrale Valenz haben; es ist „wie etwas", eine Person zu sein.</td><td>Sehr schwierig und philosophisch problematisch zu bestimmen, ob ein gegebenes System das besitzt.</td><td>5/10/85</td></tr></tbody></table>

Schlüsselfähigkeiten, die derzeit unter dem menschlichen Expertenniveau in modernen Allzweck-KI-Systemen liegen, nach Typ gruppiert. Die dritte Spalte fasst den aktuellen Status zusammen. Die letzte Spalte zeigt die vorhergesagte Wahrscheinlichkeit (%), dass menschliches Leistungsniveau erreicht wird durch: Skalierung aktueller Techniken / Kombination mit bekannten Techniken / Entwicklung neuer Techniken. Diese Fähigkeiten sind nicht unabhängig, und eine Steigerung bei einer geht typischerweise mit Steigerungen bei anderen einher. Zu beachten ist, dass nicht alle (insbesondere Empfindungsfähigkeit) für KI-Systeme notwendig sind, die zur Weiterentwicklung der KI-Entwicklung fähig sind, was die Möglichkeit mächtiger, aber nicht empfindungsfähiger KI unterstreicht.

Diese Aufschlüsselung dessen, was „fehlt", macht ziemlich deutlich, dass wir durchaus auf dem Weg zu breit übermenschlicher Intelligenz durch Skalierung existierender oder bekannter Techniken sind.[^9]

Es könnte trotzdem Überraschungen geben. Selbst wenn man „Empfindungsfähigkeit" außer Acht lässt, könnte es einige der aufgelisteten zentralen kognitiven Fähigkeiten geben, die wirklich nicht mit aktuellen Techniken erreicht werden können und neue erfordern. Aber bedenken Sie Folgendes: Der gegenwärtige Aufwand, den viele der weltgrößten Unternehmen betreiben, entspricht einem Vielfachen der Ausgaben des Apollo-Projekts und dem Zehnfachen der des Manhattan-Projekts,[^10] und beschäftigt Tausende der besten Techniker zu unerhörten Gehältern. Die Dynamik der vergangenen Jahre hat nun mehr menschliche intellektuelle Kraft (mit KI als neuer Ergänzung) darauf konzentriert als jedes Unterfangen in der Geschichte. Wir sollten nicht auf Scheitern setzen.

## Das große Ziel: generalistische autonome Agenten

Die Entwicklung allgemeiner KI in den vergangenen Jahren konzentrierte sich darauf, allgemeine und mächtige, aber werkzeugähnliche KI zu schaffen: Sie funktioniert primär als (ziemlich) treuer Assistent und führt im Allgemeinen keine Handlungen eigenständig aus. Das ist teils beabsichtigt, liegt aber größtenteils daran, dass diese Systeme bei den relevanten Fähigkeiten einfach nicht kompetent genug waren, um mit komplexen Handlungen betraut zu werden.[^11]

KI-Unternehmen und Forscher [verlagern ihren Fokus](https://www.axios.com/2025/01/23/davos-2025-ai-agents) jedoch zunehmend auf *autonome* allgemeine Agenten auf Expertenebene.[^12] Das würde den Systemen ermöglichen, eher wie ein menschlicher Assistent zu agieren, dem der Nutzer echte Handlungen delegieren kann.[^13] Was wird das erfordern? Eine Reihe der Fähigkeiten aus der „Was fehlt"-Tabelle sind beteiligt, einschließlich starker Wahrheitsverankerung, Lernen und Gedächtnis, Abstraktion und Rekursion sowie Weltmodellierung (für Intelligenz), Planung, Handlungsfähigkeit, Originalität, Selbststeuerung, Selbstbezug und Selbstbewusstsein (für Autonomie) sowie multisensorische Verarbeitung, verkörperte Intelligenz und flexible Problemlösung (für Generalität).[^14]

Diese dreifache Schnittmenge aus hoher Autonomie (Handlungsunabhängigkeit), hoher Generalität (Umfang und Aufgabenbreite) und hoher Intelligenz (Kompetenz bei kognitiven Aufgaben) ist derzeit einzigartig menschlich. Sie ist implizit das, was viele wahrscheinlich im Sinn haben, wenn sie an AGI denken – sowohl hinsichtlich ihres Werts als auch ihrer Risiken.

Das bietet eine andere Möglichkeit, A-G-I als ***A*** utonome- ***G*** enerelle- ***I*** ntelligenz zu definieren, und wir werden sehen, dass diese dreifache Schnittmenge eine sehr wertvolle Brille für hochfähige Systeme bietet, sowohl zum Verständnis ihrer Risiken und Chancen als auch für die Governance von KI.

![](https://keepthefuturehuman.ai/essay/_next/image?url=https%3A%2F%2Fkeepthefuturehuman.ai%2Fwp-content%2Fuploads%2F2025%2F02%2FAGI-Venn-Diagram-Simple-1024x1024.png&w=3840&q=75) Die transformative A-G-I-Macht- und Risikozone entsteht aus der Schnittmenge dreier Schlüsseleigenschaften: hohe Autonomie, hohe Intelligenz bei Aufgaben und hohe Generalität.

## Der KI-(Selbst-)Verbesserungszyklus

Ein letzter entscheidender Faktor zum Verständnis des KI-Fortschritts ist KIs einzigartiger technologischer Rückkopplungskreislauf. Bei der KI-Entwicklung bringt Erfolg – sowohl bei demonstrierten Systemen als auch bei eingesetzten Produkten – zusätzliche Investitionen, Talente und Wettbewerb mit sich, und wir befinden uns derzeit inmitten einer enormen KI-Hype-plus-Realitäts-Rückkopplungsschleife, die Hunderte von Milliarden oder sogar Billionen von Dollars an Investitionen antreibt.

Diese Art von Rückkopplungszyklus könnte bei jeder Technologie auftreten, und wir haben ihn bei vielen gesehen, wo Markterfolg Investitionen hervorbringt, die Verbesserung und besseren Markterfolg zur Folge haben. Aber KI-Entwicklung geht weiter, insofern nun KI-Systeme dabei helfen, neue und mächtigere KI-Systeme zu entwickeln.[^15] Wir können uns diesen Rückkopplungskreislauf in fünf Stufen vorstellen, jede mit kürzerer Zeitskala als die letzte, wie in der Tabelle gezeigt.

*Der KI-Verbesserungszyklus operiert über mehrere Zeitskalen hinweg, wobei jede Stufe möglicherweise nachfolgende Stufen beschleunigt. Frühere Stufen sind bereits im Gange, während spätere Stufen spekulativ bleiben, aber sehr schnell voranschreiten könnten, sobald sie freigesetzt werden.*

Mehrere dieser Stufen sind bereits im Gange, und ein paar beginnen eindeutig. Die letzte Stufe, in der KI-Systeme sich autonom selbst verbessern, ist ein Grundpfeiler der Literatur über das Risiko sehr mächtiger KI-Systeme, und das aus gutem Grund.[^16] Aber es ist wichtig zu bemerken, dass es nur die drastischste Form eines Rückkopplungszyklus ist, der bereits begonnen hat und zu mehr Überraschungen bei der raschen Weiterentwicklung der Technologie führen könnte.


[^1]: Sie nutzen deutlich mehr von dieser KI, als Sie wahrscheinlich denken: für Sprachgenerierung und -erkennung, Bildverarbeitung, Newsfeed-Algorithmen usw.

[^2]: Während die Beziehungen zwischen diesen Unternehmenspaaren ziemlich komplex und nuanciert sind, habe ich sie explizit aufgelistet, um sowohl die enorme Gesamtmarktkapitalisierung der Firmen zu zeigen, die nun in der KI-Entwicklung engagiert sind, als auch dass hinter sogar „kleineren" Unternehmen wie Anthropic enorm tiefe Taschen durch Investitionen und große Partnerschaftsverträge stehen.

[^3]: Es ist Mode geworden, den Turing-Test zu verunglimpfen, aber er ist durchaus mächtig und allgemein. In schwachen Versionen zeigt er an, ob typische Menschen, die mit einer KI (die darauf trainiert ist, menschlich zu agieren) auf typische Weise für kurze Zeiträume interagieren, erkennen können, ob es eine KI ist. Sie können es nicht. Zweitens kann ein hochgradig adversarieller Turing-Test praktisch jedes Element menschlicher Fähigkeit und Intelligenz prüfen – etwa durch Vergleich eines KI-Systems mit einem menschlichen Experten, bewertet von anderen menschlichen Experten. In gewissem Sinne ist ein Großteil der KI-Bewertung eine verallgemeinerte Form des Turing-Tests.

[^4]: Das gilt pro Bereich – kein Mensch könnte plausibel solche Punktzahlen in allen Fächern gleichzeitig erreichen.

[^5]: Das sind Probleme, für die selbst exzellente Mathematiker erhebliche Zeit bräuchten, wenn sie sie überhaupt lösen könnten.

[^6]: Wenn Sie skeptisch veranlagt sind, behalten Sie Ihre Skepsis bei, aber probieren Sie wirklich die aktuellsten Modelle aus und versuchen Sie selbst einige der Testfragen, die sie bestehen können. Als Physikprofessor würde ich mit nahezu Gewissheit vorhersagen, dass zum Beispiel die Top-Modelle die Graduiertenprüfung in unserem Fachbereich bestehen würden.

[^7]: Das und andere Schwächen wie Konfabulation haben die Markteinführung verlangsamt und zu einer Lücke zwischen wahrgenommenen und behaupteten Fähigkeiten geführt (was auch durch die Brille intensiven Marktwettbewerbs und der Notwendigkeit, Investitionen anzuziehen, betrachtet werden muss). Das hat sowohl die Öffentlichkeit als auch Politiker über den tatsächlichen Stand des KI-Fortschritts verwirrt. Auch wenn er vielleicht nicht dem Hype entspricht, ist der Fortschritt sehr real.

[^8]: Der größte Fortschritt seither war die Entwicklung von Systemen, die für hochqualitatives Reasoning trainiert sind, unter Nutzung von mehr Rechenleistung während der Inferenz und größerem Verstärkungslernen. Da diese Modelle neu sind und ihre Fähigkeiten weniger getestet, habe ich diese Tabelle nicht völlig überarbeitet, außer bei „Reasoning", das ich als praktisch gelöst betrachte. Aber ich habe Vorhersagen basierend auf erfahrenen und berichteten Fähigkeiten dieser Systeme aktualisiert.

[^9]: Frühere Wellen des KI-Optimismus in den 1960ern und 1980ern endeten in „KI-Wintern", als versprochene Fähigkeiten nicht materialisiert wurden. Die aktuelle Welle unterscheidet sich jedoch fundamental dadurch, dass sie übermenschliche Leistung in vielen Bereichen erreicht hat, unterstützt von massiven Rechenressourcen und kommerziellem Erfolg.

[^10]: Das vollständige Apollo-Projekt [kostete etwa 250 Milliarden USD in 2020-Dollars](https://www.planetary.org/space-policy/cost-of-apollo), und das Manhattan-Projekt [weniger als ein Zehntel davon](https://www.brookings.edu/the-costs-of-the-manhattan-project/). Goldman Sachs [projiziert eine Billion Dollar Ausgaben allein für KI-Rechenzentren](https://www.datacenterdynamics.com/en/news/goldman-sachs-1tn-to-be-spent-on-ai-data-centers-chips-and-utility-upgrades-with-little-to-show-for-it-so-far/) in den nächsten Jahren.

[^11]: Obwohl Menschen viele Fehler machen, unterschätzen wir, wie zuverlässig wir sein können! Da sich Wahrscheinlichkeiten multiplizieren, erfordert eine Aufgabe mit 20 korrekt auszuführenden Schritten, dass jeder Schritt zu 97% zuverlässig ist, nur um sie in der Hälfte der Zeit richtig zu erledigen. Wir machen solche Aufgaben ständig.

[^12]: Ein starker Schritt in diese Richtung wurde kürzlich mit OpenAIs [„Deep Research"](https://openai.com/index/introducing-deep-research/) unternommen, einem Assistenten, der autonom allgemeine Forschung durchführt, beschrieben als „eine neue agentische Fähigkeit, die mehrstufige Internetforschung für komplexe Aufgaben durchführt."

[^13]: Dinge wie dieses lästige PDF-Formular ausfüllen, Flüge buchen usw. Aber mit einem PhD in 20 Fächern! Also auch: diese Dissertation für Sie schreiben, diesen Vertrag für Sie verhandeln, diesen Satz für Sie beweisen, diese Werbekampagne für Sie erstellen usw. Was machen *Sie*? Sie sagen ihm, was zu tun ist, natürlich.

[^14]: Zu beachten ist, dass Empfindungsfähigkeit *nicht* eindeutig erforderlich ist, noch impliziert KI in dieser dreifachen Schnittmenge notwendigerweise diese.

[^15]: Die nächste Analogie hier ist vielleicht die Chip-Technologie, wo die Entwicklung das Moore'sche Gesetz jahrzehntelang aufrechterhalten hat, da Computertechnologien Menschen dabei helfen, die nächste Generation von Chip-Technologie zu entwerfen. Aber KI wird weit direkter sein.

[^16]: Es ist wichtig, es einen Moment auf sich wirken zu lassen, dass KI bald sich selbst auf einer Zeitskala von Tagen oder Wochen verbessern könnte. Oder weniger. Behalten Sie das im Hinterkopf, wenn Ihnen jemand sagt, eine KI-Fähigkeit ist definitiv weit entfernt.