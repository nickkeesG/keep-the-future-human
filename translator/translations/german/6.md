# Kapitel 6 - Das Rennen um die AGI

Was sind die treibenden Kräfte hinter dem Rennen um die Entwicklung von AGI, sowohl für Unternehmen als auch für Länder?

Die jüngsten rasanten Fortschritte in der KI haben zu einem außergewöhnlichen Maß an Aufmerksamkeit und Investitionen geführt – und sind gleichzeitig daraus entstanden. Dies wird teilweise durch die Erfolge in der KI-Entwicklung angetrieben, aber es steckt mehr dahinter. Warum wetteifern einige der größten Unternehmen der Welt und sogar ganze Länder darum, nicht nur KI zu entwickeln, sondern AGI und Superintelligenz?

## Was die KI-Forschung in Richtung menschlicher Intelligenz getrieben hat

Bis vor etwa fünf Jahren war KI größtenteils ein akademisches und wissenschaftliches Forschungsproblem, das hauptsächlich von Neugier und dem Drang angetrieben wurde, Intelligenz zu verstehen und sie in einem neuen Substrat zu erschaffen.

In dieser Phase schenkten die meisten Forscher den Vorteilen oder Gefahren von KI relativ wenig Aufmerksamkeit. Auf die Frage, warum KI entwickelt werden sollte, könnte eine typische Antwort darin bestehen, etwas vage Probleme aufzulisten, bei denen KI helfen könnte: neue Medikamente, neue Materialien, neue Wissenschaft, intelligentere Prozesse und allgemein die Verbesserung der Dinge für die Menschen.[^1]

Das sind bewundernswerte Ziele![^2] Obwohl wir hinterfragen können und werden, ob AGI – anstelle von KI im Allgemeinen – für diese Ziele notwendig ist, zeigen sie den Idealismus, mit dem viele KI-Forscher anfingen.

In den letzten fünf Jahren hat sich KI jedoch von einem relativ reinen Forschungsgebiet zu einem stärker ingenieur- und produktorientierten Bereich entwickelt, der größtenteils von einigen der weltgrößten Unternehmen vorangetrieben wird.[^3] Forscher sind zwar noch relevant, haben aber die Kontrolle über den Prozess verloren.

## Warum versuchen Unternehmen, AGI zu entwickeln?

Warum investieren also Großkonzerne (und noch mehr Investoren) riesige Ressourcen in die Entwicklung von AGI? Es gibt zwei Triebkräfte, über die die meisten Unternehmen ganz offen sprechen: Sie sehen KI als Motor für gesellschaftliche Produktivität und für ihre eigenen Gewinne. Da allgemeine KI naturgemäß vielseitig einsetzbar ist, lockt ein enormer Preis: Anstatt einen Sektor zu wählen, in dem man Produkte und Dienstleistungen entwickelt, kann man *alle auf einmal* angehen. Big-Tech-Unternehmen sind durch die Produktion digitaler Güter und Dienstleistungen riesig geworden, und zumindest einige Führungskräfte sehen KI sicherlich als den nächsten Schritt, um diese bereitzustellen – mit Risiken und Vorteilen, die denen von Suchmaschinen, sozialen Medien, Laptops, Telefonen usw. ähneln, aber über sie hinausgehen.

Aber warum AGI? Darauf gibt es eine sehr einfache Antwort, die die meisten Unternehmen und Investoren scheuen, öffentlich zu diskutieren.[^4]

AGI kann direkt, eins zu eins, *Arbeitnehmer ersetzen.*

Nicht unterstützen, nicht stärken, nicht produktiver machen. Nicht einmal *verdrängen*. All das kann und wird von Nicht-AGI geleistet werden. AGI ist spezifisch das, was Denkarbeiter vollständig *ersetzen* kann (und mit Robotik auch viele körperlich Arbeitende). Als Beleg für diese Sichtweise braucht man nur OpenAIs [(öffentlich erklärte) Definition](https://openai.com/our-structure/) von AGI zu betrachten, die lautet: "ein hochautonomes System, das Menschen bei den meisten wirtschaftlich wertvollen Arbeiten übertrifft."

Der Preis hierfür (für Unternehmen!) ist enorm. Arbeitskosten machen einen erheblichen Prozentsatz der weltweiten ∼100 Billionen Dollar Weltwirtschaft aus. Selbst wenn nur ein Bruchteil davon durch die Ersetzung menschlicher Arbeit durch KI-Arbeit erfasst wird, sprechen wir von Billionen von Dollar jährlicher Einnahmen. KI-Unternehmen sind sich auch bewusst, wer bereit ist zu zahlen. Wie sie es sehen: Sie werden nicht Tausende von Dollar pro Jahr für Produktivitätstools zahlen. Aber ein Unternehmen *wird* Tausende von Dollar pro Jahr zahlen, um Ihre Arbeitskraft zu ersetzen, wenn es das kann.

## Warum sich Länder gedrängt sehen, um die AGI zu wetteifern

Die erklärten Motivationen der Länder für die Verfolgung von AGI konzentrieren sich auf wirtschaftliche und wissenschaftliche Führerschaft. Das Argument ist überzeugend: AGI könnte die wissenschaftliche Forschung, technologische Entwicklung und das Wirtschaftswachstum dramatisch beschleunigen. Angesichts dieser Bedeutung, so argumentieren sie, kann es sich keine Großmacht leisten, zurückzufallen.[^5]

Aber es gibt auch zusätzliche und größtenteils unausgesprochene Triebkräfte. Es besteht kein Zweifel, dass wenn bestimmte Militär- und nationale Sicherheitsführer sich hinter verschlossenen Türen treffen, um eine außerordentlich mächtige und katastrophal riskante Technologie zu diskutieren, ihr Fokus nicht auf "Wie vermeiden wir diese Risiken?" liegt, sondern auf "Wie bekommen wir das zuerst?" Militär- und Geheimdienstführer sehen AGI als potenzielle Revolution in militärischen Angelegenheiten, vielleicht die bedeutendste seit Atomwaffen. Die Befürchtung ist, dass das erste Land, das AGI entwickelt, einen uneinholbaren strategischen Vorteil erlangen könnte. Dies schafft eine klassische Rüstungswettlauf-Dynamik.

Wir werden sehen, dass dieses "Rennen um AGI"-Denken,[^6] obwohl überzeugend, zutiefst fehlerhaft ist. Das liegt nicht daran, dass das Rennen gefährlich und riskant ist – obwohl es das ist –, sondern an der Natur der Technologie. Die unausgesprochene Annahme ist, dass AGI, wie andere Technologien, vom Staat kontrollierbar ist, der sie entwickelt, und eine machtverleihendes Segen für die Gesellschaft ist, die am meisten davon hat. Wie wir sehen werden, wird sie wahrscheinlich beides nicht sein.

## Warum Superintelligenz?

Während Unternehmen öffentlich auf Produktivität fokussieren und Länder auf wirtschaftliches und technologisches Wachstum, sind das für diejenigen, die bewusst vollständige AGI und Superintelligenz anstreben, nur der Anfang. Was haben sie wirklich im Sinn? Obwohl selten laut ausgesprochen, gehören dazu:

1. Heilmittel für viele oder alle Krankheiten;
2. Stoppen und Umkehrung des Alterns;
3. Neue nachhaltige Energiequellen wie Kernfusion;
4. Menschliche Verbesserungen oder maßgeschneiderte Organismen durch Gentechnik;
5. Nanotechnologie und molekulare Fertigung;
6. Geist-Uploads;
7. Exotische Physik oder Weltraumtechnologien;
8. Übermenschliche Beratung und Entscheidungsunterstützung;
9. Übermenschliche Planung und Koordination.

Die ersten drei sind größtenteils "einseitige" Technologien – d.h. wahrscheinlich ziemlich stark netto-positiv. Es ist schwer zu argumentieren gegen die Heilung von Krankheiten oder die Möglichkeit, länger zu leben, wenn man es wählt. Und wir haben bereits die negative Seite der Fusion geerntet (in Form von Atomwaffen); es wäre schön, jetzt die positive Seite zu bekommen. Die Frage bei dieser ersten Kategorie ist, ob das frühere Erhalten dieser Technologien das Risiko kompensiert.

Die nächsten vier sind eindeutig zweischneidig: transformative Technologien mit sowohl potenziell enormen Vorteilen als auch immensen Risiken, ganz wie KI. Alle diese wären, wenn sie morgen aus einer Black Box heraussprängen und eingesetzt würden, unglaublich schwer zu handhaben.[^7]

Die letzten beiden betreffen die übermenschliche KI, die Dinge selbst macht, anstatt nur Technologie zu erfinden. Präziser gesagt, Euphemismen beiseite, beinhalten diese mächtige KI-Systeme, die Menschen sagen, was sie tun sollen. Dies "Beratung" zu nennen ist unaufrichtig, wenn das System, das berät, weitaus mächtiger ist als der Beratene, der die Grundlage der Entscheidung nicht sinnvoll verstehen kann (oder selbst wenn diese bereitgestellt wird, nicht darauf vertrauen kann, dass der Berater nicht eine ähnlich überzeugende Begründung für eine andere Entscheidung liefern würde.)

Dies zeigt auf einen wichtigen Punkt, der in der obigen Liste fehlt:

10. Macht.

Es ist völlig klar, dass dem aktuellen Rennen um übermenschliche KI größtenteils die Idee zugrunde liegt, dass *Intelligenz = Macht*. Jeder Teilnehmer des Rennens setzt darauf, der beste Inhaber dieser Macht zu sein und sie aus angeblich wohlwollenden Gründen einsetzen zu können, ohne dass sie ihrer Kontrolle entgleitet oder ihnen entrissen wird.

Das heißt, was Unternehmen und Nationen wirklich verfolgen, sind nicht nur die Früchte von AGI und Superintelligenz, sondern die Macht zu kontrollieren, wer Zugang zu ihnen bekommt und wie sie verwendet werden. Unternehmen sehen sich als verantwortliche Verwalter dieser Macht im Dienste der Aktionäre und der Menschheit; Nationen sehen sich als notwendige Wächter, die feindliche Mächte daran hindern, einen entscheidenden Vorteil zu erlangen. Beide liegen gefährlich falsch und erkennen nicht, dass Superintelligenz ihrer Natur nach nicht zuverlässig von einer menschlichen Institution kontrolliert werden kann. Wir werden sehen, dass die Natur und Dynamik superintelligenter Systeme menschliche Kontrolle extrem schwierig, wenn nicht unmöglich macht.

Diese Wettlaufdynamiken – sowohl unternehmerische als auch geopolitische – machen bestimmte Risiken nahezu unvermeidlich, es sei denn, sie werden entschieden unterbrochen. Wir wenden uns nun der Untersuchung dieser Risiken zu und warum sie in einem kompetitiven[^8] Entwicklungsparadigma nicht angemessen gemildert werden können.


[^1]: Eine präzisere Liste würdiger Ziele sind die [Nachhaltigen Entwicklungsziele](https://sdgs.un.org/goals) der UN. Diese sind gewissermaßen das Nächste, was wir zu einer Reihe globaler Konsensziele dafür haben, was wir in der Welt verbessert sehen möchten. KI könnte helfen.

[^2]: Technologie im Allgemeinen hat eine transformative wirtschaftliche und soziale Kraft für menschliche Verbesserung, wie Tausende von Jahren bezeugen. In diesem Sinne findet sich eine lange und überzeugende Darlegung einer positiven AGI-Vision in [diesem Essay](https://darioamodei.com/machines-of-loving-grace) von Anthropic-Gründer Dario Amodei.

[^3]: Private KI-Investitionen [begannen 2018-19 zu boomen, überholten öffentliche Investitionen etwa zu dieser Zeit](https://cset.georgetown.edu/publication/tracking-ai-investment/) und haben sie seitdem bei weitem übertroffen.

[^4]: Ich kann bezeugen, dass sie hinter verschlosseneren Türen keine solche Zurückhaltung haben. Und es wird öffentlicher; siehe zum Beispiel Y-combinators neue ["Request for Startups"](https://www.ycombinator.com/rfs), deren viele Teile explizit nach der vollständigen Ersetzung menschlicher Arbeiter verlangen. Um sie zu zitieren: "Das Wertversprechen von B2B SaaS war, menschliche Arbeiter schrittweise effizienter zu machen. Das Wertversprechen von vertikalen KI-Agenten ist, die Arbeit vollständig zu automatisieren... Es ist durchaus möglich, dass diese Gelegenheit groß genug ist, weitere 100 Einhörner zu prägen." (Für diejenigen, die nicht im Silicon-Valley-Sprech bewandert sind: "B2B" steht für Business-to-Business und ein Einhorn ist ein Unternehmen im Wert von 1 Milliarde Dollar. Das heißt, sie sprechen von mehr als hundert Milliarden-Plus-Dollar-Unternehmen, die Arbeiter für andere Unternehmen ersetzen.)

[^5]: Siehe zum Beispiel einen aktuellen [Bericht der US-China Economic and Security Review Commission](https://www.uscc.gov/sites/default/files/2024-11/2024_Executive_Summary.pdf). Obwohl es überraschend wenig Rechtfertigung innerhalb des Berichts selbst gab, war die Hauptempfehlung, dass der Kongress "ein Manhattan-Projekt-ähnliches Programm etablieren und finanzieren sollte, das darauf ausgerichtet ist, um eine Artificial General Intelligence (AGI)-Fähigkeit zu rennen und sie zu erlangen."

[^6]: Unternehmen übernehmen jetzt diese geopolitische Rahmung als Schild gegen jede Beschränkung ihrer KI-Entwicklung, im Allgemeinen auf Weise, die offensichtlich eigennützig sind, und manchmal auf Weise, die nicht einmal grundlegend Sinn ergeben. Betrachten Sie Metas [Approach to Frontier AI](https://about.fb.com/news/2025/02/meta-approach-frontier-ai/), der gleichzeitig argumentiert, dass Amerika seine "Position als Führer in technologischer Innovation, Wirtschaftswachstum und nationaler Sicherheit zementieren" muss und auch, dass es dies tun muss, indem es seine mächtigsten KI-Systeme offen freigibt – was einschließt, sie direkt an seine geopolitischen Rivalen und Gegner zu geben.

[^7]: Daher müssten wir wahrscheinlich das Management dieser Technologien den KIs überlassen. Aber das wäre eine sehr problematische Delegierung der Kontrolle, auf die wir unten zurückkommen werden.

[^8]: Wettbewerb in der Technologieentwicklung bringt oft wichtige Vorteile mit sich: Verhinderung monopolistischer Kontrolle, Antrieb von Innovation und Kostenreduktion, Ermöglichung vielfältiger Ansätze und Schaffung gegenseitiger Aufsicht. Bei AGI müssen diese Vorteile jedoch gegen einzigartige Risiken aus Rennlauf-Dynamiken und Druck zur Reduzierung von Sicherheitsvorkehrungen abgewogen werden.