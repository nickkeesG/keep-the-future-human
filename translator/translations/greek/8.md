# Κεφάλαιο 8 - Πώς να μην κατασκευάσουμε ΤΓΝ

Η ΤΓΝ δεν είναι αναπόφευκτη – σήμερα βρισκόμαστε σε μια διασταύρωση. Αυτό το κεφάλαιο παρουσιάζει μια πρόταση για το πώς θα μπορούσαμε να αποτρέψουμε την κατασκευή της.

Αν ο δρόμος που ακολουθούμε σήμερα οδηγεί στο πιθανό τέλος του πολιτισμού μας, πώς αλλάζουμε δρόμο;

Ας υποθέσουμε ότι η επιθυμία να σταματήσει η ανάπτυξη της ΤΓΝ και της υπερνοημοσύνης ήταν ευρέως διαδεδομένη και ισχυρή,[^1] επειδή έγινε κοινή κατανόηση ότι η ΤΓΝ θα απορροφούσε εξουσία αντί να παρέχει εξουσία, και θα αποτελούσε βαθιά απειλή για την κοινωνία και την ανθρωπότητα. Πώς θα κλείναμε τις Πύλες;

Προς το παρόν γνωρίζουμε μόνο έναν τρόπο για να *κατασκευάσουμε* ισχυρή και γενική ΤΝ, που είναι μέσω πραγματικά μαζικών υπολογισμών βαθιών νευρωνικών δικτύων. Επειδή αυτά είναι απίστευτα δύσκολα και ακριβά πράγματα να κάνεις, υπάρχει μια έννοια στην οποία το να *μην* τα κάνεις είναι εύκολο.[^2] Αλλά έχουμε ήδη δει τις δυνάμεις που οδηγούν προς την ΤΓΝ, και τις παιγνιοθεωρητικές δυναμικές που καθιστούν πολύ δύσκολο για οποιοδήποτε μέρος να σταματήσει μονομερώς. Έτσι θα χρειαζόταν ένας συνδυασμός παρέμβασης από εξωτερικούς παράγοντες (δηλαδή κυβερνήσεις) για να σταματήσουν τις εταιρείες, και συμφωνιών μεταξύ κυβερνήσεων για να σταματήσουν τον εαυτό τους.[^3] Πώς θα μπορούσε να φαίνεται αυτό;

Είναι χρήσιμο πρώτα να διακρίνουμε μεταξύ των εξελίξεων της ΤΝ που πρέπει να *αποτραπούν* ή να *απαγορευτούν*, και εκείνων που πρέπει να *διαχειριστούν*. Η πρώτη κατηγορία θα περιλάμβανε κυρίως την εκτροπή προς την υπερνοημοσύνη.[^4] Για την απαγορευμένη ανάπτυξη, οι ορισμοί θα πρέπει να είναι όσο το δυνατόν πιο σαφείς, και τόσο η επαλήθευση όσο και η επιβολή θα πρέπει να είναι πρακτικές. Αυτό που πρέπει να *διαχειριστεί* θα ήταν γενικά, ισχυρά συστήματα ΤΝ – τα οποία έχουμε ήδη, και που θα έχουν πολλές γκρίζες περιοχές, αποχρώσεις και πολυπλοκότητα. Για αυτά, ισχυροί αποτελεσματικοί θεσμοί είναι κρίσιμοι.

Μπορούμε επίσης να διακρίνουμε χρησίμως τα ζητήματα που πρέπει να αντιμετωπιστούν σε διεθνές επίπεδο (συμπεριλαμβανομένων των γεωπολιτικών αντιπάλων ή αντιμαχόμενων)[^5] από εκείνα που μπορούν να διαχειριστούν μεμονωμένες δικαιοδοσίες, χώρες ή συλλογές χωρών. Η απαγορευμένη ανάπτυξη ανήκει σε μεγάλο βαθμό στην κατηγορία του «διεθνούς», επειδή μια τοπική απαγόρευση της ανάπτυξης μιας τεχνολογίας μπορεί γενικά να παρακαμφθεί με την αλλαγή τοποθεσίας.[^6]

Τέλος, μπορούμε να εξετάσουμε τα εργαλεία στο εργαλειοθήκιο. Υπάρχουν πολλά, συμπεριλαμβανομένων των τεχνικών εργαλείων, του ήπιου δικαίου (πρότυπα, κανόνες κ.λπ.), του σκληρού δικαίου (κανονισμοί και απαιτήσεις), της ευθύνης, των κινήτρων της αγοράς, και ούτω καθεξής. Ας δώσουμε ιδιαίτερη προσοχή σε ένα που είναι ιδιαίτερο της ΤΝ.

## Ασφάλεια και διακυβέρνηση υπολογιστικής ισχύος

Ένα βασικό εργαλείο στη διακυβέρνηση της ισχυρής ΤΝ θα είναι το υλικό που απαιτεί. Το λογισμικό πολλαπλασιάζεται εύκολα, έχει σχεδόν μηδενικό οριακό κόστος παραγωγής, διασχίζει τα σύνορα εύκολα, και μπορεί να τροποποιηθεί στιγμιαία· κανένα από αυτά δεν ισχύει για το υλικό. Ωστόσο όπως έχουμε συζητήσει, τεράστιες ποσότητες αυτής της «υπολογιστικής ισχύος» είναι απαραίτητες τόσο κατά την εκπαίδευση των συστημάτων ΤΝ όσο και κατά τον συμπερασμό για να επιτευχθούν τα πιο ικανά συστήματα. Η υπολογιστική ισχύς μπορεί εύκολα να ποσοτικοποιηθεί, να λογιστικοποιηθεί και να ελεγχθεί, με σχετικά λίγη ασάφεια μόλις αναπτυχθούν καλοί κανόνες για αυτό. Κυρίως, μεγάλες ποσότητες υπολογιστικών πραγματοποιήσεων είναι, όπως ο εμπλουτισμένος ουράνιος, ένας πολύ σπάνιος, ακριβός και δύσκολος στην παραγωγή πόρος. Αν και τα ολοκληρωμένα κυκλώματα είναι παντού, το υλικό που απαιτείται για την ΤΝ είναι ακριβό και εξαιρετικά δύσκολο στην κατασκευή.[^7]

Αυτό που καθιστά τα ειδικά για ΤΝ τσιπ πολύ *πιο* διαχειρίσιμα ως σπάνιο πόρο από το ουράνιο είναι ότι μπορούν να περιλαμβάνουν μηχανισμούς ασφαλείας βασισμένους σε υλικό. Τα περισσότερα σύγχρονα κινητά τηλέφωνα, και μερικά φορητούς υπολογιστές, έχουν εξειδικευμένα χαρακτηριστικά υλικού ενσωματωμένα στο τσιπ που τους επιτρέπουν να διασφαλίζουν ότι εγκαθιστούν μόνο εγκεκριμένο λογισμικό λειτουργικού συστήματος και ενημερώσεις, ότι διατηρούν και προστατεύουν ευαίσθητα βιομετρικά δεδομένα στη συσκευή, και ότι μπορούν να καθίστανται άχρηστα σε οποιονδήποτε εκτός από τον ιδιοκτήτη τους αν χαθούν ή κλαπούν. Τα τελευταία χρόνια τέτοια μέτρα ασφαλείας υλικού έχουν καθιερωθεί και υιοθετηθεί ευρέως, και γενικά έχουν αποδειχθεί αρκετά ασφαλή.

Το βασικό καινοτόμο χαρακτηριστικό αυτών των δυνατοτήτων είναι ότι συνδέουν υλικό και λογισμικό μαζί χρησιμοποιώντας κρυπτογραφία.[^8] Δηλαδή, το απλό γεγονός ότι κάποιος έχει ένα συγκεκριμένο κομμάτι υλικού υπολογιστή δεν σημαίνει ότι ένας χρήστης μπορεί να κάνει ό,τι θέλει με αυτό εφαρμόζοντας διαφορετικό λογισμικό. Και αυτός ο δεσμός επίσης παρέχει ισχυρή ασφάλεια επειδή πολλές επιθέσεις θα απαιτούσαν παραβίαση *υλικού* παρά απλώς ασφαλείας *λογισμικού*.

Πολλές πρόσφατες αναφορές (π.χ. από το [GovAI και συνεργάτες](https://www.governance.ai/post/computing-power-and-the-governance-of-ai), το [CNAS](https://www.cnas.org/publications/reports/secure-governable-chips), και τη [RAND](https://www.rand.org/content/dam/rand/pubs/working_papers/WRA3000/WRA3056-1/RAND_WRA3056-1.pdf)) έχουν επισημάνει ότι παρόμοια χαρακτηριστικά υλικού ενσωματωμένα σε υπολογιστικό υλικό αιχμής σχετικό με την ΤΝ θα μπορούσαν να διαδραματίσουν έναν εξαιρετικά χρήσιμο ρόλο στην ασφάλεια και διακυβέρνηση της ΤΝ. Επιτρέπουν μια σειρά λειτουργιών διαθέσιμων σε έναν «κυβερνήτη»[^9] που κάποιος μπορεί να μην υποθέσει ότι ήταν διαθέσιμες ή καν δυνατές. Ως μερικά βασικά παραδείγματα:

- *Γεοεντοπισμός*: Τα συστήματα μπορούν να στηθούν έτσι ώστε τα τσιπ να έχουν γνωστή τοποθεσία, και να μπορούν να ενεργούν διαφορετικά (ή να κλείνουν εντελώς) βάσει της τοποθεσίας.[^10]
- *Επιτρεπόμενες συνδέσεις*: κάθε τσιπ μπορεί να ρυθμιστεί με μια επιβαλλόμενη από το υλικό λίστα επιτρεπόμενων συγκεκριμένων άλλων τσιπ με τα οποία μπορεί να δικτυωθεί, και να είναι ανίκανο να συνδεθεί με οποιαδήποτε τσιπ που δεν είναι σε αυτή τη λίστα.[^11] Αυτό μπορεί να θέσει όριο στο μέγεθος επικοινωνιακών συστάδων τσιπ.[^12]
- *Μετρημένος συμπερασμός ή εκπαίδευση (και αυτόματος διακόπτης)*: Ένας κυβερνήτης μπορεί να άδειάσει μόνο μια συγκεκριμένη ποσότητα εκπαίδευσης ή συμπερασμού (σε χρόνο, ή FLOP, ή πιθανώς διαδοχικές λέξεις) να εκτελεστεί από έναν χρήστη, μετά την οποία απαιτείται νέα άδεια. Αν τα κλάσματα είναι μικρά, τότε απαιτείται σχετικά συνεχής επαναδειοδότηση ενός μοντέλου. Το μοντέλο μπορεί τότε να «κλείσει» απλώς με την παρακράτηση αυτού του σήματος άδειας.[^13]
- *Όριο ταχύτητας*: Ένα μοντέλο αποτρέπεται από το να τρέχει σε υψηλότερη ταχύτητα συμπερασμού από κάποιο όριο που καθορίζεται από έναν κυβερνήτη ή διαφορετικά. Αυτό θα μπορούσε να υλοποιηθεί μέσω ενός περιορισμένου συνόλου επιτρεπόμενων συνδέσεων, ή με πιο εξεζητημένα μέσα.
- *Πιστοποιημένη εκπαίδευση*: Μια διαδικασία εκπαίδευσης μπορεί να αποδώσει κρυπτογραφικά ασφαλή απόδειξη ότι ένα συγκεκριμένο σύνολο κωδίκων, δεδομένων και ποσό χρήσης υπολογιστικής ισχύος χρησιμοποιήθηκαν στη δημιουργία του μοντέλου.

## Πώς να μην κατασκευάσουμε υπερνοημοσύνη: παγκόσμια όρια στην υπολογιστική ισχύ εκπαίδευσης και συμπερασμού

Με αυτές τις παραμέτρους – ιδιαίτερα σχετικά με τον υπολογισμό – στη θέση τους, μπορούμε να συζητήσουμε πώς να κλείσουμε τις Πύλες στην τεχνητή υπερνοημοσύνη· στη συνέχεια θα στραφούμε στην πρόληψη της πλήρους ΤΓΝ, και τη διαχείριση μοντέλων ΤΝ καθώς πλησιάζουν και ξεπερνούν την ανθρώπινη ικανότητα σε διαφορετικές πτυχές.

Το πρώτο συστατικό είναι, φυσικά, η κατανόηση ότι η υπερνοημοσύνη δεν θα ήταν ελέγξιμη, και ότι οι συνέπειές της είναι θεμελιωδώς απρόβλεπτες. Τουλάχιστον η Κίνα και οι ΗΠΑ πρέπει να αποφασίσουν ανεξάρτητα, για αυτό ή άλλους σκοπούς, να μην κατασκευάσουν υπερνοημοσύνη.[^14] Στη συνέχεια χρειάζεται μια διεθνής συμφωνία μεταξύ τους και άλλων, με ισχυρό μηχανισμό επαλήθευσης και επιβολής, για να διασφαλίσει σε όλα τα μέρη ότι οι αντίπαλοί τους δεν παραβαίνουν και δεν αποφασίζουν να παίξουν το παιχνίδι.

Για να είναι επαληθεύσιμα και επιβλητά τα όρια θα πρέπει να είναι σκληρά όρια, και όσο το δυνατόν πιο σαφή. Αυτό φαίνεται σαν ένα σχεδόν αδύνατο πρόβλημα: ο περιορισμός των ικανοτήτων πολύπλοκου λογισμικού με απρόβλεπτες ιδιότητες, παγκοσμίως. Ευτυχώς η κατάσταση είναι πολύ καλύτερη από αυτή, επειδή το ίδιο πράγμα που έκανε δυνατή την προχωρημένη ΤΝ – μια τεράστια ποσότητα υπολογιστικής ισχύος – είναι πολύ, πολύ πιο εύκολο να ελεγχθεί. Αν και μπορεί να επιτρέψει ακόμα μερικά ισχυρά και επικίνδυνα συστήματα, η *εκτρεπόμενη υπερνοημοσύνη* μπορεί πιθανώς να αποτραπεί από ένα σκληρό όριο στην ποσότητα υπολογισμού που πηγαίνει σε ένα νευρωνικό δίκτυο, μαζί με ένα όριο ρυθμού στην ποσότητα συμπερασμού που ένα σύστημα ΤΝ (συνδεδεμένων νευρωνικών δικτύων και άλλου λογισμικού) μπορεί να εκτελέσει. Μια συγκεκριμένη εκδοχή αυτού προτείνεται παρακάτω.

Μπορεί να φαίνεται ότι η θέσπιση σκληρών παγκόσμιων ορίων στον υπολογισμό της ΤΝ θα απαιτούσε τεράστια επίπεδα διεθνούς συντονισμού και παρεμβατική, ιδιωτικότητα-καταστρεπτική επιτήρηση. Ευτυχώς, δεν θα χρειαζόταν. Η εξαιρετικά [σφιχτή και με στενούς κλάδους αλυσίδα εφοδιασμού](https://arxiv.org/abs/2402.08797) παρέχει ότι μόλις τεθεί ένα όριο νομικά (είτε με νόμο είτε με εκτελεστικό διάταγμα), η επαλήθευση συμμόρφωσης σε αυτό το όριο θα απαιτούσε μόνο τη συμμετοχή και συνεργασία μιας χούφτας μεγάλων εταιρειών.[^15]

Ένα τέτοιο σχέδιο έχει μια σειρά από εξαιρετικά επιθυμητά χαρακτηριστικά. Είναι ελάχιστα παρεμβατικό υπό την έννοια ότι μόνο μερικές μεγάλες εταιρείες έχουν απαιτήσεις που τους τίθενται, και μόνο αρκετά σημαντικές συστάδες υπολογιστών θα διακυβερνούνται. Τα σχετικά τσιπ περιέχουν ήδη τις ικανότητες υλικού που χρειάζονται για μια πρώτη έκδοση.[^16] Τόσο η υλοποίηση όσο και η επιβολή βασίζονται σε τυπικούς νομικούς περιορισμούς. Αλλά αυτοί υποστηρίζονται από όρους χρήσης του υλικού και από ελέγχους υλικού, απλοποιώντας πολύ την επιβολή και αποτρέποντας την εξαπάτηση από εταιρείες, ιδιωτικές ομάδες, ή ακόμα και χώρες. Υπάρχει άφθονο προηγούμενο για εταιρείες υλικού που θέτουν απομακρυσμένους περιορισμούς στη χρήση του υλικού τους, και κλειδώνουν/ξεκλειδώνουν συγκεκριμένες ικανότητες εξωτερικά,[^17] συμπεριλαμβανομένων ακόμα και σε υψηλής απόδοσης CPU σε κέντρα δεδομένων.[^18] Ακόμα και για το αρκετά μικρό κλάσμα υλικού και οργανισμών που επηρεάζονται, η επίβλεψη θα μπορούσε να περιοριστεί σε τηλεμετρία, χωρίς άμεση πρόσβαση στα δεδομένα ή τα μοντέλα τους ίδια· και το λογισμικό για αυτό θα μπορούσε να είναι ανοιχτό σε έλεγχο για να δείξει ότι δεν καταγράφονται πρόσθετα δεδομένα. Το σχήμα είναι διεθνές και συνεργατικό, και αρκετά ευέλικτο και επεκτάσιμο. Επειδή το όριο είναι κυρίως στο υλικό παρά στο λογισμικό, είναι σχετικά αγνωστικό ως προς το πώς γίνεται η ανάπτυξη και εγκατάσταση λογισμικού ΤΝ, και είναι συμβατό με ποικιλία παραδειγμάτων συμπεριλαμβανομένων πιο «αποκεντρωμένων» ή «δημόσιων» ΤΝ που στοχεύουν στην καταπολέμηση της συγκέντρωσης εξουσίας που οδηγείται από την ΤΝ.

Ένα κλείσιμο Πύλης βασισμένο στον υπολογισμό έχει επίσης μειονεκτήματα. Πρώτον, είναι μακριά από μια πλήρη λύση στο πρόβλημα της διακυβέρνησης της ΤΝ γενικά. Δεύτερον, καθώς το υλικό υπολογιστών γίνεται ταχύτερο, το σύστημα θα «πιάνει» περισσότερο και περισσότερο υλικό σε μικρότερες και μικρότερες συστάδες (ή ακόμα και μεμονωμένα GPU).[^19] Είναι επίσης δυνατόν ότι λόγω αλγοριθμικών βελτιώσεων ακόμα χαμηλότερο όριο υπολογισμού θα ήταν στο χρόνο απαραίτητο,[^20] ή ότι η ποσότητα υπολογισμού γίνεται σε μεγάλο βαθμό άσχετη και το κλείσιμο της Πύλης θα απαιτούσε αντίθετα ένα πιο λεπτομερές καθεστώς διακυβέρνησης βασισμένο στον κίνδυνο ή την ικανότητα για την ΤΝ. Τρίτον, ανεξαρτήτως εγγυήσεων και του μικρού αριθμού επηρεαζόμενων οντοτήτων, ένα τέτοιο σύστημα είναι βέβαιο ότι θα δημιουργήσει αντίδραση σχετικά με την ιδιωτικότητα και την επιτήρηση, μεταξύ άλλων ανησυχιών.[^21]

Φυσικά, η ανάπτυξη και υλοποίηση ενός σχήματος διακυβέρνησης που περιορίζει τον υπολογισμό σε μικρό χρονικό διάστημα θα είναι αρκετά προκλητική. Αλλά είναι απολύτως εφικτή.

## Α-Γ-Ν: Η τριπλή διασταύρωση ως βάση του κινδύνου, και της πολιτικής

Ας στραφούμε τώρα στην ΤΓΝ. Οι σκληρές γραμμές και οι ορισμοί εδώ είναι πιο δύσκολοι, επειδή έχουμε σίγουρα νοημοσύνη που είναι τεχνητή και γενική, και από κανέναν υπάρχον ορισμό δεν θα συμφωνούν όλοι αν ή πότε υπάρχει. Επιπλέον, ένα όριο υπολογισμού ή συμπερασμού είναι ένα κάπως άκαμπτο εργαλείο (με τον υπολογισμό να είναι ένας διαμεσολαβητής για την ικανότητα, η οποία είναι τότε ένας διαμεσολαβητής για τον κίνδυνο) που – εκτός αν είναι αρκετά χαμηλό – είναι απίθανο να αποτρέψει την ΤΓΝ που είναι αρκετά ισχυρή για να προκαλέσει κοινωνική ή πολιτισμική διαταραχή ή οξείς κινδύνους.

Έχω υποστηρίξει ότι οι πιο οξείς κίνδυνοι αναδύονται από την τριπλή διασταύρωση πολύ υψηλής ικανότητας, υψηλής αυτονομίας και μεγάλης γενικότητας. Αυτά είναι τα συστήματα που – αν αναπτυχθούν καθόλου – πρέπει να διαχειριστούν με τεράστια προσοχή. Δημιουργώντας αυστηρά πρότυπα (μέσω ευθύνης και κανονισμού) για συστήματα που συνδυάζουν και τις τρεις ιδιότητες, μπορούμε να κατευθύνουμε την ανάπτυξη ΤΝ προς ασφαλέστερες εναλλακτικές.

Όπως με άλλες βιομηχανίες και προϊόντα που θα μπορούσαν δυνητικά να βλάψουν καταναλωτές ή το κοινό, τα συστήματα ΤΝ απαιτούν προσεκτικό κανονισμό από αποτελεσματικές και εξουσιοδοτημένες κυβερνητικές υπηρεσίες. Αυτός ο κανονισμός θα πρέπει να αναγνωρίζει τους εγγενείς κινδύνους της ΤΓΝ, και να αποτρέπει την ανάπτυξη μη αποδεκτά επικίνδυνων συστημάτων ΤΝ υψηλής ισχύος.[^22]

Ωστόσο, η μεγάλης κλίμακας ρύθμιση, ειδικά με πραγματικά δόντια που είναι σίγουρο ότι θα αντιταχθεί από τη βιομηχανία,[^23] παίρνει χρόνο[^24] καθώς και πολιτική πεποίθηση ότι είναι απαραίτητη.[^25] Δεδομένου του ρυθμού προόδου, αυτό μπορεί να πάρει περισσότερο χρόνο από όσο έχουμε διαθέσιμο.

Σε πολύ ταχύτερη χρονική κλίμακα και καθώς αναπτύσσονται ρυθμιστικά μέτρα, μπορούμε να δώσουμε στις εταιρείες τα απαραίτητα κίνητρα για να (α) απόσχουν από πολύ υψηλού κινδύνου δραστηριότητες και (β) αναπτύξουν περιεκτικά συστήματα για την αξιολόγηση και μετριασμό κινδύνου, διευκρινίζοντας και αυξάνοντας τα επίπεδα ευθύνης για τα πιο επικίνδυνα συστήματα. Η ιδέα θα ήταν να επιβάλουμε τα πολύ υψηλότερα επίπεδα ευθύνης – αυστηρή και σε μερικές περιπτώσεις προσωπική ποινική – για συστήματα στην τριπλή διασταύρωση της υψηλής αυτονομίας-γενικότητας-νοημοσύνης, αλλά να παρέχουμε «ασφαλείς λιμάνια» σε πιο τυπική ευθύνη βασισμένη σε σφάλμα για συστήματα στα οποία μία από αυτές τις ιδιότητες λείπει ή εγγυάται ότι είναι διαχειρίσιμη. Δηλαδή, για παράδειγμα, ένα «ασθενές» σύστημα που είναι γενικό και αυτόνομο (όπως ένας ικανός και αξιόπιστος αλλά περιορισμένος προσωπικός βοηθός) θα ήταν υποκείμενο σε χαμηλότερα επίπεδα ευθύνης. Ομοίως ένα στενό και αυτόνομο σύστημα όπως ένα αυτοκίνητο αυτόματης οδήγησης θα ήταν ακόμα υποκείμενο στον σημαντικό κανονισμό που ήδη είναι, αλλά όχι σε ενισχυμένη ευθύνη. Παρόμοια για ένα πολύ ικανό και γενικό σύστημα που είναι «παθητικό» και σε μεγάλο βαθμό ανίκανο για ανεξάρτητη δράση. Συστήματα που στερούνται *δύο* από τις τρεις ιδιότητες είναι ακόμα πιο διαχειρίσιμα και οι ασφαλείς λιμάνες θα ήταν ακόμα ευκολότεροι να διεκδικηθούν. Αυτή η προσέγγιση αντικατοπτρίζει πώς χειριζόμαστε άλλες δυνητικά επικίνδυνες τεχνολογίες:[^26] υψηλότερη ευθύνη για πιο επικίνδυνες διαμορφώσεις δημιουργεί φυσικά κίνητρα για ασφαλέστερες εναλλακτικές.

Το προεπιλεγμένο αποτέλεσμα τέτοιων υψηλών επιπέδων ευθύνης, που ενεργούν για να *εσωτερικεύσουν* τον κίνδυνο ΤΓΝ στις εταιρείες παρά να τον μετακυλήσουν στο κοινό, είναι πιθανό (και ελπιζόμενο!) για τις εταιρείες να απλώς μην αναπτύξουν πλήρη ΤΓΝ μέχρι και εκτός αν μπορούν πραγματικά να την κάνουν αξιόπιστη, ασφαλή και ελέγξιμη δεδομένου ότι *η δική τους ηγεσία* είναι τα μέρη σε κίνδυνο. (Σε περίπτωση που αυτό δεν είναι επαρκές, η νομοθεσία που διευκρινίζει την ευθύνη θα πρέπει επίσης να επιτρέπει ρητά ανακουφιστικές δικαστικές αποφάσεις, δηλαδή έναν δικαστή που διατάζει στάση, για δραστηριότητες που είναι σαφώς στη ζώνη κινδύνου και υποστηρίζεται ότι θέτουν δημόσιο κίνδυνο.) Καθώς τίθεται σε εφαρμογή ο κανονισμός, η συμμόρφωση με τον κανονισμό μπορεί να γίνει ο ασφαλής λιμάνας, και οι ασφαλείς λιμάνες από χαμηλή αυτονομία, στενότητα ή αδυναμία συστημάτων ΤΝ μπορούν να μετατραπούν σε σχετικά ελαφρύτερα ρυθμιστικά καθεστώτα.

## Βασικές διατάξεις ενός κλεισίματος Πύλης

Με την παραπάνω συζήτηση υπόψη, αυτή η ενότητα παρέχει προτάσεις για βασικές διατάξεις που θα υλοποιούσαν και θα διατηρούσαν την απαγόρευση της πλήρους ΤΓΝ και υπερνοημοσύνης, και τη διαχείριση ανταγωνιστικής προς τον άνθρωπο ή ανταγωνιστικής προς τον ειδικό ΤΝ γενικού σκοπού κοντά στο κατώφλι πλήρους ΤΓΝ.[^27] Έχει τέσσερα βασικά κομμάτια: 1) λογιστική και επίβλεψη υπολογιστικής ισχύος, 2) όρια υπολογιστικής ισχύος στην εκπαίδευση και λειτουργία ΤΝ, 3) ένα πλαίσιο ευθύνης, και 4) διαβαθμισμένα πρότυπα ασφαλείας και ασφάλειας που ορίζονται και περιλαμβάνουν σκληρές ρυθμιστικές απαιτήσεις. Αυτά περιγράφονται συνοπτικά παρακάτω, με περαιτέρω λεπτομέρειες ή παραδείγματα υλοποίησης που δίνονται σε τρεις συνοδευτικούς πίνακες. Σημαντικά, σημειώστε ότι αυτά είναι μακριά από όλα που θα είναι απαραίτητα για να διακυβερνήσουμε προχωρημένα συστήματα ΤΝ· ενώ θα έχουν πρόσθετα οφέλη ασφαλείας και ασφάλειας, στοχεύουν στο κλείσιμο της Πύλης στην εκτροπή νοημοσύνης, και την ανακατεύθυνση της ανάπτυξης ΤΝ σε καλύτερη κατεύθυνση.

### 1\. Λογιστική υπολογιστικής ισχύος, και διαφάνεια

- Ένας οργανισμός προτύπων (π.χ. το NIST στις ΗΠΑ ακολουθούμενο από ISO/IEEE διεθνώς) θα πρέπει να κωδικοποιήσει ένα λεπτομερές τεχνικό πρότυπο για τη συνολική υπολογιστική ισχύ που χρησιμοποιείται στην εκπαίδευση και λειτουργία μοντέλων ΤΝ, σε FLOP, και την ταχύτητα σε FLOP/s στην οποία λειτουργούν. Λεπτομέρειες για το πώς θα μπορούσε να φαίνεται αυτό δίνονται στο Παράρτημα Α.[^28]
- Μια απαίτηση – είτε με νέα νομοθεσία είτε υπό υπάρχουσα εξουσία[^29] – θα πρέπει να επιβληθεί από δικαιοδοσίες στις οποίες γίνεται μεγάλης κλίμακας εκπαίδευση ΤΝ να υπολογίσουν και να αναφέρουν σε ρυθμιστικό όργανο ή άλλη υπηρεσία τα συνολικά FLOP που χρησιμοποιούνται στην εκπαίδευση και λειτουργία όλων των μοντέλων πάνω από ένα κατώφλι 10<sup>25</sup> FLOP ή 10<sup>18</sup> FLOP/s.[^30]
- Αυτές οι απαιτήσεις θα πρέπει να εισαχθούν σταδιακά, αρχικά απαιτώντας καλά τεκμηριωμένες εκτιμήσεις καλής πίστης σε τριμηνιαία βάση, με μεταγενέστερες φάσεις να απαιτούν προοδευτικά υψηλότερα πρότυπα, μέχρι κρυπτογραφικά πιστοποιημένα συνολικά FLOP και FLOP/s συνημμένα σε κάθε *έξοδο* μοντέλου.
- Αυτές οι αναφορές θα πρέπει να συμπληρώνονται από καλά τεκμηριωμένες εκτιμήσεις του οριακού ενεργειακού και οικονομικού κόστους που χρησιμοποιείται στη δημιουργία κάθε εξόδου ΤΝ.

Αιτιολόγηση: Αυτοί οι καλά υπολογισμένοι και διαφανώς αναφερόμενοι αριθμοί θα παρέχουν τη βάση για όρια εκπαίδευσης και λειτουργίας, καθώς και ένα ασφαλές λιμάνι από υψηλότερα μέτρα ευθύνης (δείτε Παραρτήματα Γ και Δ).

### 2\. Όρια υπολογιστικής ισχύος εκπαίδευσης και λειτουργίας

- Οι δικαιοδοσίες που φιλοξενούν συστήματα ΤΝ θα πρέπει να επιβάλουν σκληρό όριο στη συνολική υπολογιστική ισχύ που πηγαίνει σε οποιαδήποτε έξοδο μοντέλου ΤΝ, ξεκινώντας από 10<sup>27</sup> FLOP[^31] και προσαρμόσιμο όπως κρίνεται κατάλληλο.
- Οι δικαιοδοσίες που φιλοξενούν συστήματα ΤΝ θα πρέπει να επιβάλουν σκληρό όριο στο ρυθμό υπολογιστικής ισχύος εξόδων μοντέλων ΤΝ, ξεκινώντας από 10<sup>20</sup> FLOP/s και προσαρμόσιμο όπως κρίνεται κατάλληλο.

Αιτιολόγηση: Η συνολική υπολογιστική ισχύς, αν και πολύ ατελής, είναι ένας διαμεσολαβητής για την ικανότητα (και κίνδυνο) της ΤΝ που είναι συγκεκριμένα μετρήσιμος και επαληθεύσιμος, έτσι παρέχει ένα σκληρό φράγμα για τον περιορισμό ικανοτήτων. Μια συγκεκριμένη πρόταση υλοποίησης δίνεται στο Παράρτημα Β.

### 3\. Ενισχυμένη ευθύνη για επικίνδυνα συστήματα

- Η δημιουργία και λειτουργία[^32] ενός προχωρημένου συστήματος ΤΝ που είναι εξαιρετικά γενικό, ικανό και αυτόνομο, θα πρέπει να διευκρινιστεί νομικά μέσω νομοθεσίας ότι υπόκειται σε αυστηρή, αλληλέγγυα και εις ολόκληρον, παρά μονομερή ευθύνη βασισμένη σε σφάλμα.[^33]
- Μια νομική διαδικασία θα πρέπει να είναι διαθέσιμη για να κάνει καταφατικές περιπτώσεις ασφαλείας, που θα παρείχαν ασφαλές λιμάνι από αυστηρή ευθύνη για συστήματα που είναι μικρά (από άποψη υπολογιστικής ισχύος), ασθενή, στενά, παθητικά, ή που έχουν επαρκείς εγγυήσεις ασφαλείας, ασφάλειας και ελεγξιμότητας.
- Μια ρητή διαδρομή και σύνολο όρων για ανακουφιστική δικαστική απόφαση για να σταματήσουν δραστηριότητες εκπαίδευσης και συμπερασμού ΤΝ που αποτελούν δημόσιο κίνδυνο θα πρέπει να περιγραφεί.

Αιτιολόγηση: Τα συστήματα ΤΝ δεν μπορούν να θεωρηθούν υπεύθυνα, έτσι πρέπει να θεωρήσουμε ανθρώπινα άτομα και οργανισμούς υπεύθυνους για τη βλάβη που προκαλούν (ευθύνη).[^34] Η μη ελέγξιμη ΤΓΝ είναι απειλή για την κοινωνία και τον πολιτισμό και εν απουσία περίπτωσης ασφαλείας θα πρέπει να θεωρείται ασυνήθιστα επικίνδυνη. Η τοποθέτηση του βάρους της ευθύνης στους προγραμματιστές να δείξουν ότι τα ισχυρά μοντέλα είναι αρκετά ασφαλή για να μην θεωρούνται «ασυνήθιστα επικίνδυνα» ενθαρρύνει την ασφαλή ανάπτυξη, μαζί με διαφάνεια και τήρηση αρχείων για να διεκδικήσουν αυτούς τους ασφαλείς λιμάνια. Ο κανονισμός μπορεί τότε να αποτρέψει τη βλάβη όπου η αποτροπή από την ευθύνη είναι ανεπαρκής. Τέλος, οι προγραμματιστές ΤΝ είναι ήδη υπεύθυνοι για ζημιές που προκαλούν, έτσι η νομική διευκρίνιση ευθύνης για τα πιο επικίνδυνα συστήματα μπορεί να γίνει αμέσως, χωρίς να αναπτυχθούν εξαιρετικά λεπτομερή πρότυπα· αυτά μπορούν τότε να αναπτυχθούν με το χρόνο. Λεπτομέρειες δίνονται στο Παράρτημα Γ.

### 4\. Ρύθμιση ασφαλείας για την ΤΝ

Ένα ρυθμιστικό σύστημα που αντιμετωπίζει μεγάλης κλίμακας οξείς κινδύνους της ΤΝ θα απαιτήσει κατ' ελάχιστο:

- Την ταυτοποίηση ή δημιουργία ενός κατάλληλου συνόλου ρυθμιστικών οργάνων, πιθανότατα μια νέα υπηρεσία·
- Ένα περιεκτικό πλαίσιο αξιολόγησης κινδύνου·[^35]
- Ένα πλαίσιο για καταφατικές περιπτώσεις ασφαλείας, βασισμένο εν μέρει στο πλαίσιο αξιολόγησης κινδύνου, να γίνονται από προγραμματιστές, και για έλεγχο από *ανεξάρτητες* ομάδες και υπηρεσίες·
- Ένα διαβαθμισμένο σύστημα αδειοδότησης, με βαθμίδες που παρακολουθούν επίπεδα ικανότητας.[^36] Οι άδειες θα παρέχονταν βάσει περιπτώσεων ασφαλείας και ελέγχων, για ανάπτυξη και εγκατάσταση συστημάτων. Οι απαιτήσεις θα κυμαίνονταν από ειδοποίηση στο χαμηλό άκρο, έως ποσοτικές εγγυήσεις ασφαλείας, ασφάλειας και ελεγξιμότητας πριν την ανάπτυξη, στο κορυφαίο άκρο. Αυτές θα αποτρέπουν την απελευθέρωση συστημάτων μέχρι να αποδειχθούν ασφαλή, και θα απαγορεύουν την ανάπτυξη εγγενώς μη ασφαλών συστημάτων. Το Παράρτημα Δ παρέχει μια πρόταση για το τι θα μπορούσαν να συνεπάγονται τέτοια πρότυπα ασφαλείας και ασφάλειας.
- Συμφωνίες για να φέρουν τέτοια μέτρα στο διεθνές επίπεδο, συμπεριλαμβανομένων διεθνών οργάνων για την εναρμόνιση κανόνων και προτύπων, και δυνητικά διεθνείς υπηρεσίες για την επανεξέταση περιπτώσεων ασφαλείας.

Αιτιολόγηση: Τελικά, η ευθύνη δεν είναι ο σωστός μηχανισμός για την αποτροπή μεγάλης κλίμακας κινδύνου στο κοινό από μια νέα τεχνολογία. Περιεκτική ρύθμιση, με εξουσιοδοτημένα ρυθμιστικά όργανα, θα χρειαστεί για την ΤΝ όπως ακριβώς για κάθε άλλη μεγάλη βιομηχανία που θέτει κίνδυνο στο κοινό.[^37]

Η ρύθμιση προς την αποτροπή άλλων διάχυτων αλλά λιγότερο οξέων κινδύνων είναι πιθανό να ποικίλει στη μορφή της από δικαιοδοσία σε δικαιοδοσία. Το κρίσιμο πράγμα είναι να αποφύγουμε την ανάπτυξη των συστημάτων ΤΝ που είναι τόσο επικίνδυνα που αυτοί οι κίνδυνοι είναι αδιαχείριστοι.

## Τι μετά;

Την επόμενη δεκαετία, καθώς η ΤΝ γίνεται πιο διάχυτη και η βασική τεχνολογία προχωρά, δύο βασικά πράγματα είναι πιθανό να συμβούν. Πρώτον, η ρύθμιση υπαρχόντων ισχυρών συστημάτων ΤΝ θα γίνει πιο δύσκολη, αλλά ακόμα πιο απαραίτητη. Είναι πιθανό ότι τουλάχιστον μερικά μέτρα που αντιμετωπίζουν μεγάλης κλίμακας κινδύνους ασφαλείας θα απαιτήσουν συμφωνία σε διεθνές επίπεδο, με μεμονωμένες δικαιοδοσίες να επιβάλλουν κανόνες βασισμένους σε διεθνείς συμφωνίες.

Δεύτερον, τα όρια υπολογιστικής ισχύος εκπαίδευσης και λειτουργίας θα γίνουν δυσκολότερα να διατηρηθούν καθώς το υλικό γίνεται φθηνότερο και πιο κοστοαποδοτικό· μπορεί επίσης να γίνουν λιγότερο σχετικά (ή να χρειάζεται να είναι ακόμα πιο σφιχτά) με προόδους σε αλγόριθμους και αρχιτεκτονικές.

Το ότι ο έλεγχος της ΤΝ θα γίνει δυσκολότερος δεν σημαίνει ότι πρέπει να τα παρατήσουμε! Η υλοποίηση του σχεδίου που περιγράφεται σε αυτό το δοκίμιο θα μας έδινε τόσο πολύτιμο χρόνο όσο και κρίσιμο έλεγχο στη διαδικασία που θα μας έθετε σε πολύ, πολύ καλύτερη θέση για να αποφύγουμε τον υπαρξιακό κίνδυνο της ΤΝ στην κοινωνία, τον πολιτισμό και το είδος μας.

Σε ακόμα πιο μακροπρόθεσμο ορίζοντα, θα υπάρξουν επιλογές να κάνουμε ως προς το τι επιτρέπουμε. Μπορεί να επιλέξουμε ακόμα να δημιουργήσουμε κάποια μορφή πραγματικά ελέγξιμης ΤΓΝ, στο βαθμό που αυτό αποδειχθεί δυνατό. Ή μπορεί να αποφασίσουμε ότι η διοίκηση του κόσμου καλύτερα να αφεθεί στις μηχανές, αν μπορούμε να πείσουμε τον εαυτό μας ότι θα κάνουν καλύτερη δουλειά,