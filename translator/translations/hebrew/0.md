# סיכום מנהלים

סקירה כללית של המאמר. אם הזמן קצר לכם, קבלו את כל הנקודות העיקריות תוך 10 דקות בלבד.

ההתקדמות הדרמטית בבינה מלאכותית בעשור האחרון (עבור AI ייעודי) ובשנים האחרונות (עבור AI כללי) הפכה את הבינה המלאכותית מתחום אקדמי נישתי לאסטרטגיה העסקית המרכזית של רבות מהחברות הגדולות בעולם, עם השקעות שנתיות של מאות מיליארדי דולרים בטכניקות ובטכנולוgiות לפיתוח יכולות הבינה המלאכותית.

כעת אנו מגיעים לצומת קריטי. כשהיכולות של מערכות AI חדשות מתחילות להתאים ולעלות על אלו של בני אדם בתחומים קוגניטיביים רבים, האנושות חייבת להחליט: עד כמה רחוק אנחנו הולכים, ובאיזה כיוון?

בינה מלאכותית, כמו כל טכנולוגיה, החלה עם המטרה לשפר דברים עבור יוצרה. אבל המסלול הנוכחי שלנו, והבחירה המשתמעת, הוא מירוץ בלתי מבוקר לעבר מערכות חזקות יותר ויותר, המונע על ידי תמריצים כלכליים של כמה חברות טכנולוגיה ענקיות השואפות להפוך לאוטומטיות חלקים נרחבים מהפעילות הכלכלית הנוכחית ומעבודה אנושית. אם המירוץ הזה יימשך זמן רב יותר, יש מנצח בלתי נמנע: הבינה המלאכותית עצמה - חלופה מהירה יותר, חכמה יותר וזולה יותר לאנשים בכלכלה שלנו, בחשיבה שלנו, בהחלטות שלנו, ובסופו של דבר בשליטה על הציביליזציה שלנו.

אבל אנחנו יכולים לעשות בחירה אחרת: באמצעות הממשלות שלנו, אנחנו יכולים לקחת שליטה על תהליך פיתוח הבינה המלאכותית כדי להטיל גבולות ברורים, קווים שלא נחצה, ודברים שפשוט לא נעשה - כפי שעשינו עבור טכנולוגיות גרעיניות, נשק להשמדה המונית, נשק חלל, תהליכים הרסניים לסביבה, הנדסה ביולוגית של בני אדם ואאוגניקה. והכי חשוב, אנחנו יכולים להבטיח שבינה מלאכותית תישאר כלי להעצמת בני אדם, במקום מין חדש שמחליף ובסופו של דבר מדחיק אותנו.

מאמר זה טוען שעלינו *לשמור על העתיד אנושי* על ידי סגירת "השערים" לבינה מלאכותית חכמה מאדם, אוטונומית וכללית - הנקראת לעתים "AGI" - ובמיוחד לגרסה העל-אנושית הנקראת לעתים "על-אינטליגנציה". במקום זאת, עלינו להתמקד בכלי AI חזקים ומהימנים שיכולים להעצים אנשים ולשפר באופן טרנספורמטיבי את היכולות של החברות האנושיות לעשות את מה שהן עושות הכי טוב. מבנה הטיעון הזה נמשך בקצרה.

## בינה מלאכותית שונה

מערכות בינה מלאכותית שונות מהותית מטכנולוגיות אחרות. בעוד שתוכנה מסורתית עוקבת אחר הוראות מדויקות, מערכות AI לומדות איך להשיג מטרות מבלי שאומרים להן במפורש איך. זה עושה אותן חזקות: אם אנחנו יכולים להגדיר בבהירות את המטרה או מדד הצלחה, ברוב המקרים מערכת AI יכולה ללמוד להשיג אותה. אבל זה גם עושה אותן בלתי צפויות מטבען: אנחנו לא יכולים לקבוע באמינות אילו פעולות הן יבצעו כדי להשיג את היעדים שלהן.

הן גם בלתי ניתנות להסבר ברובן: למרות שהן חלקית קוד, הן בעיקר קבוצה עצומה של מספרים בלתי מובנים - "משקולות" רשת נוירונים - שאי אפשר לפענח; אנחנו לא הרבה יותר טובים בהבנת הפעילות הפנימית שלהן מאשר בזיהוי מחשבות על ידי הצצה לתוך מוח ביולוגי.

אופן האימון המרכזי הזה של רשתות נוירונים דיגיטליות גדל במהירות במורכבות. מערכות הבינה המלאכותית החזקות ביותר נוצרות באמצעות ניסויים חישוביים עצומים, תוך שימוש בחומרה מיוחדת לאימון רשתות נוירונים על מאגרי מידע ענקיים, שמוגברים אחר כך בכלי תוכנה ותשתית.

זה הוביל ליצירת כלים חזקים מאוד ליצירה ועיבוד של טקסט ותמונות, ביצוע חשיבה מתמטית ומדעית, צבירת מידע וחקירה אינטראקטיבית של מאגר עצום של ידע אנושי.

לצערנו, בעוד שפיתוח של כלים טכנולוגיים חזקים וראויי אמון יותר הוא מה שאנחנו *צריכים* לעשות, ומה שכמעט כולם רוצים ואומרים שהם רוצים, זה לא המסלול שאנחנו בעצם עליו.

## בינה מלאכותית כללית ועל-אינטליגנציה

מאז ראשית התחום, מחקר הבינה המלאכותית התמקד במקום זאת במטרה שונה: בינה מלאכותית כללית. המיקוד הזה הפך כעת למיקוד של החברות הטיטאניות המובילות בפיתוח AI.

מה זה AGI? לעתים קרובות זה מוגדר בצורה מעורפלת כ"AI ברמת אדם", אבל זה בעייתי: אילו בני אדם, ובאילו יכולות זה ברמת אדם? ומה לגבי היכולות העל-אנושיות שכבר יש לו? דרך שימושית יותר להבין AGI היא דרך החיתוך של שלושה מאפיינים מפתח: **אוטונומיה** גבוהה (עצמאות פעולה), **כלליות** גבוהה (היקף רחב וכושר הסתגלות), ו**אינטליגנציה** גבוהה (כשירות במשימות קוגניטיביות). מערכות AI נוכחיות עשויות להיות בעלות יכולת גבוהה אך צרות, או כלליות אך מצריכות השגחה אנושית מתמדת, או אוטונומיות אך מוגבלות בהיקף.

A-G-I מלא ישלב את שלושת המאפיינים ברמות התואמות או עולות על היכולת האנושית העליונה. באופן קריטי, השילוב הזה הוא שעושה בני אדם כל כך יעילים וכל כך שונים מתוכנה נוכחית; זה גם מה שיאפשר לאנשים להיות מוחלפים כולם על ידי מערכות דיגיטליות.

בעוד שאינטליגנציה אנושית היא מיוחדת, היא בשום פנים אינה גבול. מערכות "על-אינטליגנטיות" מלאכותיות יכולות לפעול במהירות של מאות פעמים, לעבד כמויות נתונים עצומות ולהחזיק כמויות אדירות "בראש" בו-זמנית, וליצור צברים שהם הרבה יותר גדולים ויעילים מאוספי בני אדם. הן יכולות לעקוף לא יחידים אלא חברות, מדינות, או הציביליזציה שלנו כולה.

## אנחנו בסף

יש קונסנזוס מדעי חזק שAGI *אפשרי*. בינה מלאכותית כבר עולה על ביצועים אנושיים במבחנים כלליים רבים של יכולת אינטלקטואלית, כולל לאחרונה חשיבה ופתרון בעיות ברמה גבוהה. יכולות מפגרות - כמו למידה מתמשכת, תכנון, מודעות עצמית ומקוריות - כולן קיימות ברמה כלשהי במערכות AI נוכחיות, וקיימות שיטות ידועות שעלולות לשפר את כולן.

בעוד שעד לפני כמה שנים חוקרים רבים ראו את AGI כעניין של עשרות שנים, כעת העדויות לזמנים קצרים ל-AGI חזקות:

- "חוקי קנה מידה" מאומתים אמפירית מחברים בין קלט חישובי ליכולת AI, ותאגידים נמצאים במסלול להגדיל קלט חישובי בסדרי גודל במשך מספר השנים הבאות. המשאבים האנושיים והפיסקליים המוקדשים להתקדמות AI שווים כעת לאלו של תריסר פרויקטי מנהטן וכמה פרויקטי אפולו.
- תאגידי AI ומנהיגיהם מאמינים פומבית ובאופן פרטי שAGI (לפי הגדרה כלשהי) ניתן להשגה תוך מספר שנים. לחברות האלה יש מידע שאין לציבור, כולל שלחלקן יש את הדור הבא של מערכות AI בידיהן.
- מנבאי מומחים עם רקורד מוכח נותנים 25% הסתברות ל-AGI (לפי הגדרה כלשהי) שיגיע תוך 1-2 שנים, ו-50% ל-2-5 שנים (ראו תחזיות Metaculus עבור AGI ['חלש'](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) ו['מלא'](https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/)).
- אוטונומיה (כולל תכנון גמיש לטווח ארוך) מפגרת במערכות AI, אבל חברות גדולות מתמקדות כעת במשאביהן העצומים בפיתוח מערכות AI אוטונומיות וכינו באופן לא פורמלי את 2025 ["שנת הסוכן"](https://techinformed.com/2025-informed-the-year-of-agentic-ai/).
- בינה מלאכותית תורמת יותר ויותר לשיפור עצמי. ברגע שמערכות AI יהיו מוכשרות כמו חוקרי AI אנושיים בביצוע מחקר AI, סף קריטי להתקדמות מהירה למערכות AI חזקות הרבה יותר יושג וצפוי להוביל להתחמקות ביכולת AI. (אפשר לטעון שההתחמקות הזו כבר החלה.)

הרעיון שAGI חכם מאדם מרוחק עשרות שנים או יותר פשוט אינו בר קיימא עוד לרוב המכריע של המומחים בתחום. חילוקי הדעות כעת הם על כמה חודשים או שנים זה ייקח אם נשאר על המסלול הזה. השאלה המרכזית איתה אנחנו מתמודדים היא: האם עלינו?

## מה מניע את המירוץ ל-AGI

המירוץ לעבר AGI מונע על ידי כוחות מרובים, כל אחד עושה את המצב מסוכן יותר. חברות טכנולוגיה גדולות רואות את AGI כטכנולוגיית האוטומציה האולטימטיבית - לא רק להגביר עובדים אנושיים אלא להחליף אותם במידה רבה או כולה. עבור חברות, הפרס עצום: ההזדמנות לתפוס חלק משמעותי מהתפוקה הכלכלית השנתית של 100 טריליון דולר בעולם על ידי הפיכת עלויות העבודה האנושית לאוטומטיות.

מדינות מרגישות נאלצות להצטרף למירוץ הזה, מצטטות פומבית מנהיגות כלכלית ומדעית, אבל באופן פרטי רואות את AGI כמהפכה פוטנציאלית בעניינים צבאיים הדומה לנשק גרעיני. הפחד שיריבים עלולים לזכות ביתרון אסטרטגי מכריע יוצר דינמיקת מירוץ חימוש קלאסית.

המרדפים אחר על-אינטליגנציה מצטטים לעתים קרובות חזונות גדולים: לרפא את כל המחלות, להפוך הזדקנות, להשיג פריצות דרך באנרגיה ובנסיעות חלל, או ליצור יכולות תכנון על-אנושיות.

בפחות רחמנות, מה שמניע את המירוץ הוא כוח. כל משתתף - בין אם חברה או מדינה - מאמין שאינטליגנציה שווה כוח, ושהם יהיו המפקח הטוב ביותר על הכוח הזה.

אני טוען שהמניעים האלה אמיתיים אבל מוטעים מיסודם: AGI *יספוג* ו*יחפש* כוח במקום להעניק אותו; טכנולוגיות שנוצרו על ידי AI יהיו *גם* דו-פיפיות בחדות, וכשהן מועילות ניתן ליצור אותן עם כלי AI ובלי AGI; ואפילו במידה שAGI ותוצריו נשארים תחת שליטה, הדינמיקות המתחרות האלה - תאגידיות וגיאופוליטיות - הופכות סיכונים גדולים לחברה שלנו לכמעט בלתי נמנעים אלא אם כן יופרעו באופן מכריע.

## בינה מלאכותית כללית ועל-אינטליגנציה מהווים איום דרמטי על הציביליזציה

למרות הפיתוי שלהם, בינה מלאכותית כללית ועל-אינטליגנציה מהווים איומים דרמטיים על הציביליזציה דרך מסלולים מרובים המחזקים זה את זה:

*ריכוז כוח:* AI על-אנושי יכול לשלול כוח מהרוב המכריע של האנושות על ידי ספיגת חלקים עצומים של פעילות חברתית וכלכלית למערכות AI שמנוהלות על ידי קומץ חברות ענק (שעלולות בתורן או להיתפס על ידי ממשלות, או בפועל להשתלט על ממשלות).

*הפרעה מסיבית:* אוטומציה בכמויות של רוב העבודות המבוססות קוגניציה, החלפת המערכות האפיסטמיות הנוכחיות שלנו, והטמעה של מספרים עצומים של סוכנים לא-אנושיים פעילים יהפכו את רוב המערכות הציביליזציוניות הנוכחיות שלנו בתקופה קצרה יחסית.

*קטסטרופות:* על ידי הפצת היכולת - פוטנציאלית מעל הרמה האנושית - ליצור טכנולוגיות צבאיות והרסניות חדשות וניתוקה מהמערכות החברתיות והמשפטיות המבססות אחריות, קטסטרופות פיזיות מנשק להשמדה המונית הופכות לסבירות דרמטית יותר.

*גיאופוליטיקה ומלחמה:* מעצמות עולם גדולות לא תשבנה בחיבוק ידיים אם הן ירגישו שטכנולוגיה שיכולה לספק "יתרון אסטרטגי מכריע" מפותחת על ידי יריביהן.

*התחמקות ואובדן שליטה:* אלא אם כן זה יימנע במפורש, לAI על-אנושי יהיה כל תמריץ לשפר עוד יותר את עצמו ויוכל לעלות בהרבה על בני אדם במהירות, עיבוד נתונים ורמת החשיבה. אין דרך משמעותית בה אנחנו יכולים להיות בשליטה על מערכת כזאת. AI כזה לא יעניק כוח לבני אדם; אנחנו נעניק כוח לו, או שהוא ייקח אותו.

רבים מהסיכונים האלה נשארים גם אם בעיית ה"התאמה" הטכנית - הבטחה שAI מתקדם עושה באמינות מה שבני אדם רוצים שהוא יעשה - נפתרת. בינה מלאכותית מציבה אתגר עצום באיך היא תנוהל, והרבה מאוד היבטים של הניהול הזה הופכים קשים מאוד או בלתי פתירים כשחוצים את האינטליגנציה האנושית.

באופן הכי יסודי, הסוג של AI כללי על-אנושי שמפותח כעת יהיו לו, על פי טבעו, מטרות, סוכנות ויכולות העולות על שלנו. הוא יהיה בלתי נשלט מטבעו - איך אנחנו יכולים לשלוט במשהו שאנחנו לא יכולים להבין או לחזות? הוא לא יהיה כלי טכנולוגי לשימוש אנושי, אלא מין שני של אינטליגנציה על כדור הארץ לצד שלנו. אם יותר להתקדם עוד יותר, הוא יהווה לא רק מין שני אלא מין מחליף.

אולי הוא יטפל בנו טוב, אולי לא. אבל העתיד יהיה שלו, לא שלנו. העידן האנושי יסתיים.

## זה לא בלתי נמנע; האנושות יכולה, באופן קונקרטי מאוד, להחליט לא לבנות את המחליף שלה.

יצירת AGI על-אנושי רחוקה מלהיות בלתי נמנעת. אנחנו יכולים למנוע אותה באמצעות סט מתואם של אמצעי ממשל:

ראשית, אנחנו צריכים חשבונאות ופיקוח חזקים על חישוב AI ("כוח חישוב"), שהוא מאפשר יסודי של מערכות AI גדולות ומנוף לממשל עליהן. זה בתורו דורש מדידה ודיווח סטנדרטיים של סך כוח החישוב המשמש באימון מודלי AI ובהפעלתם, ושיטות טכניות לספירה, הסמכה ואימות החישוב המשמש.

שנית, עלינו ליישם תקרות קשיחות על חישוב AI, גם לאימון וגם להפעלה; אלה מונעות מAI גם להיות חזק מדי וגם לפעול מהר מדי. התקרות האלה ניתן ליישם גם דרך דרישות משפטיות וגם אמצעי אבטחה מבוססי חומרה שבנויים בתוך שבבים מיוחדים ל-AI, אנלוגי לתכונות אבטחה בטלפונים מודרניים. בגלל שחומרה מיוחדת ל-AI מיוצרת על ידי קומץ חברות בלבד, אימות ואכיפה אפשריים דרך שרשרת האספקה הקיימת.

שלישית, אנחנו צריכים אחריות מוגברת למערכות ה-AI המסוכנות ביותר. אלה שמפתחים AI שמשלב אוטונומיה גבוהה, כלליות רחבה ואינטליגנציה עליונה צריכים להתמודד עם אחריות מוחלטת לנזקים, בעוד שמקלטים בטוחים מהאחריות הזו יעודדו פיתוח של מערכות מוגבלות ויותר נשלטות.

רביעית, אנחנו צריכים רגולציה מדורגת מבוססת רמות סיכון. המערכות הכי מסוגלות ומסוכנות ידרשו ערבויות אבטחה ושליטה נרחבות לפני פיתוח והטמעה, בעוד שמערכות פחות חזקות או יותר מיוחדות יתמודדו עם פיקוח פרופורציונלי. המסגרת הרגולטורית הזו צריכה לפעול בסופו של דבר ברמות לאומיות ובינלאומיות.

הגישה הזו - עם מפרט מפורט שניתן במסמך המלא - מעשית: בעוד שתידרש קואורדינציה בינלאומית, אימות ואכיפה יכולים לפעול דרך המספר הקטן של חברות ששולטות בשרשרת האספקה של החומרה המיוחדת. היא גם גמישה: חברות עדיין יכולות לחדש ולהרוויח מפיתוח AI, רק עם גבולות ברורים על המערכות המסוכנות ביותר.

בלימה לטווח ארוך יותר של כוח וסיכון AI תדרוש הסכמים בינלאומיים מבוססים על אינטרס עצמי ומשותף, בדיוק כפי ששליטה על הפצת נשק גרעיני עושה כעת. אבל אנחנו יכולים להתחיל מיד עם פיקוח ואחריות מוגברים, תוך בניה לעבר ממשל מקיף יותר.

המרכיב החסר המרכזי הוא רצון פוליטי וחברתי לקחת שליטה על תהליך פיתוח הבינה המלאכותית. המקור של הרצון הזה, אם הוא יגיע בזמן, יהיה המציאות עצמה - כלומר, מההכרה נרחבת של ההשלכות האמיתיות של מה שאנחנו עושים.

## אנחנו יכולים להנדס AI כלי להעצמת האנושות

במקום לרדוף אחר AGI בלתי נשלט, אנחנו יכולים לפתח "AI כלי" חזק שמשפר יכולת אנושית תוך שהוא נשאר תחת שליטה אנושית משמעותית. מערכות AI כלי יכולות להיות מסוגלות ביותר תוך הימנעות מהחיתוך המסוכן של אוטונומיה גבוהה, כלליות רחבה ואינטליגנציה על-אנושית, כל עוד אנחנו מהנדסים אותן להיות נשלטות ברמה המתאימה ליכולת שלהן. הן יכולות גם להיות משולבות למערכות מתוחכמות ששומרות על פיקוח אנושי תוך מתן יתרונות טרנספורמטיביים.

AI כלי יכול לחולל מהפכה ברפואה, להאיץ גילוי מדעי, לשפר חינוך ולשפר תהליכים דמוקרטיים. כשמנוהל כמו שצריך, הוא יכול להפוך מומחים ומוסדות אנושיים ליעילים יותר במקום להחליף אותם. בעוד שמערכות כאלה עדיין יהיו מאוד מפריעות וידרשו ניהול זהיר, הסיכונים שהן מציבות שונים מיסודם מAGI: הם סיכונים שאנחנו יכולים לנהל, כמו אלה של טכנולוגיות חזקות אחרות, לא איומים קיומיים על סוכנות אנושית וציביליזציה. ובחשיבות קריטית, כשמפותחים בחכמה, כלי AI יכולים לעזור לאנשים לנהל AI חזק ולנהל את השפעותיו.

הגישה הזו דורשת חשיבה מחדש גם על איך AI מפותח וגם על איך היתרונות שלו מופצים. מודלים חדשים של פיתוח AI ציבורי וללא רווח, מסגרות רגולטוריות חזקות ומנגנונים להפצה רחבה יותר של יתרונות כלכליים יכולים לעזור להבטיח שAI יעצים את האנושות כולה במקום לרכז כוח בידיים מעטות. בינה מלאכותית עצמה יכולה לעזור לבנות מוסדות חברתיים ואפיפיים טובים יותר, לאפשר צורות חדשות של קואורדינציה ושיח שמחזקים במקום להחליש את החברה האנושית. ממסדי ביטחון לאומי יכולים למנף את המומחיות שלהם כדי להפוך מערכות כלי AI לבטוחות ומהימנות באמת, ומקור הגנה אמיתי וגם כוח לאומי.

אנחנו עלולים בסופו של דבר לבחור לפתח מערכות עוד יותר חזקות ויותר ריבוניות שהן פחות כמו כלים ו- אנחנו יכולים לקוות - יותר כמו נדיבים חכמים וחזקים. אבל עלינו לעשות זאת רק אחרי שפיתחנו את ההבנה המדעית ויכולת הממשל לעשות זאת בבטחה. החלטה כל כך חשובה ובלתי הפיכה צריכה להתקבל במכוון על ידי האנושות כולה, לא כברירת מחדל במירוץ בין חברות טכנולוגיה ומדינות.

## בידיים אנושיות

אנשים רוצים את הטוב שבא מAI: כלים שימושיים שמעצימים אותם, מגבירים הזדמנויות וצמיחה כלכליות, ומבטיחים פריצות דרך במדע, טכנולוגיה וחינוך. למה שלא? אבל כשנשאלים, רוב מוחלט של הציבור הכללי [רוצה פיתוח AI איטי וזהיר יותר](https://www.vox.com/future-perfect/2023/8/18/23836362/ai-slow-down-poll-regulation), ולא רוצה AI חכם מאדם שיחליף אותם בעבודות שלהם ובמקומות אחרים, ימלא את התרבות שלהם ואת המרחב המשותף של המידע בתוכן לא-אנושי, ירכז כוח בסט זעיר של תאגידים, יציב סיכונים קיצוניים גלובליים גדולים, ובסופו של דבר יאיים לשלול כוח או להחליף את המין שלהם. למה שהם ירצו?

אנחנו *יכולים* לקבל אחד בלי השני. זה מתחיל בהחלטה שהגורל שלנו אינו בבלתי נמנעות כביכול של טכנולוgiה כלשהי או בידיים של כמה מנכ"לים בעמק הסיליקון, אלא בידיים שלנו האחרות אם ניקח אחיזה בו. בואו נסגור את השערים, ונשמור על העתיד אנושי.