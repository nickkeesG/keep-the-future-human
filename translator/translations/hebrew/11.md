# נספחים

מידע משלים, הכולל - פרטים טכניים בנוגע לחישוב כוח חישוב, דוגמה ליישום של 'סגירת שער', פרטים למשטר חבות AGI מחמיר, וגישה מדורגת לתקני בטיחות ואבטחה של AGI.

## נספח א': פרטים טכניים לחישוב כוח חישוב

שיטה מפורטת הן ל"אמת הקרקע" והן לקירובים טובים עבור כלל כוח החישוב המשמש באימון ובהסקה נדרשת עבור בקרה משמעותית המבוססת על כוח חישוב. להלן דוגמה כיצד ניתן לתעד את "אמת הקרקע" ברמה הטכנית.

**הגדרות:**

*גרף סיבתי של כוח חישוב:* עבור פלט O נתון של מודל AI, קיימת קבוצה של חישובים דיגיטליים שעבורה שינוי תוצאת החישוב הזה עלול לשנות את O באופן פוטנציאלי. (יש להניח זאת באופן שמרני, כלומר צריכה להיות סיבה ברורה להאמין שחישוב אינו תלוי בקודם שמתרחש מוקדם יותר בזמן ושיש לו מסלול סיבתי פיזי פוטנציאלי של השפעה.) זה כולל חישוב שנעשה על ידי מודל ה-AI במהלך ההסקה, כמו גם חישובים שנכנסו לקלט, הכנת נתונים ואימון המודל. מכיוון שכל אחד מאלה עשוי להיות בעצמו פלט ממודל AI, זה מחושב באופן רקורסיבי, נחתך כאשר בן אדם סיפק שינוי משמעותי לקלט.

*כוח חישוב אימון:* כלל כוח החישוב, ב-FLOP או יחידות אחרות, הכרוך בגרף הסיבתי של כוח החישוב של רשת נוירונים (כולל הכנת נתונים, אימון וכיוונון עדין, וכל חישוב אחר.)

*כוח חישוב פלט:* כלל כוח החישוב בגרף הסיבתי של כוח החישוב של פלט AI נתון, כולל כל הרשתות הנוירונליות (וכולל את כוח החישוב לאימון שלהן) וחישובים אחרים הנכנסים לפלט הזה.

*קצב כוח חישוב הסקה:* בסדרה של פלטים, קצב השינוי (ב-FLOP/s או יחידות אחרות) של כוח חישוב הפלט בין פלטים, כלומר כוח החישוב המשמש לייצור הפלט הבא, חלקי המרווח הזמן בין הפלטים.

**דוגמאות וקירובים:**

- עבור רשת נוירונים בודדת המאומנת על נתונים שנוצרו על ידי בני אדם, כוח החישוב לאימון הוא פשוט כלל כוח החישוב לאימון כפי שמדווח בדרך כלל.
- עבור רשת נוירונים כזאת שמבצעת הסקה בקצב קבוע, קצב כוח החישוב להסקה הוא בערך המהירות הכללית של אשכול החישוב המבצע את ההסקה ב-FLOP/s.
- עבור כיוונון עדין של מודל, כוח החישוב לאימון של המודל השלם ניתן על ידי כוח החישוב לאימון של המודל הלא-מכוונן עדין בתוספת החישוב שנעשה במהלך הכיוונון העדין ולהכנת כל נתון שנעשה בו שימוש בכיוונון העדין.
- עבור מודל מזוקק, כוח החישוב לאימון של המודל השלם כולל אימון של המודל המזוקק והמודל הגדול יותר שנעשה בו שימוש לספק נתונים סינתטיים או קלט אימון אחר.
- אם כמה מודלים מאומנים, אבל "ניסיונות" רבים מושלכים על בסיס שיקול אנושי, אלה לא נחשבים לכוח החישוב לאימון או לפלט של המודל הנשמר.

## נספח ב': דוגמה ליישום של סגירת שער

**דוגמת יישום:** להלן דוגמה אחת כיצד סגירת שער יכולה לעבוד, בהנתן גבול של 10<sup>27</sup> FLOP לאימון ו-10<sup>20</sup> FLOP/s להסקה (הפעלת ה-AI):

**1\. השהיה:** מטעמי ביטחון לאומי, הרשות המבצעת האמריקאית מבקשת מכל החברות הבסיסן בארה"ב, העוסקות בעסקים בארה"ב, או המשתמשות בשבבים המיוצרים בארה"ב, לחדול ולהפסיק כל הרצת אימון AI חדשה שעלולה לחרוג מגבול כוח החישוב לאימון של 10<sup>27</sup> FLOP. ארה"ב צריכה להתחיל דיונים עם מדינות אחרות המארחות פיתוח AI, לעודד אותן בחוזקה לנקוט צעדים דומים ולציין שההשהיה האמריקאית עשויה להיות מוסרת במידה ותבחרנה שלא לציית.

**2\. פיקוח ורישוי אמריקאי:** על ידי צו ביצועי או פעולה של סוכנות רגולטורית קיימת, ארה"ב דורשת שתוך (נאמר) שנה אחת:

- כל הרצות אימון AI המוערכות מעל 10<sup>25</sup> FLOP שנעשו על ידי חברות הפועלות בארה"ב יירשמו במסד נתונים המתוחזק על ידי סוכנות רגולטורית אמריקאית. (הערה: גרסה מעט חלשה יותר של זה כבר נכללה בצו הביצועי האמריקאי על AI משנת 2023 שבוטל, שדרש רישום עבור מודלים מעל 10<sup>26</sup> FLOP.)
- כל יצרני חומרה הרלוונטיים ל-AI הפועלים בארה"ב או עושים עסקים עם הממשלה האמריקאית יצייתו לקבוצת דרישות על החומרה המיוחדת שלהם והתוכנה המניעה אותה. (רבות מהדרישות הללו יכולות להיבנות לתוך עדכוני תוכנה וקושחה לחומרה קיימת, אבל פתרונות ארוכי טווח ויציבים ידרשו שינויים לדורות מאוחרים יותר של החומרה.) בין אלה נמצאת דרישה שאם החומרה היא חלק מאשכול מחובר במהירות גבוהה המסוגל לבצע 10<sup>18</sup> FLOP/s של חישוב, נדרשת רמה גבוהה יותר של אימות, הכוללת רשות סדירה על ידי "מושל" מרוחק המקבל גם טלמטרי וגם בקשות לבצע חישוב נוסף.
- הנאמן מדווח על כלל החישוב המבוצע על החומרה שלו לסוכנות המתחזקת את מסד הנתונים האמריקאי.
- דרישות חזקות יותר מוכנסות בהדרגה כדי לאפשר פיקוח ומתן הרשאות בטוח וגמיש יותר.

**3\. פיקוח בינלאומי:**

- ארה"ב, סין וכל מדינות אחרות המארחות יכולת ייצור שבבים מתקדמת מנהלות משא ומתן על הסכם בינלאומי.
- ההסכם הזה יוצר סוכנות בינלאומית חדשה, דומה לסוכנות הבינלאומית לאנרגיה אטומית, המופקדת על פיקוח על אימון והפעלת AI.
- מדינות חתומות חייבות לדרוש מיצרני חומרת ה-AI הביתיים שלהן לציית לקבוצת דרישות חזקות לפחות כמו אלה שהוטלו בארה"ב.
- נאמנים נדרשים כעת לדווח על מספרי חישוב AI גם לסוכנויות במדינות הבית שלהם וגם למשרד חדש בתוך הסוכנות הבינלאומית.
- מדינות נוספות מעודדות בחוזקה להצטרף להסכם הבינלאומי הקיים: בקרות יצוא על ידי מדינות חתומות מגבילות גישה לחומרה מתקדמת על ידי לא-חתומות בעוד חתומות יכולות לקבל תמיכה טכנית בניהול מערכות ה-AI שלהן.

**4\. אימות ואכיפה בינלאומיים:**

- מערכת אימות החומרה מתעדכנת כך שהיא מדווחת על שימוש בחישוב גם לנאמן המקורי וגם ישירות למשרד הסוכנות הבינלאומית.
- הסוכנות, באמצעות דיון עם החתומות על ההסכם הבינלאומי, מסכימה על הגבלות חישוב שמקבלות אז תוקף משפטי במדינות החתומות.
- במקביל, קבוצת תקנים בינלאומיים עשויה להתפתח כך שאימון והפעלה של AIs מעל סף של חישוב (אבל מתחת לגבול) נדרשים לציית לתקנים האלה.
- הסוכנות יכולה, אם נחוץ כדי לפצות על אלגוריתמים טובים יותר וכו', להוריד את גבול החישוב. או, אם זה נחשב בטוח ורצוי (נאמר ברמה של ערבויות בטיחות הניתנות להוכחה), להעלות את גבול החישוב.

## נספח ג': פרטים למשטר חבות AGI מחמיר

**פרטים למשטר חבות AGI מחמיר**

- יצירה והפעלה של מערכת AI מתקדמת שהיא כללית, בעלת יכולת ואוטונומית ברמה גבוהה, נחשבות פעילות "מסוכנת באופן חריג".
- ככזה, רמת החבות הברירת המחדל לאימון והפעלה של מערכות כאלה היא חבות קפידה, משותפת ועשויה (או המקבילה שלה מחוץ לארה"ב) עבור כל נזק שנעשה על ידי המודל או הפלטים/פעולות שלו.
- חבות אישית תוטל על מנהלים וחברי דירקטוריון במקרים של רשלנות חמורה או התנהגות זדונית בכוונה. זה צריך לכלול עונשים פליליים עבור המקרים החמורים ביותר.
- יש מספר רב של מקלטי בטיחות שתחתם החבות חוזרת לברירת המחדל (מבוססת אשמה, בארה"ב) לחבות שאנשים וחברות יהיו בדרך כלל כפופים לה.
	- מודלים מאומנים ומופעלים מתחת לסף כוח חישוב מסוים (שיהיה לפחות פי 10 נמוך יותר מהמגבלות המתוארות לעיל.)
	- AI ש"חלש" (בערך, מתחת לרמת מומחה אנושי במשימות שעבורן הוא מיועד) ו/או
	- AI ש"צר" (בעל היקף קבוע ומוגבל למדי של משימות ופעולות שהוא מתוכנן ומאומן עבורן באופן ספציפי) ו/או
	- AI ש"פסיבי" (מוגבל מאוד ביכולתו - אפילו תחת שינוי צנוע - לנקוט פעולות או לבצע משימות מורכבות רב-שלביות ללא מעורבות ובקרה אנושית ישירה.)
	- AI שמובטח להיות בטוח, מאובטח וניתן לשליטה (בטוח באופן הניתן להוכחה, או ניתוח סיכונים מעיד על רמה זניחה של נזק צפוי.)
- מקלטי בטיחות עשויים להיתבע על בסיס [מקרה בטיחות](https://arxiv.org/abs/2410.21572) שהוכן על ידי מפתח ה-AI ואושר על ידי סוכנות או מבקר המוסמך על ידי סוכנות. כדי לתבוע מקלט בטיחות על בסיס כוח חישוב, המפתח חייב רק לספק הערכות אמינות של כלל כוח החישוב לאימון וקצב הסקה מקסימלי
- החקיקה תתאר במפורש מצבים שבהם הקלה זמנית מפיתוח מערכות AI עם סיכון גבוה לנזק ציבורי תהיה מתאימה.
- קונסורציומים של חברות, העובדים עם ארגונים לא-ממשלתיים וסוכנויות ממשלתיות, צריכים לפתח תקנים ונורמות המגדירות את המונחים הללו, כיצד רגולטורים צריכים להעניק מקלטי בטיחות, כיצד מפתחי AI צריכים לפתח מקרי בטיחות, וכיצד בתי משפט צריכים לפרש חבות כאשר מקלטי בטיחות לא נתבעו באופן פעיל.

## נספח ד': גישה מדורגת לתקני בטיחות ואבטחה של AGI

**גישה מדורגת לתקני בטיחות ואבטחה של AGI**

| דרגת סיכון | מפעיל(ים) | דרישות לאימון | דרישה לפריסה |
| --- | --- | --- | --- |
| RT-0 | AI חלש באוטונומיה, כלליות ואינטליגנציה | אין | אין |
| RT-1 | AI חזק באחד מבין אוטונומיה, כלליות ואינטליגנציה | אין | על בסיס סיכון ושימוש, פוטנציאלית מקרי בטיחות מאושרים על ידי רשויות לאומיות בכל מקום שבו ניתן להשתמש במודל |
| RT-2 | AI חזק בשניים מבין אוטונומיה, כלליות ואינטליגנציה | רישום אצל הרשות הלאומית שיש לה סמכות שיפוט על המפתח | מקרה בטיחות המגביל סיכון נזק חמור מתחת לרמות מורשות בתוספת ביקורות בטיחות עצמאיות (כולל רד-טימינג קופסה שחורה ולבנה) מאושרות על ידי רשויות לאומיות בכל מקום שבו ניתן להשתמש במודל |
| RT-3 | AGI חזק באוטונומיה, כלליות ואינטליגנציה | אישור מראש של תכנית בטיחות ואבטחה על ידי הרשות הלאומית שיש לה סמכות שיפוט על המפתח | מקרה בטיחות המבטיח סיכון מוגבל של נזק חמור מתחת לרמות מורשות כמו גם מפרטים נדרשים, כולל אבטחת סייבר, יכולת שליטה, מתג הרג שלא ניתן להסרה, התאמה לערכים אנושיים ועמידות בפני שימוש זדוני. |
| RT-4 | כל מודל שגם חורג או מ-10<sup>27</sup> FLOP אימון או מ-10<sup>20</sup> FLOP/s הסקה | אסור ממתין להסכמה בינלאומית להסרת מגבלת כוח חישוב | אסור ממתין להסכמה בינלאומית להסרת מגבלת כוח חישוב |

סיווגי סיכונים ותקני בטיחות/אבטחה, עם דרגות המבוססות על ספי כוח חישוב כמו גם שילובים של אוטונומיה גבוהה, כלליות ואינטליגנציה:

- *אוטונומיה חזקה* חלה אם המערכת מסוגלת לבצע, או יכולה בקלות להיעשות לבצע, משימות רב-שלביות ו/או לנקוט פעולות מורכבות שהן רלוונטיות לעולם האמיתי, ללא פיקוח או התערבות אנושית משמעותית. דוגמאות: רכבים אוטונומיים ורובוטים; בוטים למסחר פיננסי. דוגמאות שליליות: GPT-4; מסווגי תמונות
- *כלליות חזקה* מציינת היקף יישום רחב, ביצוע משימות שעבורן המודל לא אומן במכוון ובאופן ספציפי, ויכולת משמעותית ללמוד משימות חדשות. דוגמאות: GPT-4; mu-zero. דוגמאות שליליות: AlphaFold; רכבים אוטונומיים; מחוללי תמונות
- *אינטליגנציה חזקה* מתאימה להשוואת ביצועים ברמת מומחה אנושי במשימות שעבורן המודל מתפקד הכי טוב (ועבור מודל כללי, בתחום רחב של משימות.) דוגמאות: AlphaFold; mu-zero; o3. דוגמאות שליליות: GPT-4; Siri