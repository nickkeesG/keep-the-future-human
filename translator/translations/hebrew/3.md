# פרק 3 - היבטים מרכזיים ביצירת מערכות בינה מלאכותית כללית מודרניות

רוב מערכות הבינה המלאכותית המתקדמות בעולם נוצרות באמצעות שיטות דומות באופן מפתיע. להלן היסודות.

כדי להבין באמת בן אדם צריך לדעת משהו על ביולוגיה, אבולוציה, חינוך ילדים ועוד; כדי להבין בינה מלאכותית גם צריך לדעת איך היא נוצרת. במהלך חמש השנים האחרונות, מערכות בינה מלאכותית התפתחו באופן עצום הן ביכולת והן במורכבות. גורם מאפשר מרכזי היה הזמינות של כמויות גדולות מאוד של כוח חישוב (או בפי העם "קומפיוט" כשמדובר על בינה מלאכותית).

המספרים מרהיבים. כ-10<sup>25</sup>-10<sup>26</sup> "פעולות נקודה צפה" (FLOP)[^1] משמשות באימון של מודלים כמו סדרת GPT, Claude, Gemini וכדומה.[^2] (לשם השוואה, אם כל אדם על פני כדור הארץ היה עובד ללא הפסקה ומבצע חישוב אחד כל חמש שניות, זה היה לוקח בערך מיליארד שנים להשיג זאת.) כמות עצומה זו של כוח חישוב מאפשרת אימון של מודלים עם עד טריליונים של משקולות מודל על טרהבייטים של נתונים - חלק גדול מכל הטקסט האיכותי שאי פעם נכתב לצד ספריות גדולות של צלילים, תמונות ווידאו. בשילוב אימון זה עם אימון נרחב נוסף המחזק העדפות אנושיות וביצוע טוב של משימות, מודלים המאומנים בדרך זו מציגים ביצועים תחרותיים לאדם על פני טווח משמעותי של משימות אינטלקטואליות בסיסיות, כולל חשיבה ופתרון בעיות.

אנו גם יודעים (בערך, בערך מאוד) כמה מהירות כוח חישוב, בפעולות לשנייה, מספיקה כדי שמהירות ה*הסקה*[^3] של מערכת כזו תתאים ל*מהירות* של עיבוד טקסט אנושי. זה בערך 10<sup>15</sup>-10<sup>16</sup> FLOP לשנייה.[^4]

למרות היותם חזקים, מודלים אלה מוגבלים מטבעם בדרכים מרכזיות, די דומה לאופן שבו בן אדם בודד היה מוגבל אם היה נאלץ פשוט להוציא טקסט בקצב קבוע של מילים לדקה, מבלי לעצור לחשוב או להשתמש בכלים נוספים. מערכות בינה מלאכותית עדכניות יותר מתמודדות עם מגבלות אלה דרך תהליך ואדריכלות מורכבים יותר המשלבים מספר אלמנטים מרכזיים:

- רשת נוירונים אחת או יותר, כאשר מודל אחד מספק את היכולת הקוגניטיבית הליבה, ועד כמה אחרים מבצעים משימות אחרות צרות יותר;
- *כלים* המוענקים למודל ושמיש על ידיו - לדוגמה יכולת לחפש ברשת, ליצור או לערוך מסמכים, לבצע תוכניות וכדומה.
- *פיגומים* המחברים בין קלטים ופלטים של רשתות נוירונים. פיגום פשוט מאוד עשוי פשוט לאפשר לשני "מופעים" של מודל בינה מלאכותית לשוחח זה עם זה, או לאחד לבדוק את העבודה של האחר.[^5]
- *שרשרת חשיבה* וטכניקות הנחיה דומות עושות משהו דומה, גורמות למודל למשל ליצור גישות רבות לבעיה, ואז לעבד את הגישות הללו לתשובה מצרפית.
- *אימון חוזר* של מודלים לעשות שימוש טוב יותר בכלים, פיגומים ושרשרת חשיבה.

מכיוון שההרחבות הללו יכולות להיות חזקות מאוד (וכוללות מערכות בינה מלאכותית עצמן), המערכות המורכבות הללו יכולות להיות מתוחכמות למדי ולשפר באופן דרמטי את יכולות הבינה המלאכותית.[^6] ולאחרונה, טכניקות בפיגומים ובמיוחד בהנחיית שרשרת חשיבה (וקיפול התוצאות בחזרה לאימון חוזר של מודלים להשתמש בהן טוב יותר) פותחו והופעלו ב-[o1](https://openai.com/o1/), [o3](https://openai.com/index/openai-o3-mini/) ו-[DeepSeek R1](https://api-docs.deepseek.com/news/news250120) כדי לבצע מעברים רבים של הסקה בתגובה לשאילתה נתונה.[^7] זה למעשה מאפשר למודל "לחשוב על" התגובה שלו ומשפר באופן דרמטי את יכולת המודלים הללו לבצע חשיבה ברמה גבוהה במשימות מדע, מתמטיקה ותכנות.[^8]

עבור אדריכלות בינה מלאכותית נתונה, הגדלות בכוח החישוב של האימון [ניתנות לתרגום אמין](https://arxiv.org/abs/2405.10938) לשיפורים במערכת מדדים מוגדרים בבירור. עבור יכולות כלליות פחות מוגדרות בחדות (כמו אלה שנדונות להלן), התרגום פחות ברור וחזוי, אבל זה כמעט בוודאי שמודלים גדולים יותר עם יותר כוח חישוב לאימון יהיו להם יכולות חדשות וטובות יותר, גם אם קשה לחזות מה הן יהיו.

באופן דומה, מערכות מורכבות ובמיוחד התקדמות ב"שרשרת חשיבה" (ואימון של מודלים שעובדים טוב איתה) פתחו קנה מידה בכוח חישוב *הסקה*: עבור מודל ליבה מאומן נתון, לפחות חלק מיכולות מערכת הבינה המלאכותית גדלות ככל שמיושם יותר כוח חישוב המאפשר להן "לחשוב חזק יותר ויותר זמן" על בעיות מורכבות. זה בא במחיר תלול של מהירות חישוב, מצריך מאות או אלפים יותר FLOP/s כדי להתאים לביצועים אנושיים.[^9]

למרות שזה רק חלק ממה שמוביל להתקדמות מהירה בבינה מלאכותית,[^10] תפקיד כוח החישוב והאפשרות של מערכות מורכבות יתברר כמכריע הן למניעת AGI בלתי נשלט והן לפיתוח חלופות בטוחות יותר.

[^1]: 10<sup>27</sup> אומר 1 ואחריו 25 אפסים, או עשרה טריליון טריליון. FLOP הוא פשוט חיבור או כפל חשבוני של מספרים עם דיוק מסוים. שים לב שביצועי חומרת בינה מלאכותית יכולים להשתנות בגורם של עשרה יותר תלוי בדיוק החשבון ובאדריכלות המחשב. ספירת פעולות שער לוגי (ANDs, ORs, AND NOTs) תהיה בסיסית אבל אלה לא זמינות או נבחנות בדרך כלל; למטרות נוכחיות זה שימושי להתייחס לפעולות 16-ביט (FP16), למרות שיש לקבוע גורמי המרה מתאימים.

[^2]: אוסף הערכות ונתונים קשים זמין מ-[Epoch AI](https://epochai.org/data/large-scale-ai-models) ומצביע על בערך 2×10<sup>25</sup> FLOP של 16-ביט עבור GPT-4; זה בערך תואם [מספרים שדלפו](https://mpost.io/gpt-4s-leaked-details-shed-light-on-its-massive-scale-and-impressive-architecture/) עבור GPT-4. הערכות למודלים אחרים מאמצע 2024 הן כולן בטווח של גורם של כמה מ-GPT-4.

[^3]: הסקה היא פשוט התהליך של יצירת פלט מרשת נוירונים. אימון יכול להיחשב כרצף של הסקות רבות ושינויים במשקולות המודל.

[^4]: עבור הפקת טקסט, ה-GPT-4 המקורי דרש 560 TFLOP לאסימון שנוצר. בערך 7 אסימונים/שנייה נדרשים כדי לעמוד בקצב החשיבה האנושית, אז זה נותן ≈3×10<sup>15</sup> FLOP/s. אבל יעילויות הורידו את זה; [הברושור הזה של NVIDIA](https://developer.nvidia.com/blog/supercharging-llama-3-1-across-nvidia-platforms/) למשל מצביע על מעט כמו 3×10<sup>14</sup> FLOP/s עבור מודל Llama 405B בעל ביצועים דומים.

[^5]: כדוגמה מורכבת מעט יותר, מערכת בינה מלאכותית עשויה תחילה ליצור כמה פתרונות אפשריים לבעיה מתמטית, ואז להשתמש במופע אחר לבדוק כל פתרון, ולבסוף להשתמש בשלישי לסנתז את התוצאות להסבר ברור. זה מאפשר פתרון בעיות יסודי ואמין יותר מאשר מעבר יחיד.

[^6]: ראה למשל פרטים על ["Operator" של OpenAI](https://openai.com/index/introducing-operator/), [יכולות הכלים של Claude](https://docs.anthropic.com/en/docs/build-with-claude/computer-use), ו-[AutoGPT](https://github.com/Significant-Gravitas/AutoGPT). ל-[Deep Research](https://openai.com/index/introducing-deep-research/) של OpenAI כנראה יש אדריכלות די מתוחכמת אבל פרטים לא זמינים.

[^7]: Deepseek R1 מסתמך על אימון והנחיה איטרטיביים של המודל כך שהמודל המאומן הסופי יוצר חשיבה נרחבת של שרשרת חשיבה. פרטים אדריכליים לא זמינים עבור o1 או o3, אולם Deepseek גילה שאין צורך ב"רוטב מיוחד" כלשהו כדי לפתוח קנה מידה של יכולת עם הסקה. אבל למרות קבלת הרבה עיתונות כמערערת את ה"סטטוס קוו" בבינה מלאכותית, זה לא משפיע על הטענות הליבה של החיבור הזה.

[^8]: המודלים הללו עולים משמעותית על מודלים סטנדרטיים במדדי חשיבה. לדוגמה, במדד GPQA Diamond - מבחן קפדני של שאלות מדע ברמת דוקטורט - GPT-4o [קיבל](https://openai.com/index/learning-to-reason-with-llms/) 56%, בעוד o1 ו-o3 השיגו 78% ו-88%, בהתאמה, עולים בהרבה על הניקוד הממוצע של 70% של מומחים אנושיים.

[^9]: O3 של OpenAI כנראה הוציא ∼10<sup>21</sup>-10<sup>22</sup> FLOP [להשלמת כל אחת משאלות אתגר ARC-AGI](https://www.interconnects.ai/p/openais-o3-the-2024-finale-of-ai), שבני אדם מוכשרים יכולים לעשות ב-(נגיד) 10-100 שניות, נותן נתון יותר כמו ∼10<sup>20</sup> FLOP/s.

[^10]: בעוד כוח חישוב הוא מדד מרכזי ליכולת מערכת בינה מלאכותית, הוא מתקשר הן עם איכות נתונים והן עם שיפורים אלגוריתמיים. נתונים או אלגוריתמים טובים יותר יכולים להוריד דרישות חישוביות, בעוד יותר כוח חישוב יכול לפעמים לפצות על נתונים או אלגוריתמים חלשים יותר.