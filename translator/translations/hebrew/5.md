# פרק 5 - על סף הדלת

הדרך ממערכות AI של היום ל-AGI מלא נראית קצרה וניתנת לחיזוי באופן מזעזע.

העשור האחרון הביא התקדמות דרמטית ב-AI המונעת על ידי משאבי [חישוב](https://epoch.ai/blog/training-compute-of-frontier-ai-models-grows-by-4-5x-per-year), כוח אדם ו[תקציב](https://arxiv.org/abs/2405.21015) עצומים. יישומי AI מיוחדים רבים טובים מבני אדם במשימות שהוקצו להם, ובוודאי מהירים וזולים הרבה יותר.[^1] ויש גם סוכנים על-אנושיים מיוחדים שיכולים להשמיד כל אדם במשחקים צרי-תחום כמו [גו](https://www.nature.com/articles/nature16961), [שחמט](https://arxiv.org/abs/1712.01815) ו[פוקר](https://www.deepstack.ai/), כמו גם [סוכנים כלליים יותר](https://deepmind.google/discover/blog/a-generalist-agent/) שיכולים לתכנן ולבצע פעולות בסביבות מדומות פשוטות באותה יעילות של בני אדם.

באופן בולט במיוחד, מערכות AI כלליות נוכחיות מ-OpenAI/Microsoft, Google/Deepmind, Anthropic/Amazon, Facebook/Meta, X.ai/Tesla ואחרים [^2] הופיעו מאז תחילת 2023 והגבירו בהתמדה (אם כי באופן לא אחיד) את יכולותיהן מאז. כל אלה נוצרו באמצעות חיזוי טוקנים על מאגרי נתונים עצומים של טקסט ומולטימדיה, בשילוב עם משוב חיזוק נרחב מבני אדם ומערכות AI אחרות. חלק מהן כוללות גם מערכות נרחבות של כלים ופיגום.

## חוזקות וחולשות של מערכות כלליות נוכחיות

מערכות אלה מתפקדות היטב על פני מגוון הולך ומתרחב של בדיקות שתוכננו למדוד אינטליגנציה ומומחיות, עם התקדמות שהפתיעה אפילו מומחים בתחום:

- כשפורסם לראשונה, GPT-4 [השתווה או עלה על ביצועים אנושיים טיפוסיים](https://arxiv.org/abs/2303.08774) בבחינות אקדמיות סטנדרטיות כולל SATs, GRE, בחינות כניסה ובחינות לשכת עורכי הדין. מודלים עדכניים יותר כנראה מתפקדים הרבה יותר טוב, אם כי התוצאות אינן זמינות לציבור.
- מבחן טיורינג – שזמן רב נחשב נקודת ציון מרכזית ל"AI אמיתי" – עובר כיום באופן שגרתי בכמה צורות על ידי מודלי שפה מודרניים, הן באופן בלתי פורמלי והן ב[מחקרים פורמליים](https://arxiv.org/abs/2405.08007).[^3]
- במדד MMLU המקיף הפרוש על 57 נושאים אקדמיים, [מודלים עדכניים משיגים ציוני רמת מומחה-תחום](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu) (∼90%) [^4]
- המומחיות הטכנית התקדמה באופן דרמטי: מדד GPQA של פיזיקה ברמת תואר שני ראה [ביצועים קפצו](https://epoch.ai/data/ai-benchmarking-dashboard) מניחוש כמעט אקראי (GPT-4, 2022) לרמת מומחה (o1-preview, 2024).
- אפילו בדיקות שתוכננו במיוחד להיות עמידות ל-AI נופלות: O3 של OpenAI כביכול [פותר](https://www.nextbigfuture.com/2024/12/openai-releases-o3-model-with-high-performance-and-high-cost.html) את מדד ARC-AGI לפתרון בעיות מופשטות ברמה אנושית, משיג ביצועי קידוד ברמת מומחה עליון, ומקבל 25% בבעיות "מתמטיקה חדישה" של Epoch AI שתוכננו לאתגר מתמטיקאים מהשורה הראשונה.[^5]
- המגמה כל כך ברורה שהמפתח של MMLU יצר כעת ["הבחינה האחרונה של האנושות"](https://agi.safe.ai/) – שם מבשר רעות המשקף את האפשרות ש-AI יעלה בקרוב על ביצועים אנושיים בכל מבחן משמעותי. נכון לכתיבת שורות אלה, יש טענות על מערכות AI המשיגות 27% (לפי [סם אלטמן](https://x.com/sama/status/1886220281565381078)) ו-35% (לפי [המאמר הזה](https://arxiv.org/abs/2502.09955)) בבחינה קשה ביותר זו. די לא סביר שאדם בודד יכול לעשות כך.

למרות הנתונים המרשימים האלה (והאינטליגנציה הברורה שלהן כשאדם מקיים איתן אינטראקציה) [^6] יש הרבה דברים שרשתות נוירונים אלה (לפחות הגרסאות ששוחררו) *לא יכולות* לעשות. כרגע רובן חסרות גוף – קיימות רק על שרתים – ומעבדות לכל היותר טקסט, קול ותמונות סטטיות (אבל לא וידאו). באופן מכריע, רובן לא יכולות לבצע פעילויות מתוכננות מורכבות הדורשות דיוק גבוה.[^7] ויש מספר תכונות נוספות שחזקות בקוגניציה אנושית ברמה גבוהה הנמוכות כרגע במערכות AI ששוחררו.

הטבלה הבאה מפרטת מספר מאלה, על בסיס מערכות AI מאמצע 2024 כמו GPT-4o, Claude 3.5 Sonnet, וGoogle Gemini 1.5.[^8] השאלה המרכזית לכמה מהר AI כללי יהפוך חזק יותר היא: באיזה מידה פשוט לעשות *יותר מאותו הדבר* יניב תוצאות, לעומת הוספת טכניקות נוספות אבל *ידועות*, לעומת פיתוח או יישום כיווני מחקר AI *באמת חדשים*. התחזיות שלי לזה נתונות בטבלה, במונחים של כמה סביר שכל אחד מהתרחישים האלה יביא את היכולת הזו לרמה אנושית ומעבר לה.

<table><tbody><tr><th>יכולת</th><th>תיאור היכולת</th><th>סטטוס/פרוגנוזה</th><th>קנה מידה/ידוע/חדש</th></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td colspan="4"><em>יכולות קוגניטיביות ליבה</em></td></tr><tr><td>חשיבה</td><td>בני אדם יכולים לבצע חשיבה מדויקת, רב-שלבית, לפי כללים ובדיקת דיוק.</td><td>התקדמות דרמטית לאחרונה באמצעות שרשרת חשיבה מורחבת ואימון חוזר</td><td>95/5/5</td></tr><tr><td>תכנון</td><td>בני אדם מציגים תכנון ארוך טווח והיררכי.</td><td>משתפר עם קנה מידה; יכול להיעזר מאוד בפיגום וטכניקות אימון טובות יותר.</td><td>10/85/5</td></tr><tr><td>עיגון אמת</td><td>מערכות GPAI ממציאות מידע חסר בסיס כדי לענות על שאילתות.</td><td>משתפר עם קנה מידה; נתוני כיול זמינים במודל; ניתן לבדוק/לשפר באמצעות פיגום.</td><td>30/65/5</td></tr><tr><td>פתרון בעיות גמיש</td><td>בני אדם יכולים לזהות דפוסים חדשים ולהמציא פתרונות חדשים לבעיות מורכבות; מודלי ML נוכחיים מתקשים.</td><td>משתפר עם קנה מידה אבל באופן חלש; עשוי להיפתר עם טכניקות נוירו-סימבוליות או "חיפוש" כללי.</td><td>15/75/10</td></tr><tr><td colspan="4"><em>למידה וידע</em></td></tr><tr><td>למידה וזיכרון</td><td>לבני אדם יש זיכרון עבודה, קצר טווח וארוך טווח, שכולם דינמיים וקשורים זה לזה.</td><td>כל המודלים לומדים במהלך האימון; מערכות GPAI לומדות בתוך חלון הקשר ובמהלך כוונון עדין; "למידה רציפה" וטכניקות אחרות קיימות אבל עדיין לא משולבות במערכות GPAI גדולות.</td><td>5/80/15</td></tr><tr><td>הפשטה ורקורסיה</td><td>בני אדם יכולים למפות ולהעביר קבוצות יחסים לכאלה מופשטות יותר לצורכי חשיבה ומניפולציה, כולל חשיבה "מטא" רקורסיבית.</td><td>משתפרת חלש עם קנה מידה; עשויה להתגלות במערכות נוירו-סימבוליות.</td><td>30/50/20</td></tr><tr><td>מודל(ים) עולמי(ים)</td><td>לבני אדם יש מודל עולמי חזוי שהם מעדכנים בהתמדה ובתוכו הם יכולים לפתור בעיות ולבצע חשיבה פיזית</td><td>משתפר עם קנה מידה; עדכון קשור ללמידה; מערכות GPAI חלשות בחיזוי עולם אמיתי.</td><td>20/50/30</td></tr><tr><td colspan="4"><em>עצמי וסוכנות</em></td></tr><tr><td>סוכנות</td><td>בני אדם יכולים לנקוט פעולות כדי לרדוף מטרות, על בסיס תכנון/חיזוי.</td><td>מערכות ML רבות הן סוכניות; ניתן להפוך LLMs לסוכנים באמצעות עטיפות.</td><td>5/90/5</td></tr><tr><td>כיוון עצמי</td><td>בני אדם מפתחים ורודפים אחרי מטרות משלהם, עם מוטיבציה ודחף הנוצרים פנימית.</td><td>מורכב בעיקר מסוכנות פלוס מקוריות; צפוי להתגלות במערכות סוכניות מורכבות עם מטרות מופשטות.</td><td>40/45/15</td></tr><tr><td>התייחסות עצמית</td><td>בני אדם מבינים וחושבים על עצמם כממוקמים בתוך סביבה/הקשר.</td><td>משתפרת עם קנה מידה ויכולה להיות מוגברת עם תגמול אימון.</td><td>70/15/15</td></tr><tr><td>מודעות עצמית</td><td>לבני אדם יש ידע על המחשבות והמצבים המנטליים שלהם ויכולים לחשוב עליהם.</td><td>קיימת במובן מסוים במערכות GPAI, שיכולות כביכול לעבור את "מבחן המראה" הקלסי למודעות עצמית. ניתן לשיפור עם פיגום; אבל לא ברור אם זה מספיק.</td><td>20/55/25</td></tr><tr><td colspan="4"><em>ממשק וסביבה</em></td></tr><tr><td>אינטליגנציה מגולמת</td><td>בני אדם מבינים ומקיימים אינטראקציה פעילה עם הסביבה האמיתית שלהם.</td><td>למידת חיזוק עובדת היטב בסביבות מדומות ואמיתיות (רובוטיות) וניתנת לשילוב בטרנספורמרים רב-מודליים.</td><td>5/85/10</td></tr><tr><td>עיבוד רב-חושי</td><td>בני אדם משלבים ומעבדים בזמן אמת זרמי קלט חזותיים, שמיעתיים וחושיים אחרים.</td><td>אימון במודליות מרובות נראה "פשוט עובד" ומשתפר עם קנה מידה. עיבוד וידאו בזמן אמת קשה אבל למשל מערכות נהיגה עצמית משתפרות במהירות.</td><td>30/60/10</td></tr><tr><td colspan="4"><em>יכולות רמה גבוהה</em></td></tr><tr><td>מקוריות</td><td>מודלי ML נוכחיים יצירתיים בהפיכה ושילוב רעיונות/יצירות קיימים, אבל בני אדם יכולים לבנות מסגרות ומבנים חדשים, לעתים קשורים לזהותם.</td><td>יכולה להיות קשה להבחין מ"יצירתיות," שעשויה להתרחב אליה; עשויה להתגלות מיצירתיות פלוס מודעות עצמית.</td><td>50/40/10</td></tr><tr><td>הכרה</td><td>בני אדם חווים קוואליה; אלה יכולים להיות בעלי ערכיות חיובית, שלילית או נייטרלית; זה "דומה למשהו" להיות אדם.</td><td>קשה מאוד ומסובך פילוסופית לקבוע אם מערכת נתונה היא בעלת זה.</td><td>5/10/85</td></tr></tbody></table>

יכולות מרכזיות שכרגע הן מתחת לרמת מומחה אנושי במערכות GPAI מודרניות, מקובצות לפי סוג. העמודה השלישית מסכמת מצב נוכחי. עמודה אחרונה מציגה סבירות חזויה (%) שביצועים ברמה אנושית יושגו באמצעות: הרחבת טכניקות נוכחיות / שילוב עם טכניקות ידועות / פיתוח טכניקות חדשות. יכולות אלה אינן עצמאיות, ועלייה באחת כלשהי הולכת בדרך כלל יד ביד עם עליות באחרות. שימו לב שלא כולן (במיוחד הכרה) נחוצות למערכות AI המסוגלות לקדם פיתוח AI, מה שמדגיש את האפשרות של AI חזק אבל חסר הכרה.

פירוק מה "חסר" באופן זה הופך את זה די ברור שאנחנו די על המסלול לאינטליגנציה רחבה מעל-אנושית על ידי הרחבת טכניקות קיימות או ידועות.[^9]

עדיין יכולות להיות הפתעות. גם אם נניח בצד "הכרה," יכולות להיות כמה מהיכולות הקוגניטיביות הליבה המפורטות שבאמת לא ניתן לעשות עם טכניקות נוכחיות ודורשות חדשות. אבל חישבו על זה. המאמץ הנוכחי שמופעל על ידי רבות מהחברות הגדולות בעולם מסתכם במספר כפול מההוצאה של פרויקט אפולו ובעשרות כפול מפרויקט מנהטן,[^10] ומעסיק אלפי האנשים הטכניים הטובים ביותר במשכורות חסרות תקדים. הדינמיקה של השנים האחרונות הביאה כעת למשימה זו יותר כוח מוחין אנושי (עם AI שמתווסף כעת) מכל מאמץ בהיסטוריה. אנחנו לא צריכים להמר על כישלון.

## המטרה הגדולה: סוכנים אוטונומיים כלליים

הפיתוח של AI כללי במהלך השנים האחרונות התמקד ביצירת AI כללי וחזק אך דמוי כלי: הוא מתפקד בעיקר כעוזר (די) נאמן, ובאופן כללי לא נוקט פעולות מעצמו. זה נובע חלקית מעיצוב, אבל בעיקר מכיוון שמערכות אלה פשוט לא היו מוכשרות מספיק במיומנויות הרלוונטיות כדי שניתן יהיה להפקיד בידיהן פעולות מורכבות.[^11]

חברות AI וחוקרים, עם זאת, [מעבירים התמקדות](https://www.axios.com/2025/01/23/davos-2025-ai-agents) יותר ויותר לכיוון סוכנים *אוטונומיים* ברמת מומחה לשימוש כללי.[^12] זה יאפשר למערכות לפעול יותר כמו עוזר אנושי שהמשתמש יכול לאצול אליו פעולות אמיתיות.[^13] מה זה ידרש? מספר יכולות מטבלת "מה שחסר" מעורבות, כולל עיגון אמת חזק, למידה וזיכרון, הפשטה ורקורסיה, ומודלים עולמיים (לאינטליגנציה), תכנון, סוכנות, מקוריות, כיוון עצמי, התייחסות עצמית ומודעות עצמית (לאוטונומיה), ועיבוד רב-חושי, אינטליגנציה מגולמת ופתרון בעיות גמיש (לכלליות).[^14]

הצומת המשולש הזה של אוטונומיה גבוהה (עצמאות פעולה), כלליות גבוהה (היקף ורוחב משימות) ואינטליגנציה גבוהה (יכולת במשימות קוגניטיביות) הוא כרגע ייחודי לבני אדם. זה במשתמע מה שרבים כנראה חושבים עליו כש־הם חושבים על AGI – הן מבחינת הערך שלו והן מבחינת הסיכונים שלו.

זה מספק דרך נוספת להגדיר A-G-I כ***A***וטונומית-***G***כללית-***I***נטליגנציה, ונראה שהצומת המשולש הזה מספק עדשה ערכית מאוד למערכות ביכולת גבוהה הן בהבנת הסיכונים והתגמולים שלהן והן בממשל של AI.

![](https://keepthefuturehuman.ai/essay/_next/image?url=https%3A%2F%2Fkeepthefuturehuman.ai%2Fwp-content%2Fuploads%2F2025%2F02%2FAGI-Venn-Diagram-Simple-1024x1024.png&w=3840&q=75) אזור הכוח והסיכון המהפכני של A-G-I מגיח מהצומת של שלושה מאפיינים מרכזיים: אוטונומיה גבוהה, אינטליגנציה גבוהה במשימות וכלליות גבוהה.

## מחזור השיפור (העצמי) של ה-AI

גורם מכריע אחרון בהבנת התקדמות AI הוא לולאת המשוב הטכנולוגית הייחודית של AI. בפיתוח AI, הצלחה – הן במערכות מוכחות והן במוצרים שנפרסו – מביאה השקעה, כישרון ותחרות נוספים, ואנחנו כרגע בעיצומה של לולאת משוב עצומה של הייפ-פלוס-מציאות של AI שמניעה מאות מיליארדי, או אפילו טריליוני דולרים בהשקעה.

סוג זה של מחזור משוב יכול לקרות עם כל טכנולוגיה, וראינו את זה ברבות, שבהן הצלחה בשוק מביאה השקעה, שמביאה שיפור והצלחה טובה יותר בשוק. אבל פיתוח AI הולך רחוק יותר, בכך שכעת מערכות AI עוזרות לפתח מערכות AI חדשות וחזקות יותר.[^15] אנחנו יכולים לחשוב על לולאת המשוב הזו בחמישה שלבים, כל אחד עם טווח זמן קצר יותר מהקודם, כמוצג בטבלה.

*מחזור השיפור של ה-AI פועל על פני טווחי זמן מרובים, כשכל שלב עלול להאיץ את השלבים הבאים. השלבים המוקדמים כבר בעיצומם, בעוד השלבים המאוחרים נותרו ספקולטיביים אבל יכולים להתקדם מהר מאוד ברגע שיפתחו.*

מספר מהשלבים האלה כבר מתרחשים, וכמה בבירור מתחילים. השלב האחרון, שבו מערכות AI משפרות את עצמן באופן אוטונומי, היה מרכיב עיקרי בספרות על הסיכון של מערכות AI חזקות מאוד, ומסיבה טובה.[^16] אבל חשוב לציין שזה רק הצורה הדרמטית ביותר של מחזור משוב שכבר התחיל ויכול להוביל להפתעות נוספות בהתקדמות המהירה של הטכנולוגיה.

[^1]: אתם משתמשים בהרבה יותר מה-AI הזה מכפי שכנראה אתם חושבים, הוא מניע יצירת דיבור וזיהויו, עיבוד תמונות, אלגוריתמי פידים חדשותיים וכו'.

[^2]: בעוד היחסים בין זוגות החברות האלה הם די מורכבים ומעודנים, רשמתי אותן במפורש כדי לציין הן את הון השוק הכולל העצום של חברות שמעורבות כעת בפיתוח AI, והן שמאחורי אפילו חברות "קטנות יותר" כמו Anthropic עומדים כיסים עמוקים ביותר באמצעות השקעות ועסקאות שותפות גדולות.

[^3]: זה הפך אופנתי לזלזל במבחן טיורינג, אבל הוא די חזק וכללי. בגרסאות חלשות הוא מציין האם אנשים טיפוסיים המקיימים אינטראקציה עם AI (שמאומן לפעול כמו אדם) בדרכים טיפוסיות לתקופות קצרות יכולים לספר אם זה AI. הם לא יכולים. שנית, מבחן טיורינג יריבותי מאוד יכול לבדוק בעיקרון כל אלמנט של יכולת ואינטליגנציה אנושית – על ידי למשל השוואת מערכת AI לאדם מומחה, מוערכת על ידי מומחים אנושיים אחרים. יש מובן שבו הרבה מהערכת AI היא צורה מוכללת של מבחן טיורינג.

[^4]: זה לפי תחום – אף אדם לא יכול באופן סביר להשיג ציונים כאלה על פני כל הנושאים במקביל.

[^5]: אלה בעיות שיקחו אפילו למתמטיקאים מעולים זמן משמעותי לפתור, אם הם יכולים לפתור אותן בכלל.

[^6]: אם אתם מהסוג הספקני, שמרו על הספקנות אבל באמת קחו את המודלים הכי עדכניים לסיבוב, כמו גם נסו בעצמכם כמה משאלות הבדיקה שהם יכולים לעבור. בתור פרופסור לפיזיקה, הייתי מנבא בוודאות כמעט מוחלטת שלדוגמה, המודלים הטובים ביותר יעברו את בחינת הכישורים לתואר שני במחלקה שלנו.

[^7]: זה וחולשות אחרות כמו המצאות הרחיקו אימוץ שוק והובילו לפער בין יכולות נתפסות ונטענות (שצריכות להיראות גם דרך עדשת התחרות השוק האינטנסיבית והצורך למשוך השקעה). זה בלבל הן את הציבור והן את מקבלי המדיניות לגבי המצב האמיתי של התקדמות AI. בעוד שאולי לא תואמת את ההייפ, ההתקדמות היא אמיתית מאוד.

[^8]: ההתקדמות הגדולה מאז הייתה פיתוח מערכות שמאומנות לחשיבה באיכות עליונה, תוך מינוף חישוב רב יותר במהלך ההסקה ולמידת חיזוק רבה יותר. בגלל שהמודלים האלה חדשים ויכולותיהם פחות נבדקו, לא עדכנתי את הטבלה הזו בכללותה מלבד "חשיבה," שאני רואה בה כפתורה בעיקרון. אבל עדכנתי תחזיות על בסיס יכולות מנוסות ומדווחות של המערכות האלה.

[^9]: גלי אופטימיות AI קודמים בשנות ה-60 וה-80 הסתיימו ב"חורפי AI" כשיכולות מובטחות לא התממשו. עם זאת, הגל הנוכחי שונה ביסודו בכך שהשיג ביצועי על-אנושיים בתחומים רבים, הנתמך במשאבי חישוב עצומים והצלחה מסחרית.

[^10]: פרויקט אפולו המלא [עלה כ-250 מיליארד דולר ארה"ב בדולרי 2020](https://www.planetary.org/space-policy/cost-of-apollo), ופרויקט מנהטן [פחות מעשירית מזה](https://www.brookings.edu/the-costs-of-the-manhattan-project/). גולדמן זקס [צופה טריליון דולר הוצאה רק על מרכזי נתונים של AI](https://www.datacenterdynamics.com/en/news/goldman-sachs-1tn-to-be-spent-on-ai-data-centers-chips-and-utility-upgrades-with-little-to-show-for-it-so-far/) בשנים הקרובות.

[^11]: למרות שבני אדם עושים הרבה שגיאות, אנחנו מזלזלים בכמה אמינים אנחנו יכולים להיות! בגלל שהסתברויות מתרבות, משימה הדורשת 20 שלבים לביצוע נכון דורשת שכל שלב יהיה אמין ב-97% רק כדי לעשות את זה נכון בחצי מהמקרים. אנחנו עושים משימות כאלה כל הזמן.

[^12]: מעבר חזק בכיוון הזה נעשה לאחרונה עם העוזר ["מחקר עמוק"](https://openai.com/index/introducing-deep-research/) של OpenAI שמבצע מחקר כללי באופן אוטונומי, המתואר כ"יכולת סוכנית חדשה שמבצעת מחקר רב-שלבי באינטרנט למשימות מורכבות."

[^13]: דברים כמו למלא את טופס ה-PDF המעצבן, להזמין טיסות וכו'. אבל עם דוקטורט ב-20 תחומים! אז גם: לכתוב את החיבור בשבילכם, לנהל את החוזה בשבילכם, להוכיח את המשפט בשבילכם, ליצור את מסע הפרסום בשבילכם וכו'. מה *אתם* עושים? אתם אומרים לו מה לעשות, כמובן.

[^14]: שימו לב שהכרה *לא* נדרשת בבירור, וגם AI בצומת המשולש הזה לא בהכרח מרמז עליה.

[^15]: האנלוגיה הקרובה ביותר כאן היא אולי טכנולוגיית שבבים, שבה הפיתוח שמר על חוק מור במשך עשרות שנים, כיוון שטכנולוגיות מחשב עוזרות לאנשים לעצב את הדור הבא של טכנולוגיית שבבים. אבל AI יהיה הרבה יותר ישיר.

[^16]: חשוב לתת לזה לשקוע לרגע שAI יכול – בקרוב – להיות משפר את עצמו בטווח זמן של ימים או שבועות. או פחות. זכרו את זה כשמישהו אומר לכם שיכולת AI בוודאי רחוקה.