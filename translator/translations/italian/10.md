# Capitolo 10 - La scelta che ci attende

Per preservare il nostro futuro umano, dobbiamo scegliere di chiudere le Porte alla IAG e alla superintelligenza.

L'ultima volta che l'umanità ha condiviso la Terra con altre menti che parlavano, pensavano, costruivano tecnologie e risolvevano problemi generici è stata 40.000 anni fa nell'Europa dell'era glaciale. Quelle altre menti si sono estinte, in tutto o in parte a causa degli sforzi delle nostre.

Ora stiamo rientrando in un'epoca simile. I prodotti più avanzati della nostra cultura e tecnologia – dataset costruiti dall'intero patrimonio informativo di internet e chip da 100 miliardi di elementi che rappresentano le tecnologie più complesse mai realizzate – vengono combinati per portare in essere sistemi di IA generale avanzati.

Gli sviluppatori di questi sistemi sono ansiosi di presentarli come strumenti per l'empowerment umano. E in effetti potrebbero esserlo. Ma non illudiamoci: la nostra traiettoria attuale è quella di costruire agenti digitali sempre più potenti, orientati a obiettivi, capaci di prendere decisioni e dotati di capacità generali. Già performano quanto molti esseri umani in un'ampia gamma di compiti intellettuali, stanno migliorando rapidamente e contribuiscono al proprio miglioramento.

A meno che questa traiettoria non cambi o non incontri un ostacolo imprevisto, avremo presto – in anni, non decenni – intelligenze digitali pericolosamente potenti. Anche nel *migliore* degli scenari, queste porterebbero grandi benefici economici (almeno per alcuni di noi) ma solo al costo di una profonda rottura nella nostra società, e della sostituzione degli umani nella maggior parte delle cose più importanti che facciamo: queste macchine penserebbero per noi, pianificherebbero per noi, deciderebbero per noi e creerebbero per noi. Saremmo viziati, ma come bambini viziati. Molto più probabilmente, questi sistemi sostituirebbero gli umani sia nelle cose positive *che* in quelle negative che facciamo, inclusi sfruttamento, manipolazione, violenza e guerra. Possiamo sopravvivere a versioni iperpotenziate dall'IA di tutto questo? Infine, è più che plausibile che le cose non vadano affatto bene: che relativamente presto saremmo sostituiti non solo in quello che facciamo, ma in quello che *siamo*, come architetti della civiltà e del futuro. Chiedete ai neanderthal come va a finire. Forse anche noi riceveremmo qualche fronzolo in più per un po'.

*Non dobbiamo farlo.* Abbiamo IA competitive con l'uomo, e non c'è bisogno di costruire IA con cui *non* possiamo competere. Possiamo costruire straordinari strumenti di IA senza costruire una specie successore. L'idea che la IAG e la superintelligenza siano inevitabili è una *scelta mascherata da destino*.

Imponendo alcuni limiti rigidi e globali, possiamo mantenere la capacità generale dell'IA approssimativamente a livello umano continuando comunque a raccogliere i benefici della capacità dei computer di elaborare dati in modi che noi non possiamo, e automatizzare compiti che nessuno di noi vuole svolgere. Questi porrebbero ancora molti rischi, ma se progettati e gestiti bene, sarebbero un enorme vantaggio per l'umanità, dalla medicina alla ricerca ai prodotti di consumo.

Imporre limiti richiederebbe cooperazione internazionale, ma meno di quanto si potrebbe pensare, e quei limiti lascerebbero comunque ampio spazio per un'enorme industria dell'IA e dell'hardware per IA focalizzata su applicazioni che migliorano il benessere umano, piuttosto che sulla pura ricerca del potere. E se, con forti garanzie di sicurezza e dopo un dialogo globale significativo, decidessimo di andare oltre, quell'opzione continuerebbe a essere nostra da perseguire.

L'umanità deve *scegliere* di chiudere le Porte alla IAG e alla superintelligenza.

Per mantenere il futuro umano.

## Una nota dell'autore

Grazie per aver dedicato del tempo a esplorare questo argomento con noi.

Ho scritto questo saggio perché come scienziato sento che sia importante dire la verità senza fronzoli, e perché come persona sento che sia cruciale per noi agire rapidamente e con decisione per affrontare una questione che cambierà il mondo: lo sviluppo di sistemi di IA più intelligenti dell'uomo.

Se vogliamo rispondere a questo straordinario stato di cose con saggezza, dobbiamo essere preparati a esaminare criticamente la narrativa dominante secondo cui la IAG e la superintelligenza 'devono' essere costruite per garantire i nostri interessi, o sono 'inevitabili' e non possono essere fermate. Queste narrative ci lasciano privi di potere, incapaci di vedere i percorsi alternativi che abbiamo davanti.

Spero vi unirete a me nel chiedere cautela di fronte alla sconsideratezza, e coraggio di fronte all'avidità.

Spero vi unirete a me nel chiedere un futuro umano.

*– Anthony*

![Anthony Aguirre signature](https://keepthefuturehuman.ai/essay/_next/image?url=https%3A%2F%2Fkeepthefuturehuman.ai%2Fwp-content%2Fuploads%2F2025%2F02%2FAnthony-Aguirre-signature-300x84.png&w=3840&q=75)