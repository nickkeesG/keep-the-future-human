# Capitolo 5 - Alla soglia

Il percorso dai sistemi di IA odierni a una IAG completamente sviluppata sembra sorprendentemente breve e prevedibile.

Gli ultimi dieci anni hanno visto progressi spettacolari nell'IA grazie a enormi risorse [computazionali](https://epoch.ai/blog/training-compute-of-frontier-ai-models-grows-by-4-5x-per-year), umane e [finanziarie](https://arxiv.org/abs/2405.21015). Molte applicazioni di IA specializzata superano gli esseri umani nei compiti loro assegnati, e sono sicuramente molto più veloci ed economiche.[^1] Inoltre, esistono agenti specializzati sovrumani che possono battere tutte le persone in giochi di dominio ristretto come [Go](https://www.nature.com/articles/nature16961), [Scacchi](https://arxiv.org/abs/1712.01815) e [Poker](https://www.deepstack.ai/), così come [agenti più generali](https://deepmind.google/discover/blog/a-generalist-agent/) che possono pianificare ed eseguire azioni in ambienti simulati semplificati con la stessa efficacia degli esseri umani.

Più significativamente, i sistemi di IA generale attualmente disponibili da OpenAI/Microsoft, Google/Deepmind, Anthropic/Amazon, Facebook/Meta, X.ai/Tesla e altri [^2] sono emersi dall'inizio del 2023 e hanno costantemente (sebbene in modo irregolare) aumentato le loro capacità da allora. Tutti questi sono stati creati tramite predizione di token su enormi dataset testuali e multimediali, combinata con un estensivo feedback di rinforzo da parte di esseri umani e altri sistemi di IA. Alcuni includono anche ampi sistemi di strumenti e architetture di supporto.

## Punti di forza e debolezze dei sistemi generali attuali

Questi sistemi si comportano bene in una gamma sempre più ampia di test progettati per misurare intelligenza ed expertise, con progressi che hanno sorpreso persino gli esperti del settore:

- Al momento del rilascio, GPT-4 [ha eguagliato o superato le prestazioni umane tipiche](https://arxiv.org/abs/2303.08774) in test accademici standard inclusi SAT, GRE, esami di ammissione ed esami di abilitazione forense. I modelli più recenti probabilmente si comportano significativamente meglio, sebbene i risultati non siano pubblicamente disponibili.
- Il test di Turing – a lungo considerato un benchmark chiave per l'IA "vera" – viene ora superato routinariamente in alcune forme dai modelli linguistici moderni, sia informalmente che in [studi formali](https://arxiv.org/abs/2405.08007).[^3]
- Nel benchmark comprensivo MMLU che copre 57 materie accademiche, [i modelli recenti raggiungono punteggi a livello di esperti del dominio](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu) (∼90%) [^4]
- L'expertise tecnica è avanzata drasticamente: il benchmark GPQA di fisica a livello universitario ha visto [le prestazioni saltare](https://epoch.ai/data/ai-benchmarking-dashboard) da ipotesi quasi casuali (GPT-4, 2022) a livello esperto (o1-preview, 2024).
- Persino i test specificamente progettati per essere resistenti all'IA stanno cedendo: l'O3 di OpenAI [secondo quanto riportato](https://www.nextbigfuture.com/2024/12/openai-releases-o3-model-with-high-performance-and-high-cost.html) risolve il benchmark di risoluzione di problemi astratti ARC-AGI a livello umano, raggiunge prestazioni di programmazione da esperto di punta e ottiene il 25% sui problemi di "matematica di frontiera" di Epoch AI progettati per sfidare matematici d'élite.[^5]
- La tendenza è così chiara che lo sviluppatore di MMLU ha ora creato ["L'Ultimo Esame dell'Umanità"](https://agi.safe.ai/) – un nome minaccioso che riflette la possibilità che l'IA superi presto le prestazioni umane in qualsiasi test significativo. Al momento della stesura, ci sono affermazioni di sistemi di IA che raggiungono il 27% (secondo [Sam Altman](https://x.com/sama/status/1886220281565381078)) e il 35% (secondo [questo paper](https://arxiv.org/abs/2502.09955)) in questo esame estremamente difficile. È molto improbabile che qualsiasi essere umano individuale possa farlo.

Nonostante questi numeri impressionanti (e la loro ovvia intelligenza quando si interagisce con loro) [^6] ci sono molte cose che (almeno le versioni rilasciate di) queste reti neurali *non possono* fare. Attualmente la maggior parte sono disincarnate – esistono solo sui server – e processano al massimo testo, suono e immagini statiche (ma non video). Crucialmente, la maggior parte non può svolgere attività pianificate complesse che richiedono alta precisione.[^7] E ci sono diverse altre qualità forti nella cognizione umana di alto livello attualmente deboli nei sistemi di IA rilasciati.

La seguente tabella elenca alcune di queste, basandosi sui sistemi di IA di metà 2024 come GPT-4o, Claude 3.5 Sonnet e Google Gemini 1.5.[^8] La domanda chiave su quanto rapidamente l'IA generale diventerà più potente è: fino a che punto *fare più della stessa cosa* produrrà risultati, rispetto ad aggiungere tecniche aggiuntive ma *conosciute*, rispetto a sviluppare o implementare direzioni di ricerca IA *realmente nuove*. Le mie previsioni per questo sono date nella tabella, in termini di probabilità che ciascuno di questi scenari porti quella capacità al livello umano e oltre.

<table><tbody><tr><th>Capacità</th><th>Descrizione della capacità</th><th>Stato/prognosi</th><th>Scala/conosciuto/nuovo</th></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td colspan="4"><em>Capacità Cognitive Fondamentali</em></td></tr><tr><td>Ragionamento</td><td>Le persone possono fare ragionamenti accurati e multi-passo, seguendo regole e verificando la precisione.</td><td>Progresso drammatico recente usando catene di ragionamento estese e riaddestramento</td><td>95/5/5</td></tr><tr><td>Pianificazione</td><td>Le persone mostrano pianificazione a lungo termine e gerarchica.</td><td>Migliora con la scala; può essere fortemente aiutata usando architetture di supporto e migliori tecniche di addestramento.</td><td>10/85/5</td></tr><tr><td>Ancoraggio alla verità</td><td>Le IAIG confabulano informazioni non fondate per soddisfare le richieste.</td><td>Migliora con la scala; dati di calibrazione disponibili nel modello; può essere verificato/migliorato via architetture di supporto.</td><td>30/65/5</td></tr><tr><td>Risoluzione flessibile dei problemi</td><td>Gli esseri umani possono riconoscere nuovi schemi e inventare nuove soluzioni a problemi complessi; i modelli ML attuali faticano.</td><td>Migliora con la scala ma debolmente; può essere risolvibile con tecniche neurosimboliche o di "ricerca" generalizzata.</td><td>15/75/10</td></tr><tr><td colspan="4"><em>Apprendimento e Conoscenza</em></td></tr><tr><td>Apprendimento e memoria</td><td>Le persone hanno memoria di lavoro, a breve termine e a lungo termine, tutte dinamiche e inter-correlate.</td><td>Tutti i modelli imparano durante l'addestramento; le IAIG imparano nella finestra di contesto e durante il fine-tuning; esistono tecniche di "apprendimento continuo" e altre ma non ancora integrate nelle IAIG grandi.</td><td>5/80/15</td></tr><tr><td>Astrazione e ricorsione</td><td>Le persone possono mappare e trasferire insiemi di relazioni in altri più astratti per ragionamento e manipolazione, incluso ragionamento "meta" ricorsivo.</td><td>Migliora debolmente con la scala; potrebbe emergere in sistemi neurosimbolici.</td><td>30/50/20</td></tr><tr><td>Modello(i) del mondo</td><td>Le persone hanno e aggiornano continuamente un modello predittivo del mondo entro cui possono risolvere problemi e fare ragionamento fisico</td><td>Migliora con la scala; aggiornamento legato all'apprendimento; le IAIG sono deboli nella predizione del mondo reale.</td><td>20/50/30</td></tr><tr><td colspan="4"><em>Sé e Agenzia</em></td></tr><tr><td>Agenzia</td><td>Le persone possono intraprendere azioni per perseguire obiettivi, basandosi su pianificazione/predizione.</td><td>Molti sistemi ML sono agentici; gli LLM possono essere resi agenti tramite wrapper.</td><td>5/90/5</td></tr><tr><td>Auto-direzione</td><td>Le persone sviluppano e perseguono i propri obiettivi, con motivazione e spinta generate internamente.</td><td>Largamente composta da agenzia più originalità; probabile che emerga in sistemi agentici complessi con obiettivi astratti.</td><td>40/45/15</td></tr><tr><td>Auto-riferimento</td><td>Le persone comprendono e ragionano su se stesse come situate entro un ambiente/contesto.</td><td>Migliora con la scala e potrebbe essere aumentata con ricompensa di addestramento.</td><td>70/15/15</td></tr><tr><td>Auto-consapevolezza</td><td>Le persone hanno conoscenza e possono ragionare sui propri pensieri e stati mentali.</td><td>Esiste in un certo senso nelle IAIG, che possono probabilmente superare il classico "test dello specchio" per l'auto-consapevolezza. Può essere migliorata con architetture di supporto; ma non è chiaro se questo sia sufficiente.</td><td>20/55/25</td></tr><tr><td colspan="4"><em>Interfaccia e Ambiente</em></td></tr><tr><td>Intelligenza incarnata</td><td>Le persone comprendono e interagiscono attivamente con il loro ambiente del mondo reale.</td><td>L'apprendimento per rinforzo funziona bene in ambienti simulati e del mondo reale (robotici) e può essere integrato in transformer multimodali.</td><td>5/85/10</td></tr><tr><td>Elaborazione multi-sensoriale</td><td>Le persone integrano ed elaborano in tempo reale flussi visivi, audio e di altri sensi.</td><td>L'addestramento in modalità multiple sembra "funzionare e basta", e migliora con la scala. L'elaborazione video in tempo reale è difficile ma ad es. i sistemi di guida autonoma stanno migliorando rapidamente.</td><td>30/60/10</td></tr><tr><td colspan="4"><em>Capacità di Ordine Superiore</em></td></tr><tr><td>Originalità</td><td>I modelli ML attuali sono creativi nel trasformare e combinare idee/opere esistenti, ma le persone possono costruire nuovi framework e strutture, a volte legati alla loro identità.</td><td>Può essere difficile da discernere dalla "creatività", che potrebbe scalare verso di essa; può emergere da creatività più auto-consapevolezza.</td><td>50/40/10</td></tr><tr><td>Senzienza</td><td>Le persone sperimentano qualia; questi possono essere di valenza positiva, negativa o neutrale; "è come qualcosa" essere una persona.</td><td>Molto difficile e filosoficamente controverso determinare se un dato sistema abbia questo.</td><td>5/10/85</td></tr></tbody></table>

Capacità chiave attualmente sotto il livello di esperto umano nei sistemi IAIG moderni, raggruppate per tipo. La terza colonna riassume lo stato attuale. La colonna finale mostra la probabilità prevista (%) che le prestazioni a livello umano saranno raggiunte attraverso: scalare le tecniche attuali / combinare con tecniche conosciute / sviluppare nuove tecniche. Queste capacità non sono indipendenti, e l'aumento in una tipicamente va di pari passo con aumenti nelle altre. Si noti che non tutte (particolarmente la senzienza) sono necessarie per sistemi di IA capaci di far avanzare lo sviluppo dell'IA, evidenziando la possibilità di IA potente ma non senziente.

Scomporre ciò che "manca" in questo modo rende abbastanza chiaro che siamo decisamente sulla strada per un'intelligenza ampiamente sopra-umana scalando tecniche esistenti o conosciute.[^9]

Potrebbero esserci ancora sorprese. Anche mettendo da parte la "senzienza", potrebbero esserci alcune delle capacità cognitive fondamentali elencate che realmente non possono essere fatte con le tecniche attuali e richiedono nuove. Ma considerate questo. L'attuale sforzo messo in campo da molte delle più grandi aziende del mondo ammonta a multiple volte la spesa del progetto Apollo e decine di volte quella del progetto Manhattan,[^10] e sta impiegando migliaia delle persone tecniche più brillanti a stipendi mai sentiti. Le dinamiche degli ultimi anni hanno ora portato a questo più potenza intellettuale umana (con l'IA ora aggiunta) di qualsiasi impresa nella storia. Non dovremmo scommettere sul fallimento.

## Il grande obiettivo: agenti autonomi generalisti

Lo sviluppo dell'IA generale negli ultimi anni si è concentrato sulla creazione di IA generale e potente ma simile a strumento: funziona principalmente come assistente (abbastanza) leale, e generalmente non intraprende azioni da sola. Questo è in parte per progetto, ma largamente perché questi sistemi semplicemente non sono stati abbastanza competenti nelle abilità rilevanti per essere affidati con azioni complesse.[^11]

Le aziende e i ricercatori di IA stanno, tuttavia, sempre più [spostando il focus](https://www.axios.com/2025/01/23/davos-2025-ai-agents) verso agenti autonomi *autonomi* a livello esperto e per scopi generali.[^12] Questo permetterebbe ai sistemi di agire più come un assistente umano a cui l'utente può delegare azioni reali.[^13] Cosa richiederà? Diverse delle capacità nella tabella "cosa manca" sono implicate, inclusi forte ancoraggio alla verità, apprendimento e memoria, astrazione e ricorsione, e modellazione del mondo (per l'intelligenza), pianificazione, agenzia, originalità, auto-direzione, auto-riferimento e auto-consapevolezza (per l'autonomia), e elaborazione multi-sensoriale, intelligenza incarnata e risoluzione flessibile dei problemi (per la generalità).[^14]

Questa triplice intersezione di alta autonomia (indipendenza d'azione), alta generalità (ampiezza di scopo e compiti) e alta intelligenza (competenza nei compiti cognitivi) è attualmente unica agli esseri umani. È implicitamente ciò che molti probabilmente hanno in mente quando pensano alla IAG – sia in termini del suo valore che dei suoi rischi.

Questo fornisce un altro modo di definire I-A-G come ***I***ntelligenza ***A***utonoma- ***G***enerale, e vedremo che questa tripla intersezione fornisce una lente molto preziosa per i sistemi ad alta capacità sia nel comprendere i loro rischi e benefici, sia nella governance dell'IA.

![](https://keepthefuturehuman.ai/essay/_next/image?url=https%3A%2F%2Fkeepthefuturehuman.ai%2Fwp-content%2Fuploads%2F2025%2F02%2FAGI-Venn-Diagram-Simple-1024x1024.png&w=3840&q=75) La zona di potere e rischio trasformativo I-A-G emerge dall'intersezione di tre proprietà chiave: alta Autonomia, alta Intelligenza nei compiti e alta Generalità.

## Il ciclo di miglioramento dell'IA (auto-)

Un fattore cruciale finale nel comprendere il progresso dell'IA è il ciclo di feedback tecnologico unico dell'IA. Nello sviluppare l'IA, il successo – sia nei sistemi dimostrati che nei prodotti deployati – porta investimenti aggiuntivi, talento e competizione, e siamo attualmente nel mezzo di un enorme ciclo di feedback hype-più-realtà dell'IA che sta guidando centinaia di miliardi, o persino trilioni, di dollari di investimento.

Questo tipo di ciclo di feedback potrebbe accadere con qualsiasi tecnologia, e l'abbiamo visto in molte, dove il successo di mercato genera investimento, che genera miglioramento e migliore successo di mercato. Ma lo sviluppo dell'IA va oltre, in quanto ora i sistemi di IA stanno aiutando a sviluppare sistemi di IA nuovi e più potenti.[^15] Possiamo pensare a questo ciclo di feedback in cinque fasi, ognuna con una scala temporale più breve dell'ultima, come mostrato nella tabella.

*Il ciclo di miglioramento dell'IA opera attraverso multiple scale temporali, con ogni fase che potenzialmente accelera le fasi successive. Le fasi precedenti sono ben avviate, mentre quelle successive rimangono speculative ma potrebbero procedere molto rapidamente una volta sbloccate.*

Diverse di queste fasi sono già in corso, e un paio chiaramente stanno iniziando. L'ultima fase, in cui i sistemi di IA migliorano autonomamente se stessi, è stata un pilastro della letteratura sui rischi dei sistemi di IA molto potenti, e per una buona ragione.[^16] Ma è importante notare che è solo la forma più drastica di un ciclo di feedback che è già iniziato e potrebbe portare a più sorprese nel rapido avanzamento della tecnologia.


[^1]: Utilizzate molta più di questa IA di quanto probabilmente pensiate, guidando generazione e riconoscimento vocale, elaborazione delle immagini, algoritmi dei newsfeed, ecc.

[^2]: Mentre le relazioni tra queste coppie di aziende sono piuttosto complesse e sfumate, le ho esplicitamente elencate per indicare sia l'enorme capitalizzazione di mercato complessiva delle aziende ora impegnate nello sviluppo dell'IA, sia anche che dietro aziende persino "più piccole" come Anthropic ci sono tasche enormemente profonde tramite investimenti e accordi di partnership principali.

[^3]: È diventato di moda denigrare il test di Turing, ma è piuttosto potente e generale. Nelle versioni deboli indica se le persone tipiche che interagiscono con un'IA (che è addestrata ad agire come umana) in modi tipici per brevi periodi possono dire se è un'IA. Non possono. Secondo, un test di Turing altamente avversariale può sondare essenzialmente qualsiasi elemento della capacità e intelligenza umana – ad es. confrontando un sistema di IA con un esperto umano, valutato da altri esperti umani. C'è un senso in cui molta della valutazione dell'IA è una forma generalizzata di test di Turing.

[^4]: Questo è per dominio – nessun umano potrebbe plausibilmente raggiungere tali punteggi in tutte le materie simultaneamente.

[^5]: Questi sono problemi che richiederebbero anche a matematici eccellenti tempo sostanziale per risolverli, se potessero risolverli affatto.

[^6]: Se avete un atteggiamento scettico, mantenete il vostro scetticismo ma provate davvero i modelli più attuali, così come provate voi stessi alcune delle domande di test che possono superare. Come professore di fisica, predirrei con quasi certezza che, ad esempio, i modelli migliori supererebbero l'esame di qualificazione per laureati nel nostro dipartimento.

[^7]: Questa e altre debolezze come la confabulazione hanno rallentato l'adozione di mercato e portato a un divario tra capacità percepite e dichiarate (che deve anche essere visto attraverso la lente dell'intensa competizione di mercato e la necessità di attrarre investimenti). Questo ha confuso sia il pubblico che i policymaker sullo stato reale del progresso dell'IA. Pur forse non eguagliando l'hype, il progresso è molto reale.

[^8]: L'avanzamento principale da allora è stato lo sviluppo di sistemi addestrati per ragionamento di alta qualità, sfruttando più capacità computazionale durante l'inferenza e maggiore apprendimento per rinforzo. Poiché questi modelli sono nuovi e le loro capacità meno testate, non ho completamente rivisto questa tabella eccetto per "ragionamento", che considero essenzialmente risolto. Ma ho aggiornato le previsioni basandomi sulle capacità sperimentate e riportate di quei sistemi.

[^9]: Le precedenti ondate di ottimismo dell'IA negli anni '60 e '80 finirono in "inverni dell'IA" quando le capacità promesse non si materializzarono. Tuttavia, l'ondata attuale differisce fondamentalmente nell'aver raggiunto prestazioni sovrumane in molti domini, sostenuta da enormi risorse computazionali e successo commerciale.

[^10]: L'intero progetto Apollo [è costato circa 250 miliardi di dollari USD in dollari del 2020](https://www.planetary.org/space-policy/cost-of-apollo), e il progetto Manhattan [meno di un decimo di quello](https://www.brookings.edu/the-costs-of-the-manhattan-project/). Goldman Sachs [proietta un trilione di dollari di spesa solo sui data center IA](https://www.datacenterdynamics.com/en/news/goldman-sachs-1tn-to-be-spent-on-ai-data-centers-chips-and-utility-upgrades-with-little-to-show-for-it-so-far/) nei prossimi anni.

[^11]: Anche se gli esseri umani fanno molti errori, sottovalutiamo quanto possiamo essere affidabili! Poiché le probabilità si moltiplicano, un compito che richiede 20 passi per essere fatto correttamente richiede che ogni passo sia affidabile al 97% solo per farlo bene la metà delle volte. Facciamo tali compiti tutto il tempo.

[^12]: Una mossa forte in questa direzione è stata presa molto di recente con l'assistente ["Deep Research"](https://openai.com/index/introducing-deep-research/) di OpenAI che esegue autonomamente ricerche generali, descritto come "una nuova capacità agentica che conduce ricerche multi-passo su internet per compiti complessi."

[^13]: Cose come compilare quel fastidioso modulo PDF, prenotare voli, ecc. Ma con un PhD in 20 campi! Quindi anche: scrivere quella tesi per voi, negoziare quel contratto per voi, dimostrare quel teorema per voi, creare quella campagna pubblicitaria per voi, ecc. Cosa fate *voi*? Gli dite cosa fare, naturalmente.

[^14]: Si noti che la senzienza *non* è chiaramente richiesta, né l'IA in questa tripla intersezione implica necessariamente essa.

[^15]: L'analogia più vicina qui è forse la tecnologia dei chip, dove lo sviluppo ha mantenuto la legge di Moore per decenni, mentre le tecnologie informatiche aiutano le persone a progettare la prossima generazione di tecnologia dei chip. Ma l'IA sarà molto più diretta.

[^16]: È importante lasciare che affondi per un momento che l'IA potrebbe – presto – migliorare se stessa in una scala temporale di giorni o settimane. O meno. Tenete questo a mente quando qualcuno vi dice che una capacità dell'IA è definitivamente lontana.