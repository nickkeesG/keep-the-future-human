# Capitolo 6 - La corsa verso la IAG

Quali sono le forze trainanti dietro la corsa alla costruzione della IAG, sia per le aziende che per i paesi?

I rapidi progressi recenti nell'IA hanno generato e sono stati alimentati da un livello straordinario di attenzione e investimenti. Questo è dovuto in parte ai successi nello sviluppo dell'IA, ma c'è dell'altro. Perché alcune delle più grandi aziende del mondo, e persino interi paesi, stanno correndo per costruire non solo l'IA, ma la IAG e la superintelligenza?

## Cosa ha spinto la ricerca sull'IA verso un'intelligenza di livello umano

Fino a circa cinque anni fa, l'IA è stata principalmente un problema di ricerca accademica e scientifica, quindi largamente guidata dalla curiosità e dal desiderio di comprendere l'intelligenza e come crearla in un nuovo substrato.

In questa fase, c'era relativamente poca attenzione ai benefici o ai pericoli dell'IA tra la maggior parte dei ricercatori. Quando veniva chiesto perché l'IA dovesse essere sviluppata, una risposta comune poteva essere elencare, in modo piuttosto vago, i problemi che l'IA avrebbe potuto aiutare a risolvere: nuove medicine, nuovi materiali, nuova scienza, processi più intelligenti, e in generale il miglioramento delle condizioni di vita delle persone.[^1]

Questi sono obiettivi ammirevoli![^2] Anche se possiamo e dovremo chiederci se la IAG – piuttosto che l'IA in generale – sia necessaria per questi obiettivi, essi mostrano l'idealismo con cui molti ricercatori di IA hanno iniziato.

Nel corso dell'ultimo quinquennio, tuttavia, l'IA si è trasformata da un campo di ricerca relativamente puro in un settore molto più orientato all'ingegneria e ai prodotti, guidato principalmente da alcune delle più grandi aziende del mondo.[^3] I ricercatori, pur rimanendo rilevanti, non controllano più il processo.

## Perché le aziende stanno cercando di costruire la IAG?

Quindi, perché le corporation giganti (e ancora di più gli investitori) stanno versando enormi risorse nella costruzione della IAG? Ci sono due fattori trainanti di cui la maggior parte delle aziende è abbastanza sincera: vedono l'IA come motore di produttività per la società e di profitti per loro. Poiché l'IA generale è per natura multi-purpose, c'è un premio enorme: invece di scegliere un settore in cui creare prodotti e servizi, si può provare a farli *tutti contemporaneamente.* Le grandi aziende tecnologiche sono cresciute enormemente producendo beni e servizi digitali, e almeno alcuni dirigenti vedono sicuramente l'IA semplicemente come il passo successivo nel fornirli bene, con rischi e benefici che ampliano ma echeggiano quelli forniti da motori di ricerca, social media, laptop, telefoni, ecc.

Ma perché la IAG? C'è una risposta molto semplice a questo, che la maggior parte delle aziende e degli investitori evita di discutere pubblicamente.[^4]

È che la IAG può direttamente, uno per uno, *sostituire i lavoratori.*

Non potenziare, non responsabilizzare, non rendere più produttivi. Nemmeno *spostare.* Tutto questo può e sarà fatto da IA non-generale. La IAG è specificamente ciò che può completamente *sostituire* i lavoratori intellettuali (e con la robotica, anche molti di quelli fisici). Come supporto a questa visione basta non guardare oltre la [definizione (dichiarata pubblicamente)](https://openai.com/our-structure/) di IAG di OpenAI, che è "un sistema altamente autonomo che supera gli esseri umani nella maggior parte del lavoro economicamente prezioso."

Il premio qui (per le aziende!) è enorme. I costi del lavoro sono una percentuale sostanziale dei circa $100 trilioni dell'economia globale mondiale. Anche se solo una frazione di questo viene catturata dalla sostituzione del lavoro umano con il lavoro dell'IA, si tratta di trilioni di dollari di ricavi annuali. Le aziende di IA sono anche consapevoli di chi è disposto a pagare. Come la vedono loro, tu non pagherai migliaia di dollari all'anno per strumenti di produttività. Ma un'azienda *pagherà* migliaia di dollari all'anno per sostituire il tuo lavoro, se può.

## Perché i paesi sentono di dover correre verso la IAG

Le motivazioni dichiarate dei paesi per perseguire la IAG si concentrano sulla leadership economica e scientifica. L'argomento è convincente: la IAG potrebbe accelerare drammaticamente la ricerca scientifica, lo sviluppo tecnologico e la crescita economica. Date le poste in gioco, sostengono, nessuna grande potenza può permettersi di rimanere indietro.[^5]

Ma ci sono anche fattori trainanti aggiuntivi e largamente non dichiarati. Non c'è dubbio che quando certi leader militari e della sicurezza nazionale si incontrano a porte chiuse per discutere di una tecnologia straordinariamente potente e catastroficamente rischiosa, il loro focus non è su "come evitiamo questi rischi" ma piuttosto "come otteniamo questo per primi?" I leader militari e dell'intelligence vedono la IAG come una potenziale rivoluzione negli affari militari, forse la più significativa dalle armi nucleari. Il timore è che il primo paese a sviluppare la IAG potrebbe ottenere un vantaggio strategico insormontabile. Questo crea una classica dinamica di corsa agli armamenti.

Vedremo che questo pensiero di "corsa verso la IAG",[^6] pur essendo convincente, è profondamente viziato. Questo non è perché correre è pericoloso e rischioso – anche se lo è – ma a causa della natura della tecnologia. L'assunto non dichiarato è che la IAG, come altre tecnologie, sia controllabile dallo stato che la sviluppa, e sia un beneficio che conferisce potere alla società che ne ha di più. Come vedremo, probabilmente non sarà né l'una né l'altra cosa.

## Perché la superintelligenza?

Mentre le aziende si concentrano pubblicamente sulla produttività, e i paesi sulla crescita economica e tecnologica, per coloro che perseguono deliberatamente la IAG completa e la superintelligenza questi sono solo l'inizio. Cosa hanno veramente in mente? Anche se raramente detto ad alta voce, includono:

1. Cure per molte o tutte le malattie;
2. Arresto e inversione dell'invecchiamento;
3. Nuove fonti di energia sostenibile come la fusione;
4. Potenziamenti umani, o organismi progettati tramite ingegneria genetica;
5. Nanotecnologie e produzione molecolare;
6. Upload della mente;
7. Fisica esotica o tecnologie spaziali;
8. Consigli e supporto decisionale super-umani;
9. Pianificazione e coordinamento super-umani.

I primi tre sono largamente tecnologie "a vantaggio unico" – cioè probabilmente molto fortemente positive nel complesso. È difficile argomentare contro il curare malattie o essere in grado di vivere più a lungo se si sceglie. E abbiamo già raccolto il lato negativo della fusione (sotto forma di armi nucleari); ora sarebbe bello ottenere il lato positivo. La questione con questa prima categoria è se ottenere queste tecnologie prima compensi il rischio.

Le successive quattro sono chiaramente a doppio taglio: tecnologie trasformative con sia potenziali enormi vantaggi che immensi rischi, molto simili all'IA. Tutte queste, se saltassero fuori da una scatola nera domani e fossero implementate, sarebbero incredibilmente difficili da gestire.[^7]

Le ultime due riguardano l'IA super-umana che fa cose essa stessa piuttosto che inventare semplicemente tecnologia. Più precisamente, mettendo da parte gli eufemismi, queste coinvolgono sistemi di IA potenti che dicono alle persone cosa fare. Chiamare questo "consiglio" è disonesto se il sistema che consiglia è molto più potente del consigliato, che non può comprendere significativamente la base della decisione (o anche se questa viene fornita, fidarsi che il consigliere non fornirebbe una giustificazione altrettanto convincente per una decisione diversa).

Questo indica un elemento chiave mancante dalla lista sopra:

10. Potere.

È abbondantemente chiaro che molto di ciò che sta alla base dell'attuale corsa verso l'IA super-umana è l'idea che *intelligenza = potere*. Ogni corridore sta scommettendo di essere il miglior detentore di quel potere, e che sarà in grado di esercitarlo per ragioni apparentemente benevole senza che gli sfugga o venga sottratto dal loro controllo.

Cioè, quello che aziende e nazioni stanno realmente inseguendo non sono solo i frutti della IAG e della superintelligenza, ma il potere di controllare chi ha accesso ad essi e come vengono usati. Le aziende si vedono come amministratori responsabili di questo potere al servizio degli azionisti e dell'umanità; le nazioni si vedono come guardiani necessari per impedire a potenze ostili di ottenere un vantaggio decisivo. Entrambi sbagliano pericolosamente, non riuscendo a riconoscere che la superintelligenza, per sua natura, non può essere controllata in modo affidabile da alcuna istituzione umana. Vedremo che la natura e le dinamiche dei sistemi superintelligenti rendono il controllo umano estremamente difficile, se non impossibile.

Queste dinamiche di corsa – sia corporative che geopolitiche – rendono certi rischi quasi inevitabili a meno che non vengano decisamente interrotte. Ora passiamo a esaminare questi rischi e perché non possono essere adeguatamente mitigati all'interno di un paradigma di sviluppo competitivo.[^8]


[^1]: Una lista più precisa di obiettivi degni sono gli [Obiettivi di Sviluppo Sostenibile](https://sdgs.un.org/goals) delle Nazioni Unite. Questi sono, in un certo senso, il più vicino che abbiamo a un insieme di obiettivi di consenso globale per quello che vorremmo vedere migliorato nel mondo. L'IA potrebbe aiutare.

[^2]: La tecnologia in generale ha un potere trasformativo economico e sociale per il miglioramento umano, come attestano migliaia di anni. In questo senso, una lunga e convincente esplicazione di una visione positiva della IAG può essere trovata in [questo saggio](https://darioamodei.com/machines-of-loving-grace) del fondatore di Anthropic Dario Amodei.

[^3]: Gli investimenti privati nell'IA [hanno iniziato a esplodere nel 2018-19, superando gli investimenti pubblici intorno ad allora,](https://cset.georgetown.edu/publication/tracking-ai-investment/) e da allora li hanno enormemente superati.

[^4]: Posso attestare che dietro porte più chiuse, non hanno tali remore. E sta diventando più pubblico; vedi per esempio la nuova ["richiesta per startup"](https://www.ycombinator.com/rfs) di Y-combinator, molte parti della quale chiamano esplicitamente per la sostituzione all'ingrosso dei lavoratori umani. Per citarli, "La proposta di valore del B2B SaaS era rendere i lavoratori umani incrementalmente più efficienti. La proposta di valore degli agenti IA verticali è automatizzare completamente il lavoro... È del tutto possibile che questa opportunità sia abbastanza grande da creare altri 100 unicorni." (Per coloro che non conoscono il gergo della Silicon Valley, "B2B" è business-to-business e un unicorno è un'azienda da $1 miliardo. Cioè stanno parlando di più di cento aziende da miliardi-plus-dollari che sostituiscono lavoratori per altre aziende.)

[^5]: Vedi per esempio un recente [rapporto della Commissione di Revisione Economica e della Sicurezza USA-Cina](https://www.uscc.gov/sites/default/files/2024-11/2024_Executive_Summary.pdf). Anche se c'era sorprendentemente poca giustificazione all'interno del rapporto stesso, la raccomandazione principale era che gli Stati Uniti "Il Congresso stabilisca e finanzi un programma simile al Progetto Manhattan dedicato a correre verso e acquisire una capacità di Intelligenza Artificiale Generale (IAG)."

[^6]: Le aziende stanno ora adottando questa cornice geopolitica come scudo contro qualsiasi vincolo sul loro sviluppo di IA, generalmente in modi che sono palesemente auto-serventi, e a volte in modi che non hanno nemmeno senso di base. Considera l'[Approccio all'IA di Frontiera](https://about.fb.com/news/2025/02/meta-approach-frontier-ai/) di Meta, che contemporaneamente argomenta che l'America deve "[Consolidare la sua] posizione come leader nell'innovazione tecnologica, crescita economica e sicurezza nazionale" e anche che deve farlo rilasciando apertamente i suoi sistemi di IA più potenti – il che include darli direttamente ai suoi rivali e avversari geopolitici.

[^7]: Quindi probabilmente dovremmo lasciare la gestione di queste tecnologie alle IA. Ma questa sarebbe una delega di controllo molto problematica, a cui torneremo sotto.

[^8]: La competizione nello sviluppo tecnologico spesso porta benefici importanti: prevenire il controllo monopolistico, guidare l'innovazione e la riduzione dei costi, abilitare approcci diversi, e creare supervisione reciproca. Tuttavia, con la IAG questi benefici devono essere pesati contro i rischi unici dalle dinamiche di corsa e la pressione a ridurre le precauzioni di sicurezza.