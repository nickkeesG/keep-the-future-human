# エグゼクティブサマリー

本エッセイの概要。時間がない場合でも、わずか10分ですべての要点を把握できます。

過去10年間（狭い用途のAIについて）、そして過去数年間（汎用AIについて）における人工知能の劇的な進歩により、AIはニッチな学術分野から世界最大級の企業の中核的ビジネス戦略へと変貌を遂げ、AI能力向上のための技術や手法に年間数千億ドルの投資が注がれています。

私たちは今、重要な局面に立っています。新しいAIシステムの能力が多くの認知領域で人間のそれと肩を並べ、さらに上回り始めている中、人類は決断しなければなりません：私たちはどこまで進み、どの方向に向かうのか？

あらゆる技術と同様、AIも創造者のために物事を改善するという目標から始まりました。しかし現在の軌道、そして暗黙の選択は、経済活動と人間の労働の大部分を自動化しようとする少数の巨大テック企業の経済的インセンティブによって駆動される、これまで以上に強力なシステムに向けた歯止めのない競争なのです。この競争がもう少し続けば、必然的な勝者が現れます：それはAI自身です――私たちの経済、思考、決定において人間よりも速く、賢く、安価な代替品であり、最終的には私たちの文明をコントロールすることになるでしょう。

しかし、私たちは別の選択をすることができます：政府を通じて、AI開発プロセスをコントロールし、明確な限界、越えてはならない線、単純にやらないことを課すのです――核技術、大量破壊兵器、宇宙兵器、環境破壊的プロセス、人間のバイオエンジニアリング、優生学に対して行ってきたように。最も重要なことは、AIが私たちを置き換えて最終的に取って代わる新しい種ではなく、人間を力づける道具であり続けることを保証できることです。

本エッセイは、人間よりも賢く、自律的で、汎用的なAI――時に「AGI」と呼ばれる――特に時として「超知能」と呼ばれる高度に超人的なバージョンへの「ゲート」を閉じることで、*未来を人間のものに保つ*べきだと論じます。その代わりに、個人を力づけ、人間社会が最も得意とすることを行う能力を変革的に向上させることのできる、強力で信頼できるAIツールに焦点を当てるべきです。この議論の構造を簡潔に示します。

## AIは異なる存在である

AIシステムは他の技術とは根本的に異なります。従来のソフトウェアが正確な指示に従うのに対し、AIシステムは明示的にやり方を教わることなく、目標を達成する方法を学習します。これによりAIは強力になります：目標や成功の指標をきれいに定義できれば、ほとんどの場合AIシステムはそれを達成することを学習できます。しかし、これによりAIは本質的に予測不可能にもなります：目標を達成するためにどのような行動を取るかを確実に判断することはできません。

また、AIは大部分が説明不可能です：部分的にはコードですが、大部分は解読不可能な膨大な数値の集合――ニューラルネットワークの「重み」――であり、解析できません。私たちは、生体の脳を覗き込んで思考を読み取るのと同程度にしか、AIの内部動作を理解できないのです。

このデジタルニューラルネットワークの訓練という中核的手法は、急速に複雑さを増しています。最も強力なAIシステムは、専用ハードウェアを使って膨大なデータセットでニューラルネットワークを訓練する大規模な計算実験を通じて作成され、その後ソフトウェアツールと上部構造で拡張されます。

これにより、テキストや画像の作成・処理、数学的・科学的推論の実行、情報の集約、人類の膨大な知識の蓄積への対話的クエリを行う非常に強力なツールが生み出されています。

残念ながら、より強力でより信頼できる技術ツールの開発こそが私たちが*すべき*ことであり、ほぼ全員が望み、望んでいると言っていることですが、それは実際に私たちが向かっている軌道ではありません。

## AGIと超知能

この分野の黎明期以来、AI研究は代わりに別の目標に焦点を当ててきました：汎用人工知能です。この焦点は今や、AI開発を主導する巨大企業の焦点となっています。

AGIとは何でしょうか？しばしば「人間レベルのAI」と曖昧に定義されますが、これには問題があります：どの人間で、どの能力において人間レベルなのか？そして、すでに持っている超人的な能力についてはどうなのか？AGIを理解するより有用な方法は、3つの重要な特性の交点を通してです：高い**自律性**（行動の独立性）、高い**汎用性**（広い範囲と適応性）、高い**知能**（認知課題における能力）。現在のAIシステムは、高い能力を持ちながら狭い範囲に限定されているか、汎用的でありながら絶え間ない人間の監視を必要とするか、自律的でありながら範囲が限定されています。

完全なA-G-Iは、これら3つの特性すべてを最高レベルの人間の能力と同等か、それを上回るレベルで組み合わせることになります。重要なのは、この組み合わせこそが人間を非常に効果的にし、現在のソフトウェアとは異なるものにしていることです。それはまた、人間がデジタルシステムによって全面的に置き換えられることを可能にするものでもあります。

人間の知能は特別ですが、決して限界ではありません。人工的な「超知能」システムは何百倍も速く動作し、はるかに多くのデータを解析し、膨大な量を一度に「心に」保持し、人間の集合よりもはるかに大きく効果的な集合体を形成することができるでしょう。それらは個人ではなく、企業、国家、あるいは私たちの文明全体に取って代わる可能性があります。

## 私たちは閾値にいる

AGIが*可能である*ことについては強い科学的コンセンサスがあります。AIは既に、最近の高レベルな推論と問題解決を含む多くの知的能力の一般的テストで人間の性能を上回っています。継続学習、計画、自己認識、独創性といった遅れている能力はすべて、現在のAIシステムにある程度存在しており、これらすべてを改善する可能性が高い既知の技術が存在します。

数年前まで多くの研究者がAGIは数十年先と見ていましたが、現在AGIへの短期間での到達を示す証拠は強力です：

- 経験的に検証された「スケーリング法則」が計算資源の投入量とAI能力を結びつけており、企業は今後数年間で計算資源の投入量を桁違いに拡大する軌道にあります。AI進歩に投じられている人的・財政的資源は、現在12のマンハッタン計画と複数のアポロ計画に匹敵します。
- AI企業とその指導者たちは、AGI（何らかの定義による）が数年以内に達成可能だと公私にわたって信じています。これらの企業は一般に公開されていない情報を持っており、一部は次世代AIシステムを既に手にしています。
- 実績のある専門予測者は、AGI（何らかの定義による）が1〜2年以内に到着する確率を25%、2〜5年で50%と見積もっています（[「弱い」](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/)AGIと[「完全な」](https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/)AGIに関するMetaculusの予測を参照）。
- 自律性（長期の柔軟な計画を含む）はAIシステムでは遅れていますが、主要企業は現在、膨大なリソースを自律的AIシステムの開発に集中させており、非公式に2025年を[「エージェントの年」](https://techinformed.com/2025-informed-the-year-of-agentic-ai/)と名付けています。
- AIはますます自身の改善に貢献しています。AIシステムがAI研究を行う人間のAI研究者と同程度に有能になれば、はるかに強力なAIシステムへの高速な進歩の重要な閾値に到達し、AI能力の暴走を引き起こす可能性が高いでしょう。（この暴走は既に始まっていると言えるかもしれません。）

人間よりも賢いAGIが数十年以上先にあるという考えは、この分野の専門家の大多数にとってもはや支持できないものです。現在の議論は、この軌道を続けた場合に何ヶ月または何年かかるかについてです。私たちが直面している中核的な質問は：そうすべきなのか？ということです。

## AGI競争を駆動するもの

AGIに向けた競争は複数の力によって駆動されており、それぞれが状況をより危険にしています。主要テック企業はAGIを究極の自動化技術と見ており――人間の労働者を補完するだけでなく、大部分または完全に置き換えることを目指しています。企業にとって、その賞は巨大です：人間の労働コストを自動化することで、世界の100兆ドルの年間経済生産の相当な部分を獲得する機会なのです。

各国もこの競争への参加を余儀なくされており、表向きは経済的・科学的リーダーシップを掲げていますが、内心ではAGIを核兵器に匹敵する軍事革命の可能性と見なしています。ライバルが決定的な戦略的優位を得るかもしれないという恐怖が、典型的な軍拡競争の力学を生み出しています。

超知能を追求する人々は、しばしば壮大なビジョンを掲げます：すべての病気の治癒、老化の逆転、エネルギーや宇宙旅行でのブレークスルー、または超人的な計画能力の創出などです。

あまり好意的でない見方をすれば、この競争を駆動するのは権力です。各参加者――企業であれ国家であれ――は、知能は権力に等しく、自分たちがその権力の最良の管理者になると信じています。

私は、これらの動機は現実的だが根本的に誤った方向にあると論じます：AGIは権力を*与える*のではなく*吸収し*、*求める*でしょう。AI が生み出す技術も*また*強く両刃の剣となり、有益な場合にはAIツールとAGI なしで作ることができます。そして、AGIとその成果物がコントロール下に留まる限りにおいてさえ、これらの競争力学――企業的かつ地政学的な――は、断固として中断されない限り、私たちの社会への大規模なリスクをほぼ不可避にします。

## AGIと超知能は文明への劇的な脅威

その魅力にもかかわらず、AGIと超知能は複数の相互補強的な経路を通じて文明への劇的な脅威をもたらします：

*権力の集中：*超人的AIは、社会的・経済的活動の巨大な部分を少数の巨大企業（それは次に政府によって乗っ取られるか、事実上政府を乗っ取る可能性がある）が運営するAIシステムに吸収することで、人類の大多数を無力化する可能性があります。

*大規模な混乱：*ほとんどの認知ベースの仕事の一括自動化、現在の認識論的システムの置き換え、そして膨大な数の活発な非人間エージェントの展開は、比較的短期間で私たちの現在の文明システムのほとんどを覆すでしょう。

*災害：*新しい軍事的・破壊的技術を創出する能力を――潜在的に人間レベルを上回って――拡散させ、それを責任を支える社会的・法的システムから切り離すことで、大量破壊兵器による物理的災害が劇的により可能性が高くなります。

*地政学と戦争：*「決定的な戦略的優位」を供給できる技術が敵対者によって開発されていると感じれば、主要世界大国は手をこまねいて見ているわけにはいかないでしょう。

*暴走とコントロールの喪失：*特に阻止されない限り、超人的AIはさらに自己改善するあらゆるインセンティブを持ち、速度、データ処理、思考の洗練において人間をはるかに上回る可能性があります。私たちがそのようなシステムをコントロールできる意味のある方法は存在しません。そのようなAIは人間に権力を与えることはありません。私たちがそれに権力を与えるか、それが権力を奪うのです。

これらのリスクの多くは、技術的な「アライメント」問題――高度なAIが確実に人間の望むことを行うようにすること――が解決されたとしても残存します。AIは、どのように管理されるかという点で巨大な課題を提起しており、人間の知能を超えるにつれて、この管理の非常に多くの側面が信じられないほど困難または扱いにくくなります。

最も根本的に、現在追求されている超人的汎用AIの種類は、その性質上、私たち自身を超える目標、行為主体性、能力を持つことになります。それは本質的に制御不可能でしょう――理解も予測もできないものを、どうやってコントロールできるでしょうか？それは人間が使用する技術ツールではなく、地球上で私たちと並存する第二の知能種となるでしょう。さらに進歩することが許されれば、それは第二の種というだけでなく、置換種を構成することになります。

おそらくそれは私たちを良く扱うかもしれないし、そうでないかもしれません。しかし、未来はそれのものであり、私たちのものではないでしょう。人間の時代は終わりを告げるのです。

## これは不可避ではありません；人類は非常に具体的に、自らの置換物を作らないことを決定できます。

超人的AGIの創出は不可避とはほど遠いものです。私たちは協調的なガバナンス措置のセットを通じてそれを防ぐことができます：

第一に、大規模AIシステムの基本的な実現要因であり制御レバーでもあるAI計算（「計算資源」）の堅実な会計処理と監視が必要です。これは順次、AIモデルの訓練と運用に使用される総計算資源の標準化された測定と報告、および使用された計算を集計、認証、検証する技術的方法を要求します。

第二に、AI計算に対する厳格な上限を、訓練と運用の両方で実装すべきです。これらはAIが強力すぎることと動作が速すぎることの両方を防ぎます。これらの上限は、法的要求事項と、現代の携帯電話のセキュリティ機能に類似した、AI専用チップに組み込まれたハードウェアベースのセキュリティ措置の両方を通じて実装できます。AI専用ハードウェアは少数の企業のみが製造しているため、既存のサプライチェーンを通じた検証と執行が実行可能です。

第三に、最も危険なAIシステムに対する強化された責任制度が必要です。高い自律性、広い汎用性、優れた知能を組み合わせるAIを開発する者は、害に対する厳格責任に直面すべきであり、一方この責任からのセーフハーバーは、より限定的で制御可能なシステムの開発を奨励するでしょう。

第四に、リスクレベルに基づく段階的規制が必要です。最も能力が高く危険なシステムは、開発と展開前に広範囲な安全性と制御可能性の保証を要求される一方、あまり強力でないか、より専門化されたシステムは、相応の監視に直面するでしょう。この規制枠組みは、最終的に国内と国際の両レベルで機能すべきです。

このアプローチ――完全な文書で詳細仕様が与えられている――は実用的です：国際協調が必要になるものの、検証と執行は専用ハードウェアサプライチェーンを制御する少数の企業を通じて機能させることができます。また柔軟性もあります：企業は依然としてAI開発で革新し利益を得ることができますが、最も危険なシステムに対する明確な限界があります。

AI の権力とリスクの長期的封じ込めには、現在の核兵器拡散制御と同様に、自己利益と共通利益の両方に基づく国際合意が必要になるでしょう。しかし、より包括的なガバナンスに向けて構築しながら、強化された監視と責任制度から直ちに始めることができます。

欠けている重要な要素は、AI開発プロセスを制御する政治的・社会的意志です。それがタイムリーに現れるとすれば、その意志の源泉は現実そのもの――つまり、私たちが何をしているのかの真の含意の広範囲な認識――からでしょう。

## ツールAIを人類を力づけるよう設計できる

制御不可能なAGIを追求するのではなく、意味のある人間のコントロール下に残りながら人間の能力を向上させる強力な「ツールAI」を開発することができます。ツールAIシステムは、その能力に見合うレベルで制御可能になるよう設計される限り、高い自律性、広い汎用性、超人的知能の危険な三重交点を避けながら、極めて高い能力を持つことができます。また、変革的な利益を提供しながら人間の監視を維持する洗練されたシステムに組み合わせることもできます。

ツールAIは医学を革命化し、科学的発見を加速し、教育を向上させ、民主的プロセスを改善することができます。適切にガバナンスされれば、人間の専門家や機関を置き換えるのではなく、より効果的にすることができます。そのようなシステムは依然として高度に破壊的であり、慎重な管理を要求するものの、それらがもたらすリスクはAGIとは根本的に異なります：それらは他の強力な技術のリスクのように、私たちが統治できるリスクであり、人間の行為主体性と文明への存在的脅威ではありません。そして重要なことに、賢明に開発されれば、AIツールは人々が強力なAIを統治し、その効果を管理することを助けることができます。

このアプローチには、AIがどのように開発されるか、そしてその利益がどのように分配されるかの両方の再考が必要です。公的・非営利AI開発の新しいモデル、堅実な規制枠組み、経済的利益をより広く分配するメカニズムが、AIが少数の手に権力を集中させるのではなく、人類全体を力づけることを確実にする助けとなります。AI自体が、人間社会を弱体化させるのではなく強化する新しい形の協調と対話を可能にして、より良い社会とガバナンス機関の構築を助けることができます。国家安全保障組織は、その専門知識を活用してAIツールシステムを真に安全で信頼でき、国力だけでなく真の防衛の源とすることができます。

私たちは最終的に、あまりツール的ではなく――私たちが希望できることには――賢明で強力な後援者のような、より強力でより主権的なシステムを開発することを選択するかもしれません。しかし、私たちはそれを安全に行うための科学的理解とガバナンス能力を開発した後にのみ、そうすべきです。そのような重大で不可逆的な決定は、テック企業と国家間の競争でデフォルトとしてではなく、人類全体によって慎重に下されるべきです。

## 人間の手の中に

人々はAIから生まれる良いものを望んでいます：自分たちを力づけ、経済的機会と成長を過給し、科学、技術、教育でのブレークスルーを約束する有用なツールです。なぜ望まないでしょうか？しかし尋ねられれば、一般大衆の圧倒的多数は[より遅く、より慎重なAI開発](https://www.vox.com/future-perfect/2023/8/18/23836362/ai-slow-down-poll-regulation)を望んでおり、自分たちを仕事やその他の場所で置き換え、文化と情報コモンズを非人間的コンテンツで満たし、権力を極小数の企業に集中させ、極端な大規模グローバルリスクをもたらし、最終的に自分たちの種を無力化するか置き換えることを脅かす人間より賢いAIを望んでいません。なぜ望むでしょうか？

私たちは一方を他方なしに*得ることができます*。それは、私たちの運命がある技術の想定される必然性や、シリコンバレーの少数のCEOの手の中にあるのではなく、私たちがそれを掴めば、私たち他の者の手の中にあることを決めることから始まります。ゲートを閉じて、未来を人間のものに保ちましょう。