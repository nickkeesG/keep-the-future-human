# 第1章 - 序論

人間を上回る知能を持つAIの見通しにどう対応するかは、現代において最も切迫した問題である。本エッセイはその道筋を示す。

我々は人間の時代の終わりを迎えようとしているのかもしれない。

過去10年間に、人類史上類を見ない事態が始まった。その帰結は、人類の未来を大きく左右することになるだろう。2015年頃から、研究者たちは*特化型*人工知能（AI）の開発に成功を収めている。囲碁などのゲームで勝利し、画像や音声を認識するなど、あらゆる人間を上回るシステムである。[^1]

これは驚くべき成功であり、人類に力を与える極めて有用なシステムや製品をもたらしている。しかし、特化型人工知能は、この分野の真の目標ではなかった。むしろ、その目的は*汎用*AIシステムの創造にあった。特に、しばしば「AGI（汎用人工知能）」や「超知能」と呼ばれる、AIが現在囲碁、チェス、ポーカー、ドローンレースなどで超人的性能を発揮しているのと同様に、ほぼ*すべて*のタスクで人間と同等かそれ以上の性能を同時に持つシステムである。これは多くの主要AI企業が掲げる明確な目標だ。[^2]

*これらの取り組みも成功を収めている。*ChatGPT、Gemini、Llama、Grok、Claude、Deepseekといった汎用AIシステムは、膨大な計算量とデータの山に基づいて、幅広いタスクで一般的な人間と同等の性能に達し、一部の領域では人間の専門家に匹敵している。現在、最大手のテクノロジー企業のAIエンジニアたちは、こうした機械知能の巨大な実験を次のレベルまで押し上げ、人間の能力、専門性、自律性の全範囲に匹敵し、そして凌駕する水準に到達させようと競争している。

*これは差し迫っている。*過去10年間で、現在の道筋を続けた場合にこれが実現するまでの期間に関する専門家の予測は、数十年（あるいは数世紀）から一桁の年数へと短縮された。

これはまた、時代を画する重要性と、途方もないリスクを孕んでいる。AGI支持者は、それが科学的問題を解決し、病気を治癒し、新技術を開発し、単純作業を自動化する前向きな変革だと捉えている。そしてAIは確実にこうしたことすべての達成に貢献できるし、実際にすでに貢献している。しかし、数十年にわたって、アラン・チューリングからスティーブン・ホーキング、現在のジェフリー・ヒントンやヨシュア・ベンジオまで、多くの慎重な思想家たちが[^3]厳しい警告を発してきた：真に人間より賢く、汎用的で自律的なAIを構築することは、最低でも社会を完全かつ不可逆的に覆し、最悪の場合は人類絶滅をもたらすと。[^4]

超知能AIは現在の道筋で急速に接近しているが、避けられない運命では決してない。本エッセイは、なぜ、どのようにして我々がこの迫りくる非人間的な未来への*ゲートを閉じる*べきなのか、そして代わりに何をすべきなのかについての詳細な論考である。


[^1]: この[チャート](https://time.com/6300942/ai-progress-charts/)は一連のタスクを示している；このグラフには多くの類似した曲線を追加することができる。特化型AIにおけるこの急速な進歩は、この分野の専門家たちをも驚かせ、ベンチマークが予測より何年も早く突破されている。

[^2]: Deepmind、OpenAI、Anthropic、X.aiはすべてAGI開発を明確な目標として設立された。例えば、OpenAIの憲章では「すべての人類に利益をもたらすAGI（汎用人工知能）」の開発を目標として明記し、DeepMindの使命は「知能を解決し、それを使ってあらゆることを解決する」となっている。Meta、Microsoft、その他も現在実質的に同様の道筋を追求している。Metaは[AGIを開発してオープンソースで公開する計画](https://www.forbes.com/sites/johnkoetsier/2024/01/18/zuckerberg-on-ai-meta-building-agi-for-everyone-and-open-sourcing-it/)があると述べている。

[^3]: ヒントンとベンジオは最も引用されるAI研究者の二人で、ともにAI分野のノーベル賞であるチューリング賞を受賞し、ヒントンは加えてノーベル物理学賞も受賞している。

[^4]: 商業的インセンティブの下で、政府の監督がほぼ皆無の状態でこのようなリスクを持つものを構築することは、まったく前例がない。それを構築している人々の間でさえ、このリスクについて議論の余地はない！Deepmind、OpenAI、Anthropic、その他多くの専門家のリーダーたちは皆、高度なAIが*人類にとっての絶滅リスク*をもたらすという[声明](https://www.safe.ai/work/statement-on-ai-risk)に文字通り署名している。警鐘はこれ以上ないほど鳴り響いており、これを無視する人々は単純にAGIと超知能を真剣に受け止めていないと結論せざるを得ない。本エッセイの目的の一つは、なぜ彼らがそれを真剣に受け止めるべきなのかを理解してもらうことである。