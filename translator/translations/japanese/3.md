# 第3章 - 現代の汎用AIシステムの作り方の重要な側面

世界最先端のAIシステムの多くは、驚くほど似通った手法で作られています。ここではその基本的な仕組みを説明します。

人間を本当に理解するためには生物学、進化、子育てなどについて知る必要があるのと同じように、AIを理解するにはその作り方を知る必要があります。過去5年間で、AIシステムは能力と複雑さの両面で劇的に進歩しました。その主要な推進力となったのは、膨大な計算資源（AI分野では俗に「計算資源」と呼ばれる）が利用できるようになったことです。

その数値は驚異的です。GPTシリーズ、Claude、Geminiなどのモデルの訓練には、約10<sup>25</sup>から10<sup>26</sup>の「浮動小数点演算」（FLOP）[^1]が使用されています[^2]（比較のために言えば、地球上のすべての人間が5秒に1回の計算を休みなく続けたとしても、これを完了するには約10億年かかるでしょう）。この膨大な計算量により、数兆個のモデルパラメータを持つモデルを、テラバイト規模のデータ──これまでに書かれた質の高いテキストの大部分と、音声、画像、動画の膨大なライブラリ──で訓練することが可能になりました。さらに人間の好みと優れたタスク性能を強化する広範な追加訓練を組み合わせることで、このように訓練されたモデルは、推論や問題解決を含む幅広い基礎的な知的タスクにおいて人間と競合する性能を示しています。

また、このようなシステムの*推論*速度[^3]が人間のテキスト処理*速度*に匹敵するために必要な計算速度（1秒あたりの演算数）についても、（非常に粗い推定ですが）分かっています。それは約10<sup>15</sup>から10<sup>16</sup>FLOP/秒です[^4]。

強力でありながら、これらのモデルはその性質上、重要な点で制限があります。これは、人間が立ち止まって考えたり追加のツールを使ったりすることなく、単に一定の速度で文章を出力し続けることを強制された場合の制限と非常に似ています。より最近のAIシステムは、いくつかの重要な要素を組み合わせた、より複雑なプロセスとアーキテクチャによってこれらの制限に対処しています：

- 1つまたは複数のニューラルネットワーク。1つのモデルが中核的な認知能力を提供し、最大で他の数個がより限定的なタスクを実行する
- モデルに提供され使用可能な*ツール機能*──例えばウェブ検索、文書の作成や編集、プログラムの実行など
- ニューラルネットワークの入力と出力を接続する*足場（スキャフォールディング）*。非常にシンプルな足場では、AIモデルの2つの「インスタンス」が互いに対話したり、一方が他方の作業をチェックしたりできるかもしれません[^5]
- *思考連鎖*および関連するプロンプト技術は似たようなことを行い、例えばモデルに問題への多くのアプローチを生成させ、それらのアプローチを処理して統合的な答えを出させます
- ツール、足場、思考連鎖をより良く活用するためのモデルの*再訓練*

これらの拡張は非常に強力であり（AIシステム自体も含む）、これらの複合システムは非常に洗練されており、AI能力を劇的に向上させることができます[^6]。そして最近では、足場と特に思考連鎖プロンプティング（そして結果をモデルの再訓練にフィードバックしてこれらをより良く使えるようにする）の技術が[o1](https://openai.com/o1/)、[o3](https://openai.com/index/openai-o3-mini/)、[DeepSeek R1](https://api-docs.deepseek.com/news/news250120)で開発・採用され、与えられたクエリに対して多くの推論パスを実行するようになりました[^7]。これにより事実上、モデルが応答について「考える」ことが可能になり、科学、数学、プログラミングタスクにおける高水準の推論能力が劇的に向上しました[^8]。

特定のAIアーキテクチャにおいて、訓練計算量の増加は明確に定義された指標の改善に[確実に変換できます](https://arxiv.org/abs/2405.10938)。あまり厳密に定義されていない一般的な能力（以下で議論するようなもの）については、この変換はそれほど明確で予測的ではありませんが、より多くの訓練計算量を使用したより大きなモデルは、それが何であるかを予測するのは困難だとしても、新しくより良い能力を持つことはほぼ確実です。

同様に、複合システム、特に「思考連鎖」（およびそれとうまく機能するモデルの訓練）の進歩により、*推論*計算量のスケーリングが可能になりました。与えられた訓練済みの中核モデルに対して、少なくとも一部のAIシステム能力は、複雑な問題について「より懸命に長時間考える」ことを可能にするより多くの計算資源が適用されるにつれて向上します。これは計算速度の面で高いコストを伴い、人間の性能に匹敵するために数百倍から数千倍のFLOP/秒が必要になります[^9]。

急速なAI進歩を導いている要因の一部に過ぎませんが[^10]、計算資源の役割と複合システムの可能性は、制御不能なAGIを防ぎ、より安全な代替案を開発する上で重要であることが証明されるでしょう。

[^1]: 10<sup>25</sup>は1の後に25個のゼロが続く数、つまり1000兆の1兆倍を意味します。FLOPは単に、ある精度での数値の算術的な加算または乗算です。なお、AIハードウェアの性能は、算術の精度やコンピュータのアーキテクチャによって10倍程度変動することがあります。論理ゲート演算（AND、OR、AND NOT）を数える方が基本的ですが、これらは一般的に利用できず、ベンチマークもされていません。現在の目的には16ビット演算（FP16）で標準化するのが有用ですが、適切な変換係数を確立すべきです。

[^2]: [Epoch AI](https://epochai.org/data/large-scale-ai-models)から推定値と確実なデータの集合が入手可能で、GPT-4については約2×10<sup>25</sup>の16ビットFLOPを示しています。これはGPT-4について[リークされた数値](https://mpost.io/gpt-4s-leaked-details-shed-light-on-its-massive-scale-and-impressive-architecture/)とほぼ一致します。2024年半ばの他のモデルの推定値は、すべてGPT-4の数倍の範囲内にあります。

[^3]: 推論は単に、ニューラルネットワークから出力を生成するプロセスです。訓練は多くの推論とモデル重みの調整の連続と考えることができます。

[^4]: テキスト生成について、オリジナルのGPT-4は生成されるトークンあたり560TFLOPを必要としました。人間の思考についていくには約7トークン/秒が必要なので、これは≈3×10<sup>15</sup>FLOP/秒となります。しかし効率化によりこれは低下しており、例えば[このNVIDIAのパンフレット](https://developer.nvidia.com/blog/supercharging-llama-3-1-across-nvidia-platforms/)では、同等の性能のLlama 405Bモデルで3×10<sup>14</sup>FLOP/秒程度まで少なくなることが示されています。

[^5]: やや複雑な例として、AIシステムがまず数学問題の複数の可能な解法を生成し、次に別のインスタンスを使って各解法をチェックし、最後に3番目を使って結果を明確な説明に統合するかもしれません。これにより、単一のパスよりも徹底的で信頼性の高い問題解決が可能になります。

[^6]: 例えば[OpenAIの「Operator」](https://openai.com/index/introducing-operator/)、[Claudeのツール機能](https://docs.anthropic.com/en/docs/build-with-claude/computer-use)、[AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)の詳細を参照してください。OpenAIの[Deep Research](https://openai.com/index/introducing-deep-research/)はおそらく非常に洗練されたアーキテクチャを持っていますが、詳細は公開されていません。

[^7]: Deepseek R1は、最終的に訓練されたモデルが広範な思考連鎖推論を作成するように、モデルを反復的に訓練およびプロンプトすることに依存しています。o1やo3についてはアーキテクチャの詳細は公開されていませんが、Deepseekは推論による能力のスケーリングを解き放つために特別な「秘密のソース」は必要ないことを明らかにしています。ただし、AIの「現状」を覆すものとして大きな注目を集めているにも関わらず、この論文の核心的な主張には影響しません。

[^8]: これらのモデルは推論ベンチマークで標準的なモデルを大幅に上回る性能を示しています。例えば、博士レベルの科学問題の厳密なテストであるGPQA Diamond Benchmarkにおいて、GPT-4oは[56%のスコア](https://openai.com/index/learning-to-reason-with-llms/)でしたが、o1とo3はそれぞれ78%と88%を達成し、人間の専門家の平均スコア70%を大きく上回りました。

[^9]: OpenAIのO3は、有能な人間が（例えば）10-100秒で解けるARC-AGIチャレンジの各問題を完了するために[∼10<sup>21</sup>-10<sup>22</sup>FLOPを消費した](https://www.interconnects.ai/p/openais-o3-the-2024-finale-of-ai)と推定され、これは∼10<sup>20</sup>FLOP/秒のような数値を与えます。

[^10]: 計算資源はAIシステム能力の重要な指標ですが、データ品質とアルゴリズムの改善の両方と相互作用します。より良いデータやアルゴリズムは計算要求を削減でき、一方でより多くの計算資源は時として弱いデータやアルゴリズムを補うことができます。