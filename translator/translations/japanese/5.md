# 第5章 - 閾値にて

今日のAIシステムから本格的なAGIへの道のりは、驚くほど短く予測可能なものに思えます。

過去10年間で、膨大な[計算資源](https://epoch.ai/blog/training-compute-of-frontier-ai-models-grows-by-4-5x-per-year)、人的資源、[財政的資源](https://arxiv.org/abs/2405.21015)によって、AIは劇的な進歩を遂げました。多くの狭域AI応用は、割り当てられたタスクにおいて人間より優秀であり、確実により高速で安価です。[^1] また、[囲碁](https://www.nature.com/articles/nature16961)、[チェス](https://arxiv.org/abs/1712.01815)、[ポーカー](https://www.deepstack.ai/)などの特定領域のゲームで全ての人間を圧倒する狭域超人エージェントや、簡略化されたシミュレーション環境において人間と同様に効果的に計画・実行できる[より汎用的なエージェント](https://deepmind.google/discover/blog/a-generalist-agent/)も存在します。

最も注目すべきは、OpenAI/Microsoft、Google/Deepmind、Anthropic/Amazon、Facebook/Meta、X.ai/Tesla等 [^2] による現在の汎用AIシステムが2023年初頭以降に登場し、それ以来着実に（ただし不均等に）能力を向上させていることです。これらは全て、膨大なテキスト・マルチメディアデータセットでのトークン予測と、人間および他のAIシステムからの広範な強化フィードバックを組み合わせて作られました。一部にはツールやスキャフォールドシステムも含まれています。

## 現在の汎用システムの強みと弱み

これらのシステムは知能と専門性を測定するように設計された幅広いテストで良好な性能を示しており、その進歩は分野の専門家でさえ驚かせています：

- 最初にリリースされた際、GPT-4は SAT、GRE、入学試験、司法試験を含む標準的な学術テストで[典型的な人間の性能に匹敵するか、それを上回りました](https://arxiv.org/abs/2303.08774)。より最新のモデルは大幅に良い性能を示すと考えられますが、結果は公開されていません。
- 長い間「真の」AIの重要なベンチマークとされてきたチューリングテストは、現代の言語モデルによって非公式にも[正式な研究](https://arxiv.org/abs/2405.08007)においても日常的にパスされています。[^3]
- 57の学術分野にわたる包括的なMMLUベンチマークで、[最新のモデルは領域専門家レベルのスコア](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu)（約90％）を達成しています [^4]
- 技術的専門性は劇的に向上しています：大学院レベルの物理学のGPQAベンチマークでは、[性能が](https://epoch.ai/data/ai-benchmarking-dashboard)ほぼランダムな推測（GPT-4、2022年）から専門家レベル（o1-preview、2024年）へと飛躍しました。
- AI耐性を持つように特別に設計されたテストでさえ陥落しています：OpenAIのO3は ARC-AGI抽象問題解決ベンチマークを人間レベルで解き、最上位専門家のコーディング性能を達成し、エリート数学者に挑戦するように設計されたEpoch AIの「フロンティア数学」問題で25%のスコアを記録したと[報告](https://www.nextbigfuture.com/2024/12/openai-releases-o3-model-with-high-performance-and-high-cost.html)されています。[^5]
- この傾向は非常に明確で、MMLUの開発者は今や["人類最後の試験"](https://agi.safe.ai/)を作成しました。この不吉な名前は、AIが間もなく意味のある全てのテストで人間の性能を上回る可能性を反映しています。この記事執筆時点で、この極めて困難な試験で27%（[Sam Altman](https://x.com/sama/status/1886220281565381078)による）および35%（[この論文](https://arxiv.org/abs/2502.09955)による）を達成したAIシステムがあるとの主張があります。個々の人間がこれを行うことはほぼ不可能でしょう。

これらの印象的な数値（およびそれらと対話する際に感じる明らかな知性）にも関わらず [^6]、これらのニューラルネットワークができない（少なくともリリース版では）ことが多くあります。現在、ほとんどは具体化されておらず（サーバー上にのみ存在し）、せいぜいテキスト、音声、静止画像を処理する（ビデオは処理しない）に留まります。重要なのは、ほとんどが高精度を要求する複雑な計画的活動を実行できないことです。[^7] そして、現在リリースされているAIシステムでは、高次の人間認知において強い他の多くの性質が低いレベルにとどまっています。

以下の表は、GPT-4o、Claude 3.5 Sonnet、Google Gemini 1.5などの2024年中頃のAIシステムに基づいて、これらの多くをリストアップしています。[^8] 汎用AIがどれほど急速により強力になるかの鍵となる問題は、*同じことをより多く*行うだけでどの程度結果が得られるか、追加の*既知の*技術を加えることと、*本当に新しい*AI研究方向を開発・実装することのバランスです。これに対する私自身の予測を、これらのシナリオのそれぞれがその能力を人間レベル以上に到達させる可能性として表に示しました。

<table><tbody><tr><th>能力</th><th>能力の説明</th><th>現状/予後</th><th>スケーリング/既知/新規</th></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td colspan="4"><em>中核認知能力</em></td></tr><tr><td>推論</td><td>人間は正確で多段階の推論を行い、規則に従い精度をチェックできる。</td><td>拡張思考連鎖と再訓練による劇的な最近の進歩</td><td>95/5/5</td></tr><tr><td>計画</td><td>人間は長期的で階層的な計画を示す。</td><td>スケールと共に改善；スキャフォールディングとより良い訓練技術により強力に支援される。</td><td>10/85/5</td></tr><tr><td>真実の根拠</td><td>汎用AIはクエリを満たすため根拠のない情報を作り出す。</td><td>スケールと共に改善；較正データがモデル内で利用可能；スキャフォールディングによりチェック・改善可能。</td><td>30/65/5</td></tr><tr><td>柔軟な問題解決</td><td>人間は新しいパターンを認識し複雑な問題に新しい解決策を発明できる；現在のMLモデルは苦戦。</td><td>スケールと共に改善するが弱い；ニューロシンボリックや一般化された「探索」技術で解決可能かもしれない。</td><td>15/75/10</td></tr><tr><td colspan="4"><em>学習と知識</em></td></tr><tr><td>学習と記憶</td><td>人間は作業記憶、短期記憶、長期記憶を持ち、全て動的で相互関連している。</td><td>全モデルが訓練中に学習；汎用AIはコンテキストウィンドウ内および微調整中に学習；「継続学習」等の技術は存在するが大規模汎用AIには未統合。</td><td>5/80/15</td></tr><tr><td>抽象化と再帰</td><td>人間は関係セットをより抽象的なものにマッピング・転移し推論・操作でき、再帰的「メタ」推論を含む。</td><td>スケールと共に弱く改善；ニューロシンボリックシステムで出現する可能性。</td><td>30/50/20</td></tr><tr><td>世界モデル</td><td>人間は問題解決や物理推論に使える予測的世界モデルを持ち継続的に更新する</td><td>スケールと共に改善；更新は学習と結びついている；汎用AIは実世界予測で弱い。</td><td>20/50/30</td></tr><tr><td colspan="4"><em>自己とエージェンシー</em></td></tr><tr><td>エージェンシー</td><td>人間は計画・予測に基づいて目標を追求するため行動を取れる。</td><td>多くのMLシステムがエージェント的；LLMはラッパーでエージェントにできる。</td><td>5/90/5</td></tr><tr><td>自己指向</td><td>人間は内的に生成される動機と意欲で自分の目標を発達・追求する。</td><td>主にエージェンシーと独創性で構成；抽象的目標を持つ複雑なエージェントシステムで出現する可能性。</td><td>40/45/15</td></tr><tr><td>自己言及</td><td>人間は環境・文脈内に位置する自分を理解し推論する。</td><td>スケールと共に改善し訓練報酬で増強可能。</td><td>70/15/15</td></tr><tr><td>自己認識</td><td>人間は自分の思考や精神状態について知識を持ち推論できる。</td><td>ある意味で汎用AIに存在し、自己認識の古典的「鏡テスト」を通ると言える。スキャフォールディングで改善可能；ただしこれで十分かは不明。</td><td>20/55/25</td></tr><tr><td colspan="4"><em>インターフェースと環境</em></td></tr><tr><td>身体化知能</td><td>人間は現実世界環境を理解し積極的に相互作用する。</td><td>強化学習はシミュレーション・現実世界（ロボット）環境で良く機能しマルチモーダルトランスフォーマーに統合可能。</td><td>5/85/10</td></tr><tr><td>マルチセンス処理</td><td>人間は視覚、聴覚、その他の感覚ストリームを統合しリアルタイム処理する。</td><td>複数モダリティでの訓練は「うまく機能」しスケールと共に改善するようだ。リアルタイムビデオ処理は困難だが自動運転システム等は急速改善中。</td><td>30/60/10</td></tr><tr><td colspan="4"><em>高次能力</em></td></tr><tr><td>独創性</td><td>現在のMLモデルは既存のアイデア・作品を変換・組み合わせる創造性を持つが、人間はアイデンティティと結びつくことがある新しい枠組みや構造を構築できる。</td><td>「創造性」と区別が困難で、それがスケールして独創性になるかもしれない；創造性と自己認識から出現する可能性。</td><td>50/40/10</td></tr><tr><td>感覚</td><td>人間はクオリアを経験する；これらは正・負・中性の感情価を持てる；人間であることには「何かのようなもの」がある。</td><td>与えられたシステムがこれを持つかは哲学的に複雑で判定が非常に困難。</td><td>5/10/85</td></tr></tbody></table>

現代の汎用AIシステムで現在人間専門家レベルを下回る主要能力を種類別にグループ化。第3列は現状をまとめる。最終列は人間レベル性能が達成される予測可能性（%）を示す：現技術のスケーリング / 既知技術との組み合わせ / 新技術の開発。これらの能力は独立ではなく、いずれかの向上は通常他の向上と連動する。全て（特に感覚）がAI開発を進歩させうるAIシステムに必要ではないことに注意。これは強力だが非感覚的AIの可能性を強調している。

何が「欠けている」かをこのように分解すると、既存または既知の技術をスケーリングすることで、我々が広範に人間を上回る知能に向けて十分軌道に乗っていることがかなり明確になります。[^9]

まだ驚きがある可能性はあります。「感覚」を別にしても、リストされた中核認知能力の一部が現在の技術では本当にできず、新しい技術を必要とする可能性があります。しかし、これを考えてみてください。世界最大の企業の多くが現在投じている努力は、アポロ計画の数倍、マンハッタン計画の数十倍の支出に相当し、[^10] 前例のない給与で数千人の最高レベルの技術者を雇用しています。過去数年の動向は、今や歴史上のどんな試みよりも多くの人間の知的火力（現在はAIも追加されている）をこれにもたらしています。我々は失敗に賭けるべきではありません。

## 大きな目標：汎用自律エージェント

過去数年の汎用AI開発は、汎用的で強力だがツール様のAIを作ることに焦点を当ててきました：主に（かなり）忠実なアシスタントとして機能し、一般的に独自に行動することはありません。これは部分的には設計によるものですが、主にこれらのシステムが複雑な行動を任せるのに十分な関連スキルでの能力を持っていなかったからです。[^11]

しかし、AI企業と研究者は*自律的な*専門家レベル汎用エージェントへと[焦点を移し](https://www.axios.com/2025/01/23/davos-2025-ai-agents)つつあります。[^12] これにより、システムはユーザーが実際の行動を委任できる人間のアシスタントのように動作できるようになります。[^13] それには何が必要でしょうか？「欠けているもの」の表の多くの能力が関わっています：強い真実の根拠、学習と記憶、抽象化と再帰、世界モデリング（知能用）、計画、エージェンシー、独創性、自己指向、自己言及、自己認識（自律性用）、マルチセンス処理、身体化知能、柔軟な問題解決（汎用性用）が含まれます。[^14]

高い自律性（行動の独立性）、高い汎用性（範囲とタスクの広さ）、高い知能（認知タスクでの能力）のこの三重交差は、現在人間に固有のものです。これは多くの人がAGIを考えるときに暗黙のうちに念頭に置いているもの、その価値とリスクの両面においてそうでしょう。

これはA-G-Iを***自律的***-***汎用***-***知能***として定義する別の方法を提供し、この三重交差が高能力システムのリスクと報酬の理解、そしてAIのガバナンスの両方において非常に価値あるレンズを提供することがわかります。

![](https://keepthefuturehuman.ai/essay/_next/image?url=https%3A%2F%2Fkeepthefuturehuman.ai%2Fwp-content%2Fuploads%2F2025%2F02%2FAGI-Venn-Diagram-Simple-1024x1024.png&w=3840&q=75) 変革的なA-G-I権力とリスクゾーンは、3つの重要な特性の交差から生まれる：高い自律性、タスクでの高い知能、高い汎用性。

## AI（自己）改良サイクル

AI進歩を理解する上で最後の重要な要因は、AIの独特な技術フィードバックループです。AI開発において、成功は（実証されたシステムと展開された製品の両方で）追加の投資、人材、競争をもたらし、我々は現在、数千億、あるいは数兆ドルの投資を推進している巨大なAIハイプ・プラス・リアリティフィードバックループの最中にいます。

この種のフィードバックサイクルはどの技術でも起こり得るもので、市場成功が投資をもたらし、それが改良とより良い市場成功をもたらすという多くの技術で見てきました。しかし、AI開発はさらに先に進んでおり、今やAIシステムが新しくより強力なAIシステムの開発を助けています。[^15] このフィードバックループを5段階で考えることができ、それぞれが最後よりも短いタイムスケールを持つ、表に示す通りです。

*AI改良サイクルは複数のタイムスケールで動作し、各段階が後続段階を加速する可能性がある。初期段階は既に進行中で、後期段階は推測的だが一度解放されれば非常に急速に進行し得る。*

これらの段階のいくつかは既に進行中で、いくつかは明らかに始まっています。最後の段階、つまりAIシステムが自律的に自分自身を改良する段階は、非常に強力なAIシステムのリスクに関する文献の定番であり、それには十分な理由があります。[^16] しかし、これは既に始まっており技術の急速な進歩でより多くの驚きをもたらし得るフィードバックサイクルの最も劇的な形態に過ぎないことに注意することが重要です。


[^1]: あなたは恐らく思っているより多くのAIを使っています。音声生成・認識、画像処理、ニュースフィードアルゴリズム等を動かしています。

[^2]: これらの企業ペアの関係は非常に複雑で微妙ですが、現在AI開発に従事している企業の膨大な全体的市場資本化と、Anthropicのような「小さな」企業の背後にさえも投資や主要パートナーシップ契約により非常に深いポケットがあることの両方を示すため明示的にリストしました。

[^3]: チューリングテストを軽視することが流行していますが、それは非常に強力で汎用的です。弱いバージョンでは、（人間のように振る舞うよう訓練された）AIと典型的な方法で短期間相互作用する典型的な人々がそれがAIかどうか分かるかを示します。分かりません。第二に、高度に敵対的なチューリングテストは、例えばAIシステムを人間専門家と比較し、他の人間専門家が評価することで、人間能力と知能の本質的にあらゆる要素を探ることができます。AI評価の多くが一般化されたチューリングテストの形態であるという意味があります。

[^4]: これは領域ごとです。全科目で同時にそのようなスコアを達成できる人間は妥当に存在しないでしょう。

[^5]: これらは優秀な数学者でさえ解決するのに相当な時間を要する、もし解決できるとしての問題です。

[^6]: もしあなたが懐疑的な傾向にあるなら、懐疑を保ちつつ最新のモデルを本当に試し、それらがパスできるテスト問題を自分で試してみてください。物理学教授として、例えばトップモデルが我々の学科の大学院資格試験に合格するとほぼ確実に予測します。

[^7]: 作り話のような他の弱点と共にこれが市場採用を遅らせ、認識される能力と主張される能力の間にギャップを生じさせました（これも激しい市場競争と投資を引きつける必要というレンズを通して見る必要があります）。これは一般大衆と政策立案者の両方をAI進歩の実際の状況について混乱させました。ハイプに見合わないかもしれませんが、進歩は非常に現実的です。

[^8]: それ以降の主要な進歩は、推論時により多くの計算を活用しより多くの強化学習を行う、最高品質の推論のために訓練されたシステムの開発でした。これらのモデルは新しく能力があまりテストされていないため、本質的に解決されたと考える「推論」以外はこの表を完全には改訂しませんでした。しかし、それらのシステムの経験された・報告された能力に基づいて予測を更新しました。

[^9]: 1960年代と1980年代の以前のAI楽観主義の波は、約束された能力が実現されなかった際の「AI冬」で終わりました。しかし、現在の波は多くの領域で超人的性能を達成し、膨大な計算資源と商業的成功に裏付けられている点で根本的に異なります。

[^10]: アポロ計画全体の[費用は2020年ドルで約2500億USD](https://www.planetary.org/space-policy/cost-of-apollo)、マンハッタン計画は[その10分の1未満](https://www.brookings.edu/the-costs-of-the-manhattan-project/)でした。Goldman Sachsは今後数年で[AIデータセンターだけで1兆ドルの支出](https://www.datacenterdynamics.com/en/news/goldman-sachs-1tn-to-be-spent-on-ai-data-centers-chips-and-utility-upgrades-with-little-to-show-for-it-so-far/)を予測しています。

[^11]: 人間は多くの間違いを犯しますが、我々がどれほど信頼できるかを過小評価しています！確率は掛け算されるため、正しく行うのに20ステップを要するタスクは、半分の時間で正しく完了するだけでも各ステップが97%信頼できる必要があります。我々はそのようなタスクを常に行っています。

[^12]: この方向への強い動きは最近OpenAIの[「Deep Research」](https://openai.com/index/introducing-deep-research/)アシスタントで取られました。これは複雑なタスクのためにインターネットで多段階研究を自律的に実行し、「複雑なタスクのためにインターネットで多段階研究を行う新しいエージェント的能力」と説明されています。

[^13]: 面倒なPDF書式の記入、フライト予約等のようなもの。しかし20分野でPhDを持つような！つまり：あなたのためにその論文を書く、その契約を交渉する、その定理を証明する、その広告キャンペーンを作る等。あなたは何をする？もちろん、何をするかを指示するのです。

[^14]: 感覚は明らかに必要でなく、この三重交差のAIが必ずしもそれを意味するわけでもないことに注意してください。

[^15]: ここで最も近い類似は、コンピュータ技術が人々が次世代チップ技術を設計するのを助けることで、チップ技術が数十年間ムーアの法則を維持してきたようなことです。しかしAIははるかに直接的でしょう。

[^16]: AIが間もなく数日や数週間のタイムスケールで自分自身を改良できるということを一瞬沈んで考えることが重要です。またはそれより短く。誰かがAI能力が確実に遠い先だと言うとき、これを心に留めておいてください。