# 第6章 - AGIを巡る競争

企業と国家の両方において、AGI構築を推進している原動力とは何だろうか？

AI分野における最近の急速な進歩は、並外れた注目と投資をもたらし、同時にそれによって生み出されてもいる。これは部分的にはAI開発の成功によるものだが、それ以上の要因が働いている。なぜ地球上最大級の企業や国家までもが、単なるAIではなく、AGIや超知能の構築を競い合っているのだろうか？

## AI研究を人間レベルAIに向かわせた要因

ここ5年ほどまで、AIは主として学術・科学研究分野の問題であり、そのため好奇心と、知能を理解し新しい基盤で創造したいという探求心によって推進されていた。

この段階では、研究者の多くはAIの利益や危険性にそれほど注意を払っていなかった。なぜAIを開発すべきかと問われれば、AIが役立つ可能性のある問題を漠然と列挙するのが一般的な回答だった：新薬、新素材、新科学、より賢いプロセス、そして一般的に人々の生活の改善など[^1]。

これらは立派な目標である！[^2] これらの目標にAI全般ではなくAGIが必要なのかどうかは疑問視できるし、そうするつもりだが、多くのAI研究者が抱いていた理想主義を示している。

しかし過去5年間で、AIは比較的純粋な研究分野から、世界最大級の企業によって主導される工学・製品開発分野へと変貌した[^3]。研究者は依然として重要だが、もはやプロセスを主導してはいない。

## なぜ企業はAGI構築を目指すのか？

では、なぜ巨大企業（そして投資家はさらに顕著に）がAGI構築に膨大な資源を注ぎ込んでいるのだろうか？多くの企業が率直に認める2つの推進要因がある：AIを社会の生産性向上の原動力として、そして自社の利益の源泉として見ているからだ。汎用AIは本質的に汎用であるため、巨大な賞金がある：製品やサービスを作る分野を選ぶのではなく、*すべてを一度に*試すことができるのだ。大手テック企業はデジタル商品・サービスの提供によって巨大化してきており、少なくとも一部の経営陣は、AIを検索、ソーシャルメディア、ラップトップ、スマートフォンなどが提供したリスクと利益を拡張・反映するものとして、それらを提供する次のステップと見なしているに違いない。

しかし、なぜAGIなのか？これには非常にシンプルな答えがあるが、多くの企業や投資家は公に議論することを避けている[^4]。

それは、AGIが労働者を直接、一対一で*置換*できるからである。

補強でもなく、エンパワーでもなく、より生産的にすることでもない。*代替*ですらない。これらはすべて非AGIによって可能であり、実際そうなるだろう。AGIは特に、思考労働者を完全に*置換*できるものである（そしてロボット工学と組み合わせれば、多くの肉体労働者も）。この見解を裏付けるものとして、OpenAIの[（公式に表明された）AGIの定義](https://openai.com/our-structure/)を見れば十分だろう。それは「経済的に価値のある仕事のほとんどで人間を上回る高度な自律システム」である。

ここでの（企業にとっての！）賞金は巨大である。労働コストは世界の約100兆ドルの世界経済の相当な割合を占める。人間の労働をAI労働で置換することでその一部でも獲得できれば、それは年間数兆ドルの収益となる。AI企業は誰が金を払うかもよく理解している。彼らの見方では、あなたは生産性ツールに年間数千ドルは払わないだろう。しかし企業は、可能であればあなたの労働を置換するために年間数千ドルを*払うだろう*。

## なぜ国家はAGI競争に参入せざるを得ないと感じるのか

AGI追求に対する国家の表明された動機は、経済と科学のリーダーシップに焦点を当てている。その論拠は説得力がある：AGIは科学研究、技術開発、経済成長を劇的に加速させる可能性がある。利害関係の大きさを考えると、主要国は後れを取る余裕がない、というのが彼らの主張である[^5]。

しかし、追加的でほぼ表明されない推進要因もある。軍事・国家安全保障の指導者たちが密室で非常に強力で破滅的にリスクの高い技術について話し合う際、その焦点が「どうすればこれらのリスクを避けられるか」ではなく「どうすれば最初にこれを手に入れられるか」にあることは疑いない。軍事・情報機関の指導者たちは、AGIを軍事情勢の潜在的革命として、おそらく核兵器以来最も重要なものと見なしている。AGIを最初に開発した国が乗り越えがたい戦略的優位を得る可能性があるという恐れがある。これが典型的な軍拡競争のダイナミクスを生み出している。

この「AGI競争」思考[^6]は説得力があるものの、根本的に欠陥があることを見ていこう。これは競争が危険でリスクが高いからではない—確かにそうだが—技術の性質によるものだ。暗黙の仮定は、AGIが他の技術と同様に、それを開発した国家によって制御可能であり、最も多く保有する社会に力を与える恩恵だということである。見ていくように、おそらくそのどちらでもないだろう。

## なぜ超知能なのか？

企業が公には生産性に焦点を当て、国家が経済・技術成長に焦点を当てる一方で、完全なAGIと超知能を意図的に追求する者にとって、これらは始まりに過ぎない。彼らが本当に心に描いているものは何か？声に出されることは稀だが、以下のものが含まれる：

1. 多くの、あるいは全ての病気の治療法；
2. 老化の停止と逆転；
3. 核融合のような新しい持続可能エネルギー源；
4. 遺伝子工学による人間の改良や設計生物；
5. ナノテクノロジーと分子製造；
6. 精神のアップロード；
7. エキゾチック物理学や宇宙技術；
8. 超人的助言と意思決定支援；
9. 超人的計画と調整。

最初の3つは主として「単刃」技術である—つまり、非常に強く正味でポジティブである可能性が高い。病気を治すことや、選択すればより長く生きられることに反対するのは困難だ。そして我々はすでに核融合の負の側面を（核兵器という形で）享受しているのだから、今度は正の側面を得られれば素晴らしいだろう。この最初のカテゴリーでの問題は、これらの技術をより早く得ることがリスクを補償するかどうかである。

次の4つは明らかに両刃である：AIと同様に、潜在的に巨大な上昇面と膨大なリスクの両方を持つ変革的技術である。これらすべてが、明日ブラックボックスから飛び出して展開されれば、管理は信じられないほど困難だろう[^7]。

最後の2つは、超人的AIが単に技術を発明するだけでなく、自ら物事を行うことに関する。より正確には、婉曲表現を脇に置けば、これらは強力なAIシステムが人々に何をすべきかを告げることを含んでいる。助言を行うシステムが助言される側よりもはるかに強力で、助言される側が決定の根拠を有意味に理解できない（あるいはこれが提供されても、助言者が異なる決定に対して同じように説得力のある根拠を提供しないだろうと信頼できない）場合、これを「助言」と呼ぶのは不誠実である。

これは上記のリストから欠けている重要な項目を指し示している：

10. 権力。

現在の超人的AI競争の根底にあるものの多くが、*知能＝権力*という考えであることは明白である。各競争者は、その権力の最良の保持者となり、その権力が自分たちの支配から滑り落ちたり奪われたりすることなく、表向きは慈悲深い理由のためにそれを行使できるだろうと期待している。

つまり、企業や国家が本当に追い求めているのは、AGIや超知能の成果だけでなく、誰がそれらにアクセスでき、どのように使われるかを制御する権力なのである。企業は自分たちを株主と人類に奉仕する責任ある管理者と見なし、国家は敵対勢力が決定的優位を得ることを防ぐ必要な守護者と自分たちを見なしている。両者とも危険なほど間違っており、超知能はその性質上、いかなる人間の機関によっても確実に制御できないことを認識していない。我々は、超知能システムの性質とダイナミクスが人間による制御を極めて困難に、不可能でないとしても、することを見ていこう。

これらの競争ダイナミクス—企業的・地政学的両方—は、断固として中断されない限り、特定のリスクをほぼ不可避にする。次に、これらのリスクと、なぜそれらが競争的[^8]開発パラダイムの中では適切に軽減できないかを検討しよう。


[^1]: より正確な価値ある目標のリストは、国連の[持続可能な開発目標](https://sdgs.un.org/goals)である。これらは、ある意味で、世界で改善したいことについて我々が持つ最も近いグローバルコンセンサス目標セットである。AIは役立つ可能性がある。

[^2]: 技術全般は人間の向上のための変革的な経済・社会的力を持っており、数千年の歴史がそれを証明している。この文脈で、ポジティブなAGIビジョンの長く説得力のある解説は、Anthropic創設者Dario AmodeiによるAnthropicの[このエッセイ](https://darioamodei.com/machines-of-loving-grace)で見つけることができる。

[^3]: 民間AI投資は[2018-19年にブームを始め、その頃公的投資を上回り](https://cset.georgetown.edu/publication/tracking-ai-investment/)、それ以降大幅にそれを上回っている。

[^4]: より秘密性の高い場では、彼らにはそのような遠慮がないことを証言できる。そしてそれはより公になりつつある；例えばY-combinator の新しい[「スタートアップ募集」](https://www.ycombinator.com/rfs)を見よ。その多くの部分で人間労働者の全面的置換を明示的に求めている。彼らを引用すれば、「B2B SaaSの価値提案は人間労働者を段階的により効率的にすることでした。垂直AIエージェントの価値提案は作業を完全に自動化することです...この機会がもう100のユニコーンを生み出すのに十分な大きさである可能性は十分にあります。」（シリコンバレーの話法に詳しくない人のために、「B2B」はbusiness-to-businessの略で、ユニコーンは10億ドル企業のことである。つまり彼らは、他の企業のために労働者を置換する100以上の10億ドル超企業について話しているのだ。）

[^5]: 例えば最近の[米中経済安全保障検討委員会報告書](https://www.uscc.gov/sites/default/files/2024-11/2024_Executive_Summary.pdf)を参照。報告書自体に驚くほど根拠が少なかったにもかかわらず、最上位の推奨事項は米国「議会が汎用人工知能（AGI）能力に向けて競争し、それを獲得することを目的としたマンハッタン計画のようなプログラムを設立し、資金提供する」ことだった。

[^6]: 企業は現在、この地政学的フレーミングを自社のAI開発への制約に対する盾として採用しており、一般的にあからさまに利己的な方法で、時には基本的な意味すらなさない方法でそうしている。Metaの[フロンティアAIへのアプローチ](https://about.fb.com/news/2025/02/meta-approach-frontier-ai/)を考えてみよう。これは同時に、アメリカが「技術革新、経済成長、国家安全保障のリーダーとしての地位を\[確固たるものにする\]」必要があると論じ、また最も強力なAIシステムを公開リリースすることでそうしなければならない—これは地政学的ライバルや敵対国に直接それらを提供することを含む—と論じている。

[^7]: したがって、我々はこれらの技術の管理をAIに委ねることになるだろう。しかしこれは非常に問題のある制御の委任となり、以下で再度取り上げる。

[^8]: 技術開発における競争はしばしば重要な利益をもたらす：独占的支配の防止、イノベーションとコスト削減の促進、多様なアプローチの実現、相互監視の創出。しかしAGIにおいては、これらの利益は競争ダイナミクスと安全予防策削減圧力による独特のリスクと比較検討されなければならない。