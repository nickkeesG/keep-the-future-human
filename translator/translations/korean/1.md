# 제1장 - 서론

인간보다 똑똑한 AI의 전망에 우리가 어떻게 대응할 것인가는 우리 시대의 가장 시급한 문제다. 이 에세이는 나아갈 길을 제시한다.

우리는 인간 시대의 끝자락에 있을지도 모른다.

지난 10년간 우리 종의 역사에서 유례없는 일이 시작되었다. 그 결과는 상당 부분 인류의 미래를 결정하게 될 것이다. 2015년 무렵부터 연구자들은 *특화된* 인공지능(AI) 개발에 성공했다. 바둑과 같은 게임에서 승리하고, 이미지와 음성을 인식하는 등의 작업을 어떤 인간보다도 잘 수행하는 시스템들 말이다.[^1]

이는 놀라운 성공이며, 인류에게 힘을 실어줄 극도로 유용한 시스템과 제품들을 만들어내고 있다. 하지만 특화된 인공지능은 결코 이 분야의 진정한 목표가 아니었다. 오히려 그 목표는 *범용* 목적 AI 시스템, 특히 "인공일반지능(AGI)"이나 "초지능"이라고 불리는 시스템을 만드는 것이었다. 이들은 AI가 현재 바둑, 체스, 포커, 드론 레이싱 등에서 인간을 압도하는 것처럼, 거의 *모든* 작업에서 동시에 인간과 같거나 더 나은 성능을 보이는 시스템들이다. 이것이 많은 주요 AI 기업들의 공언된 목표다.[^2]

*이러한 노력들도 성공하고 있다.* ChatGPT, Gemini, Llama, Grok, Claude, Deepseek 같은 범용 AI 시스템들은 막대한 연산량과 엄청난 데이터를 바탕으로 다양한 작업에서 일반적인 인간과 동등한 수준에 도달했으며, 일부 영역에서는 인간 전문가와도 견줄 만하다. 이제 일부 거대 기술 기업의 AI 엔지니어들은 이러한 거대한 기계 지능 실험을 다음 단계로 밀어붙이기 위해 경쟁하고 있다. 인간의 능력, 전문성, 자율성의 전 범위와 먼저 견주고, 그다음에는 이를 뛰어넘는 단계 말이다.

*이는 임박한 일이다.* 지난 10년간, 현재 경로를 계속 따를 경우 이것이 얼마나 걸릴지에 대한 전문가 추정치는 수십 년(또는 수백 년)에서 한 자릿수 년으로 줄어들었다.

이는 또한 획기적인 중요성과 초월적 위험을 지닌다. AGI 지지자들은 이를 과학적 문제를 해결하고, 질병을 치료하며, 새로운 기술을 개발하고, 단순 반복 작업을 자동화할 긍정적 변화로 본다. 그리고 AI는 분명 이 모든 것을 달성하는 데 도움이 될 수 있다. 실제로 이미 그렇게 하고 있다. 하지만 수십 년간 앨런 튜링부터 스티븐 호킹, 그리고 현재의 제프리 힌턴과 요슈아 벤지오[^3]에 이르기까지 많은 신중한 사상가들이 극명한 경고를 발해왔다. 진정으로 인간보다 똑똑하고, 범용적이며, 자율적인 AI를 구축하는 것은 최소한 사회를 완전히 그리고 돌이킬 수 없게 뒤엎을 것이고, 최악의 경우 인류 멸종을 초래할 것이라고 말이다.[^4]

초지능 AI는 현재 경로에서 빠르게 접근하고 있지만, 결코 불가피한 것은 아니다. 이 에세이는 우리가 왜 그리고 어떻게 이 다가오는 비인간적 미래에 대해 *관문을 차단*해야 하는지, 그리고 대신 무엇을 해야 하는지에 대한 확장된 논증이다.


[^1]: 이 [차트](https://time.com/6300942/ai-progress-charts/)는 일련의 작업들을 보여준다. 이 그래프에 많은 유사한 곡선들을 추가할 수 있다. 특화 AI에서의 이러한 급속한 진보는 해당 분야 전문가들조차 놀라게 했으며, 벤치마크들이 예측보다 몇 년 앞서 돌파되고 있다.

[^2]: Deepmind, OpenAI, Anthropic, X.ai는 모두 AGI 개발이라는 구체적 목표를 가지고 설립되었다. 예를 들어, OpenAI의 헌장은 "모든 인류에게 이익이 되는 인공일반지능" 개발을 목표로 명시적으로 밝히고 있으며, DeepMind의 사명은 "지능을 해결하고, 그다음 그것을 사용해 모든 것을 해결하는 것"이다. Meta, Microsoft 등도 현재 실질적으로 유사한 경로를 추구하고 있다. Meta는 AGI를 개발해 [공개적으로 배포할 계획이라고 밝혔다.](https://www.forbes.com/sites/johnkoetsier/2024/01/18/zuckerberg-on-ai-meta-building-agi-for-everyone-and-open-sourcing-it/)

[^3]: 힌턴과 벤지오는 가장 많이 인용되는 AI 연구자 중 두 명으로, 둘 다 AI 분야의 노벨상인 튜링상을 수상했으며, 힌턴은 추가로 (물리학) 노벨상까지 수상했다.

[^4]: 상업적 인센티브 하에서 거의 제로에 가까운 정부 감독으로 이런 위험을 지닌 무언가를 구축하는 것은 완전히 전례 없는 일이다. 이를 구축하는 사람들 사이에서조차 위험에 대한 논란이 없을 정도다! Deepmind, OpenAI, Anthropic의 리더들을 비롯한 많은 전문가들이 모두 고도 AI가 인류에게 *멸종 위험*을 제기한다는 [성명서](https://www.safe.ai/work/statement-on-ai-risk)에 문자 그대로 서명했다. 경보가 이보다 더 크게 울릴 수는 없으며, 이를 무시하는 사람들은 단순히 AGI와 초지능을 진지하게 받아들이지 않고 있다고 결론지을 수밖에 없다. 이 에세이의 목표 중 하나는 그들이 왜 진지하게 받아들여야 하는지 이해하도록 돕는 것이다.