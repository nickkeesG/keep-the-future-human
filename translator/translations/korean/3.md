# 3장 - 현대 일반 AI 시스템의 핵심 제작 방식

전 세계에서 가장 첨단의 AI 시스템들은 놀랍도록 유사한 방법으로 만들어진다. 여기 그 기본 원리들을 소개한다.

인간을 제대로 이해하려면 생물학, 진화, 육아 등에 대해 알아야 하듯이, AI를 이해하려면 그것이 어떻게 만들어지는지 알아야 한다. 지난 5년간 AI 시스템은 능력과 복잡성 측면에서 엄청나게 발전했다. 이를 가능하게 한 핵심 요인은 대규모 연산량(AI 분야에서는 흔히 "컴퓨트"라고 부른다)의 가용성이었다.

그 규모는 놀랍다. GPT 시리즈, Claude, Gemini 등과 같은 모델을 훈련하는 데는 약 10<sup>25</sup>-10<sup>26</sup>번의 "부동소수점 연산"(FLOP)[^1]이 사용된다.[^2] (비교해보면, 지구상 모든 인간이 5초에 한 번씩 계산을 쉬지 않고 계속한다면, 이를 완수하는 데 약 10억 년이 걸릴 것이다.) 이 어마어마한 연산량 덕분에 수조 개의 모델 가중치를 가진 모델을 테라바이트 규모의 데이터로 훈련할 수 있게 되었다. 이 데이터는 지금까지 작성된 양질의 텍스트 대부분과 방대한 음성, 이미지, 동영상 라이브러리를 포함한다. 여기에 인간의 선호도와 우수한 작업 수행을 강화하는 추가적인 광범위한 훈련을 더하면, 이런 방식으로 훈련된 모델들은 추론과 문제해결을 포함한 다양한 기본적 지적 작업에서 인간과 경쟁할 만한 성능을 보여준다.

또한 이러한 시스템의 *추론* 속도[^3]가 인간의 텍스트 처리 *속도*와 맞먹으려면 초당 얼마나 많은 연산 속도가 필요한지도 (아주 대략적으로) 알고 있다. 약 10<sup>15</sup>-10<sup>16</sup> FLOP/초 정도이다.[^4]

강력하긴 하지만, 이러한 모델들은 본질적으로 핵심적인 한계를 지니고 있다. 마치 개별 인간이 멈춰서 생각하거나 추가 도구를 사용하지 못한 채 분당 일정한 속도로 텍스트만 출력해야 한다면 제약을 받는 것과 매우 유사하다. 보다 최근의 AI 시스템들은 여러 핵심 요소를 결합한 더 복잡한 프로세스와 아키텍처를 통해 이러한 한계를 해결한다:

- 하나 또는 여러 개의 신경망. 하나의 모델이 핵심 인지 능력을 제공하고, 최대 여러 개의 다른 모델들이 보다 특화된 작업을 수행한다.
- 모델이 제공받고 사용할 수 있는 *도구* - 예를 들어 웹 검색, 문서 생성이나 편집, 프로그램 실행 등의 능력
- 신경망의 입력과 출력을 연결하는 *스캐폴딩*. 매우 간단한 스캐폴드는 AI 모델의 두 "인스턴스"가 서로 대화하거나, 하나가 다른 하나의 작업을 검토할 수 있게 해줄 수 있다.[^5]
- *사고의 연쇄*와 관련 프롬프팅 기법들도 비슷한 역할을 한다. 모델이 예를 들어 문제에 대한 여러 접근법을 생성한 다음, 이러한 접근법들을 처리해서 종합적인 답을 도출하게 만든다.
- 도구, 스캐폴딩, 사고의 연쇄를 더 잘 활용하도록 모델을 *재훈련*한다.

이러한 확장 기능들은 매우 강력할 수 있고(AI 시스템 자체를 포함하기도 한다), 이러한 복합 시스템들은 상당히 정교해져서 AI 능력을 극적으로 향상시킬 수 있다.[^6] 최근에는 스캐폴딩과 특히 사고의 연쇄 프롬프팅 기법들(그리고 그 결과를 모델 재훈련에 반영하여 이를 더 잘 활용하게 하는 것)이 [o1](https://openai.com/o1/), [o3](https://openai.com/index/openai-o3-mini/), [DeepSeek R1](https://api-docs.deepseek.com/news/news250120)에서 개발되고 활용되어, 주어진 질의에 대해 여러 차례의 추론을 수행한다.[^7] 이는 사실상 모델이 응답에 대해 "생각할" 수 있게 해주며, 과학, 수학, 프로그래밍 작업에서 이러한 모델들의 고수준 추론 능력을 극적으로 향상시킨다.[^8]

주어진 AI 아키텍처에서 훈련 연산량의 증가는 명확하게 정의된 지표들의 개선으로 [안정적으로 변환될 수 있다](https://arxiv.org/abs/2405.10938). 덜 명확하게 정의된 일반적 능력들(아래에서 논의되는 것들과 같은)의 경우, 그 변환은 덜 명확하고 예측하기 어렵지만, 더 많은 훈련 연산량을 가진 더 큰 모델들이 새롭고 더 나은 능력을 갖게 될 것은 거의 확실하다. 비록 그것이 무엇인지 예측하기는 어렵더라도 말이다.

마찬가지로, 복합 시스템들과 특히 "사고의 연쇄"의 발전(그리고 이것과 잘 작동하는 모델들의 훈련)은 *추론* 연산량에서의 스케일링을 가능하게 했다: 주어진 훈련된 핵심 모델에 대해, 복잡한 문제에 대해 "더 깊고 오래 생각할" 수 있게 해주는 더 많은 연산량이 적용될 때 적어도 일부 AI 시스템 능력이 증가한다. 이는 인간 수준의 성능에 맞추려면 수백 배 또는 수천 배 더 많은 FLOP/초가 필요하다는 가파른 연산 속도 비용을 수반한다.[^9]

급속한 AI 발전을 이끄는 요인의 일부에 불과하지만,[^10] 연산량의 역할과 복합 시스템의 가능성은 통제 불가능한 AGI를 방지하고 더 안전한 대안을 개발하는 데 모두 중요한 것으로 판명될 것이다.

[^1]: 10<sup>27</sup>는 1 뒤에 25개의 0이 따라오는 수, 즉 천조의 천조를 의미한다. FLOP은 단순히 어느 정도 정밀도를 가진 숫자들의 산술적 덧셈이나 곱셈이다. AI 하드웨어 성능은 산술 연산의 정밀도와 컴퓨터 아키텍처에 따라 10배 정도 차이날 수 있다는 점에 주의하라. 논리 게이트 연산(AND, OR, AND NOT)을 세는 것이 더 근본적이겠지만 이들은 일반적으로 이용하거나 벤치마킹하기 어렵다; 현재 목적상 16비트 연산(FP16)으로 표준화하는 것이 유용하지만, 적절한 변환 인수들이 확립되어야 한다.

[^2]: 추정치와 실제 데이터 모음은 [Epoch AI](https://epochai.org/data/large-scale-ai-models)에서 확인할 수 있으며, GPT-4에 대해 약 2×10<sup>25</sup> 16비트 FLOP을 나타낸다; 이는 GPT-4에 대해 [유출된 수치](https://mpost.io/gpt-4s-leaked-details-shed-light-on-its-massive-scale-and-impressive-architecture/)와 대략 일치한다. 다른 2024년 중반 모델들에 대한 추정치들은 모두 GPT-4의 몇 배 범위 내에 있다.

[^3]: 추론은 단순히 신경망에서 출력을 생성하는 과정이다. 훈련은 많은 추론과 모델 가중치 조정의 연속으로 간주될 수 있다.

[^4]: 텍스트 생성에서 원래 GPT-4는 토큰당 560 TFLOP이 필요했다. 인간의 사고를 따라가려면 약 7토큰/초가 필요하므로, 이는 ≈3×10<sup>15</sup> FLOP/초가 된다. 하지만 효율성 개선으로 이는 감소했다; 예를 들어 [이 NVIDIA 브로슈어](https://developer.nvidia.com/blog/supercharging-llama-3-1-across-nvidia-platforms/)는 비교할 만한 성능의 Llama 405B 모델에 대해 3×10<sup>14</sup> FLOP/초 정도의 낮은 수치를 제시한다.

[^5]: 조금 더 복잡한 예로, AI 시스템이 먼저 수학 문제에 대한 여러 가능한 해법을 생성한 다음, 다른 인스턴스를 사용해 각 해법을 검토하고, 마지막으로 세 번째를 사용해 결과를 명확한 설명으로 종합할 수 있다. 이는 단일 패스보다 더 철저하고 신뢰할 만한 문제 해결을 가능하게 한다.

[^6]: 예를 들어 [OpenAI의 "Operator"](https://openai.com/index/introducing-operator/), [Claude의 도구 능력](https://docs.anthropic.com/en/docs/build-with-claude/computer-use), [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)에 대한 세부 정보를 참조하라. OpenAI의 [Deep Research](https://openai.com/index/introducing-deep-research/)는 아마도 상당히 정교한 아키텍처를 가지고 있을 것이지만 세부 사항은 공개되지 않았다.

[^7]: Deepseek R1은 최종 훈련된 모델이 광범위한 사고의 연쇄 추론을 생성하도록 모델을 반복적으로 훈련하고 프롬프팅하는 데 의존한다. o1이나 o3에 대한 아키텍처 세부 사항은 공개되지 않았지만, Deepseek은 추론으로 능력 스케일링을 가능하게 하는 데 특별한 "비밀 공식"이 필요하지 않다고 밝혔다. 하지만 AI의 "현상 유지"를 뒤엎는 것으로 언론의 큰 주목을 받았음에도 불구하고, 이것이 이 에세이의 핵심 주장에 영향을 주지는 않는다.

[^8]: 이러한 모델들은 추론 벤치마크에서 표준 모델들을 크게 능가한다. 예를 들어, 박사 수준의 과학 문제에 대한 엄격한 테스트인 GPQA Diamond Benchmark에서 GPT-4o는 [56%](https://openai.com/index/learning-to-reason-with-llms/)를 기록한 반면, o1과 o3는 각각 78%와 88%를 달성하여 인간 전문가의 평균 점수 70%를 훨씬 넘어섰다.

[^9]: OpenAI의 O3는 아마도 [ARC-AGI 챌린지 문제 각각을 완성하는 데](https://www.interconnects.ai/p/openais-o3-the-2024-finale-of-ai) ∼10<sup>21</sup>-10<sup>22</sup> FLOP를 소모했을 것이다. 유능한 인간들은 이를 (예를 들어) 10-100초에 할 수 있으므로, 이는 ∼10<sup>20</sup> FLOP/초 정도의 수치를 준다.

[^10]: 연산량이 AI 시스템 능력의 핵심 지표이긴 하지만, 데이터 품질과 알고리즘 개선과 상호작용한다. 더 나은 데이터나 알고리즘은 연산 요구량을 줄일 수 있고, 더 많은 연산량은 때로 약한 데이터나 알고리즘을 보상할 수 있다.