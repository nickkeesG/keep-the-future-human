# 5장 - 임계점에서

오늘날의 AI 시스템에서 완전한 인공일반지능(AGI)에 이르는 경로는 충격적일 만큼 짧고 예측 가능해 보인다.

지난 10년간 막대한 [연산량](https://epoch.ai/blog/training-compute-of-frontier-ai-models-grows-by-4-5x-per-year), 인력, [재정](https://arxiv.org/abs/2405.21015) 자원에 힘입어 AI 분야에서 극적인 발전이 있었다. 많은 특화된 AI 애플리케이션이 맡은 작업에서 인간보다 뛰어난 성능을 보이며, 확실히 훨씬 빠르고 저렴하다.[^1] 또한 [바둑](https://www.nature.com/articles/nature16961), [체스](https://arxiv.org/abs/1712.01815), [포커](https://www.deepstack.ai/)와 같은 특정 영역 게임에서 모든 인간을 압도할 수 있는 특화된 초인적 에이전트들이 있으며, 단순화된 시뮬레이션 환경에서 인간만큼 효과적으로 계획하고 행동을 실행할 수 있는 더욱 [범용적인 에이전트](https://deepmind.google/discover/blog/a-generalist-agent/)들도 존재한다.

가장 주목할 만한 것은 OpenAI/Microsoft, Google/Deepmind, Anthropic/Amazon, Facebook/Meta, X.ai/Tesla 등의 현재 범용 AI 시스템들이[^2] 2023년 초부터 등장하여 그 이후 꾸준히(비록 고르지는 않지만) 능력을 향상시켜왔다는 점이다. 이들은 모두 거대한 텍스트 및 멀티미디어 데이터셋에 대한 토큰 예측과 인간 및 다른 AI 시스템으로부터의 광범위한 강화 피드백을 결합하여 만들어졌다. 일부는 광범위한 도구 및 스캐폴딩 시스템도 포함하고 있다.

## 현재 범용 시스템들의 장단점

이러한 시스템들은 지능과 전문성을 측정하도록 설계된 점점 더 광범위한 테스트에서 좋은 성과를 보이고 있으며, 해당 분야 전문가들마저 놀라게 하는 진전을 이루고 있다:

- 처음 출시되었을 때 GPT-4는 SAT, GRE, 입학시험, 변호사시험을 포함한 표준 학업 시험에서 [일반적인 인간 성능과 동등하거나 이를 능가했다](https://arxiv.org/abs/2303.08774). 더 최근의 모델들은 훨씬 더 나은 성능을 보일 가능성이 높지만, 결과가 공개되지 않았다.
- 오랫동안 "진정한" AI의 핵심 기준으로 여겨졌던 튜링 테스트를 현대 언어모델들이 비공식적으로나 [공식 연구](https://arxiv.org/abs/2405.08007)에서나 일상적으로 통과하고 있다.[^3]
- 57개 학문 분야를 아우르는 포괄적인 MMLU 벤치마크에서 [최신 모델들은 도메인 전문가 수준의 점수](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu)(∼90%)를 달성하고 있다.[^4]
- 기술적 전문성이 극적으로 향상되었다: 대학원 수준 물리학의 GPQA 벤치마크에서 [성능이](https://epoch.ai/data/ai-benchmarking-dashboard) 거의 무작위 추측 수준(GPT-4, 2022년)에서 전문가 수준(o1-preview, 2024년)으로 급상승했다.
- AI 저항성을 위해 특별히 설계된 테스트들도 무너지고 있다: OpenAI의 O3가 ARC-AGI 추상 문제해결 벤치마크를 인간 수준으로 해결하고, 최고 전문가 수준의 코딩 성능을 달성하며, 엘리트 수학자들을 겨냥해 설계된 Epoch AI의 "frontier math" 문제에서 25%의 점수를 기록했다고 [보고되었다](https://www.nextbigfuture.com/2024/12/openai-releases-o3-model-with-high-performance-and-high-cost.html).[^5]
- 이러한 추세가 너무나 명확해서 MMLU 개발자는 이제 ["인류의 마지막 시험"](https://agi.safe.ai/)을 만들었다 - AI가 곧 의미 있는 모든 테스트에서 인간 성능을 능가할 가능성을 반영하는 불길한 이름이다. 이 글을 쓰는 시점에서 AI 시스템이 이 극도로 어려운 시험에서 27%([Sam Altman](https://x.com/sama/status/1886220281565381078)에 따르면)와 35%([이 논문](https://arxiv.org/abs/2502.09955)에 따르면)를 달성했다는 주장들이 있다. 어떤 개별 인간도 그렇게 할 가능성은 매우 낮다.

이러한 인상적인 수치들(그리고 상호작용할 때 느껴지는 명백한 지능)[^6]에도 불구하고 (적어도 공개된 버전의) 이러한 신경망이 *할 수 없는* 일들이 많다. 현재 대부분은 서버에만 존재하는 비물리적 형태이며, 기껏해야 텍스트, 소리, 정지 이미지를 처리할 뿐(비디오는 처리하지 못한다.) 결정적으로, 대부분은 높은 정확도를 요구하는 복잡하게 계획된 활동을 수행할 수 없다.[^7] 그리고 현재 공개된 AI 시스템에서는 낮지만 고급 인간 인지에서는 강한 여러 다른 특성들이 있다.

다음 표는 GPT-4o, Claude 3.5 Sonnet, Google Gemini 1.5와 같은 2024년 중반 AI 시스템들을 기준으로 이러한 특성들 중 일부를 나열한다.[^8] 범용 AI가 얼마나 빠르게 더 강력해질 것인가에 대한 핵심 질문은: *기존과 동일한 방식을 더 많이* 수행하는 것 대 추가적이지만 *알려진* 기술들을 더하는 것 대 *정말 새로운* AI 연구 방향을 개발하거나 구현하는 것이 각각 어느 정도까지 결과를 낼 것인가이다. 이에 대한 나의 예측이 표에 제시되어 있으며, 각각의 시나리오가 해당 능력을 인간 수준까지 그리고 그 이상으로 끌어올릴 가능성으로 표현되어 있다.

<table><tbody><tr><th>능력</th><th>능력 설명</th><th>현황/전망</th><th>스케일링/기존기술/신기술</th></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td colspan="4"><em>핵심 인지 능력</em></td></tr><tr><td>추론</td><td>사람들은 정확하고 다단계적인 추론을 할 수 있으며, 규칙을 따르고 정확성을 확인한다.</td><td>확장된 사고 연쇄와 재훈련을 통해 최근 극적인 진전</td><td>95/5/5</td></tr><tr><td>계획</td><td>사람들은 장기적이고 계층적인 계획을 세운다.</td><td>규모와 함께 개선되고 있음; 스캐폴딩과 더 나은 훈련 기법으로 크게 도움받을 수 있음</td><td>10/85/5</td></tr><tr><td>사실 기반성</td><td>범용 AI들이 쿼리를 만족시키기 위해 근거 없는 정보를 지어낸다.</td><td>규모와 함께 개선되고 있음; 모델 내에서 보정 데이터 이용 가능; 스캐폴딩을 통해 확인/개선 가능</td><td>30/65/5</td></tr><tr><td>유연한 문제해결</td><td>인간은 새로운 패턴을 인식하고 복잡한 문제에 대한 새로운 해결책을 발명할 수 있음; 현재 머신러닝 모델들은 어려워함</td><td>규모와 함께 개선되지만 약하게; 신경기호적 또는 일반화된 "탐색" 기법으로 해결 가능할 수 있음</td><td>15/75/10</td></tr><tr><td colspan="4"><em>학습과 지식</em></td></tr><tr><td>학습 및 기억</td><td>사람들은 작업, 단기, 장기 기억을 가지며, 이들은 모두 동적이고 상호연관되어 있다.</td><td>모든 모델이 훈련 중 학습; 범용 AI들은 컨텍스트 윈도우 내에서와 미세조정 중에 학습; "지속 학습" 등 기법이 존재하지만 아직 대형 범용 AI에 통합되지 않음</td><td>5/80/15</td></tr><tr><td>추상화 및 재귀</td><td>사람들은 관계 집합을 추론과 조작을 위해 더 추상적인 것으로 매핑하고 전이시킬 수 있으며, 재귀적인 "메타" 추론을 포함한다.</td><td>규모와 함께 약하게 개선되고 있음; 신경기호 시스템에서 나타날 수 있음</td><td>30/50/20</td></tr><tr><td>세계 모델</td><td>사람들은 문제를 해결하고 물리적 추론을 할 수 있는 예측적 세계 모델을 가지고 지속적으로 업데이트한다</td><td>규모와 함께 개선되고 있음; 업데이트가 학습과 연결됨; 범용 AI들은 실세계 예측에서 약함</td><td>20/50/30</td></tr><tr><td colspan="4"><em>자아와 주체성</em></td></tr><tr><td>주체성</td><td>사람들은 계획/예측에 기반해 목표를 추구하기 위해 행동을 취할 수 있다.</td><td>많은 머신러닝 시스템이 주체적임; 대규모 언어모델들은 래퍼를 통해 에이전트로 만들 수 있음</td><td>5/90/5</td></tr><tr><td>자기주도성</td><td>사람들은 내부에서 생성된 동기와 욕구로 자신만의 목표를 개발하고 추구한다.</td><td>주로 주체성과 독창성으로 구성됨; 추상적 목표를 가진 복잡한 주체적 시스템에서 나타날 가능성</td><td>40/45/15</td></tr><tr><td>자기참조</td><td>사람들은 환경/맥락 내에 위치한 자신을 이해하고 추론한다.</td><td>규모와 함께 개선되고 있으며 훈련 보상으로 강화될 수 있음</td><td>70/15/15</td></tr><tr><td>자기인식</td><td>사람들은 자신의 사고와 정신 상태에 대한 지식을 가지고 이를 추론할 수 있다.</td><td>어떤 의미에서 범용 AI들에게 존재하며, 이들은 틀림없이 자기인식을 위한 고전적인 "거울 테스트"를 통과할 수 있음. 스캐폴딩으로 개선될 수 있지만, 이것이 충분한지는 불분명</td><td>20/55/25</td></tr><tr><td colspan="4"><em>인터페이스와 환경</em></td></tr><tr><td>체화된 지능</td><td>사람들은 실세계 환경을 이해하고 적극적으로 상호작용한다.</td><td>강화학습이 시뮬레이션과 실세계(로봇) 환경에서 잘 작동하며 멀티모달 트랜스포머에 통합될 수 있음</td><td>5/85/10</td></tr><tr><td>다감각 처리</td><td>사람들은 시각, 청각, 기타 감각 스트림을 통합하고 실시간으로 처리한다.</td><td>다중 모달리티 훈련이 "그냥 작동"하는 것으로 보이며, 규모와 함께 개선됨. 실시간 비디오 처리는 어렵지만 예를 들어 자율주행 시스템이 빠르게 개선되고 있음</td><td>30/60/10</td></tr><tr><td colspan="4"><em>고차원 능력</em></td></tr><tr><td>독창성</td><td>현재 머신러닝 모델들은 기존 아이디어/작품을 변형하고 결합하는 창의성을 보이지만, 사람들은 때로 자신의 정체성과 연결된 새로운 프레임워크와 구조를 구축할 수 있다.</td><td>"창의성"과 구분하기 어려울 수 있으며, 이것이 독창성으로 확장될 수 있음; 창의성과 자기인식에서 나타날 수 있음</td><td>50/40/10</td></tr><tr><td>감각능력</td><td>사람들은 질감을 경험하며; 이는 긍정적, 부정적 또는 중성적 감정가를 가질 수 있음; 사람이 된다는 것은 "무언가 같은" 것이다.</td><td>주어진 시스템이 이것을 가지고 있는지 판단하기 매우 어렵고 철학적으로 복잡함</td><td>5/10/85</td></tr></tbody></table>

현대 범용 AI 시스템에서 현재 인간 전문가 수준 이하인 핵심 능력들을 유형별로 그룹화. 세 번째 열은 현재 상황을 요약. 마지막 열은 인간 수준 성능이 달성될 가능성(%)을 다음을 통해 예측: 현재 기술의 스케일링 / 알려진 기술과의 결합 / 새로운 기술 개발. 이러한 능력들은 독립적이지 않으며, 어느 하나의 증가는 일반적으로 다른 것들의 증가를 동반한다. 모든 것이 (특히 감각능력이) AI 개발을 발전시킬 수 있는 AI 시스템에 필요한 것은 아니라는 점을 주목하라. 이는 강력하지만 무감각한 AI의 가능성을 강조한다.

이런 식으로 "빠진 것"을 분해해보면 기존 또는 알려진 기술들을 스케일링함으로써 광범위하게 인간을 넘어서는 지능을 향해 상당히 순조롭게 나아가고 있음이 꽤 명확해진다.[^9]

여전히 놀라운 일들이 있을 수 있다. "감각능력"을 제쳐두더라도, 나열된 핵심 인지 능력 중 일부는 현재 기술로는 정말 할 수 없고 새로운 기술이 필요할 수 있다. 하지만 이것을 생각해보자. 세계 최대 기업들 중 다수가 현재 기울이고 있는 노력은 아폴로 프로젝트의 몇 배, 맨해튼 프로젝트의 수십 배에 달하는 지출에 해당하며,[^10] 전례 없는 급여로 수천 명의 최고 기술 인재들을 고용하고 있다. 지난 몇 년간의 역학은 이제 역사상 그 어떤 시도보다도 더 많은 인간 지적 화력을(이제 AI도 추가되어) 이 일에 집중시켜왔다. 우리는 실패에 베팅해서는 안 된다.

## 큰 목표: 범용 자율 에이전트

지난 몇 년간 범용 AI의 개발은 범용적이고 강력하지만 도구와 같은 AI를 만드는 데 초점을 맞춰왔다: 주로 (상당히) 충실한 보조자 역할을 하며, 일반적으로 스스로 행동을 취하지는 않는다. 이는 부분적으로는 의도된 설계이지만, 주로 이러한 시스템들이 복잡한 행동을 맡기기에는 관련 기술에서 충분히 능숙하지 않았기 때문이다.[^11]

하지만 AI 회사들과 연구자들은 점점 더 *자율적인* 전문가 수준의 범용 에이전트를 향해 [초점을 이동](https://www.axios.com/2025/01/23/davos-2025-ai-agents)시키고 있다.[^12] 이는 시스템들이 사용자가 실제 행동을 위임할 수 있는 인간 보조자처럼 더 많이 행동할 수 있게 해줄 것이다.[^13] 그렇게 하려면 무엇이 필요할까? "빠진 것" 표의 여러 능력들이 관련되어 있는데, 강한 사실 기반성, 학습과 기억, 추상화와 재귀, 세계 모델링(지능을 위해), 계획, 주체성, 독창성, 자기주도성, 자기참조, 자기인식(자율성을 위해), 그리고 다감각 처리, 체화된 지능, 유연한 문제해결(범용성을 위해)이 포함된다.[^14]

높은 자율성(행동의 독립성), 높은 범용성(범위와 작업 폭), 높은 지능(인지 작업에서의 능력)의 이런 삼중 교집합은 현재 인간에게만 고유하다. 이것이 많은 사람들이 AGI를 생각할 때 암묵적으로 염두에 두는 것일 가능성이 높다 - 그 가치와 위험 모두 측면에서 말이다.

이는 A-G-I를 ***A***utonomous(자율)- ***G***eneral(범용)- ***I***ntelligence(지능)로 정의하는 또 다른 방법을 제공하며, 이 삼중 교집합이 고능력 시스템들의 위험과 보상을 이해하고 AI 거버넌스에서 매우 가치 있는 렌즈를 제공한다는 것을 보게 될 것이다.

![](https://keepthefuturehuman.ai/essay/_next/image?url=https%3A%2F%2Fkeepthefuturehuman.ai%2Fwp-content%2Fuploads%2F2025%2F02%2FAGI-Venn-Diagram-Simple-1024x1024.png&w=3840&q=75) 변혁적인 A-G-I의 힘과 위험 영역은 세 가지 핵심 속성의 교집합에서 나타난다: 높은 자율성, 높은 지능, 높은 범용성.

## AI (자기)개선 사이클

AI 진보를 이해하는 데 있어 마지막으로 중요한 요소는 AI의 독특한 기술적 피드백 루프이다. AI를 개발하는 데 있어 성공은 - 입증된 시스템과 배포된 제품 모두에서 - 추가적인 투자, 인재, 경쟁을 가져오며, 우리는 현재 수천억 달러, 아니 수조 달러의 투자를 이끌고 있는 거대한 AI 과대광고-플러스-현실 피드백 루프의 한복판에 있다.

이런 유형의 피드백 사이클은 어떤 기술에서든 일어날 수 있으며, 시장 성공이 투자를 낳고, 이것이 개선과 더 나은 시장 성공을 낳는 여러 기술에서 이를 봐왔다. 하지만 AI 개발은 더 나아가, 이제 AI 시스템들이 새롭고 더 강력한 AI 시스템을 개발하는 데 도움을 주고 있다.[^15] 우리는 이 피드백 루프를 5단계로 생각해볼 수 있으며, 각 단계는 이전 단계보다 더 짧은 시간 척도를 가진다고 표에 나와 있듯이 말이다.

*AI 개선 사이클은 여러 시간 척도에 걸쳐 작동하며, 각 단계는 잠재적으로 후속 단계들을 가속화할 수 있다. 초기 단계들은 이미 잘 진행되고 있으며, 후기 단계들은 여전히 추측의 영역이지만 일단 잠금이 해제되면 매우 빠르게 진행될 수 있다.*

이러한 단계들 중 몇 개는 이미 진행 중이며, 몇 개는 명백히 시작되고 있다. 마지막 단계인 AI 시스템들이 자율적으로 자기 자신을 개선하는 것은 매우 강력한 AI 시스템의 위험에 대한 문헌에서 주요 소재였으며, 그럴 만한 이유가 있다.[^16] 하지만 이것이 이미 시작되었고 기술의 급속한 발전에서 더 많은 놀라움으로 이어질 수 있는 피드백 사이클의 가장 극단적인 형태일 뿐이라는 점을 주목하는 것이 중요하다.


[^1]: 당신이 아마 생각하는 것보다 훨씬 더 많은 이런 AI를 사용하고 있다. 음성 생성과 인식, 이미지 처리, 뉴스피드 알고리즘 등을 구동하고 있다.

[^2]: 이들 기업 쌍 간의 관계는 매우 복잡하고 미묘하지만, 현재 AI 개발에 참여하고 있는 기업들의 막대한 전체 시가총액과 Anthropic과 같은 "더 작은" 회사들 뒤에도 투자와 주요 파트너십 거래를 통해 엄청나게 깊은 주머니가 있다는 것을 나타내기 위해 명시적으로 나열했다.

[^3]: 튜링 테스트를 폄하하는 것이 유행이 되었지만, 그것은 매우 강력하고 범용적이다. 약한 버전에서는 AI와 (인간처럼 행동하도록 훈련된) 상호작용하는 일반적인 사람들이 짧은 기간 동안 일반적인 방식으로 그것이 AI인지 알 수 있는지를 나타낸다. 그들은 알 수 없다. 둘째, 고도로 적대적인 튜링 테스트는 본질적으로 인간 능력과 지능의 모든 요소를 탐사할 수 있다 - 예를 들어 AI 시스템을 인간 전문가와 비교하고 다른 인간 전문가들이 평가하는 식으로. AI 평가의 대부분이 일반화된 형태의 튜링 테스트라는 의미가 있다.

[^4]: 이는 도메인별로 - 어떤 인간도 모든 과목에서 동시에 그런 점수를 달성할 수는 없을 것이다.

[^5]: 이것들은 훌륭한 수학자들조차 해결할 수 있다면 상당한 시간이 걸릴 문제들이다.

[^6]: 회의적인 성향이라면 회의론을 유지하되 최신 모델들을 정말로 직접 써보고, 그들이 통과할 수 있는 테스트 문제들 중 일부를 직접 시도해보라. 물리학 교수로서 나는 예를 들어 최고 모델들이 우리 학과의 대학원 자격시험을 통과할 것이라고 거의 확실하게 예측한다.

[^7]: 이것과 착각과 같은 다른 약점들이 시장 채택을 늦추고 인식된 능력과 주장된 능력(이것 역시 치열한 시장 경쟁과 투자 유치 필요성의 렌즈를 통해 봐야 한다) 사이의 격차를 만들었다. 이것이 AI 진보의 실제 상황에 대해 대중과 정책입안자들을 모두 혼란스럽게 했다. 과대광고와 일치하지 않을 수도 있지만, 진보는 매우 실재한다.

[^8]: 그 이후의 주요 진전은 추론 중 더 많은 연산량과 더 큰 강화학습을 활용하여 최고 품질의 추론을 위해 훈련된 시스템들의 개발이었다. 이러한 모델들은 새롭고 그들의 능력이 덜 테스트되었기 때문에, 본질적으로 해결된 것으로 간주하는 "추론"을 제외하고는 이 표를 전면 개편하지 않았다. 하지만 그러한 시스템들의 경험되고 보고된 능력들을 바탕으로 예측을 업데이트했다.

[^9]: 1960년대와 1980년대의 이전 AI 낙관주의 물결들은 약속된 능력들이 실현되지 못했을 때 "AI 겨울"로 끝났다. 하지만 현재의 물결은 많은 도메인에서 초인적 성능을 달성했고 막대한 연산 자원과 상업적 성공에 뒷받침되어 근본적으로 다르다.

[^10]: 전체 아폴로 프로젝트는 [2020년 달러로 약 2,500억 달러가 들었고](https://www.planetary.org/space-policy/cost-of-apollo), 맨해튼 프로젝트는 [그것의 10분의 1도 안 됐다](https://www.brookings.edu/the-costs-of-the-manhattan-project/). 골드만삭스는 [향후 몇 년간 AI 데이터센터만을 위해 1조 달러가 지출될 것이라고](https://www.datacenterdynamics.com/en/news/goldman-sachs-1tn-to-be-spent-on-ai-data-centers-chips-and-utility-upgrades-with-little-to-show-for-it-so-far/) 전망한다.

[^11]: 인간들도 많은 실수를 하지만, 우리는 우리가 얼마나 신뢰할 수 있는지를 과소평가한다! 확률이 곱해지기 때문에, 올바르게 하기 위해 20단계가 필요한 작업은 절반의 시간에 올바르게 완료하기 위해서만도 각 단계가 97% 신뢰할 수 있어야 한다. 우리는 그런 작업들을 항상 한다.

[^12]: 이 방향으로의 강한 움직임이 OpenAI의 ["Deep Research"](https://openai.com/index/introducing-deep-research/) 보조자로 최근에 이루어졌는데, 이는 인터넷에서 복잡한 작업을 위한 다단계 연구를 자율적으로 수행하며 "복잡한 작업을 위해 인터넷에서 다단계 연구를 수행하는 새로운 주체적 능력"이라고 설명된다.

[^13]: 그 성가신 PDF 양식 작성하기, 항공편 예약하기 같은 것들. 하지만 20개 분야의 박사학위와 함께! 그러니까 또한: 당신을 위해 그 논문 쓰기, 당신을 위해 그 계약 협상하기, 당신을 위해 그 정리 증명하기, 당신을 위해 그 광고 캠페인 만들기 등등. *당신*은 무엇을 하는가? 물론 그것에게 무엇을 할지 말해주는 것이다.

[^14]: 감각능력은 명확하게 필요하지 *않으며*, 이 삼중 교집합의 AI가 반드시 그것을 의미하지도 않는다는 점을 주목하라.

[^15]: 여기서 가장 가까운 유사점은 아마도 칩 기술일 것인데, 컴퓨터 기술이 사람들이 다음 세대 칩 기술을 설계하는 데 도움을 주면서 수십 년간 무어의 법칙을 유지해온 개발이다. 하지만 AI는 훨씬 더 직접적일 것이다.

[^16]: AI가 - 곧 - 며칠이나 몇 주의 시간 척도로 스스로를 개선할 수 있다는 것을 잠시 받아들여보는 것이 중요하다. 아니면 그보다도 짧게. 누군가 AI 능력이 분명히 멀리 있다고 말할 때 이것을 염두에 두어라.