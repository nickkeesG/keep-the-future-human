# 6장 - AGI를 향한 경쟁

기업과 국가가 AGI 개발 경쟁에 뛰어드는 원동력은 무엇일까?

최근 AI 분야의 급속한 발전은 그 결과이면서 동시에 원인이 되어 엄청난 관심과 투자를 불러일으켰다. 이는 부분적으로는 AI 개발의 성공에서 비롯되었지만, 더 복잡한 배경이 있다. 지구상에서 가장 거대한 기업들과 심지어 국가들까지 단순한 AI가 아니라 AGI와 초지능을 구축하려고 경쟁하는 이유는 무엇일까?

## AI 연구를 인간 수준 AI로 이끈 동력

약 5년 전까지만 해도 AI는 주로 학술적이고 과학적인 연구 문제였으며, 따라서 호기심과 지능을 이해하고 새로운 기질에서 이를 창조하려는 욕구에 의해 주도되었다.

이 시기에는 대부분의 연구자들이 AI의 이점이나 위험에 상대적으로 적은 관심을 보였다. AI를 개발해야 하는 이유를 물으면, 다소 막연하게 AI가 도움을 줄 수 있는 문제들의 목록을 나열하는 것이 일반적인 대답이었다: 새로운 의약품, 새로운 소재, 새로운 과학, 더 똑똑한 프로세스, 그리고 전반적으로 사람들의 삶을 개선하는 것.[^1]

이는 훌륭한 목표들이다![^2] AI 전반이 아니라 AGI가 이러한 목표에 필요한지는 의문을 제기할 수 있고 또 그럴 것이지만, 이러한 목표들은 많은 AI 연구자들이 시작할 때 가졌던 이상주의를 보여준다.

그러나 지난 5년 동안 AI는 상대적으로 순수한 연구 분야에서 세계 최대 기업들이 주도하는 훨씬 더 공학적이고 제품 중심적인 분야로 변모했다.[^3] 연구자들은 여전히 중요하지만 더 이상 이 과정을 주도하지 않는다.

## 기업들이 AGI를 만들려는 이유는 무엇인가?

그렇다면 거대 기업들(그리고 투자자들은 더욱더)이 AGI 구축에 막대한 자원을 쏟아붓는 이유는 무엇일까? 대부분의 기업들이 꽤 솔직하게 밝히는 두 가지 동력이 있다: 그들은 AI를 사회의 생산성 동력으로, 그리고 자신들의 이익 동력으로 보고 있다. 범용 AI는 본질적으로 범용이기 때문에 엄청난 상금이 걸려 있다: 제품과 서비스를 만들 분야를 선택하는 대신 *모든 분야를 한 번에* 시도할 수 있다. 빅테크 기업들은 디지털 상품과 서비스를 생산하여 거대해졌으며, 적어도 일부 임원들은 AI를 검색, 소셜 미디어, 노트북, 휴대폰 등이 제공하는 것과 유사하지만 더 확장된 위험과 이익을 가지고 이를 잘 제공하는 다음 단계로 보고 있는 것이 확실하다.

하지만 왜 AGI인가? 이에 대한 매우 간단한 답이 있는데, 대부분의 기업과 투자자들은 공개적으로 논의하기를 꺼린다.[^4]

AGI는 직접적으로, 일대일로 *노동자를 대체할 수* 있기 때문이다.

보완하거나, 권한을 부여하거나, 더 생산적으로 만드는 것이 아니다. 심지어 *대체하는* 것도 아니다. 이 모든 것은 비AGI로도 가능하고 실제로 이루어질 것이다. AGI는 구체적으로 사고하는 노동자들을(그리고 로봇공학과 함께라면 많은 육체노동자들까지도) 완전히 *대체할 수* 있는 것이다. 이러한 견해의 근거로 OpenAI의 [(공개적으로 발표된) AGI 정의](https://openai.com/our-structure/)만 봐도 충분한데, 그것은 "경제적으로 가치 있는 대부분의 일에서 인간을 능가하는 고도로 자율적인 시스템"이다.

여기서 (기업들에게!) 주어지는 상금은 엄청나다. 노동 비용은 세계 약 100조 달러 규모의 전 세계 경제에서 상당한 비율을 차지한다. 이중 일부만이라도 인간 노동을 AI 노동으로 대체하여 포획된다면, 이는 연간 수조 달러의 수익이다. AI 기업들은 또한 누가 돈을 지불할 의향이 있는지도 잘 알고 있다. 그들이 보기에, 당신은 생산성 도구에 연간 수천 달러를 지불하지 않을 것이다. 하지만 기업은 가능하다면 당신의 노동을 대체하기 위해 연간 수천 달러를 지불*할* 것이다.

## 국가들이 AGI 경쟁에 뛰어들 수밖에 없다고 느끼는 이유

AGI 추구에 대한 국가들의 공식적인 동기는 경제적, 과학적 리더십에 초점을 맞춘다. 이 논리는 설득력이 있다: AGI는 과학 연구, 기술 개발, 경제 성장을 극적으로 가속화할 수 있다. 이해관계를 고려할 때, 어떤 주요 강국도 뒤처질 수 없다고 그들은 주장한다.[^5]

하지만 추가적이고 대부분 표면화되지 않은 동력들도 있다. 특정 군사 및 국가보안 지도자들이 극도로 강력하고 파국적으로 위험한 기술에 대해 논의하기 위해 비공개로 만날 때, 그들의 초점이 "어떻게 이러한 위험을 피할 것인가"가 아니라 "어떻게 이것을 먼저 얻을 것인가"라는 데 있다는 것은 의심의 여지가 없다. 군사 및 정보 지도자들은 AGI를 군사 업무의 잠재적 혁명으로, 아마도 핵무기 이후 가장 중대한 혁명으로 본다. 우려는 AGI를 먼저 개발하는 국가가 극복 불가능한 전략적 우위를 얻을 수 있다는 것이다. 이는 전형적인 군비 경쟁 역학을 만들어낸다.

우리는 이러한 "AGI 경쟁" 사고가[^6] 설득력이 있지만 심각하게 결함이 있다는 것을 보게 될 것이다. 이는 경쟁이 위험하고 모험적이어서가 아니라 - 물론 그렇기도 하지만 - 기술의 본질 때문이다. 암묵적인 가정은 AGI가 다른 기술들처럼 그것을 개발한 국가에 의해 통제 가능하고, 그것을 가장 많이 보유한 사회에 권력을 부여하는 혜택이라는 것이다. 앞으로 보게 되겠지만, 아마도 둘 다 아닐 것이다.

## 초지능은 왜인가?

기업들이 공개적으로는 생산성에, 국가들이 경제적, 기술적 성장에 초점을 맞추는 반면, 의도적으로 완전한 AGI와 초지능을 추구하는 이들에게 이것들은 시작에 불과하다. 그들이 실제로 염두에 두고 있는 것은 무엇인가? 공개적으로는 거의 말하지 않지만, 다음과 같은 것들을 포함한다:

1. 많거나 모든 질병의 치료법;
2. 노화의 중단과 역전;
3. 핵융합 같은 새로운 지속 가능한 에너지원;
4. 유전공학을 통한 인간 업그레이드나 맞춤형 생명체;
5. 나노기술과 분자 제조;
6. 마음 업로드;
7. 이색적 물리학이나 우주 기술;
8. 초인간적 조언과 의사결정 지원;
9. 초인간적 계획과 조정.

처음 세 가지는 대체로 "단일 날개" 기술들이다 - 즉, 상당히 강하게 순 긍정적일 가능성이 높다. 질병을 치료하거나 선택한다면 더 오래 살 수 있는 것에 반대하기는 어렵다. 그리고 우리는 이미 핵융합의 부정적인 면을(핵무기 형태로) 거두어들였으니, 이제 긍정적인 면을 얻는다면 좋을 것이다. 이 첫 번째 범주의 질문은 이러한 기술들을 더 빨리 얻는 것이 위험을 상쇄하는지이다.

다음 네 가지는 명백히 양날의 검이다: AI와 마찬가지로 잠재적으로 거대한 장점과 엄청난 위험을 모두 가진 변혁적 기술들이다. 이 모든 것들이 내일 블랙박스에서 튀어나와 배치된다면 관리하기가 믿을 수 없이 어려울 것이다.[^7]

마지막 두 가지는 기술을 발명하는 것이 아니라 초인간적 AI가 직접 일을 하는 것에 관한 것이다. 더 정확히 말하면, 완곡어법을 제쳐두고, 이는 강력한 AI 시스템이 사람들에게 무엇을 할지 말해주는 것을 포함한다. 조언을 하는 시스템이 조언받는 사람보다 훨씬 더 강력하여, 조언받는 사람이 결정의 근거를 의미 있게 이해할 수 없는 상황에서(또는 이것이 제공되더라도, 조언자가 다른 결정에 대해서도 마찬가지로 설득력 있는 근거를 제공하지 않을 것이라고 신뢰할 수 없는 상황에서) 이를 "조언"이라고 부르는 것은 기만적이다.

이는 위 목록에서 빠진 핵심 항목을 지적한다:

10. 권력.

초인간적 AI를 향한 현재 경쟁의 기저에 있는 것의 대부분이 *지능 = 권력*이라는 아이디어라는 것은 명백하다. 각 경쟁자는 자신이 그 권력의 최고 보유자가 될 것이며, 표면적으로는 선의의 이유로 그것을 휘두를 수 있을 것이고 그것이 자신의 통제에서 미끄러지거나 빼앗기지 않을 것이라고 기대하고 있다.

즉, 기업과 국가들이 실제로 쫓고 있는 것은 AGI와 초지능의 결실뿐만 아니라 누가 그것들에 접근할 수 있고 어떻게 사용될지를 통제할 권력이다. 기업들은 자신들을 주주와 인류를 위해 봉사하는 이 권력의 책임감 있는 관리자로 본다; 국가들은 자신들을 적대적 세력이 결정적 우위를 얻는 것을 막는 필요한 수호자로 본다. 둘 다 위험할 정도로 틀렸으며, 초지능은 본질적으로 어떤 인간 기관에 의해서도 확실하게 통제될 수 없다는 것을 인식하지 못하고 있다. 우리는 초지능 시스템의 본질과 역학이 인간의 통제를 극도로 어렵게, 불가능하지는 않을지라도, 만든다는 것을 보게 될 것이다.

이러한 경쟁 역학 - 기업적이든 지정학적이든 - 은 결정적으로 중단되지 않는 한 특정 위험들을 거의 불가피하게 만든다. 이제 이러한 위험들과 왜 그것들이 경쟁적인[^8] 개발 패러다임 내에서는 적절히 완화될 수 없는지를 살펴보자.


[^1]: 더 정확한 가치 있는 목표 목록은 UN [지속가능발전목표](https://sdgs.un.org/goals)이다. 이것들은 어떤 의미에서 우리가 세계에서 개선되기를 바라는 것에 대한 전 지구적 합의 목표에 가장 가까운 것이다. AI가 도움을 줄 수 있다.

[^2]: 일반적으로 기술은 수천 년이 증명하듯이 인간의 복지를 위한 변혁적인 경제적, 사회적 힘을 가지고 있다. 이러한 맥락에서, 긍정적인 AGI 비전에 대한 길고 설득력 있는 해설은 Anthropic 창립자 Dario Amodei의 [이 에세이](https://darioamodei.com/machines-of-loving-grace)에서 찾을 수 있다.

[^3]: 민간 AI 투자는 [2018-19년경부터 급증하기 시작하여 그 무렵 공공 투자를 넘어섰고](https://cset.georgetown.edu/publication/tracking-ai-investment/), 그 이후로 이를 크게 앞질렀다.

[^4]: 더 비공개적인 자리에서는 그들이 그런 거리낌이 없다는 것을 내가 증언할 수 있다. 그리고 이는 점점 더 공개되고 있다; 예를 들어 Y-combinator의 새로운 ["스타트업 요청"](https://www.ycombinator.com/rfs)을 보라. 이 중 많은 부분이 인간 노동자의 전면적 대체를 명시적으로 요구한다. 그들을 인용하면, "B2B SaaS의 가치 제안은 인간 노동자를 점진적으로 더 효율적으로 만드는 것이었다. 수직 AI 에이전트의 가치 제안은 업무를 완전히 자동화하는 것이다...이 기회가 또 다른 100개의 유니콘을 만들어낼 만큼 충분히 클 가능성이 있다." (실리콘밸리 용어에 익숙하지 않은 사람들을 위해, "B2B"는 기업간 거래이고 유니콘은 10억 달러 기업이다. 즉 그들은 다른 기업들을 위해 노동자를 대체하는 천억 달러 이상의 가치를 가진 기업 100개 이상에 대해 말하고 있다.)

[^5]: 예를 들어 최근의 [미-중 경제안보검토위원회 보고서](https://www.uscc.gov/sites/default/files/2024-11/2024_Executive_Summary.pdf)를 보라. 보고서 자체에는 놀랍게도 정당화 근거가 거의 없었지만, 최우선 권고사항은 미국 "의회가 인공일반지능(AGI) 역량을 경쟁적으로 확보하는 데 전념하는 맨해튼 프로젝트와 같은 프로그램을 설립하고 자금을 지원"하는 것이었다.

[^6]: 기업들은 이제 이러한 지정학적 틀을 자신들의 AI 개발에 대한 모든 제약에 대한 방패막으로 채택하고 있으며, 일반적으로 뻔뻔스럽게 자기중심적인 방식으로, 때로는 기본적인 상식조차 맞지 않는 방식으로 그렇게 하고 있다. Meta의 [프론티어 AI에 대한 접근법](https://about.fb.com/news/2025/02/meta-approach-frontier-ai/)을 생각해보자. 이는 미국이 "기술 혁신, 경제 성장, 국가 안보 분야의 리더로서의 지위를 \[확고히\]" 해야 한다고 동시에 주장하면서도, 가장 강력한 AI 시스템을 공개적으로 출시함으로써 그렇게 해야 한다고 주장한다 - 이는 지정학적 경쟁자와 적대자들에게 직접 제공하는 것을 포함한다.

[^7]: 따라서 우리는 아마도 이러한 기술들의 관리를 AI에 맡겨야 할 것이다. 하지만 이는 매우 문제가 되는 통제권 위임이 될 것인데, 이에 대해서는 아래에서 다시 다루겠다.

[^8]: 기술 개발에서의 경쟁은 종종 중요한 이익을 가져온다: 독점적 통제를 방지하고, 혁신과 비용 절감을 추진하며, 다양한 접근법을 가능하게 하고, 상호 감시를 만들어낸다. 그러나 AGI의 경우 이러한 이익들은 경쟁 역학과 안전 예방조치를 줄이라는 압력으로부터 오는 고유한 위험들과 비교 검토되어야 한다.