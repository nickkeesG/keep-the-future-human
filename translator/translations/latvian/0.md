# Kopsavilkums

Augsta līmeņa esejas pārskats. Ja jums ir maz laika, iegūstiet visas galvenās idejas tikai 10 minūtēs.

Dramatiskie sasniegumi mākslīgajā intelektā pēdējās desmitgades laikā (šaurās nozīmes AI) un pēdējos gados (vispārējās nozīmes AI) ir pārveidojuši AI no nišas akadēmiskās jomas par daudzu pasaules lielāko uzņēmumu galveno biznesa stratēģiju, ar simtiem miljardu dolāru ikgadējām investīcijām tehnikās un tehnoloģijās AI spēju attīstībai.

Tagad mēs nonākam pie kritiski svarīga pagrieziena punkta. Tā kā jauno AI sistēmu spējas sāk līdzināties un pārspēt cilvēku spējas daudzos kognitīvajos jomās, cilvēcei jāizšķiras: cik tālu mēs ejam un kādā virzienā?

AI, tāpat kā jebkura tehnoloģija, sākās ar mērķi uzlabot lietas savam radītājam. Bet mūsu pašreizējā trajektorija un netiešā izvēle ir nekontrolēta sacīkste uz arvien jaudīgākām sistēmām, ko virza ekonomiskie stimuli dažiem milzīgiem tehnoloģiju uzņēmumiem, kas cenšas automatizēt lielas daļas no pašreizējās ekonomiskās darbības un cilvēku darba. Ja šī sacīkste turpinās vēl ilgi, ir neizbēgams uzvarētājs: pats AI – ātrāka, gudrāka, lētāka alternatīva cilvēkiem mūsu ekonomikā, mūsu domāšanā, mūsu lēmumos un galu galā mūsu civilizācijas kontrolē.

Bet mēs varam izdarīt citu izvēli: caur savām valdībām mēs varam pārņemt kontroli pār AI attīstības procesu, lai noteiktu skaidrus ierobežojumus, līnijas, kuras nedrīkstam šķērsot, un lietas, ko vienkārši nedarīsim – kā mēs esam darījuši ar kodoltehnoloģijām, masu iznīcināšanas ieročiem, kosmosa ieročiem, videi kaitīgiem procesiem, cilvēku bioinženieriju un eigēniku. Vissvarīgāk, mēs varam nodrošināt, ka AI paliek kā rīks cilvēku iespēju paplašināšanai, nevis jauna suga, kas mūs aizstāj un galu galā nomaina.

Šis esejs argumentē, ka mums vajadzētu *saglabāt nākotni cilvēcisku*, aizverot "vārtus" gudrākam par cilvēku, autonomam, vispārējās nozīmes AI – dažkārt saucot to par "MVI" – un jo īpaši augsti pārcilvēciskajai versijai, ko dažkārt sauc par "superintelektu". Tā vietā mums vajadzētu fokusēties uz jaudīgiem, uzticamiem AI rīkiem, kas var dot spēku indivīdiem un transformējoši uzlabot cilvēku sabiedrību spējas darīt to, ko tās dara vislabāk. Šī argumenta struktūra īsumā seko tālāk.

## AI ir atšķirīgs

AI sistēmas fundamentāli atšķiras no citām tehnoloģijām. Kamēr tradicionālā programmatūra seko precīzām instrukcijām, AI sistēmas mācās, kā sasniegt mērķus, nepastāstot tām precīzi kā. Tas padara tās jaudīgas: ja mēs varam skaidri definēt mērķi vai panākumu metriku, lielākajā daļā gadījumu AI sistēma var iemācīties to sasniegt. Bet tas arī padara tās būtībā neprognozējamas: mēs nevaram droši noteikt, kādas darbības tās veiks, lai sasniegtu savus mērķus.

Tās ir arī lielākoties neizskaidrojamas: lai gan tās daļēji ir kods, tās lielākoties ir milzīgs neskaidru skaitļu kopums – neironu tīklu "svari" – kas nav analizējami; mēs neesam daudz labāki to iekšējo mehānismu izpratnē nekā domu noskaidrošanā, ieskatoties bioloģiskajās smadzenēs.

Šis digitālo neironu tīklu apmācības pamatveids strauji palielinās sarežģītībā. Jaudīgākās AI sistēmas tiek radītas ar masīviem skaitļošanas eksperimentiem, izmantojot specializētu aparatūru neironu tīklu apmācībai uz milzīgām datu kopām, ko pēc tam papildina ar programmatūras rīkiem un virsbūvi.

Tas ir novedis pie ļoti jaudīgu rīku radīšanas teksta un attēlu veidošanai un apstrādei, matemātisku un zinātnisku spriedumu veikšanai, informācijas apkopošanai un interaktīvai cilvēku zināšanu milzīgā krājuma vaicāšanai.

Diemžēl, kamēr jaudīgāku, uzticamāku tehnoloģisko rīku attīstība ir tas, ko mums *vajadzētu* darīt, un ko gandrīz visi vēlas un saka, ka vēlas, tā nav trajektorija, uz kuras mēs faktiski atrodamies.

## MVI un superintelekts

Kopš jomas pirmsākumiem AI pētniecība tā vietā ir fokusējusies uz citu mērķi: Mākslīgo vispārējo intelektu. Šis fokuss tagad ir kļuvis par titānisku uzņēmumu, kas vada AI attīstību, fokusu.

Kas ir MVI? To bieži vagt definē kā "cilvēka līmeņa AI", bet tas ir problemātiski: kuri cilvēki un kurās spējās tas ir cilvēka līmenī? Un kā ar pārcilvēciskajām spējām, kas tam jau ir? Noderīgāks veids, kā izprast MVI, ir caur trīs galveno īpašību krustošanos: augsta **A**utonomija (darbības neatkarība), augsta **V**ispārīgums (plašs darbības lauks un pielāgošanās spēja) un augsts **I**ntelekts (kompetence kognitīvos uzdevumos). Pašreizējās AI sistēmas var būt ļoti spējīgas, bet šauras, vai vispārīgas, bet prasīt pastāvīgu cilvēku uzraudzību, vai autonomas, bet ierobežotas darbības jomā.

Pilnīgs A-V-I apvienotu visas trīs īpašības līmeņos, kas atbilst vai pārspēj augstākās cilvēku spējas. Kritiski svarīgi, ka tieši šī kombinācija padara cilvēkus tik efektīvus un tik atšķirīgus no pašreizējās programmatūras; tas ir arī tas, kas ļautu cilvēkus pilnībā aizstāt ar digitālām sistēmām.

Lai gan cilvēka intelekts ir īpašs, tas nekādā ziņā nav ierobežojums. Mākslīgas "superintelektuālas" sistēmas varētu darboties simtiem reižu ātrāk, analizēt daudz vairāk datu un vienlaikus turēt "prātā" milzīgas daudzumus, un veidot apvienības, kas ir daudz lielākas un efektīvākas nekā cilvēku kolekcijas. Tās varētu aizstāt ne atsevišķus indivīdus, bet uzņēmumus, nācijas vai mūsu civilizāciju kopumā.

## Mēs esam pie sliekšņa

Pastāv stiprs zinātnisks konsenss, ka MVI ir *iespējams.* AI jau pārspēj cilvēka veiktspēju daudzos vispārējos intelektuālo spēju testos, ieskaitot nesen arī augsta līmeņa spriedumu veidošanu un problēmu risināšanu. Atpaliekošās spējas – piemēram, nepārtraukta mācīšanās, plānošana, pašapzināšanās un oriģinalitāte – visas pastāv kādā līmenī pašreizējās AI sistēmās, un ir zināmas tehnikas, kas visticamāk uzlabos tās visas.

Kamēr vēl pirms dažiem gadiem daudzi pētnieki uzskatīja MVI par gadu desmitiem attālu, pašlaik pierādījumi īsiem termiņiem līdz MVI ir spēcīgi:

- Empīriski pārbaudīti "mērogošanas likumi" savieno skaitļošanas ievadi ar AI spējām, un korporācijas ir uz ceļa palielināt skaitļošanas ievadi par vairākām pakāpēm nākamajos gados. Cilvēku un finanšu resursi, kas veltīti AI attīstībai, tagad līdzinās ducim Manhetenas projektu un vairākiem Apollo projektiem.
- AI korporācijas un to vadītāji publiski un privāti tic, ka MVI (pēc kādas definīcijas) ir sasniedzams dažu gadu laikā. Šiem uzņēmumiem ir informācija, kas sabiedrībai nav pieejama, ieskaitot dažiem ir nākamā AI sistēmu paaudze rokās.
- Ekspertu prognozētāji ar pierādītiem sasniegumiem piešķir 25% varbūtību MVI (pēc kādas definīcijas) ierašanās 1-2 gadu laikā, un 50% 2-5 gadiem (skatiet Metaculus prognozes ['vājam'](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) un ['pilnīgam'](https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/) MVI).
- Autonomija (ieskaitot tālas darbības elastīgu plānošanu) atpaliek AI sistēmās, bet lielākie uzņēmumi tagad fokusē savus milzīgos resursus autonomu AI sistēmu izstrādē un neformāli nosaukuši 2025. gadu par ["aģentu gadu."](https://techinformed.com/2025-informed-the-year-of-agentic-ai/)
- AI arvien vairāk piedalās savā uzlabošanā. Tiklīdz AI sistēmas būs tikpat kompetents kā cilvēku AI pētnieki AI pētniecībā, tiks sasniegts kritisks slieksnis ātram progresam uz daudz jaudīgākām AI sistēmām un visticamāk novedīs pie AI spēju strauja pieauguma. (Varētu apgalvot, ka šis straujais pieaugums jau ir sācies.)

Ideja, ka gudrāks par cilvēku MVI ir gadu desmitiem attāls vai vairāk, vienkārši vairs nav aizturam lielākajai daļai ekspertu šajā jomā. Domstarpības tagad ir par to, cik mēnešu vai gadu tas prasīs, ja mēs paliekam uz šī kursa. Pamatjautājums, ar ko saskaramies, ir: vai mums vajadzētu?

## Kas virza sacīksti uz MVI

Sacīksti uz MVI virza vairāki spēki, katrs padarot situāciju bīstamāku. Lielākie tehnoloģiju uzņēmumi redz MVI kā galējo automatizācijas tehnoloģiju – ne tikai papildinot cilvēku darbiniekus, bet aizstājot tos lielākoties vai pilnībā. Uzņēmumiem balva ir milzīga: iespēja iegūt ievērojamu daļu no pasaules 100 triljoniem dolāru ikgadējās ekonomiskās produkcijas, automatizējot cilvēku darba izmaksas.

Nācijas jūtas spiestās pievienoties šai sacīkstei, publiski atsaucoties uz ekonomisko un zinātnisko līderību, bet privāti uzskatot MVI par potenciālu revolūciju militārajās lietās, salīdzināmu ar kodolieroču. Bailes, ka konkurenti varētu iegūt izšķirošu stratēģisku priekšrocību, rada klasisku bruņošanās sacīkstes dinamiku.

Tie, kas cenšas pēc superintelekta, bieži min grandiozu vīziju: visu slimību izārstēšanu, novecošanas apgriezšanu, energijas un kosmosa ceļojumu caursitspējīgus sasniegums, vai pārcilvēcisku plānošanas spēju radīšanu.

Mazāk labvēlīgi, to, kas virza sacīksti, ir vara. Katrs dalībnieks – vai tas būtu uzņēmums vai valsts – tic, ka intelekts līdzinās varai un ka viņi būs vislabākie šīs varas pārvaldītāji.

Es argumentēju, ka šīs motivācijas ir reālas, bet fundamentāli maldīgas: MVI *absorbēs* un *meklēs* varu, nevis to piešķirs; AI radītas tehnoloģijas *arī* būs spēcīgi divpusējas, un tur, kur tās ir labvēlīgas, tās var radīt ar AI rīkiem un bez MVI; un pat tiktāl, ciktāl MVI un tā rezultāti paliek kontrolē, šīs sacīkstes dinamikas – gan korporatīvās, gan ģeopolitiskās – padara liela mēroga riskus mūsu sabiedrībai gandrīz neizbēgamus, ja vien tie netiek izšķiroši pārtraukti.

## MVI un superintelekts rada dramatisku draudu civilizācijai

Neraugoties uz to pievilcību, MVI un superintelekts rada dramatiskus draudus civilizācijai caur vairākiem savstarpēji stiprinošiem ceļiem:

*Varas koncentrācija:* pārcilvēcisks AI varētu atņemt varu lielākajai daļai cilvēcības, absorbējot milzīgas sociālās un ekonomiskās darbības daļas AI sistēmās, ko vada sauja gigantisko uzņēmumu (kuri savukārt var būt vai nu pārņemti, vai efektīvi pārņemt valdības).

*Masīvi traucējumi:* vairuma kognitīvo darbu lielapjoma automatizācija, mūsu pašreizējo epistēmisko sistēmu aizstāšana un milzīga daudzuma aktīvu necilvēcisku aģentu ieviešana īsā laika periodā apgrieztu otrādi lielāko daļu mūsu pašreizējo civilizācijas sistēmu.

*Katastrofas:* paplašinot spēju – potenciāli virs cilvēka līmeņa – radīt jaunas militāras un destruktīvas tehnoloģijas un atdalot to no sociālajām un juridiskajām sistēmām, kas pamato atbildību, fiziski katastrofu no masu iznīcināšanas ieročiem kļūst dramatiski ticamāka.

*Ģeopolitika un karš:* lielās pasaules varas nesēdēs mierīgi, ja jūtas, ka viņu pretinieki attīsta tehnoloģiju, kas varētu nodrošināt "izšķirošu stratēģisku priekšrocību".

*Straujais pieaugums un kontroles zaudēšana:* Ja vien tas nav īpaši novērsts, pārcilvēciskam AI būs visi stimuli sevi tālāk uzlabot un tas varētu tālu apsteigt cilvēkus ātrumā, datu apstrādē un domāšanas sarežģītībā. Nav jēgpilna veida, kādā mēs varam būt šādas sistēmas kontrolē. Šāds AI nepiešķirs varu cilvēkiem; mēs piešķirsim varu tam, vai tas to paņems.

Daudzi no šiem riskiem paliek pat ja tehniskā "saskaņošanas" problēma – nodrošinot, ka progresīvs AI uzticami dara to, ko cilvēki vēlas, lai tas darītu – ir atrisināta. AI rada milzīgu izaicinājumu tajā, kā to pārvaldīt, un ļoti daudzi šīs pārvaldības aspekti kļūst ļoti grūti vai neatrisināmi, kad cilvēka intelekts tiek pārspēts.

Vissvarīgākais, pārcilvēcisku vispārējās nozīmes AI veids, kas pašlaik tiek attīstīts, pēc savas būtības būtu ar mērķiem, aģentūru un spējām, kas pārspēj mūsējās. Tas būtu būtībā nekontrolējams – kā mēs varam kontrolēt kaut ko, ko mēs nevaram ne izprast, ne prognozēt? Tas nebūtu tehnoloģisks rīks cilvēku lietošanai, bet otrā intelektuālā suga uz Zemes līdzās mūsējai. Ja ļautos progresēt tālāk, tas būtu ne tikai otrā suga, bet aizstājējsuga.

Varbūt tā pret mums izturētos labi, varbūt nē. Bet nākotne piederētu tai, ne mums. Cilvēku ēra būtu beigusies.

## Tas nav neizbēgami; cilvēce var ļoti konkrēti izlemt neveidot savu aizstājēju.

Pārcilvēcisku MVI radīšana ir tālu no neizbēgamas. Mēs varam to novērst ar koordinētu pārvaldības pasākumu kopumu:

Pirmkārt, mums nepieciešama stabila AI skaitļošanas ("skaitļošanas jaudas") uzskaite un uzraudzība, kas ir fundamentāls lielāka mēroga AI sistēmu veicinātājs un svira to pārvaldībai. Tas savukārt prasa standartizētu kopējās skaitļošanas jaudas, kas izmantota AI modeļu apmācībā un to darbināšanā, mērīšanu un ziņošanu, kā arī tehniskās metodes izmantotās skaitļošanas saskaitīšanai, sertificēšanai un verifikācijai.

Otrkārt, mums vajadzētu ieviest cietus AI skaitļošanas jaudas ierobežojumus gan apmācībai, gan darbībai; tie novērš AI no būšanas pārāk jaudīgam un darbošanās pārāk ātri. Šos ierobežojumus var īstenot gan ar likumīgām prasībām, gan aparatūrā balstītiem drošības pasākumiem, kas iebūvēti AI specializētajos mikroshēmās, analoģiski drošības līdzekļiem mūsdienu telefonos. Tā kā specializēto AI aparatūru ražo tikai sauja uzņēmumu, verifikācija un ieviešana ir īstenojama caur esošo piegādes ķēdi.

Treškārt, mums nepieciešama pastiprināta atbildība visbisstamākajām AI sistēmām. Tiem, kas attīsta AI, kurš apvieno augstu autonomiju, plašu vispārīgumu un pārāku intelektu, jāsaskaras ar stingru atbildību par kaitējumu, kamēr drošie ostas no šīs atbildības mudinātu attīstīt ierobežotākas un kontrolējamākas sistēmas.

Ceturtkārt, mums nepieciešama pakāpeniska regulācija, pamatojoties uz riska līmeņiem. Spējīgākajām un bīstamākajām sistēmām būtu nepieciešamas plašas drošības un kontrolējamības garantijas pirms attīstības un ieviešanas, kamēr mazāk jaudīgas vai specializētākas sistēmas saskartos ar proporcionālu uzraudzību. Šim regulatīvajam ietvaram galu galā vajadzētu darboties gan nacionālā, gan starptautiskā līmenī.

Šī pieeja – ar detalizētu specifikāciju, kas sniegta pilnā dokumentā – ir praktiska: lai gan būs nepieciešama starptautiska koordinācija, verifikācija un ieviešana var darboties caur nelielu skaitu uzņēmumu, kas kontrolē specializētās aparatūras piegādes ķēdi. Tā ir arī elastīga: uzņēmumi joprojām var ieviest jauninājumus un gūt peļņu no AI attīstības, tikai ar skaidriem ierobežojumiem visbisstamākajām sistēmām.

Ilgtermiņa AI varas un risku ierobežošana prasītu starptautiskas vienošanās, pamatojoties gan uz paš-, gan kopējām interesēm, tieši tāpat kā kodolierožu proliferācijas kontrole tagad. Bet mēs varam sākt tūlīt ar pastiprinātu uzraudzību un atbildību, vienlaikus veidojot ceļu uz visaptverošāku pārvaldību.

Galvenā trūkstošā sastāvdaļa ir politiskā un sociālā griba pārņemt kontroli pār AI attīstības procesu. Šīs gribas avots, ja tas nāks laikā, būs pati realitāte – tas ir, no plaša apzināšanās par īstajām sekām tam, ko mēs darām.

## Mēs varam konstruēt AI rīkus, lai dotu spēku cilvēcei

Nevis cenšoties pēc nekontrolējama MVI, mēs varam attīstīt jaudīgus "AI rīkus", kas uzlabo cilvēku spējas, vienlaikus paliekot jēgpilnas cilvēku kontroles ietvaros. AI rīku sistēmas var būt ārkārtīgi spējīgas, vienlaikus izvairoties no bīstamā trīskāršā krustojuma starp augstu autonomiju, plašu vispārīgumu un pārcilvēcisku intelektu, ja vien mēs tās konstruējam, lai būtu kontrolējamas līmenī, kas atbilst to spējām. Tās var arī apvienot sarežģītās sistēmās, kas saglabā cilvēku uzraudzību, vienlaikus piegādājot transformējošus ieguvumus.

AI rīki var revolucionizēt medicīnu, paātrināt zinātniskos atklājumus, uzlabot izglītību un pilnveidot demokrātiskos procesus. Kad pareizi pārvaldīti, tie var padarīt cilvēku ekspertus un institūcijas efektīvākus, nevis tos aizstāt. Lai gan šādas sistēmas joprojām būs ļoti traucējošas un prasīs rūpīgu pārvaldību, riski, ko tās rada, ir fundamentāli atšķirīgi no MVI: tie ir riski, kurus mēs varam pārvaldīt, kā citu jaudīgo tehnoloģiju riski, nevis eksistenciāli draudi cilvēku aģentūrai un civilizācijai. Un kritiski svarīgi, ka, kad gudri attīstīti, AI rīki var palīdzēt cilvēkiem pārvaldīt jaudīgu AI un pārvaldīt tā ietekmi.

Šī pieeja prasa pārdomāt gan to, kā AI tiek attīstīts, gan to, kā tā ieguvumi tiek sadalīti. Jauni publiskās un bezpeļņas AI attīstības modeļi, spēcīgi regulatīvie ietvari un mehānismi ekonomisko ieguvumu plašākai izplatīšanai var palīdzēt nodrošināt, ka AI dod spēku visai cilvēcei, nevis koncentrē varu dažās rokās. Pats AI var palīdzēt veidot labākas sociālās un pārvaldības institūcijas, ļaujot jaunas koordinācijas un diskursa formas, kas stiprina, nevis grauj cilvēku sabiedrību. Nacionālās drošības iestādes var izmantot savu ekspertīzi, lai padarītu AI rīku sistēmas īsti drošas un uzticamas, un īstu aizsardzības, kā arī nacionālās varas avotu.

Mēs galu galā varam izlemt attīstīt vēl jaudīgākas un suverēnākas sistēmas, kas ir mazāk līdzīgas rīkiem un – varam cerēt – vairāk līdzīgas gudriem un jaudīgiem labdariem. Bet mums vajadzētu to darīt tikai pēc tam, kad esam attīstījuši zinātnisko izpratni un pārvaldības spēju to darīt droši. Šāds monumentāls un neatgriezenisks lēmums vajadzētu pieņemt apzināti visai cilvēcei, nevis pēc noklusējuma sacīkstē starp tehnoloģiju uzņēmumiem un nācijām.

## Cilvēku rokās

Cilvēki vēlas to labumu, kas nāk no AI: noderīgus rīkus, kas dod tiem spēku, dod papildu spēku ekonomiskajām iespējām un izaugsmei, un sola caursitspēju zinātnē, tehnoloģijā un izglītībā. Kāpēc gan nē? Bet kad vaicā, milzīga vairākums sabiedrības [vēlas lēnāku un piesardzīgāku AI attīstību](https://www.vox.com/future-perfect/2023/8/18/23836362/ai-slow-down-poll-regulation), un nevēlas gudrāku par cilvēku AI, kas aizstās viņus darba vietās un citur, piepildīs viņu kultūru un informācijas telpas ar necilvēcisku saturu, koncentrēs varu nelielajā uzņēmumu kopā, radīs ārkārtējus liela mēroga globālus riskus un galu galā draudēs atņemt varu vai aizstāt viņu sugu. Kāpēc gan viņi to vēlētos?

Mēs *varam* iegūt vienu bez otra. Tas sākas ar izlēmi, ka mūsu liktenis nav kādas tehnoloģijas iedomātajā neizbēgamībā vai dažu dyrektoru rokās Silikona ielejā, bet mūsu pārējo rokās, ja mēs to satveram. Aizverīsim Vārtus un saglabāsim nākotni cilvēcisku.