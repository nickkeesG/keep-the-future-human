# Pielikumi

Papildu informācija, tostarp — Tehniskie dati par skaitļošanas jaudas uzskaiti, vārtu slēgšanas ieviešanas piemērs, strikta MVI atbildības režīma detaļas un pakāpeniska pieeja MVI drošības un drošuma standartiem.

## Pielikums A: Skaitļošanas jaudas uzskaites tehniskie dati

Detalizēta metode gan "objektīvai patiesībai", gan labiem aprēķiniem kopējai skaitļošanas jaudai, kas izmantota apmācībā un secinājumu izdarīšanā, ir nepieciešama jēgpilnai uz skaitļošanu balstītai kontrolei. Šeit ir piemērs tam, kā "objektīvā patiesība" varētu tikt aprēķināta tehniskā līmenī.

**Definīcijas:**

*Skaitļošanas cēloniskais grafs:* Konkrētam AI modeļa iznākumam O pastāv digitālo skaitļošanu kopa, kurām mainot šīs skaitļošanas rezultātu, potenciāli varētu mainīties O. (Tas būtu konservatīvi pieņemams, t.i., jābūt skaidram iemeslam uzskatīt, ka skaitļošana ir neatkarīga no priekšgājēja, kas gan notiek agrāk laikā, gan kurām ir fizisks potenciālais cēloniskās ietekmes ceļš.) Tas ietver skaitļošanu, ko AI modelis veic secinājumu izdarīšanas laikā, kā arī skaitļošanu, kas ieiet modeļa ievadē, datu sagatavošanā un apmācībā. Tā kā katra no tām pati var būt AI modeļa iznākums, tas tiek aprēķināts rekursīvi, apraujot tur, kur cilvēks ir sniedzis nozīmīgas izmaiņas ievadē.

*Apmācības skaitļošana:* Kopējā skaitļošana FLOP vai citās vienībās, ko ietver neironu tīkla skaitļošanas cēloniskais grafs (ieskaitot datu sagatavošanu, apmācību un precīzu regulēšanu, un jebkuras citas skaitļošanas.)

*Iznākuma skaitļošana:* Kopējā skaitļošana konkrēta AI iznākuma skaitļošanas cēloniskajā grafā, ieskaitot visus neironu tīklus (un ieskaitot to apmācības skaitļošanu) un citas skaitļošanas, kas ieiet šajā iznākumā.

*Secinājumu skaitļošanas ātrums:* Iznākumu sērijā, iznākuma skaitļošanas izmaiņu ātrums (FLOP/s vai citās vienībās) starp iznākumiem, t.i., skaitļošana, kas izmantota nākamā iznākuma iegūšanai, dalīta ar laika intervālu starp iznākumiem.

**Piemēri un aprēķini:**

- Vienam neironu tīklam, kas apmācīts uz cilvēku radītiem datiem, apmācības skaitļošana ir vienkārši kopējā apmācības skaitļošana, kā parasti tiek ziņots.
- Šādam neironu tīklam, kas veic secinājumus pastāvīgā ātrumā, secinājumu skaitļošanas ātrums ir aptuveni kopējais skaitļošanas klastera ātrums, kas veic secinājumus FLOP/s.
- Modeļa precīzai regulēšanai pilna modeļa apmācības skaitļošana ir neprecīzi regulētā modeļa apmācības skaitļošana plus skaitļošana, kas veikta precīzās regulēšanas laikā un datu sagatavošanai, kas izmantoti precīzajā regulēšanā.
- Destilētam modelim pilna modeļa apmācības skaitļošana ietver gan destilētā modeļa, gan lielākā modeļa apmācību, kas izmantots sintētisko datu vai citu apmācības ievadu nodrošināšanai.
- Ja apmācīti vairāki modeļi, bet daudzi "izmēģinājumi" tiek atmesti, pamatojoties uz cilvēka spriedumu, tie neskaitās paturētā modeļa apmācības vai iznākuma skaitļošanā.

## Pielikums B: Vārtu slēgšanas ieviešanas piemērs

**Ieviešanas piemērs:** Šeit ir viens piemērs tam, kā varētu darboties vārtu slēgšana ar ierobežojumu 10<sup>27</sup> FLOP apmācībai un 10<sup>20</sup> FLOP/s secinājumu izdarīšanai (AI darbināšanai):

**1\. Pauze:** Nacionālās drošības apsvērumu dēļ ASV izpildvara lūdz visus uzņēmumus, kas bāzēti ASV, darbojas ASV vai izmanto ASV ražotus čipus, pārtraukt jebkuras jaunas AI apmācības, kas varētu pārsniegt 10<sup>27</sup> FLOP apmācības skaitļošanas ierobežojumu. ASV jāuzsāk diskusijas ar citām valstīm, kurās notiek AI izstrāde, stingri mudināt tās veikt līdzīgus soļus un norādīt, ka ASV pauze var tikt atcelta, ja tās izvēlas neievērot.

**2\. ASV uzraudzība un licencēšana:** Ar izpildrīkojumu vai esošas regulējošas iestādes rīcību ASV pieprasa, lai gada laikā:

- Visi AI apmācības palaišanas gadījumi, kas pārsniedz 10<sup>25</sup> FLOP un ko veic uzņēmumi, kuri darbojas ASV, tiek reģistrēti ASV regulējošās iestādes uzturētā datubāzē. (Piezīme: nedaudz vājāka šīs prasības versija jau bija iekļauta tagad atceltajā 2023. gada ASV izpildrīkojumā par AI, pieprasot reģistrāciju modeļiem virs 10<sup>26</sup> FLOP.)
- Visi ar AI saistītie aparatūras ražotāji, kas darbojas ASV vai veic darījumus ar ASV valdību, ievēro prasību kopumu attiecībā uz savu specializēto aparatūru un to darbināmo programmatūru. (Daudzas no šīm prasībām varētu iestrādāt esošās aparatūras programmatūras un aparātprogrammatūras atjauninājumos, bet ilgtermiņa un noturīgi risinājumi prasītu izmaiņas vēlākās aparatūras paaudzēs.) Starp tām ir prasība, ka ja aparatūra ir daļa no ātrgaitas savienotā klastera, kas spēj izpildīt 10<sup>18</sup> FLOP/s skaitļošanu, nepieciešams augstāks verifikācijas līmenis, kas ietver regulāru atļauju no attālināta "regulatora", kurš saņem gan telemetriju, gan pieprasījumus veikt papildu skaitļošanu.
- Glabātājs ziņo par savu aparatūras kopējo skaitļošanu iestādei, kas uztur ASV datubāzi.
- Tiek pakāpeniski ieviesti stingrāki nosacījumi, lai nodrošinātu gan drošāku, gan elastīgāku uzraudzību un atļauju sniegšanu.

**3\. Starptautiska uzraudzība:**

- ASV, Ķīna un jebkuras citas valstis, kurās atrodas progresīvas čipu ražošanas iespējas, sarunu ceļā panāk starptautisku vienošanos.
- Šī vienošanās izveido jaunu starptautisku iestādi, līdzīgu Starptautiskajai atomenerģijas aģentūrai, kas atbildīga par AI apmācības un darbības uzraudzību.
- Parakstītājvalstīm jāpieprasa saviem vietējiem AI aparatūras ražotājiem ievērot prasību kopumu, kas ir vismaz tikpat stingrs kā ASV uzlikto prasību kopums.
- Glabātājiem tagad jāziņo AI skaitļošanas skaitļi gan savās mājvalstīs esošajām iestādēm, gan jaunajam birojam starptautiskajā iestādē.
- Papildu valstis tiek stingri mudinātas pievienoties esošajai starptautiskajai vienošanai: parakstītājvalstu eksporta kontrole ierobežo neparakstītāju piekļuvi augstklases aparatūrai, kamēr parakstītājvalstis var saņemt tehnisko atbalstu savu AI sistēmu pārvaldīšanā.

**4\. Starptautiska verifikācija un izpilde:**

- Aparatūras verifikācijas sistēma tiek atjaunināta tā, lai tā ziņotu par skaitļošanas izmantojumu gan sākotnējam glabātājam, gan tieši starptautiskās iestādes birojam.
- Iestāde, diskusijā ar starptautiskās vienošanās parakstītājiem, vienojas par skaitļošanas ierobežojumiem, kas pēc tam iegūst juridisko spēku parakstītājvalstīs.
- Paralēli var tikt izstrādāti starptautiski standarti tā, lai AI apmācībai un darbināšanai virs skaitļošanas sliekšņa (bet zem ierobežojuma) būtu jāievēro šie standarti.
- Iestāde var, ja nepieciešams labāku algoritmu utt. kompensēšanai, pazemināt skaitļošanas ierobežojumu. Vai, ja tas tiek uzskatīts par drošu un ieteicamu (piemēram, pierādāmu drošības garantiju līmenī), paaugstināt skaitļošanas ierobežojumu.

## Pielikums C: Strikta MVI atbildības režīma detaļas

**Strikta MVI atbildības režīma detaļas**

- Progresīvas AI sistēmas, kas ir ļoti vispārēja, spējīga un autonoma, izveide un darbība tiek uzskatīta par "neparasti bīstamu" darbību.
- Kā tāda, noklusējuma atbildība par šādu sistēmu apmācību un darbību ir strikta, kopīga un solidāra atbildība (vai tās ārpus ASV ekvivalents) par jebkādiem kaitējumiem, ko rada modelis vai tā iznākumi/darbības.
- Personiskā atbildība tiks uzlikta vadītājiem un valdes locekļiem rupjas nevērības vai tīšas ļaunprātības gadījumos. Tam jāietver kriminālatbildība vissmagāko gadījumu gadījumā.
- Pastāv daudzas drošas ostasāgas, saskaņā ar kurām atbildība atgriežas pie noklusējuma (vainas balstītas ASV) atbildības, kādai parasti būtu pakļauti cilvēki un uzņēmumi.
	- Modeļi, kas apmācīti un darbināti zem kāda skaitļošanas sliekšņa (kas būtu vismaz 10 reizes zemāks par iepriekš aprakstītajiem ierobežojumiem.)
	- AI, kas ir "vājš" (aptuveni, zem cilvēka eksperta līmeņa uzdevumos, kuriem tas ir paredzēts) un/vai
	- AI, kas ir "šaurs" (ar fiksētu un diezgan ierobežotu uzdevumu un operāciju tvērumu, kam tas ir īpaši paredzēts un apmācīts) un/vai
	- AI, kas ir "pasīvs" (ļoti ierobežotas spējas – pat pie mērenas modifikācijas – veikt darbības vai sarežģītus daudzpakāpju uzdevumus bez tiešas cilvēka iesaistes un kontroles.)
	- AI, kuram garantēta drošība, drošums un kontrolējamība (pierādāmi drošs vai riska analīze norāda uz nenozīmīgu gaidāmā kaitējuma līmeni.)
- Drošās ostasāgas var pieteikt, pamatojoties uz AI izstrādātāja sagatavoto un iestādes vai iestādes akreditēta auditora apstiprinātu [drošības lietu](https://arxiv.org/abs/2410.21572). Lai pieteiktu drošo ostasāgu, pamatojoties uz skaitļošanu, izstrādātājam jāsniedz ticami kopējās apmācības skaitļošanas un maksimālā secinājumu ātruma aprēķini.
- Likumdošana skaidri izklāstītu situācijas, kurās būtu piemērots aizlieguma rakstura atvieglojums no AI sistēmu izstrādes ar augstu sabiedriskā kaitējuma risku.
- Uzņēmumu konsorcijiem, sadarbībā ar NVO un valdības iestādēm, jāizstrādā standarti un normas, kas definē šos terminus, kā regulatoriem būtu jāpiešķir drošās ostasāgas, kā AI izstrādātājiem jāizstrādā drošības lietas, un kā tiesām jāinterpretē atbildība, ja drošās ostasāgas nav proaktīvi pieteiktas.

## Pielikums D: Pakāpeniska pieeja MVI drošības un drošuma standartiem

**Pakāpeniska pieeja MVI drošības un drošuma standartiem**

| Riska līmenis | Aktivizētājs(i) | Apmācības prasības | Izvietošanas prasības |
| --- | --- | --- | --- |
| RL-0 | AI vājš autonomijā, vispārībā un intelektā | nav | nav |
| RL-1 | AI spēcīgs vienā no autonomijas, vispārības un intelekta | nav | Pamatojoties uz risku un izmantošanu, potenciāli drošības lietas, ko apstiprina nacionālās institūcijas jebkur, kur modelis var tikt izmantots |
| RL-2 | AI spēcīgs divās no autonomijas, vispārības un intelekta | Reģistrācija nacionālā institūcijā ar jurisdikciju pār izstrādātāju | Drošības lieta, kas ierobežo nozīmīga kaitējuma risku zem atļautajiem līmeņiem, plus neatkarīgi drošības auditi (ieskaitot melnās kastes un baltās kastes pārbaudīšanu), ko apstiprina nacionālās institūcijas jebkur, kur modelis var tikt izmantots |
| RL-3 | MVI spēcīgs autonomijā, vispārībā un intelektā | Drošības un drošuma plāna iepriekšēja apstiprināšana nacionālā institūcijā ar jurisdikciju pār izstrādātāju | Drošības lieta, kas garantē ierobežotu nozīmīga kaitējuma risku zem atļautajiem līmeņiem, kā arī nepieciešamās specifikācijas, ieskaitot kiberdrošību, kontrolējamību, nenovākamu izslēgšanas slēdzi, saskaņošanu ar cilvēku vērtībām un noturību pret ļaunprātīgu izmantošanu. |
| RL-4 | Jebkurš modelis, kas pārsniedz arī 10<sup>27</sup> FLOP apmācību vai 10<sup>20</sup> FLOP/s secinājumus | Aizliegts, gaidot starptautisku vienošanos par skaitļošanas ierobežojuma atcelšanu | Aizliegts, gaidot starptautisku vienošanos par skaitļošanas ierobežojuma atcelšanu |

Riska klasifikācijas un drošības/drošuma standarti ar līmeņiem, kas balstīti uz skaitļošanas slieksņiem, kā arī augstas autonomijas, vispārības un intelekta kombinācijām:

- *Spēcīga autonomija* attiecas, ja sistēma spēj veikt vai var viegli tikt pielāgota, lai veiktu daudzpakāpju uzdevumus un/vai veiktu sarežģītas darbības, kas ir reālajā pasaulē nozīmīgas, bez būtiskas cilvēka uzraudzības vai iejaukšanās. Piemēri: autonomie transportlīdzekļi un roboti; finanšu tirdzniecības roboti. Nepiemēri: GPT-4; attēlu klasifikatori
- *Spēcīga vispārība* norāda uz plašu pielietojuma tvērumu, uzdevumu veikšanu, kuriem modelis nebija apzināti un īpaši apmācīts, un nozīmīgu spēju apgūt jaunus uzdevumus. Piemēri: GPT-4; mu-zero. Nepiemēri: AlphaFold; autonomie transportlīdzekļi; attēlu ģeneratori
- *Spēcīgs intelekts* atbilst cilvēka eksperta līmeņa sniegumam uzdevumos, kuros modelis darbojas vislabāk (un vispārēja modeļa gadījumā plašā uzdevumu spektrā.) Piemēri: AlphaFold; mu-zero; o3. Nepiemēri: GPT-4; Siri