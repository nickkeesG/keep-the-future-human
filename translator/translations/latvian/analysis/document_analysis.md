## Summary

This essay presents a comprehensive argument for preventing the development of Artificial General Intelligence (AGI) and superintelligence while promoting safer "Tool AI" alternatives. The document is structured as a 10-chapter treatise with appendices, progressing from current AI capabilities to specific policy proposals.

**Core Arguments:**
1. Current AI systems are rapidly approaching human-level general intelligence, with expert predictions placing AGI arrival within 1-5 years
2. The development of AGI/superintelligence poses existential risks including loss of human control, societal disruption, geopolitical instability, and potential human extinction
3. These systems would be inherently uncontrollable due to their opacity, unpredictability, and superior capabilities
4. Corporate and national "races" toward AGI are driven by profit motives and power considerations, creating dangerous competitive dynamics

**Proposed Solutions:**
The author advocates "closing the Gates" through:
- Global limits on AI computational power (training and inference)
- Enhanced liability frameworks for dangerous AI systems
- Tiered safety regulations based on autonomy-generality-intelligence intersections
- International cooperation modeled on nuclear non-proliferation treaties

**Alternative Vision:**
Instead of AGI, the essay promotes "Tool AI" that remains under human control while still delivering transformative benefits in medicine, science, and technology. This approach emphasizes human empowerment over replacement.

The document combines technical AI knowledge with policy analysis, game theory, and risk assessment, targeting both technical and general audiences concerned about AI's societal impact.

## Glossary

- **Source Term**: Artificial General Intelligence (AGI)
- **Target Translation**: Mākslīgais vispārējais intelekts (MVI)
- **Context**: Central concept throughout - AI matching/exceeding human cognitive abilities across all domains
- **Notes**: While "AGI" is used internationally, Latvian translation needed for broader public understanding

- **Source Term**: superintelligence
- **Target Translation**: superintelekts
- **Context**: AI far surpassing human capabilities across all domains
- **Notes**: Direct borrowing with Latvian phonetic adaptation, as term is emerging globally

- **Source Term**: neural networks
- **Target Translation**: neironu tīkli
- **Context**: Core AI architecture underlying modern systems
- **Notes**: Established Latvian scientific terminology

- **Source Term**: compute/computation
- **Target Translation**: skaitļošanas jauda/skaitļošana
- **Context**: Computational resources required for AI training and operation
- **Notes**: "Compute" as noun requires explanation in Latvian context

- **Source Term**: FLOP (floating-point operations)
- **Target Translation**: FLOP (peldošā komata operācijas)
- **Context**: Unit of computational measurement for AI systems
- **Notes**: Technical abbreviation kept with Latvian explanation in parentheses

- **Source Term**: training
- **Target Translation**: apmācība
- **Context**: Process of developing AI model capabilities through data processing
- **Notes**: Standard Latvian term for machine learning training

- **Source Term**: inference
- **Target Translation**: secinājumu izdarīšana/darbība
- **Context**: AI system's operation phase when generating outputs
- **Notes**: Contextual translation as "inference" has specific meaning in AI

- **Source Term**: alignment
- **Target Translation**: saskaņošana/orientācija uz cilvēku vērtībām
- **Context**: Ensuring AI systems act according to human intentions and values
- **Notes**: Requires explanation as technical concept lacks direct Latvian equivalent

- **Source Term**: autonomous agents
- **Target Translation**: autonomie aģenti
- **Context**: AI systems capable of independent action and decision-making
- **Notes**: "Aģenti" is adopted in Latvian tech context

- **Source Term**: Tool AI
- **Target Translation**: AI rīki/instrumentālais AI
- **Context**: Author's proposed alternative - controllable AI that enhances human capabilities
- **Notes**: "Rīki" emphasizes tool nature; may need explanation as author's concept

- **Source Term**: scaffolding
- **Target Translation**: atbalsta struktūra/ietvars
- **Context**: Software framework connecting AI system components
- **Notes**: Metaphorical term requiring contextual translation

- **Source Term**: chain-of-thought
- **Target Translation**: domāšanas ķēde/secīga spriedumu veidošana
- **Context**: AI technique for multi-step reasoning
- **Notes**: Technical term needing descriptive translation

- **Source Term**: multimodal models
- **Target Translation**: daudzveidīgie modeļi
- **Context**: AI systems processing multiple data types (text, images, audio)
- **Notes**: Established in Latvian AI discourse

- **Source Term**: liability regime
- **Target Translation**: atbildības režīms
- **Context**: Legal framework for AI developer responsibility
- **Notes**: Standard legal terminology in Latvian

- **Source Term**: compute caps
- **Target Translation**: skaitļošanas jaudas ierobežojumi
- **Context**: Proposed limits on AI computational resources
- **Notes**: Policy concept requiring clear descriptive translation

- **Source Term**: Gates/closing the Gates
- **Target Translation**: Vārti/vārtu aizvēršana
- **Context**: Author's metaphor for preventing dangerous AI development
- **Notes**: Central metaphor maintained with capital letter in Latvian