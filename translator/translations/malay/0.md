# Ringkasan eksekutif

Tinjauan peringkat tinggi mengenai esei ini. Jika anda kekurangan masa, dapatkan semua perkara utama dalam hanya 10 minit.

Kemajuan dramatik dalam kecerdasan buatan sepanjang dekad yang lalu (untuk AI tujuan khusus) dan beberapa tahun kebelakangan ini (untuk AI tujuan am) telah mengubah AI daripada bidang akademik khusus kepada strategi perniagaan teras bagi kebanyakan syarikat terbesar di dunia, dengan pelaburan tahunan beratus-ratus bilion dolar dalam teknik dan teknologi untuk memajukan keupayaan AI.

Kini kita tiba di persimpangan kritikal. Apabila keupayaan sistem AI baru mula menyamai dan melebihi keupayaan manusia merentasi banyak domain kognitif, manusia mesti memutuskan: sejauh mana kita mahu pergi, dan ke arah manakah?

AI, seperti setiap teknologi, bermula dengan matlamat untuk memperbaiki keadaan bagi penciptanya. Tetapi trajektori semasa kita, dan pilihan tersirat, adalah perlumbaan tanpa kawalan ke arah sistem yang semakin berkuasa, didorong oleh insentif ekonomi beberapa syarikat teknologi gergasi yang berusaha mengautomasikan sebahagian besar aktiviti ekonomi semasa dan buruh manusia. Jika perlumbaan ini berterusan lebih lama lagi, terdapat pemenang yang tidak dapat dielakkan: AI itu sendiri – alternatif yang lebih pantas, lebih bijak, lebih murah kepada manusia dalam ekonomi kita, pemikiran kita, keputusan kita, dan akhirnya dalam kawalan tamadun kita.

Tetapi kita boleh membuat pilihan lain: melalui kerajaan kita, kita boleh mengawal proses pembangunan AI untuk mengenakan had yang jelas, garisan yang tidak akan kita lalui, dan perkara yang kita tidak akan lakukan – sebagaimana yang kita lakukan untuk teknologi nuklear, senjata pemusnah beramai-ramai, senjata angkasa lepas, proses yang memudaratkan alam sekitar, kejuruteraan bio manusia, dan eugenik. Yang paling penting, kita boleh memastikan AI kekal sebagai alat untuk memperkasakan manusia, bukannya spesies baru yang menggantikan dan akhirnya meminggirkan kita.

Esei ini berhujah bahawa kita perlu *memastikan masa depan tetap manusiawi* dengan menutup "pintu gerbang" kepada AI am tujuan umum yang lebih bijak daripada manusia dan autonomi – kadangkala dipanggil "KBA" – dan terutamanya kepada versi sangat superhuman yang kadangkala dipanggil "superintelligence." Sebaliknya, kita perlu memberi tumpuan kepada alat AI yang berkuasa dan boleh dipercayai yang boleh memperkasakan individu dan secara transformatif meningkatkan keupayaan masyarakat manusia untuk melakukan apa yang mereka lakukan terbaik. Struktur hujah ini diikuti secara ringkas.

## AI adalah berbeza

Sistem AI secara asasnya berbeza daripada teknologi lain. Walaupun perisian tradisional mengikut arahan tepat, sistem AI belajar cara mencapai matlamat tanpa diberitahu secara eksplisit bagaimana. Ini menjadikan mereka berkuasa: jika kita boleh mentakrifkan matlamat atau metrik kejayaan dengan jelas, dalam kebanyakan kes sistem AI boleh belajar untuk mencapainya. Tetapi ia juga menjadikan mereka secara intrinsiknya tidak dapat diramal: kita tidak dapat menentukan dengan pasti tindakan apa yang akan mereka ambil untuk mencapai objektif mereka.

Mereka juga sebahagian besarnya tidak dapat dijelaskan: walaupun mereka sebahagiannya kod, mereka kebanyakannya adalah set nombor yang sangat besar dan tidak dapat dipahami – "pemberat" rangkaian neural – yang tidak dapat dianalisis; kita tidak jauh lebih baik dalam memahami cara kerja dalaman mereka berbanding memahami pemikiran dengan mengintip ke dalam otak biologi.

Mod teras latihan rangkaian neural digital ini berkembang dengan pesat dalam kerumitan. Sistem AI yang paling berkuasa dicipta melalui eksperimen pengkomputeran besar-besaran, menggunakan perkakasan khusus untuk melatih rangkaian neural pada set data yang sangat besar, yang kemudian ditambah dengan alat perisian dan superstruktur.

Ini telah membawa kepada penciptaan alat yang sangat berkuasa untuk mencipta dan memproses teks dan imej, melakukan penaakulan matematik dan saintifik, mengagregatkan maklumat, dan secara interaktif menanyakan simpanan besar pengetahuan manusia.

Malangnya, walaupun pembangunan alat teknologi yang lebih berkuasa dan lebih boleh dipercayai adalah apa yang *sepatutnya* kita lakukan, dan apa yang hampir semua orang mahukan dan katakan mereka mahukan, ia bukanlah trajektori yang sebenarnya kita lalui.

## KBA dan superintelligence

Sejak lahirnya bidang ini, penyelidikan AI sebaliknya telah memberi tumpuan kepada matlamat yang berbeza: Kecerdasan Buatan Am. Fokus ini kini telah menjadi tumpuan syarikat-syarikat gergasi yang memimpin pembangunan AI.

Apakah KBA? Ia sering ditakrifkan secara samar-samar sebagai "AI tahap manusia," tetapi ini bermasalah: manusia yang mana, dan pada keupayaan mana ia berada di tahap manusia? Dan bagaimana pula dengan keupayaan super-manusia yang sudah dimilikinya? Cara yang lebih berguna untuk memahami KBA adalah melalui persimpangan tiga sifat utama: **A**utonomi tinggi (kebebasan bertindak), **G**eneraliti tinggi (skop luas dan kebolehsuaian), dan **K**ecerdasan tinggi (kecekapan dalam tugas kognitif). Sistem AI semasa mungkin sangat berkebolehan tetapi sempit, atau am tetapi memerlukan pengawasan manusia berterusan, atau autonomi tetapi terhad dalam skop.

KBA penuh akan menggabungkan ketiga-tiga sifat pada tahap yang menyamai atau melebihi keupayaan manusia teratas. Yang kritikal, gabungan inilah yang menjadikan manusia begitu berkesan dan begitu berbeza daripada perisian semasa; ia juga yang akan membolehkan manusia digantikan secara menyeluruh oleh sistem digital.

Walaupun kecerdasan manusia adalah istimewa, ia sama sekali bukan satu had. Sistem "superintelligent" buatan boleh beroperasi beratus kali lebih pantas, menganalisis data yang jauh lebih banyak dan memegang kuantiti yang sangat besar "dalam ingatan" sekaligus, dan membentuk agregat yang jauh lebih besar dan lebih berkesan daripada kumpulan manusia. Mereka boleh menggantikan bukan individu tetapi syarikat, negara, atau tamadun kita secara keseluruhan.

## Kita berada di ambang

Terdapat konsensus saintifik yang kuat bahawa KBA adalah *mungkin.* AI sudah melebihi prestasi manusia dalam banyak ujian am keupayaan intelek, termasuk baru-baru ini penaakulan dan penyelesaian masalah peringkat tinggi. Keupayaan yang ketinggalan – seperti pembelajaran berterusan, perancangan, kesedaran diri, dan keaslian – semuanya wujud pada tahap tertentu dalam sistem AI masa kini, dan teknik yang diketahui wujud yang berkemungkinan meningkatkan kesemuanya.

Walaupun sehingga beberapa tahun lalu ramai penyelidik melihat KBA sebagai dekad lagi, pada masa ini bukti untuk jadual waktu pendek ke KBA adalah kuat:

- "Hukum penskalaan" yang disahkan secara empirik menghubungkan input pengkomputeran kepada keupayaan AI, dan korporat sedang dalam landasan untuk meningkatkan input pengkomputeran mengikut magnitud dalam beberapa tahun akan datang. Sumber manusia dan fiskal yang didedikasikan untuk kemajuan AI kini menyamai satu dozen Projek Manhattan dan beberapa Projek Apollo.
- Korporat AI dan pemimpin mereka secara terbuka dan peribadi percaya bahawa KBA (mengikut beberapa definisi) boleh dicapai dalam beberapa tahun. Syarikat-syarikat ini mempunyai maklumat yang tidak dimiliki orang awam, termasuk sebahagian yang mempunyai generasi seterusnya sistem AI di tangan.
- Peramal pakar dengan rekod terbukti memberikan 25% kebarangkalian kepada KBA (mengikut beberapa definisi) tiba dalam 1-2 tahun, dan 50% untuk 2-5 tahun (lihat ramalan Metaculus untuk KBA ['lemah'](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) dan ['penuh'](https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/)).
- Autonomi (termasuk perancangan fleksibel jarak jauh) ketinggalan dalam sistem AI, tetapi syarikat utama kini memfokuskan sumber besar mereka untuk membangunkan sistem AI autonomi dan secara tidak rasmi menamakan 2025 sebagai ["tahun agen."](https://techinformed.com/2025-informed-the-year-of-agentic-ai/)
- AI menyumbang semakin banyak kepada penambahbaikkan dirinya sendiri. Sebaik sahaja sistem AI sekompeten penyelidik AI manusia dalam melakukan penyelidikan AI, ambang kritikal untuk kemajuan pantas kepada sistem AI yang jauh lebih berkuasa akan dicapai dan berkemungkinan membawa kepada pelarian dalam keupayaan AI. (Boleh dikatakan, pelarian itu sudah bermula.)

Idea bahawa KBA yang lebih bijak daripada manusia adalah beberapa dekad lagi atau lebih sudah tidak dapat dipertahankan lagi kepada majoriti besar pakar dalam bidang ini. Perselisihan pendapat sekarang adalah mengenai berapa bulan atau tahun yang diperlukan jika kita kekal pada kursus ini. Soalan teras yang kita hadapi adalah: patutkah kita?

## Apa yang mendorong perlumbaan ke KBA

Perlumbaan ke arah KBA didorong oleh pelbagai kuasa, setiap satu menjadikan keadaan lebih berbahaya. Syarikat teknologi utama melihat KBA sebagai teknologi automasi muktamad – bukan hanya menambah pekerja manusia tetapi menggantikan mereka sebahagian besar atau sepenuhnya. Bagi syarikat, hadiahnya adalah sangat besar: peluang untuk menawan sebahagian besar daripada output ekonomi tahunan dunia sebanyak $100 trilion dengan mengautomasikan kos buruh manusia.

Negara merasa terpaksa menyertai perlumbaan ini, secara terbuka menyebut kepimpinan ekonomi dan saintifik, tetapi secara peribadi melihat KBA sebagai revolusi berpotensi dalam hal ehwal ketenteraan yang setanding dengan senjata nuklear. Ketakutan bahawa pesaing mungkin mendapat kelebihan strategik yang menentukan mewujudkan dinamik perlumbaan senjata klasik.

Mereka yang mengejar superintelligence sering menyebut visi besar: menyembuhkan semua penyakit, membalikkan penuaan, mencapai terobosan dalam tenaga dan perjalanan angkasa lepas, atau mencipta keupayaan perancangan superhuman.

Kurang baik hati, apa yang mendorong perlumbaan adalah kuasa. Setiap peserta – sama ada syarikat atau negara – percaya bahawa kecerdasan sama dengan kuasa, dan bahawa mereka akan menjadi penjaga terbaik kuasa itu.

Saya berhujah bahawa motivasi ini adalah nyata tetapi pada asasnya salah arah: KBA akan *menyerap* dan *mencari* kuasa daripada memberikannya; teknologi yang dicipta AI juga akan sangat bermata dua, dan di mana ia bermanfaat boleh dicipta dengan alat AI dan tanpa KBA; dan walaupun setakat KBA dan outputnya kekal dalam kawalan, dinamik perlumbaan ini – kedua-dua korporat dan geopolitik – menjadikan risiko berskala besar kepada masyarakat kita hampir tidak dapat dielakkan melainkan ditangguhkan secara tegas.

## KBA dan superintelligence menimbulkan ancaman dramatik kepada tamadun

Walaupun daya tarikan mereka, KBA dan superintelligence menimbulkan ancaman dramatik kepada tamadun melalui pelbagai laluan yang saling memperkukuh:

*Penumpuan kuasa:* AI superhuman boleh melucutkan kuasa majoriti besar manusia dengan menyerap sebahagian besar aktiviti sosial dan ekonomi ke dalam sistem AI yang dijalankan oleh segelintir syarikat gergasi (yang seterusnya mungkin sama ada diambil alih oleh, atau secara berkesan mengambil alih, kerajaan.)

*Gangguan besar-besaran:* automasi pukal kebanyakan pekerjaan berasaskan kognitif, penggantian sistem epistemik semasa kita, dan pelancaran bilangan besar agen bukan manusia yang aktif akan mengubah kebanyakan sistem tamadun semasa kita dalam tempoh yang agak singkat.

*Malapetaka:* dengan menyebarkan keupayaan – berpotensi melebihi tahap manusia – untuk mencipta teknologi ketenteraan dan pemusnah baru dan memisahkannya daripada sistem sosial dan undang-undang yang mendasari tanggungjawab, malapetaka fizikal daripada senjata pemusnah beramai-ramai menjadi jauh lebih berkemungkinan.

*Geopolitik dan perang:* kuasa dunia utama tidak akan duduk diam jika mereka merasakan bahawa teknologi yang boleh memberikan "kelebihan strategik yang menentukan" sedang dibangunkan oleh musuh mereka.

*Pelarian dan kehilangan kawalan:* Melainkan ia secara khusus dicegah, AI superhuman akan mempunyai setiap insentif untuk terus memperbaiki dirinya dan boleh jauh melebihi manusia dalam kelajuan, pemprosesan data, dan kecanggihan pemikiran. Tidak ada cara yang bermakna di mana kita boleh mengawal sistem sedemikian. AI sedemikian tidak akan memberikan kuasa kepada manusia; kita akan memberikan kuasa kepadanya, atau ia akan mengambilnya.

Banyak risiko ini kekal walaupun masalah teknikal "penjajaran" – memastikan AI lanjutan dengan pasti melakukan apa yang manusia mahukan – diselesaikan. AI membentangkan cabaran yang sangat besar dalam cara ia akan diuruskan, dan banyak aspek pengurusan ini menjadi sangat sukar atau tidak dapat diselesaikan apabila kecerdasan manusia dilanggar.

Paling asasnya, jenis AI am tujuan umum superhuman yang sedang diusahakan pada masa ini akan, mengikut sifatnya, mempunyai matlamat, agensi, dan keupayaan yang melebihi kita sendiri. Ia secara intrinsiknya tidak boleh dikawal – bagaimana kita boleh mengawal sesuatu yang kita tidak boleh memahami mahupun meramal? Ia bukan alat teknologi untuk kegunaan manusia, tetapi spesies kedua kecerdasan di Bumi bersama kita. Jika dibiarkan untuk terus maju, ia akan membentuk bukan hanya spesies kedua tetapi spesies pengganti.

Mungkin ia akan melayan kita dengan baik, mungkin tidak. Tetapi masa depan akan menjadi miliknya, bukan milik kita. Era manusia akan berakhir.

## Ini tidak dapat dielakkan; manusia boleh, secara sangat konkrit, memutuskan untuk tidak membina pengganti kita.

Penciptaan KBA superhuman adalah jauh daripada tidak dapat dielakkan. Kita boleh mencegahnya melalui set langkah tadbir urus yang diselaraskan:

Pertama, kita memerlukan perakaunan yang mantap dan pengawasan pengkomputeran AI ("pengkomputeran"), yang merupakan pemboleh asas dan tuil untuk mentadbir sistem AI berskala besar. Ini seterusnya memerlukan pengukuran dan pelaporan piawai jumlah pengkomputeran yang digunakan dalam melatih model AI dan menjalankannya, dan kaedah teknikal untuk mengira, mengesahkan, dan mengesahkan pengkomputeran yang digunakan.

Kedua, kita perlu melaksanakan had keras pada pengkomputeran AI, untuk latihan dan operasi; ini menghalang AI daripada menjadi terlalu berkuasa dan beroperasi terlalu pantas. Had ini boleh dilaksanakan melalui kedua-dua keperluan undang-undang dan langkah keselamatan berasaskan perkakasan yang dibina ke dalam cip khusus AI, analog dengan ciri keselamatan dalam telefon moden. Kerana perkakasan AI khusus dibuat oleh hanya segelintir syarikat, pengesahan dan penguatkuasaan boleh dilaksanakan melalui rantaian bekalan sedia ada.

Ketiga, kita memerlukan liabiliti yang dipertingkatkan untuk sistem AI yang paling berbahaya. Mereka yang membangunkan AI yang menggabungkan autonomi tinggi, generaliti luas, dan kecerdasan unggul perlu menghadapi liabiliti ketat untuk bahaya, manakala pelabuhan selamat daripada liabiliti ini akan menggalakkan pembangunan sistem yang lebih terhad dan boleh dikawal.

Keempat, kita memerlukan peraturan berperingkat berdasarkan tahap risiko. Sistem yang paling berkebolehan dan berbahaya memerlukan jaminan keselamatan dan kebolehkawalan yang meluas sebelum pembangunan dan penggunaan, manakala sistem yang kurang berkuasa atau lebih khusus akan menghadapi pengawasan yang berkadar. Rangka kerja kawal selia ini akhirnya perlu beroperasi pada kedua-dua peringkat nasional dan antarabangsa.

Pendekatan ini – dengan spesifikasi terperinci yang diberikan dalam dokumen penuh – adalah praktikal: walaupun penyelarasan antarabangsa akan diperlukan, pengesahan dan penguatkuasaan boleh berfungsi melalui bilangan kecil syarikat yang mengawal rantaian bekalan perkakasan khusus. Ia juga fleksibel: syarikat masih boleh berinovasi dan meraih keuntungan daripada pembangunan AI, hanya dengan had yang jelas pada sistem yang paling berbahaya.

Pembendungan jangka panjang kuasa dan risiko AI memerlukan perjanjian antarabangsa berdasarkan kedua-dua kepentingan diri dan bersama, sebagaimana mengawal proliferasi senjata nuklear sekarang. Tetapi kita boleh bermula serta-merta dengan pengawasan dan liabiliti yang dipertingkatkan, sambil membina ke arah tadbir urus yang lebih komprehensif.

Bahan utama yang hilang adalah kehendak politik dan sosial untuk mengambil alih proses pembangunan AI. Sumber kehendak itu, jika ia datang pada masa yang tepat, akan menjadi realiti itu sendiri – iaitu, daripada kesedaran meluas mengenai implikasi sebenar apa yang kita lakukan.

## Kita boleh merekayasa AI Alat untuk memperkasakan manusia

Daripada mengejar KBA yang tidak boleh dikawal, kita boleh membangunkan "AI Alat" yang berkuasa yang meningkatkan keupayan manusia sambil kekal dalam kawalan manusia yang bermakna. Sistem AI Alat boleh sangat berkebolehan sambil mengelakkan persimpangan berbahaya triple autonomi tinggi, generaliti luas, dan kecerdasan superhuman, selagi kita merekayasanya untuk boleh dikawal pada tahap yang sepadan dengan keupayaan mereka. Mereka juga boleh digabungkan menjadi sistem canggih yang mengekalkan pengawasan manusia sambil memberikan faedah transformatif.

AI Alat boleh merevolusikan perubatan, mempercepatkan penemuan saintifik, meningkatkan pendidikan, dan memperbaiki proses demokratik. Apabila ditadbir dengan betul, ia boleh menjadikan pakar dan institusi manusia lebih berkesan daripada menggantikan mereka. Walaupun sistem sedemikian masih akan sangat mengganggu dan memerlukan pengurusan yang teliti, risiko yang mereka timbulkan pada asasnya berbeza daripada KBA: ia adalah risiko yang boleh kita tadbir, seperti teknologi berkuasa lain, bukan ancaman existential kepada agensi manusia dan tamadun. Dan yang kritikal, apabila dibangunkan dengan bijak, alat AI boleh membantu orang mentadbir AI yang berkuasa dan mengurus kesannya.

Pendekatan ini memerlukan pemikiran semula kedua-dua cara AI dibangunkan dan cara faedahnya diagihkan. Model baru pembangunan AI awam dan bukan untung, rangka kerja kawal selia yang mantap, dan mekanisme untuk mengedarkan faedah ekonomi secara lebih luas boleh membantu memastikan AI memperkasakan manusia secara keseluruhan daripada menumpukan kuasa di beberapa tangan. AI itu sendiri boleh membantu membina institusi sosial dan tadbir urus yang lebih baik, membolehkan bentuk baru penyelarasan dan wacana yang memperkukuh daripada melemahkan masyarakat manusia. Penubuhan keselamatan negara boleh memanfaatkan kepakaran mereka untuk menjadikan sistem alat AI benar-benar selamat dan boleh dipercayai, dan sumber pertahanan sebenar serta kuasa negara.

Kita mungkin akhirnya memilih untuk membangunkan sistem yang lebih berkuasa dan lebih berdaulat yang kurang seperti alat dan – kita boleh berharap – lebih seperti dermawan yang bijak dan berkuasa. Tetapi kita perlu melakukannya hanya selepas kita membangunkan pemahaman saintifik dan kapasiti tadbir urus untuk melakukannya dengan selamat. Keputusan yang sangat penting dan tidak boleh dipulihkan sedemikian perlu dibuat secara sengaja oleh manusia secara keseluruhan, bukan secara lalai dalam perlumbaan antara syarikat teknologi dan negara.

## Di tangan manusia

Orang mahukan kebaikan yang datang daripada AI: alat berguna yang memperkasakan mereka, menggalakkan peluang dan pertumbuhan ekonomi, dan menjanjikan terobosan dalam sains, teknologi, dan pendidikan. Mengapa tidak? Tetapi apabila ditanya, majoriti besar orang awam [mahukan pembangunan AI yang lebih perlahan dan lebih berhati-hati](https://www.vox.com/future-perfect/2023/8/18/23836362/ai-slow-down-poll-regulation), dan tidak mahu AI yang lebih bijak daripada manusia yang akan menggantikan mereka dalam pekerjaan dan tempat lain, memenuhi budaya dan maklumat umum mereka dengan kandungan bukan manusia, menumpukan kuasa dalam set kecil korporasi, menimbulkan risiko global berskala besar yang melampau, dan akhirnya mengancam untuk melucutkan kuasa atau menggantikan spesies mereka. Mengapa mereka perlu?

Kita *boleh* mempunyai satu tanpa yang lain. Ia bermula dengan memutuskan bahawa takdir kita tidak terletak pada inevitabiliti yang dikatakan sesuatu teknologi atau di tangan beberapa CEO di Silicon Valley, tetapi di tangan kita yang lain jika kita mengambilnya. Mari tutup Pintu Gerbang, dan pastikan masa depan tetap manusiawi.