# Bab 10 - Pilihan di hadapan kita

Untuk memelihara masa depan manusia kita, kita mesti memilih untuk menutup Pintu Gerbang kepada KBA dan superintelligence.

Kali terakhir manusia berkongsi Bumi dengan minda-minda lain yang bertutur, berfikir, membina teknologi, dan melakukan penyelesaian masalah secara umum adalah 40,000 tahun yang lalu di Eropah zaman ais. Minda-minda lain itu telah pupus, sepenuhnya atau sebahagiannya disebabkan usaha minda kita.

Kita kini memasuki kembali zaman sedemikian. Produk-produk paling canggih dalam budaya dan teknologi kita – set data yang dibina daripada seluruh ruang maklumat internet kita, dan cip 100-bilion-elemen yang merupakan teknologi paling kompleks yang pernah kita cipta – sedang digabungkan untuk melahirkan sistem AI tujuan umum yang canggih.

Para pembangun sistem ini berminat untuk menggambarkannya sebagai alat untuk memperkasakan manusia. Dan memang ia boleh menjadi begitu. Tetapi jangan silap: trajektori semasa kita ialah membina agen digital yang semakin berkuasa, terarah matlamat, membuat keputusan, dan berkebolehan umum. Mereka sudah berprestasi sebaik ramai manusia dalam pelbagai tugasan intelektual, sedang berkembang pesat, dan menyumbang kepada penambahbaikan diri mereka sendiri.

Melainkan trajektori ini berubah atau menghadapi halangan yang tidak dijangka, kita akan segera – dalam tahun-tahun, bukan dekad-dekad – mempunyai kecerdasan digital yang berbahaya kuasa. Walaupun dalam hasil yang *terbaik*, ini akan membawa manfaat ekonomi yang besar (sekurang-kurangnya kepada sebahagian kita) tetapi hanya dengan kos gangguan yang mendalam dalam masyarakat kita, dan penggantian manusia dalam kebanyakan perkara paling penting yang kita lakukan: mesin-mesin ini akan berfikir untuk kita, merancang untuk kita, membuat keputusan untuk kita, dan mencipta untuk kita. Kita akan dimanjakan, tetapi seperti kanak-kanak yang dimanja. Yang lebih berkemungkinan, sistem ini akan menggantikan manusia dalam perkara positif *dan* negatif yang kita lakukan, termasuk eksploitasi, manipulasi, keganasan, dan peperangan. Bolehkah kita bertahan dengan versi yang diperkuatkan-AI ini? Akhirnya, lebih daripada munasabah bahawa keadaan tidak akan berjalan lancar sama sekali: bahawa agak tidak lama lagi kita akan digantikan bukan sahaja dalam apa yang kita lakukan, tetapi dalam apa yang kita *adakan*, sebagai arkitek tamadun dan masa depan. Tanya orang Neanderthal bagaimana keadaannya. Mungkin kita memberikan mereka pernak-pernik tambahan untuk sementara waktu juga.

*Kita tidak perlu melakukan ini.* Kita mempunyai AI yang boleh bersaing dengan manusia, dan tiada keperluan untuk membina AI yang tidak *boleh* kita tandingi. Kita boleh membina alat AI yang menakjubkan tanpa membina spesies pengganti. Tanggapan bahawa KBA dan superintelligence tidak dapat dielakkan adalah *pilihan yang menyamar sebagai takdir*.

Dengan mengenakan beberapa had yang keras dan global, kita boleh mengekalkan keupayaan umum AI pada tahap lebih kurang manusia sambil masih meraih manfaat keupayaan komputer memproses data dengan cara yang tidak boleh kita lakukan, dan mengautomasikan tugasan yang tidak mahu dilakukan oleh sesiapa pun. Ini masih akan menimbulkan banyak risiko, tetapi jika direka dan diurus dengan baik, akan menjadi anugerah yang sangat besar kepada manusia, dari perubatan hingga penyelidikan hingga produk pengguna.

Mengenakan had akan memerlukan kerjasama antarabangsa, tetapi kurang daripada yang mungkin disangka, dan had tersebut masih akan meninggalkan banyak ruang untuk industri AI dan perkakasan AI yang sangat besar yang tertumpu pada aplikasi yang meningkatkan kesejahteraan manusia, bukannya pada pengejaran kuasa mentah. Dan jika, dengan jaminan keselamatan yang kukuh dan selepas dialog global yang bermakna, kita memutuskan untuk pergi lebih jauh, pilihan itu terus menjadi milik kita untuk diusahakan.

Manusia mesti *memilih* untuk menutup Pintu Gerbang kepada KBA dan superintelligence.

Untuk mengekalkan masa depan yang berperikemanusiaan.

## Nota daripada Pengarang

Terima kasih kerana meluangkan masa untuk menerokai topik ini bersama kami.

Saya menulis esei ini kerana sebagai seorang saintis saya merasakan adalah penting untuk menyatakan kebenaran yang tidak dipoles, dan kerana sebagai seorang manusia saya merasakan adalah penting bagi kita untuk bertindak dengan pantas dan tegas dalam menangani isu yang mengubah dunia: pembangunan sistem AI yang lebih pintar daripada manusia.

Jika kita ingin bertindak balas terhadap keadaan yang luar biasa ini dengan bijaksana, kita mesti bersedia untuk meneliti secara kritikal naratif semasa bahawa KBA dan superintelligence 'mesti' dibina untuk menjamin kepentingan kita, atau adalah 'tidak dapat dielakkan' dan tidak boleh dihentikan. Naratif ini menyebabkan kita tidak berdaya, tidak dapat melihat laluan alternatif di hadapan kita.

Saya berharap anda akan bergabung dengan saya dalam menyeru berhati-hati dalam menghadapi kecuaian, dan berani dalam menghadapi ketamakan.

Saya berharap anda akan bergabung dengan saya dalam menyeru masa depan yang berperikemanusiaan.

*– Anthony*

![Anthony Aguirre signature](https://keepthefuturehuman.ai/essay/_next/image?url=https%3A%2F%2Fkeepthefuturehuman.ai%2Fwp-content%2Fuploads%2F2025%2F02%2FAnthony-Aguirre-signature-300x84.png&w=3840&q=75)