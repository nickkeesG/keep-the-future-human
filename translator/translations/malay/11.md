# Lampiran

Maklumat tambahan, termasuk - Butiran teknikal mengenai perakaunan pengkomputeran, contoh pelaksanaan 'penutupan pintu gerbang', butiran untuk rejim liabiliti KBA yang ketat, dan pendekatan berperingkat untuk piawaian keselamatan dan keamanan KBA.

## Lampiran A: Butiran teknikal perakaunan pengkomputeran

Kaedah terperinci untuk kedua-dua "kebenaran asas" serta anggaran yang baik bagi jumlah pengkomputeran yang digunakan dalam latihan dan inferens diperlukan untuk kawalan berasaskan pengkomputeran yang bermakna. Berikut adalah contoh bagaimana "kebenaran asas" boleh dikira pada tahap teknikal.

**Definisi:**

*Graf kausal pengkomputeran:* Bagi output O yang diberikan dari model AI, terdapat set pengkomputeran digital yang mengubah hasil pengkomputeran tersebut berpotensi mengubah O. (Ini harus dianggap secara konservatif, iaitu harus ada sebab yang jelas untuk mempercayai bahawa pengkomputeran adalah bebas daripada prekursor yang berlaku lebih awal dalam masa dan mempunyai laluan kausal fizikal yang berpotensi memberi kesan.) Ini termasuk pengkomputeran yang dilakukan oleh model AI semasa inferens, serta pengkomputeran yang masuk ke dalam input, penyediaan data, dan latihan model. Kerana mana-mana ini mungkin merupakan output dari model AI, ini dikira secara rekursif, dipotong di mana manusia telah memberikan perubahan yang signifikan kepada input.

*Pengkomputeran Latihan:* Jumlah pengkomputeran, dalam FLOP atau unit lain, yang diperlukan oleh graf kausal pengkomputeran rangkaian neural (termasuk penyediaan data, latihan, dan penalaan halus, dan mana-mana pengkomputeran lain.)

*Pengkomputeran Output:* Jumlah pengkomputeran dalam graf kausal pengkomputeran output AI yang diberikan, termasuk semua rangkaian neural (dan termasuk Pengkomputeran Latihan mereka) dan pengkomputeran lain yang masuk ke dalam output tersebut.

*Kadar Pengkomputeran Inferens:* Dalam siri output, kadar perubahan (dalam FLOP/s atau unit lain) Pengkomputeran Output antara output, iaitu pengkomputeran yang digunakan untuk menghasilkan output seterusnya, dibahagi dengan selang masa antara output.

**Contoh dan anggaran:**

- Untuk rangkaian neural tunggal yang dilatih pada data yang dicipta manusia, Pengkomputeran Latihan hanyalah jumlah pengkomputeran latihan seperti yang lazimnya dilaporkan.
- Untuk rangkaian neural sedemikian yang melakukan inferens pada kadar yang tetap, Kadar Pengkomputeran Inferens adalah lebih kurang jumlah kelajuan kelompok pengkomputeran yang melakukan inferens dalam FLOP/s.
- Untuk penalaan halus model, Pengkomputeran Latihan model lengkap diberikan oleh Pengkomputeran Latihan model tidak ditala halus ditambah pengkomputeran yang dilakukan semasa penalaan halus dan untuk menyediakan sebarang data yang digunakan dalam penalaan halus.
- Untuk model yang disuling, Pengkomputeran Latihan model lengkap termasuk latihan kedua-dua model yang disuling dan model yang lebih besar yang digunakan untuk menyediakan data sintetik atau input latihan lain.
- Jika beberapa model dilatih, tetapi banyak "percubaan" dibuang berdasarkan pertimbangan manusia, ini tidak dikira ke arah Pengkomputeran Latihan atau Output model yang dikekalkan.

## Lampiran B: Contoh pelaksanaan penutupan pintu gerbang

**Contoh Pelaksanaan:** Berikut adalah satu contoh bagaimana penutupan pintu gerbang boleh berfungsi, dengan had 10<sup>27</sup> FLOP untuk latihan dan 10<sup>20</sup> FLOP/s untuk inferens (menjalankan AI):

**1\. Jeda:** Atas sebab keselamatan negara, cabang Eksekutif AS meminta semua syarikat yang berpangkalan di AS, menjalankan perniagaan di AS, atau menggunakan cip yang dikeluarkan di AS, untuk berhenti dan menghentikan sebarang larian latihan AI baru yang mungkin melebihi had Pengkomputeran Latihan 10<sup>27</sup> FLOP. AS harus memulakan perbincangan dengan negara-negara lain yang menjadi tuan rumah pembangunan AI, menggalakkan mereka dengan kuat untuk mengambil langkah yang serupa dan menunjukkan bahawa jeda AS mungkin ditarik balik sekiranya mereka memilih untuk tidak mematuhi.

**2\. Pengawasan dan pelesenan AS:** Melalui perintah eksekutif atau tindakan agensi kawal selia sedia ada, AS menghendaki dalam tempoh (katakan) satu tahun:

- Semua larian latihan AI yang dianggarkan melebihi 10<sup>25</sup> FLOP yang dilakukan oleh syarikat yang beroperasi di AS didaftarkan dalam pangkalan data yang dikekalkan oleh agensi kawal selia AS. (Nota: Versi yang lebih lemah sedikit daripada ini telah dimasukkan dalam perintah eksekutif AS 2023 mengenai AI yang kini dibatalkan, yang memerlukan pendaftaran untuk model melebihi 10<sup>26</sup> FLOP.)
- Semua pengeluar perkakasan berkaitan AI yang beroperasi di AS atau menjalankan perniagaan dengan USG mematuhi set keperluan pada perkakasan khusus mereka dan perisian yang menggerakkannya. (Banyak daripada keperluan ini boleh dibina ke dalam kemas kini perisian dan perisian tegar kepada perkakasan sedia ada, tetapi penyelesaian jangka panjang dan kukuh memerlukan perubahan kepada generasi perkakasan kemudian.) Antara ini adalah keperluan bahawa jika perkakasan adalah sebahagian daripada kelompok yang saling berkaitan berkelajuan tinggi yang mampu melaksanakan 10<sup>18</sup> FLOP/s pengkomputeran, tahap pengesahan yang lebih tinggi diperlukan, yang merangkumi kebenaran tetap oleh "gabenor" jauh yang menerima kedua-dua telemetri dan permintaan untuk melakukan pengkomputeran tambahan.
- Penjaga melaporkan jumlah pengkomputeran yang dilakukan pada perkakasannya kepada agensi yang mengekalkan pangkalan data AS.
- Keperluan yang lebih kuat diperkenalkan secara berperingkat untuk membolehkan pengawasan dan pemberian kebenaran yang lebih selamat dan fleksibel.

**3\. Pengawasan antarabangsa:**

- AS, China, dan mana-mana negara lain yang menjadi tuan rumah keupayaan pembuatan cip maju merundingkan perjanjian antarabangsa.
- Perjanjian ini mencipta agensi antarabangsa baru, serupa dengan Agensi Tenaga Atom Antarabangsa, yang bertugas mengawasi latihan dan pelaksanaan AI.
- Negara-negara penandatangan mesti menghendaki pengeluar perkakasan AI domestik mereka mematuhi set keperluan sekurang-kurangnya sekuat yang dikenakan di AS.
- Penjaga kini dikehendaki melaporkan nombor pengkomputeran AI kepada kedua-dua agensi di negara asal mereka serta pejabat baru dalam agensi antarabangsa.
- Negara-negara tambahan digalakkan dengan kuat untuk menyertai perjanjian antarabangsa sedia ada: kawalan eksport oleh negara penandatangan mengehadkan akses kepada perkakasan mewah oleh bukan penandatangan manakala penandatangan boleh menerima sokongan teknikal dalam menguruskan sistem AI mereka.

**4\. Pengesahan dan penguatkuasaan antarabangsa:**

- Sistem pengesahan perkakasan dikemas kini supaya ia melaporkan penggunaan pengkomputeran kepada kedua-dua penjaga asal dan juga terus kepada pejabat agensi antarabangsa.
- Agensi, melalui perbincangan dengan penandatangan perjanjian antarabangsa, bersetuju mengenai had pengkomputeran yang kemudian berkuat kuasa undang-undang di negara penandatangan.
- Secara selari, set piawaian antarabangsa mungkin dibangunkan supaya latihan dan menjalankan AI melebihi ambang pengkomputeran (tetapi di bawah had) dikehendaki mematuhi piawaian tersebut.
- Agensi boleh, jika perlu untuk mengimbangi algoritma yang lebih baik dll., menurunkan had pengkomputeran. Atau, jika dianggap selamat dan digalakkan (pada katakan tahap jaminan keselamatan yang boleh dibuktikan), menaikkan had pengkomputeran.

## Lampiran C: Butiran untuk rejim liabiliti KBA yang ketat

**Butiran untuk rejim liabiliti KBA yang ketat**

- Penciptaan dan operasi sistem AI maju yang sangat am, berkebolehan, dan autonomi, dianggap sebagai aktiviti "luar biasa berbahaya".
- Oleh itu, liabiliti lalai untuk latihan dan operasi sistem sedemikian adalah liabiliti ketat, bersama dan beberapa (atau setarafnya bukan AS) untuk sebarang kemudaratan yang dilakukan oleh model atau output/tindakannya.
- Liabiliti peribadi akan dikenakan untuk eksekutif dan ahli lembaga dalam kes kecuaian kasar atau salah laku yang disengajakan. Ini harus termasuk penalti jenayah untuk kes yang paling teruk.
- Terdapat banyak pelabuhan selamat di mana liabiliti kembali kepada liabiliti lalai (berasaskan kesalahan, di AS) yang biasanya dikenakan kepada orang dan syarikat.
	- Model yang dilatih dan dioperasikan di bawah ambang pengkomputeran tertentu (yang sekurang-kurangnya 10x lebih rendah daripada had yang diterangkan di atas.)
	- AI yang "lemah" (secara kasarnya, di bawah tahap pakar manusia pada tugas-tugas yang dimaksudkan) dan/atau
	- AI yang "sempit" (mempunyai skop tugas dan operasi yang tetap dan agak terhad yang direka dan dilatih khusus untuknya) dan/atau
	- AI yang "pasif" (sangat terhad dalam keupayaannya â€“ walaupun di bawah pengubahsuaian sederhana â€“ untuk mengambil tindakan atau melakukan tugas berbilang langkah yang kompleks tanpa penglibatan dan kawalan manusia langsung.)
	- AI yang dijamin selamat, terjamin, dan boleh dikawal (selamat secara boleh dibuktikan, atau analisis risiko menunjukkan tahap kemudaratan yang dijangka boleh diabaikan.)
- Pelabuhan selamat boleh dituntut berdasarkan [kes keselamatan](https://arxiv.org/abs/2410.21572) yang disediakan oleh pembangun AI dan diluluskan oleh agensi atau juruaudit yang diberi akreditasi oleh agensi. Untuk menuntut pelabuhan selamat berdasarkan pengkomputeran, pembangun hanya perlu membekalkan anggaran yang boleh dipercayai bagi jumlah Pengkomputeran Latihan dan Kadar Inferens maksimum
- Perundangan akan menggariskan secara jelas situasi di mana pelepasan injunktif daripada pembangunan sistem AI dengan risiko tinggi kemudaratan awam adalah sesuai.
- Konsortium syarikat, bekerjasama dengan NGO dan agensi kerajaan, harus membangunkan piawaian dan norma yang mentakrifkan istilah-istilah ini, bagaimana pengawal selia harus memberikan pelabuhan selamat, bagaimana pembangun AI harus membangunkan kes keselamatan, dan bagaimana mahkamah harus mentafsir liabiliti di mana pelabuhan selamat tidak dituntut secara proaktif.

## Lampiran D: Pendekatan berperingkat untuk piawaian keselamatan & keamanan KBA

**Pendekatan berperingkat untuk piawaian keselamatan & keamanan KBA**

| Peringkat Risiko | Pencetus | Keperluan untuk latihan | Keperluan untuk penggunaan |
| --- | --- | --- | --- |
| RT-0 | AI lemah dalam autonomi, kegeneralan, dan kecerdasan | tiada | tiada |
| RT-1 | AI kuat dalam satu daripada autonomi, kegeneralan, dan kecerdasan | tiada | Berdasarkan risiko dan penggunaan, berpotensi kes keselamatan yang diluluskan oleh pihak berkuasa negara di mana sahaja model boleh digunakan |
| RT-2 | AI kuat dalam dua daripada autonomi, kegeneralan, dan kecerdasan | Pendaftaran dengan pihak berkuasa negara dengan bidang kuasa ke atas pembangun | Kes keselamatan yang mengehadkan risiko kemudaratan besar di bawah paras yang diberi kuasa ditambah audit keselamatan bebas (termasuk redteaming kotak hitam dan kotak putih) yang diluluskan oleh pihak berkuasa negara di mana sahaja model boleh digunakan |
| RT-3 | KBA kuat dalam autonomi, kegeneralan, dan kecerdasan | Pra-kelulusan pelan keselamatan dan keamanan oleh pihak berkuasa negara dengan bidang kuasa ke atas pembangun | Kes keselamatan yang menjamin risiko terbatas kemudaratan besar di bawah paras yang diberi kuasa serta spesifikasi yang diperlukan, termasuk keamanan siber, kebolehkawalan, suis bunuh yang tidak boleh ditanggalkan, penjajaran dengan nilai manusia, dan ketahanan terhadap penggunaan berniat jahat. |
| RT-4 | Mana-mana model yang juga melebihi sama ada 10<sup>27</sup> FLOP Latihan atau 10<sup>20</sup> FLOP/s Inferens | Dilarang sementara menunggu penarikan had pengkomputeran yang dipersetujui antarabangsa | Dilarang sementara menunggu penarikan had pengkomputeran yang dipersetujui antarabangsa |

Klasifikasi risiko dan piawaian keselamatan/keamanan, dengan peringkat berdasarkan ambang pengkomputeran serta gabungan autonomi, kegeneralan, dan kecerdasan yang tinggi:

- *Autonomi kuat* terpakai jika sistem mampu melaksanakan, atau boleh dibuat dengan mudah untuk melaksanakan, tugas berbilang langkah dan/atau mengambil tindakan kompleks yang relevan dengan dunia sebenar, tanpa pengawasan atau campur tangan manusia yang signifikan. Contoh: kenderaan autonomi dan robot; bot perdagangan kewangan. Bukan contoh: GPT-4; pengklasifikasi imej
- *Kegeneralan kuat* menunjukkan skop aplikasi yang luas, prestasi tugas-tugas yang mana model tidak sengaja dan khusus dilatih, dan keupayaan signifikan untuk mempelajari tugas baru. Contoh: GPT-4; mu-zero. Bukan contoh: AlphaFold; kenderaan autonomi; penjana imej
- *Kecerdasan kuat* sepadan dengan prestasi yang menyamai tahap pakar manusia pada tugas-tugas yang mana model berprestasi terbaik (dan untuk model am, merentas pelbagai tugas yang luas.) Contoh: AlphaFold; mu-zero; o3. Bukan contoh: GPT-4; Siri