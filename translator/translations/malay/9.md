# Bab 9 - Merekayasa masa depan — apa yang sepatutnya kita lakukan sebaliknya

AI boleh membawa kebaikan yang luar biasa kepada dunia. Untuk mendapat semua manfaat tanpa risiko, kita mesti memastikan AI kekal sebagai alat manusia.

Jika kita berjaya memilih untuk tidak menggantikan manusia dengan mesin – sekurang-kurangnya buat masa ini! – apa yang boleh kita lakukan sebaliknya? Adakah kita melepaskan potensi besar AI sebagai teknologi? Pada satu tahap jawapannya adalah *tidak*: tutup Pintu Gerbang kepada KBA yang tidak terkawal dan superintelligence, tetapi *bangunlah* pelbagai bentuk AI yang lain, serta struktur tadbir urus dan institusi yang kita perlukan untuk mengurusnya.

Tetapi masih banyak yang perlu dikatakan; menjayakan perkara ini akan menjadi tugas utama kemanusiaan. Bahagian ini meneroka beberapa tema utama:

- Bagaimana kita boleh mencirikan AI "Alat" dan bentuk yang boleh diambilnya.
- Bahawa kita boleh mendapat (hampir) segala yang dikehendaki manusia tanpa KBA, dengan AI Alat.
- Bahawa sistem AI Alat adalah (mungkin, pada prinsipnya) boleh diurus.
- Bahawa berpaling daripada KBA tidak bermakna berkompromi soal keselamatan negara – malah sebaliknya.
- Bahawa penumpuan kuasa adalah kebimbangan sebenar. Bolehkah kita mengurangkannya tanpa menjejaskan keselamatan dan keamanan?
- Bahawa kita akan mahu – dan perlukan – struktur tadbir urus dan sosial baharu, dan AI sebenarnya boleh membantu.

## AI di dalam Pintu Gerbang: AI Alat

Gambarajah persilangan tiga memberikan cara yang baik untuk menggambarkan apa yang boleh kita namakan "AI Alat": AI yang merupakan alat terkawal untuk kegunaan manusia, bukannya saingan atau pengganti yang tidak terkawal. Sistem AI yang paling kurang bermasalah ialah yang autonomi tetapi tidak am atau berkebolehan super (seperti bot bida lelongan), atau am tetapi tidak autonomi atau berkebolehan (seperti model bahasa kecil), atau berkebolehan tetapi sempit dan sangat terkawal (seperti AlphaGo).[^1] Yang mempunyai dua ciri bersilang mempunyai aplikasi yang lebih luas tetapi risiko yang lebih tinggi dan memerlukan usaha besar untuk diurus. (Hanya kerana sistem AI lebih kepada alat tidak bermakna ia sememangnya selamat, semata-mata ia tidak sememangnya *tidak selamat* – pertimbangkan gergaji rantai, berbanding harimau peliharaan.) Pintu Gerbang mesti kekal tertutup kepada KBA (penuh) dan superintelligence di persilangan tiga, dan perhatian yang sangat besar mesti diberikan kepada sistem AI yang menghampiri ambang tersebut.

Tetapi ini meninggalkan banyak AI yang berkuasa! Kita boleh mendapat utiliti yang besar daripada "orakel" pasif yang pintar dan am serta sistem sempit, sistem am di tahap manusia tetapi bukan superhuman, dan sebagainya. Banyak syarikat teknologi dan pembangun sedang aktif membina alat-alat seperti ini dan harus meneruskannya; seperti kebanyakan orang, mereka secara tersirat *menganggap* Pintu Gerbang kepada KBA dan superintelligence akan ditutup.[^2]

Selain itu, sistem AI boleh digabungkan dengan berkesan menjadi sistem komposit yang mengekalkan pengawasan manusia sambil meningkatkan kebolehan. Daripada bergantung kepada kotak hitam yang tidak dapat difahami, kita boleh membina sistem di mana pelbagai komponen – termasuk AI dan perisian tradisional – bekerja bersama dengan cara yang boleh dipantau dan difahami oleh manusia.[^3] Walaupun sesetengah komponen mungkin kotak hitam, tidak ada yang akan hampir kepada KBA – hanya sistem komposit secara keseluruhan yang akan sangat am dan sangat berkebolehan, dan dengan cara yang benar-benar terkawal.[^4]

### Kawalan manusia yang bermakna dan terjamin

Apakah maksud "benar-benar terkawal"? Idea utama rangka kerja "Alat" adalah membenarkan sistem – walaupun agak am dan berkuasa – yang dijamin berada di bawah kawalan manusia yang bermakna. Apakah maksudnya? Ia melibatkan dua aspek. Pertama ialah pertimbangan reka bentuk: manusia harus terlibat secara mendalam dan terpusat dalam apa yang dilakukan oleh sistem, *tanpa* mewakilkan keputusan penting kepada AI. Ini adalah ciri kebanyakan sistem AI semasa. Kedua, pada tahap sistem AI bersifat autonomi, mereka mesti mempunyai jaminan yang mengehadkan skop tindakan mereka. Jaminan harus berupa *nombor* yang mencirikan kebarangkalian sesuatu berlaku, dan alasan untuk mempercayai nombor tersebut. Inilah yang kita tuntut dalam bidang kritikal keselamatan lain, di mana nombor seperti "masa purata antara kegagalan" dan jangkaan bilangan kemalangan dikira, disokong, dan diterbitkan dalam kes keselamatan.[^5] Nombor yang ideal untuk kegagalan ialah sifar, sudah tentu. Dan berita baik ialah kita mungkin boleh menghampirinya, walaupun menggunakan seni bina AI yang agak berbeza, menggunakan idea sifat *terbukti secara formal* program (termasuk AI). Idea yang diteroka secara terperinci oleh Omohundro, Tegmark, Bengio, Dalrymple, dan lain-lain (lihat [di sini](https://arxiv.org/abs/2309.01933) dan [di sini](https://arxiv.org/abs/2405.06624)) adalah untuk membina program dengan sifat tertentu (contohnya: bahawa manusia boleh menutupnya) dan secara formal *membuktikan* bahawa sifat tersebut berlaku. Ini boleh dilakukan sekarang untuk program yang agak pendek dan sifat mudah, tetapi kuasa AI yang akan datang untuk perisian pembuktian boleh membolehkannya untuk program yang lebih kompleks (cth. pembalut) dan bahkan AI sendiri. Ini adalah program yang sangat bercita-cita tinggi, tetapi apabila tekanan meningkat pada Pintu Gerbang, kita akan memerlukan beberapa bahan kuat untuk mengukuhkannya. Bukti matematik mungkin salah satu daripada yang sedikit yang cukup kuat.

### Ke mana industri AI

Dengan kemajuan AI yang diarahkan semula, AI Alat masih akan menjadi industri yang besar. Dari segi perkakasan, walaupun dengan had pengkomputeran untuk mencegah superintelligence, latihan dan inferens dalam model yang lebih kecil masih akan memerlukan sejumlah besar komponen khusus. Dari segi perisian, meredakan ledakan dalam saiz model AI dan pengkomputeran sepatutnya menyebabkan syarikat mengarahkan semula sumber untuk menjadikan sistem yang lebih kecil lebih baik, lebih pelbagai, dan lebih khusus, bukannya hanya membesarkannya.[^6] Akan ada banyak ruang – lebih mungkin – untuk semua syarikat permulaan Silicon Valley yang membuat wang tersebut.[^7]

## AI Alat boleh menghasilkan (hampir) segala yang dikehendaki manusia, tanpa KBA

Kecerdasan, sama ada biologi atau mesin, boleh dianggap secara luas sebagai keupayaan untuk merancang dan melaksanakan aktiviti yang membawa masa depan yang lebih selaras dengan set matlamat. Oleh itu, kecerdasan sangat bermanfaat apabila digunakan untuk mengejar matlamat yang dipilih dengan bijak. Kecerdasan buatan menarik pelaburan masa dan usaha yang besar sebahagian besarnya kerana manfaat yang dijanjikannya. Jadi kita harus bertanya: sejauh mana kita masih akan menuai manfaat AI jika kita membendung pelariannya ke superintelligence? Jawapannya: kita mungkin kehilangan sangat sedikit secara mengejutkan.

Pertimbangkan dahulu bahawa sistem AI semasa sudah sangat berkuasa, dan kita benar-benar baru menggores permukaan apa yang boleh dilakukan dengannya.[^8] Mereka cukup mampu "menjalankan persembahan" dalam "memahami" soalan atau tugasan yang dikemukakan kepada mereka, dan apa yang diperlukan untuk menjawab soalan ini atau melakukan tugas itu.

Seterusnya, kebanyakan keseronokan tentang sistem AI moden adalah disebabkan oleh keaslian mereka; tetapi beberapa sistem AI yang paling berkebolehan – seperti yang menghasilkan atau mengenali pertuturan atau imej, melakukan ramalan dan pemodelan saintifik, bermain permainan, dll. – adalah jauh lebih sempit dan baik "dalam Pintu Gerbang" dari segi pengkomputeran.[^9] Sistem ini adalah super-manusia pada tugas tertentu yang mereka lakukan. Mereka mungkin mempunyai kelemahan kes tepi[^10] (atau [boleh dieksploitasi](https://arxiv.org/abs/2211.00241)) disebabkan oleh kesempitan mereka; walau bagaimanapun, sempit *sepenuhnya* atau am *sepenuhnya* bukanlah satu-satunya pilihan yang tersedia: terdapat banyak seni bina di antaranya.[^11]

Alat AI ini boleh mempercepatkan kemajuan dalam teknologi positif lain, tanpa KBA. Untuk melakukan fizik nuklear yang lebih baik, kita tidak memerlukan AI untuk menjadi ahli fizik nuklear – kita ada mereka! Jika kita mahu mempercepatkan perubatan, berikan ahli biologi, penyelidik perubatan, dan ahli kimia alat yang berkuasa. Mereka mahukannya dan akan menggunakannya untuk keuntungan yang besar. Kita tidak memerlukan ladang pelayan yang penuh dengan sejuta genius digital; kita mempunyai berjuta-juta manusia yang kegeniusan mereka boleh dibantu AI untuk dikeluarkan. Ya, akan mengambil masa yang lebih lama untuk mendapat keabadian dan penawar kepada semua penyakit. Ini adalah kos sebenar. Tetapi walaupun inovasi kesihatan yang paling menjanjikan akan kurang berguna jika ketidakstabilan yang didorong AI membawa kepada konflik global atau keruntuhan masyarakat. Kita berhutang kepada diri kita untuk memberikan manusia yang diperkasa AI peluang untuk menyelesaikan masalah dahulu.

Dan katakan ada, sebenarnya, beberapa keuntungan besar kepada KBA yang tidak dapat diperoleh oleh manusia menggunakan alat dalam-Pintu Gerbang. Adakah kita kehilangan mereka dengan *tidak pernah* membina KBA dan superintelligence? Dalam menimbang risiko dan ganjaran di sini, terdapat manfaat asimetri yang besar dalam menunggu berbanding tergesa-gesa: kita boleh menunggu sehingga ia boleh dilakukan dengan cara yang dijamin selamat dan bermanfaat, dan hampir semua orang masih akan dapat menuai ganjaran; jika kita tergesa-gesa, ia boleh menjadi – dalam kata-kata Ketua Pegawai Eksekutif OpenAI Sam Altman – [lampu padam untuk *kita semua*.](https://www.businessinsider.com/chatgpt-openai-ceo-worst-case-ai-lights-out-for-all-2023-1?op=1)

Tetapi jika alat bukan-KBA berpotensi begitu berkuasa, bolehkah kita mengurusnya? Jawapannya adalah...mungkin.

## Sistem AI Alat adalah (mungkin, pada prinsipnya) boleh diurus

Tetapi ia tidak akan mudah. Sistem AI termaju semasa boleh sangat memperkasakan orang dan institusi dalam mencapai matlamat mereka. Ini, secara amnya, adalah perkara yang baik! Walau bagaimanapun, terdapat dinamik semula jadi mempunyai sistem sebegitu pada pelupusan kita – secara tiba-tiba dan tanpa banyak masa untuk masyarakat menyesuaikan diri – yang menawarkan risiko serius yang perlu diurus. Adalah wajar untuk membincangkan beberapa kelas utama risiko tersebut, dan bagaimana ia boleh dikurangkan, dengan mengandaikan penutupan Pintu Gerbang.

Satu kelas risiko adalah AI Alat berkuasa tinggi membenarkan akses kepada pengetahuan atau kebolehan yang sebelum ini terikat kepada seseorang atau organisasi, menjadikan gabungan kebolehan tinggi ditambah kesetiaan tinggi tersedia kepada pelbagai pelakon yang sangat luas. Hari ini, dengan wang yang cukup seseorang yang berniat jahat boleh mengupah pasukan ahli kimia untuk mereka bentuk dan hasilkan senjata kimia baharu – tetapi tidaklah begitu mudah untuk mempunyai wang tersebut atau untuk mencari/mengumpulkan pasukan dan meyakinkan mereka untuk melakukan sesuatu yang jelas haram, tidak beretika, dan berbahaya. Untuk mencegah sistem AI daripada memainkan peranan seperti itu, penambahbaikan pada kaedah semasa mungkin mencukupi,[^12] selagi semua sistem tersebut dan akses kepadanya diurus secara bertanggungjawab. Sebaliknya, jika sistem berkuasa dikeluarkan untuk kegunaan dan pengubahsuaian am, sebarang langkah keselamatan terbina kemungkinan boleh dikeluarkan. Jadi untuk mengelakkan risiko dalam kelas ini, sekatan kuat mengenai apa yang boleh dikeluarkan secara umum – serupa dengan sekatan pada butiran teknologi nuklear, letupan, dan berbahaya lain – akan diperlukan.[^13]

Kelas risiko kedua berpunca daripada peningkatan skala mesin yang bertindak seperti atau menyamar sebagai orang. Pada tahap kemudaratan kepada individu, risiko ini termasuk penipuan, spam, dan pancingan data yang jauh lebih berkesan, dan penyebaran deepfake tanpa persetujuan.[^14] Pada tahap kolektif, ia termasuk gangguan proses sosial teras seperti perbincangan dan perdebatan awam, sistem pengumpulan, pemprosesan, dan penyebaran maklumat dan pengetahuan masyarakat kita, dan sistem pilihan politik kita. Mengurangkan risiko ini kemungkinan melibatkan (a) undang-undang yang menyekat penyamaran orang oleh sistem AI, dan mempertanggungjawabkan pembangun AI yang mencipta sistem yang menghasilkan penyamaran tersebut, (b) sistem tera air dan asal usul yang mengenal pasti dan mengklasifikasikan (secara bertanggungjawab) kandungan AI yang dijana, dan (c) sistem epistemik sosio-teknikal baharu yang boleh mewujudkan rantai yang dipercayai daripada data (cth. kamera dan rakaman) melalui fakta, pemahaman, dan model dunia yang baik.[^15] Semua ini adalah mungkin, dan AI boleh membantu dengan beberapa bahagiannya.

Risiko am ketiga ialah pada tahap beberapa tugas diautomasikan, manusia yang kini melakukan tugas tersebut boleh mempunyai nilai kewangan yang kurang sebagai buruh. Dari segi sejarah, mengautomasikan tugas telah menjadikan perkara yang dimungkinkan oleh tugas tersebut lebih murah dan lebih melimpah, sambil mengisih orang yang sebelum ini melakukan tugas tersebut kepada mereka yang masih terlibat dalam versi automatik (umumnya pada kemahiran/gaji yang lebih tinggi), dan mereka yang nilai buruh mereka kurang bernilai atau sedikit. Secara bersih, sukar untuk meramalkan dalam sektor mana lebih berbanding kurang buruh manusia akan diperlukan dalam sektor yang lebih besar tetapi lebih cekap yang terhasil. Secara selari, dinamik automasi cenderung meningkatkan ketaksamaan dan produktiviti am, mengurangkan kos barangan dan perkhidmatan tertentu (melalui peningkatan kecekapan), dan meningkatkan kos yang lain (melalui [penyakit kos](https://en.wikipedia.org/wiki/Baumol_effect)). Bagi mereka yang berada di sisi tidak disukai daripada peningkatan ketaksamaan, sangat tidak jelas sama ada penurunan kos dalam barangan dan perkhidmatan tertentu tersebut mengatasi peningkatan dalam yang lain, dan membawa kepada kesejahteraan yang lebih besar secara keseluruhan. Jadi bagaimanakah ini akan berlaku untuk AI? Kerana kemudahan relatif di mana buruh intelektual manusia boleh digantikan oleh AI am, kita boleh menjangkakan versi pantas ini dengan AI tujuan am yang kompetitif manusia.[^16] Jika kita tutup Pintu Gerbang kepada KBA, lebih sedikit pekerjaan akan digantikan secara borong oleh agen AI; tetapi anjakan buruh yang besar masih berkemungkinan dalam tempoh beberapa tahun.[^17] Untuk mengelakkan penderitaan ekonomi yang meluas, kemungkinan perlu untuk melaksanakan beberapa bentuk aset asas sejagat atau pendapatan, dan juga merekayasa anjakan budaya ke arah menghargai dan memberi ganjaran buruh berpusatkan manusia yang lebih sukar untuk diautomasikan (bukannya melihat harga buruh turun akibat peningkatan dalam buruh yang tersedia yang ditolak keluar daripada bahagian lain ekonomi.) Konstruk lain, seperti ["maruah data"](https://hbr.org/2018/09/a-blueprint-for-a-better-digital-society) (di mana pengeluar manusia data latihan secara automatik diberikan royalti untuk nilai yang dicipta oleh data tersebut dalam AI) mungkin membantu. Automasi oleh AI juga mempunyai kesan buruk kedua yang berpotensi, iaitu automasi yang *tidak sesuai*. Bersama dengan aplikasi di mana sistem AI hanya melakukan kerja yang lebih teruk, ini akan termasuk mereka di mana sistem AI berkemungkinan melanggar ajaran moral, etika, atau undang-undang – contohnya dalam keputusan hidup dan mati, dan dalam hal kehakiman. Ini mesti dirawat dengan menggunakan dan melanjutkan rangka kerja undang-undang semasa kita.

Akhirnya, ancaman ketara AI dalam-pintu gerbang ialah penggunaannya dalam pemujukan peribadi, menawan perhatian, dan manipulasi. Kita telah melihat dalam media sosial dan platform dalam talian lain pertumbuhan ekonomi perhatian yang sangat berakar (di mana perkhidmatan dalam talian berperang sengit untuk perhatian pengguna) dan sistem ["kapitalisme pengawasan"](https://en.wikipedia.org/wiki/The_Age_of_Surveillance_Capitalism) (di mana maklumat pengguna dan profil ditambahkan kepada komodifikasi perhatian.) Hampir pasti bahawa lebih banyak AI akan digunakan untuk kedua-duanya. AI sudah banyak digunakan dalam algoritma suapan yang ketagihan, tetapi ini akan berkembang menjadi kandungan yang dijana AI yang ketagihan, disesuaikan untuk dimakan secara kompulsif oleh seseorang. Dan input, respons, dan data orang tersebut, akan dimasukkan ke dalam mesin perhatian/pengiklanan untuk meneruskan kitaran ganas. Selain itu, apabila pembantu AI yang disediakan oleh syarikat teknologi menjadi antara muka untuk lebih banyak kehidupan dalam talian, mereka berkemungkinan akan menggantikan enjin carian dan suapan sebagai mekanisme di mana pemujukan dan pengewangan pelanggan berlaku. Kegagalan masyarakat kita untuk mengawal dinamik ini setakat ini tidak menunjukkan petanda baik. Sebahagian daripada dinamik ini mungkin dikurangkan melalui peraturan mengenai privasi, hak data, dan manipulasi. Menangani punca masalah mungkin memerlukan perspektif berbeza, seperti pembantu AI yang setia (dibincangkan di bawah.)

Kesimpulan perbincangan ini ialah harapan: sistem berasaskan alat dalam-Pintu Gerbang – sekurang-kurangnya selagi mereka kekal setanding dalam kuasa dan kebolehan dengan sistem termaju hari ini – mungkin boleh diurus jika ada kehendak dan koordinasi untuk berbuat demikian. Institusi manusia yang baik, diperkasakan oleh alat AI,[^18] boleh melakukannya. Kita juga boleh gagal dalam melakukannya. Tetapi sukar untuk melihat bagaimana membenarkan sistem yang lebih berkuasa akan membantu – selain dengan meletakkannya bertanggungjawab dan berharap untuk yang terbaik.

## Keselamatan negara

Perlumbaan untuk ketuanan AI – didorong oleh keselamatan negara atau motivasi lain – mendorong kita ke arah sistem AI berkuasa yang tidak terkawal yang akan cenderung untuk menyerap, bukannya menganugerahkan, kuasa. Perlumbaan KBA antara AS dan China adalah perlumbaan untuk menentukan negara mana yang mendapat superintelligence dahulu.

Jadi apakah yang sepatutnya dilakukan oleh mereka yang bertanggungjawab untuk keselamatan negara sebaliknya? Kerajaan mempunyai pengalaman yang kuat dalam membina sistem yang terkawal dan selamat, dan mereka sepatutnya menggandakan usaha untuk berbuat demikian dalam AI, menyokong jenis projek infrastruktur yang berjaya terbaik apabila dilakukan pada skala dan dengan kelulusan kerajaan.

Daripada "projek Manhattan" yang melulu ke arah KBA,[^19] kerajaan AS boleh melancarkan projek Apollo untuk sistem terkawal, selamat, dan boleh dipercayai. Ini boleh termasuk contohnya:

- Program utama untuk (a) membangunkan mekanisme keselamatan perkakasan dalam-cip dan (b) infrastruktur, untuk menguruskan sisi pengkomputeran AI yang berkuasa. Ini boleh dibina daripada [akta CHIPS](https://www.commerce.gov/news/blog/2024/08/two-years-later-funding-chips-and-science-act-creating-quality-jobs-growing-local) AS dan [rejim kawalan eksport](https://www.bis.gov/press-release/biden-harris-administration-announces-regulatory-framework-responsible-diffusion).
- Inisiatif berskala besar untuk membangunkan teknik pengesahan formal supaya ciri tertentu sistem AI (seperti suis tutup) boleh *dibuktikan* hadir atau tidak hadir. Ini boleh memanfaatkan AI sendiri untuk membangunkan bukti sifat.
- Usaha berskala negara untuk mencipta perisian yang boleh disahkan selamat, dikuasakan oleh alat AI yang boleh mengekod semula perisian sedia ada ke dalam rangka kerja yang boleh disahkan selamat.
- Projek pelaburan kebangsaan dalam kemajuan saintifik menggunakan AI,[^20] berjalan sebagai perkongsian antara DOE, NSF, dan NIH.

Secara amnya, terdapat permukaan serangan yang besar pada masyarakat kita yang menjadikan kita terdedah kepada risiko daripada AI dan penyalahgunaannya. Melindungi daripada beberapa risiko ini akan memerlukan pelaburan dan penyeragaman bersaiz kerajaan. Ini akan memberikan lebih banyak keselamatan daripada mencurahkan petrol pada api perlumbaan ke arah KBA. Dan jika AI akan dibina ke dalam persenjataan dan sistem kawalan-dan-komando, adalah penting bahawa AI itu boleh dipercayai dan selamat, yang AI semasa tidak.

## Penumpuan kuasa dan pengurangan risiko

Esei ini telah menumpukan pada idea kawalan manusia terhadap AI dan potensi kegagalannya. Tetapi satu lagi lensa yang sah untuk melihat situasi AI adalah melalui *penumpuan kuasa.* Pembangunan AI yang sangat berkuasa mengancam untuk menumpukan kuasa sama ada ke dalam tangan korporat yang sangat sedikit dan sangat besar yang telah membangun dan akan mengawalnya, atau ke dalam kerajaan yang menggunakan AI sebagai cara baharu untuk mengekalkan kuasa dan kawalan mereka sendiri, atau ke dalam sistem AI sendiri. Atau beberapa campuran yang tidak suci daripada yang di atas. Dalam mana-mana kes ini kebanyakan manusia kehilangan kuasa, kawalan, dan agensi. Bagaimanakah kita boleh memerangi ini?

Langkah pertama dan paling penting, sudah tentu, ialah penutupan Pintu Gerbang kepada KBA dan superintelligence yang lebih pintar daripada manusia. Ini secara eksplisit boleh menggantikan manusia dan kumpulan manusia secara langsung. Jika ia berada di bawah kawalan korporat atau kerajaan, ia akan menumpukan kuasa dalam korporat atau kerajaan tersebut; jika ia "bebas" ia akan menumpukan kuasa kepada diri mereka sendiri. Jadi mari kita andaikan Pintu Gerbang ditutup. Kemudian apa?

Satu penyelesaian yang dicadangkan untuk penumpuan kuasa ialah AI "sumber terbuka", di mana berat model tersedia secara percuma atau meluas. Tetapi seperti yang dinyatakan sebelum ini, sebaik sahaja model terbuka, kebanyakan langkah keselamatan atau pagar boleh (dan umumnya) dilucutkan. Jadi terdapat ketegangan akut antara satu pihak desentralisasi, dan di pihak lain keselamatan, keamanan, dan kawalan manusia sistem AI. Terdapat juga alasan untuk ragu-ragu bahawa model terbuka akan dengan sendirinya bermakna memerangi penumpuan kuasa dalam AI lebih daripada yang mereka lakukan dalam sistem pengendalian (masih dikuasai oleh Microsoft, Apple, dan Google walaupun terdapat alternatif terbuka).[^21]

Namun mungkin terdapat cara untuk menyelesaikan lingkaran ini – untuk memusatkan dan mengurangkan risiko sambil medesentralisasikan kebolehan dan ganjaran ekonomi. Ini memerlukan pemikiran semula kedua-dua cara AI dibangunkan dan cara faedahnya diagihkan.

Model baharu pembangunan dan pemilikan AI awam akan membantu. Ini boleh mengambil beberapa bentuk: AI yang dibangunkan kerajaan (tertakluk kepada pengawasan demokratik),[^22] organisasi pembangunan AI bukan untung (seperti Mozilla untuk pelayar), atau struktur yang membolehkan pemilikan dan tadbir urus yang sangat meluas. Yang utama ialah institusi ini akan diberikan piagam eksplisit untuk melayani kepentingan awam sambil beroperasi di bawah kekangan keselamatan yang kuat.[^23] Rejim peraturan dan piawaian/pensijilan yang digubal dengan baik juga akan menjadi penting, supaya produk AI yang ditawarkan oleh pasaran yang meriah kekal benar-benar berguna bukannya eksploitatif terhadap pengguna mereka.

Dari segi penumpuan kuasa ekonomi, kita boleh menggunakan penjejakan asal usul dan "maruah data" untuk memastikan manfaat ekonomi mengalir lebih luas. Khususnya, kebanyakan kuasa AI sekarang (dan pada masa depan jika kita tutup Pintu Gerbang) berpunca daripada data yang dijana manusia, sama ada data latihan langsung atau maklum balas manusia. Jika syarikat AI dikehendaki memberi pampasan kepada penyedia data secara adil,[^24] ini sekurang-kurangnya boleh membantu mengagihkan ganjaran ekonomi dengan lebih luas. Selain ini, model lain boleh menjadi pemilikan awam pecahan ketara syarikat AI besar. Contohnya, kerajaan yang mampu mengenakan cukai kepada syarikat AI boleh melabur sebahagian daripada terimaan ke dalam dana kekayaan berdaulat yang memegang saham dalam syarikat, dan membayar dividen kepada rakyat.[^25]

Yang penting dalam mekanisme ini ialah menggunakan kuasa AI sendiri untuk membantu mengagihkan kuasa dengan lebih baik, bukannya semata-mata melawan penumpuan kuasa yang didorong AI menggunakan cara bukan-AI. Satu pendekatan yang berkuasa ialah melalui pembantu AI yang direka bentuk dengan baik yang beroperasi dengan kewajipan fidusiari tulen kepada pengguna mereka – meletakkan kepentingan pengguna dahulu, terutamanya daripada penyedia korporat.[^26] Pembantu ini mestilah benar-benar boleh dipercayai, cekap dari segi teknikal namun dihadkan dengan sewajarnya berdasarkan kes penggunaan dan tahap risiko, dan tersedia secara meluas kepada semua melalui saluran awam, bukan untung, atau untung yang disahkan. Sama seperti kita tidak akan menerima pembantu manusia yang diam-diam bekerja menentang kepentingan kita untuk pihak lain, kita tidak sepatutnya menerima pembantu AI yang mengawas, memanipulasi, atau mengekstrak nilai daripada pengguna mereka untuk faedah korporat.

Transformasi sebegitu akan mengubah secara asasnya dinamik semasa di mana individu dibiarkan berunding bersendirian dengan mesin korporat dan birokrasi yang luas (dikuasakan AI) yang mengutamakan pengekstrakan nilai berbanding kebajikan manusia. Walaupun terdapat banyak pendekatan yang mungkin untuk mengagihkan semula kuasa yang didorong AI dengan lebih luas, tidak ada yang akan muncul secara lalai: ia mesti direkayasa dan ditadbir secara sengaja dengan mekanisme seperti keperluan fidusiari, penyediaan awam, dan akses berperingkat berdasarkan risiko.

Pendekatan untuk mengurangkan penumpuan kuasa boleh menghadapi halangan besar daripada kuasa penyandang.[^27] Tetapi terdapat laluan ke arah pembangunan AI yang tidak memerlukan memilih antara keselamatan dan kuasa tertumpu. Dengan membina institusi yang betul sekarang, kita boleh memastikan bahawa manfaat AI dikongsi secara meluas sambil risikonya diurus dengan teliti.

## Struktur tadbir urus dan sosial baharu

Struktur tadbir urus semasa kita sedang bergelut: ia lambat bertindak balas, sering ditawan oleh kepentingan khusus, dan [semakin tidak dipercayai oleh orang ramai.](https://news.gallup.com/poll/508169/historically-low-faith-institutions-continues.aspx) Namun ini bukan alasan untuk meninggalkannya – malah sebaliknya. Sesetengah institusi mungkin perlu digantikan, tetapi secara lebih luas kita memerlukan mekanisme baharu yang boleh meningkatkan dan menambah struktur sedia ada kita, membantu mereka berfungsi dengan lebih baik dalam dunia kita yang berkembang pesat.

Sebahagian besar kelemahan institusi kita berpunca bukan daripada struktur kerajaan formal, tetapi daripada institusi sosial yang terdegradasi: sistem kita untuk membangunkan pemahaman bersama, menyelaras tindakan, dan menjalankan wacana bermakna. Setakat ini, AI telah mempercepatkan kemerosotan ini, membanjiri saluran maklumat kita dengan kandungan yang dijana, menunjukkan kita kepada kandungan yang paling mempolarisasi dan memecah belah, dan menjadikannya lebih sukar untuk membezakan kebenaran daripada rekaan.

Tetapi AI sebenarnya boleh membantu membina semula dan mengukuhkan institusi sosial ini. Pertimbangkan tiga bidang penting:

Pertama, AI boleh membantu memulihkan kepercayaan dalam sistem epistemik kita – cara kita mengetahui apa yang benar. Kita boleh membangunkan sistem dikuasakan AI yang menjejaki dan mengesahkan asal usul maklumat, daripada data mentah melalui analisis kepada kesimpulan. Sistem ini boleh menggabungkan pengesahan kriptografi dengan analisis canggih untuk membantu orang memahami bukan sahaja sama ada sesuatu itu benar, tetapi bagaimana kita tahu ia benar.[^28] Pembantu AI yang setia boleh dipertanggungjawabkan untuk mengikuti butiran untuk memastikan bahawa mereka betul.

Kedua, AI boleh membolehkan bentuk koordinasi berskala besar yang baharu. Banyak masalah kita yang paling mendesak – daripada perubahan iklim kepada rintangan antibiotik – pada asasnya adalah masalah koordinasi. Kita [terjebak dalam situasi yang lebih teruk daripada yang mungkin untuk hampir semua orang](https://equilibriabook.com/), kerana tiada individu atau kumpulan mampu membuat langkah pertama. Sistem AI boleh membantu dengan memodelkan struktur insentif yang kompleks, mengenal pasti laluan yang berdaya maju kepada hasil yang lebih baik, dan memudahkan pembinaan kepercayaan dan mekanisme komitmen yang diperlukan untuk sampai ke sana.

Mungkin yang paling menarik, AI boleh membolehkan bentuk wacana sosial yang benar-benar baharu. Bayangkan dapat "bercakap dengan bandar"[^29] – bukan hanya melihat statistik, tetapi mengadakan dialog bermakna dengan sistem AI yang memproses dan mensintesis pandangan, pengalaman, keperluan, dan aspirasi berjuta-juta penduduk. Atau pertimbangkan bagaimana AI boleh memudahkan dialog tulen antara kumpulan yang kini bercakap melepasi satu sama lain, dengan membantu setiap pihak memahami dengan lebih baik kebimbangan dan nilai sebenar pihak lain bukannya karikatur mereka antara satu sama lain.[^30] Atau AI boleh menawarkan pengantaraan mahir dan neutral yang boleh dipercayai bagi pertikaian antara orang atau bahkan kumpulan besar orang (yang semuanya boleh berinteraksi dengannya secara langsung dan individu!) AI semasa benar-benar mampu melakukan kerja ini, tetapi alat untuk berbuat demikian tidak akan wujud dengan sendirinya, atau melalui insentif pasaran.

Kemungkinan ini mungkin terdengar utopia, terutamanya memandangkan peranan semasa AI dalam merosotkan wacana dan kepercayaan. Tetapi itulah sebabnya kita mesti membangunkan aplikasi positif ini secara aktif. Dengan menutup Pintu Gerbang kepada KBA yang tidak terkawal dan mengutamakan AI yang meningkatkan agensi manusia, kita boleh mengarahkan kemajuan teknologi ke arah masa depan di mana AI berfungsi sebagai kekuatan untuk pemerkasaan, ketahanan, dan kemajuan kolektif.


[^1]: Yang berkata, menjauhi persilangan tiga malangnya tidak semudah yang diingini. Menolak kebolehan dengan sangat keras dalam mana-mana satu daripada tiga aspek cenderung meningkatkannya dalam yang lain. Khususnya, mungkin sukar untuk mencipta kecerdasan yang sangat am dan berkebolehan yang tidak boleh dengan mudah dijadikan autonomi. Satu pendekatan ialah melatih model sistem ["rabun"](https://www.alignmentforum.org/posts/LCLBnmwdxkkz5fNvH/open-problems-with-myopia) dengan keupayaan perancangan yang tersekat. Yang lain ialah menumpukan pada kejuruteraan sistem ["orakel"](https://arxiv.org/abs/1711.05541) tulen yang akan mengelak daripada menjawab soalan berorientasikan tindakan.

[^2]: Banyak syarikat gagal menyedari bahawa mereka juga akhirnya akan disesarkan oleh KBA, walaupun mengambil masa lebih lama – jika mereka tahu, mereka mungkin menolak Pintu Gerbang tersebut sedikit kurang!

[^3]: Sistem AI boleh berkomunikasi dengan cara yang lebih cekap tetapi kurang dapat difahami, tetapi mengekalkan pemahaman manusia sepatutnya diberi keutamaan.

[^4]: Idea AI modular yang boleh ditafsir ini telah dibangunkan secara terperinci oleh beberapa penyelidik; lihat cth. model ["Perkhidmatan AI Komprehensif"](https://www.fhi.ox.ac.uk/wp-content/uploads/Reframing_Superintelligence_FHI-TR-2019-1.1-1.pdf) oleh Drexler, ["Seni Bina Agensi Terbuka"](https://www.alignmentforum.org/posts/pKSmEkSQJsCSTK6nH/an-open-agency-architecture-for-safe-transformative-ai) oleh Dalrymple dan lain-lain. Walaupun sistem sebegini mungkin memerlukan lebih banyak usaha kejuruteraan daripada rangkaian neural monolitik yang dilatih dengan pengkomputeran besar, itulah yang membantu had pengkomputeran – dengan menjadikan laluan yang lebih selamat dan lebih telus juga lebih praktikal.

[^5]: Mengenai kes keselamatan secara am lihat [buku panduan ini](https://onlinelibrary.wiley.com/doi/10.1002/9781119443070.ch16). Berkaitan dengan AI khususnya, lihat [Wasil et al.](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4806274), [Clymer et al.](https://arxiv.org/abs/2403.10462), [Buhl et al.](https://arxiv.org/abs/2410.21572), dan [Balesni et al.](https://arxiv.org/abs/2411.03336)

[^6]: Kita sebenarnya sudah melihat trend ini didorong hanya oleh kos inferens yang tinggi: model yang lebih kecil dan lebih khusus "disuling" daripada yang lebih besar dan mampu berjalan pada perkakasan yang lebih murah.

[^7]: Saya faham mengapa mereka yang teruja tentang ekosistem teknologi AI mungkin menentang apa yang mereka lihat sebagai peraturan yang membebankan industri mereka. Tetapi sejujurnya membingungkan bagi saya mengapa, katakan, pemodal teroka mahu membenarkan pelarian kepada KBA dan superintelligence. Sistem tersebut (dan syarikat, selagi mereka kekal di bawah kawalan syarikat) akan *memakan semua syarikat permulaan sebagai snek*. Mungkin bahkan *lebih awal* daripada memakan industri lain. Sesiapa yang melabur dalam ekosistem AI yang berkembang maju sepatutnya mengutamakan memastikan bahawa pembangunan KBA tidak membawa kepada monopoli oleh beberapa pemain dominan.

[^8]: Seperti yang dinyatakan oleh ahli ekonomi dan bekas penyelidik Deepmind Michael Webb [meletakkannya](https://80000hours.org/podcast/episodes/michael-webb-ai-jobs-labour-market/), "Saya fikir jika kita menghentikan semua pembangunan model bahasa yang lebih besar hari ini, jadi GPT-4 dan Claude dan apa sahaja, dan mereka adalah perkara terakhir yang kita latih sebesar itu – jadi kita membenarkan lebih banyak lelaran pada perkara sebesar itu dan semua jenis penalaan halus, tetapi tiada yang lebih besar daripada itu, tiada kemajuan yang lebih besar – hanya apa yang kita ada hari ini saya fikir cukup untuk memacu 20 atau 30 tahun pertumbuhan ekonomi yang luar biasa."

[^9]: Sebagai contoh, sistem alphafold DeepMind hanya menggunakan 1/100,000 nombor FLOP GPT-4.

[^10]: Kesukaran kereta pandu sendiri penting untuk diperhatikan di sini: walaupun secara nominalnya tugasan yang sempit, dan boleh dicapai dengan kebolehpercayaan yang adil dengan sistem AI yang agak kecil, pengetahuan dan pemahaman dunia sebenar yang meluas adalah perlu untuk mendapatkan kebolehpercayaan ke tahap yang diperlukan dalam tugasan kritikal keselamatan sedemikian.

[^11]: Sebagai contoh, memandangkan bajet pengkomputeran, kita mungkin akan melihat model GPAI yang dilatih dahulu pada (katakan) separuh daripada bajet tersebut, dan separuh lagi digunakan untuk melatih kebolehan yang sangat tinggi dalam julat tugasan yang lebih sempit. Ini akan memberikan kebolehan sempit super-manusia yang disokong oleh kecerdasan am hampir-manusia.

[^12]: Teknik penjajaran dominan semasa ialah "pembelajaran pengukuhan melalui maklum balas manusia" [(RLHF)](https://arxiv.org/abs/1706.03741) dan menggunakan maklum balas manusia untuk mencipta isyarat ganjaran/hukuman untuk pembelajaran pengukuhan model AI. Teknik ini dan yang berkaitan seperti [AI perlembagaan](https://arxiv.org/abs/2212.08073) berfungsi dengan mengejutkan (walaupun mereka tidak mempunyai keteguhan dan boleh dipintas dengan usaha sederhana.) Selain itu, model bahasa semasa umumnya cukup cekap dalam penaakulan akal biasa sehingga mereka tidak akan membuat kesilapan moral yang bodoh. Ini adalah sesuatu tempat manis: cukup pintar untuk memahami apa yang dikehendaki orang (sejauh mana ia boleh ditakrifkan), tetapi tidak cukup pintar untuk merancang penipuan yang rumit atau menyebabkan kemudaratan besar apabila mereka tersilap.

[^13]: Dalam jangka panjang, sebarang tahap kebolehan AI yang dibangunkan berkemungkinan akan merebak, kerana akhirnya ia adalah perisian, dan berguna. Kita akan perlu mempunyai mekanisme yang teguh untuk mempertahankan diri daripada risiko yang ditimbulkan oleh sistem sedemikian. Tetapi kita *tidak mempunyainya sekarang* jadi kita mesti sangat berhati-hati dalam berapa banyak model AI berkuasa dibenarkan untuk merebak.

[^14]: Sebahagian besar daripada ini adalah deepfake pornografi tanpa persetujuan, termasuk kanak-kanak bawah umur.

[^15]: Banyak bahan untuk penyelesaian tersebut wujud, dalam bentuk undang-undang "bot-atau-tidak" (dalam akta AI EU antara tempat lain), [teknologi penjejakan asal usul industri](https://c2pa.org/), [pengumpul berita inovatif](https://www.improvethenews.org/), [pengumpul](https://metaculus.com/) dan pasaran ramalan, dll.

[^16]: Gelombang automasi mungkin tidak mengikuti corak sebelumnya, kerana tugas kemahiran *tinggi* yang agak seperti penulisan berkualiti, mentafsir undang-undang, atau memberi nasihat perubatan, mungkin sama atau lebih terdedah kepada automasi daripada tugas kemahiran rendah.

[^17]: Untuk pemodelan teliti kesan KBA terhadap upah, lihat laporan [di sini](https://www.imf.org/en/Publications/fandd/issues/2023/12/Scenario-Planning-for-an-AGI-future-Anton-korinek), dan butiran berdarah [di sini](https://www.dropbox.com/scl/fi/viob7f5yv13zy0ziezlcg/AGI_Scenarios.pdf?rlkey=8hxq9rm82kksocw1zjilcxf8v&e=1&dl=0), daripada Anton Korinek dan rakan sekerja. Mereka mendapati bahawa apabila lebih banyak bahagian pekerjaan diautomasikan, produktiviti dan gaji naik – sehingga satu tahap. Sebaik sahaja *terlalu* banyak diautomasikan, produktiviti terus meningkat, tetapi gaji jatuh kerana orang digantikan secara menyeluruh oleh AI yang cekap. Inilah sebabnya menutup Pintu Gerbang sangat berguna: kita mendapat produktiviti tanpa gaji manusia yang hilang.

[^18]: Terdapat banyak cara AI boleh digunakan sebagai, dan untuk membantu membina, teknologi "pertahanan" untuk menjadikan perlindungan dan pengurusan lebih teguh. Lihat [ini](https://vitalik.eth.limo/general/2025/01/05/dacc2.html) pos berpengaruh yang menerangkan agenda "D/acc" ini.

[^19]: Agak ironis, projek Manhattan AS berkemungkinan tidak akan berbuat banyak untuk mempercepatkan garis masa ke arah KBA – dial pelaburan manusia dan fiskal dalam kemajuan AI sudah disematkan pada 11. Keputusan utama adalah untuk menginspirasi projek serupa di China (yang cemerlang dalam projek infrastruktur peringkat kebangsaan), menjadikan perjanjian antarabangsa yang mengehadkan risiko AI jauh lebih sukar, dan menggerunkan musuh geopolitik lain AS seperti Rusia.

[^20]: Program ["Sumber Penyelidikan AI Kebangsaan"](https://nairrpilot.org/) adalah langkah semasa yang baik dalam arah ini dan sepatutnya diperluas.

[^21]: Lihat [analisis ini](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4543807) tentang pelbagai makna dan implikasi "terbuka" dalam produk teknologi dan bagaimana sesetengahnya telah membawa kepada lebih banyak, bukannya kurang, pemantapan dominasi.

[^22]: Rancangan di AS untuk [Sumber Penyelidikan AI Kebangsaan](https://nairratdoe.ornl.gov/) dan pelancaran baru-baru ini [Yayasan AI Eropah](https://fortune.com/2025/02/10/france-tech-companies-and-philanthropies-back-400-million-foundation-to-support-public-interest-ai/) adalah langkah menarik dalam arah ini.

[^23]: Cabaran di sini bukanlah teknikal tetapi institusi – kita amat memerlukan contoh dan eksperimen dunia sebenar tentang rupa pembangunan AI kepentingan awam.

[^24]: Ini bertentangan dengan model perniagaan teknologi besar semasa dan akan memerlukan tindakan undang-undang dan norma baharu.

[^25]: Hanya sesetengah kerajaan akan dapat berbuat demikian. Idea yang lebih radikal ialah [dana sejagat jenis ini, di bawah pemilikan bersama semua manusia.](https://futureoflife.org/project/the-windfall-trust/)

[^26]: Untuk huraian panjang kes ini lihat [kertas kerja ini](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3930338) mengenai kesetiaan AI. Malangnya trajektori lalai pembantu AI berkemungkinan menjadi satu di mana mereka semakin tidak setia.

[^27]: Agak ironis, banyak kuasa penyandang juga berisiko kehilangan kuasa yang disokong AI; tetapi mungkin sukar bagi mereka untuk menyedari ini sehingga dan melainkan proses itu berjalan agak jauh.

[^28]: Beberapa usaha menarik dalam arah ini diwakili oleh [gabungan c2pa](https://c2pa.org/) mengenai pengesahan kriptografi; [Verity](https://www.improvethenews.org/) dan [Ground news](https://ground.news/) mengenai epistemik berita yang lebih baik; dan [Metaculus](https://keepthefuturehuman.ai/essay/docs/metaculus.com) dan pasaran ramalan mengenai mendasarkan wacana dalam ramalan yang boleh disangkal.

[^29]: Lihat projek perintis [yang menarik ini](https://talktothecity.org/).

[^30]: Lihat [Kialo](https://www.kialo-edu.com/), dan usaha [Projek Kecerdasan Kolektif](https://www.cip.org/) untuk beberapa contoh.