## Summary

"Keep the Future Human" is a comprehensive essay arguing against the development of Artificial General Intelligence (AGI) and superintelligence. The document is structured as a 10-chapter essay with appendices, presenting both technical analysis and policy proposals.

**Core Arguments:**
- Current AI development trajectory leads toward AGI (human-level general AI) and superintelligence within years, not decades
- AGI poses existential risks: societal disruption, loss of human control, potential species replacement, and increased probability of global conflict
- These risks stem from the convergence of three properties: high Autonomy, high Generality, and high Intelligence (the "A-G-I" framework)
- AGI development is driven by corporate profit motives and geopolitical competition, not genuine human benefit

**Proposed Solutions:**
- "Close the Gates" through international cooperation using compute caps, enhanced liability, and tiered regulation
- Focus on "Tool AI" - powerful but controllable systems that enhance rather than replace humans
- Implement compute governance using hardware-based security measures
- Establish strict liability frameworks and safety standards for dangerous AI systems

**Structure:** Executive summary, technical background (Chapters 1-4), risk analysis (Chapters 5-7), governance proposals (Chapters 8-9), and conclusion, with detailed implementation appendices.

## Glossary

- **Source Term**: Artificial General Intelligence (AGI)
- **Target Translation**: Kecerdasan Buatan Am (KBA)
- **Context**: Central concept throughout document - AI matching/exceeding human capabilities across all cognitive domains
- **Notes**: "Am" captures the "general" aspect better than "umum" in this technical context

- **Source Term**: Superintelligence
- **Target Translation**: Superintelligence
- **Context**: AI systems far surpassing human capabilities across all domains
- **Notes**: Retained in English as it's established terminology in AI discourse globally

- **Source Term**: Neural networks
- **Target Translation**: Rangkaian neural
- **Context**: Mathematical/computational structures underlying modern AI systems
- **Notes**: "Neural" commonly retained in Malaysian technical usage

- **Source Term**: Compute/Computation
- **Target Translation**: Pengkomputeran
- **Context**: Computational resources/processing power required for AI training and operation
- **Notes**: "Compute" as noun often retained in tech contexts, but "pengkomputeran" used for clarity

- **Source Term**: Training (AI model)
- **Target Translation**: Latihan (model AI)
- **Context**: Process of developing AI capabilities through data processing
- **Notes**: Standard translation in Malaysian AI terminology

- **Source Term**: Inference
- **Target Translation**: Inferens
- **Context**: Process of AI generating outputs from trained models
- **Notes**: Technical term widely understood in English across Malaysian tech sector

- **Source Term**: FLOP (Floating-point operations)
- **Target Translation**: FLOP
- **Context**: Unit of computational measurement for AI systems
- **Notes**: Technical acronym retained as standard in computing

- **Source Term**: Alignment (AI)
- **Target Translation**: Penjajaran
- **Context**: Making AI systems do what humans want them to do
- **Notes**: "Penjajaran" captures the concept of aligning AI behavior with human values

- **Source Term**: Autonomous agents
- **Target Translation**: Agen autonomi
- **Context**: AI systems capable of independent action
- **Notes**: "Agen" commonly used in Malaysian tech terminology

- **Source Term**: Tool AI
- **Target Translation**: AI Alat
- **Context**: AI systems that enhance rather than replace human capabilities
- **Notes**: "Alat" emphasizes the instrumental nature of these systems

- **Source Term**: Gates (metaphorical)
- **Target Translation**: Pintu Gerbang
- **Context**: Metaphor for preventing dangerous AI development
- **Notes**: "Pintu Gerbang" maintains the metaphorical strength of controlling access

- **Source Term**: Scaling laws
- **Target Translation**: Hukum penskalaan
- **Context**: Empirical relationships between computational input and AI capability
- **Notes**: Technical term requiring literal translation for clarity

- **Source Term**: Compute caps
- **Target Translation**: Had pengkomputeran
- **Context**: Proposed limits on computational resources for AI development
- **Notes**: "Had" (limits) more precise than "penutup" (caps) in policy context

- **Source Term**: Liability framework
- **Target Translation**: Rangka kerja liabiliti
- **Context**: Legal responsibility structure for AI systems
- **Notes**: "Liabiliti" established in Malaysian legal terminology

- **Source Term**: Safety case
- **Target Translation**: Kes keselamatan
- **Context**: Formal argument demonstrating AI system safety
- **Notes**: Direct translation maintains technical precision

- **Source Term**: Multimodal models
- **Target Translation**: Model multimodal
- **Context**: AI systems processing multiple types of data (text, images, sound)
- **Notes**: Technical term widely understood in English

- **Source Term**: Chain-of-thought
- **Target Translation**: Rantai pemikiran
- **Context**: AI technique for step-by-step reasoning
- **Notes**: Literal translation conveys the sequential reasoning concept clearly

- **Source Term**: Scaffolding (AI)
- **Target Translation**: Perancah
- **Context**: Supporting structures connecting AI system components
- **Notes**: Maintains the metaphor of temporary supporting structure