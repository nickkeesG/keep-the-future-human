# 第一章 - 引言

如何应对超越人类智能的人工智能前景，是我们这个时代最紧迫的问题。本文为此提供了一条前进道路。

我们或许正处于人类纪元的终结。

过去十年间，人类历史上一件前所未有的事情开始发生。其后果将在很大程度上决定人类的未来。大约从2015年开始，研究人员成功开发出了*狭义*人工智能（AI）——这些系统在围棋等游戏、图像和语音识别等方面的表现都超过了任何人类。[^1]

这是惊人的成就，正在产生极其有用的系统和产品来赋能人类。但狭义人工智能从来不是这个领域的真正目标。相反，目标一直是创造*通用*目的AI系统，特别是通常被称为"通用人工智能"(AGI)或"超级智能"的系统——它们在几乎*所有*任务上都能同时达到或超过人类水平，就像AI现在在围棋、象棋、扑克、无人机竞速等方面已经超越人类一样。这是许多主要AI公司明确宣布的目标。[^2]

*这些努力也正在获得成功。*基于大规模计算和海量数据的通用AI系统，如ChatGPT、Gemini、Llama、Grok、Claude和Deepseek，已经在各种各样的任务上达到了普通人类的水平，甚至在某些领域匹配人类专家的能力。现在，一些最大科技公司的AI工程师们正在竞相将这些机器智能的巨型实验推向新的高度，使其匹配并超越人类能力、专业知识和自主性的全部范围。

*这即将到来。*在过去十年中，专家们对于这需要多长时间的估计——如果我们继续目前的路线——已经从几十年（或几个世纪）下降到个位数年份。

这也具有划时代的重要性和超越性风险。AGI的支持者将其视为一场积极的变革，将解决科学问题、治愈疾病、开发新技术并实现繁重工作的自动化。AI确实可以帮助实现所有这些目标——实际上已经在这样做了。但几十年来，从阿兰·图灵到斯蒂芬·霍金，再到当代的杰弗里·辛顿和约书亚·本吉奥[^3]等众多深思熟虑的思想家都发出了严厉警告：构建真正超越人类智能的、通用的、自主的AI，至少将完全且不可逆转地颠覆社会，最坏情况下将导致人类灭绝。[^4]

超级智能AI在我们目前的道路上正在快速逼近，但绝非不可避免。本文是一个扩展论证，阐述我们为什么以及如何应该*关闭大门*，阻止这个即将到来的非人类未来，以及我们应该做些什么。


[^1]: 这张[图表](https://time.com/6300942/ai-progress-charts/)显示了一系列任务；许多类似的曲线都可以添加到这个图中。狭义AI的这种快速进展甚至让该领域的专家都感到惊讶，基准测试被超越的时间比预测提前了数年。

[^2]: Deepmind、OpenAI、Anthropic和X.ai都是以开发AGI为具体目标而成立的。例如，OpenAI的章程明确说明其目标是开发"造福全人类的通用人工智能"，而DeepMind的使命是"解决智能问题，然后用它来解决一切其他问题"。Meta、微软等公司现在也在追求基本相同的路径。Meta表示计划[开发AGI并将其开源发布](https://www.forbes.com/sites/johnkoetsier/2024/01/18/zuckerberg-on-ai-meta-building-agi-for-everyone-and-open-sourcing-it/)。

[^3]: 辛顿和本吉奥是被引用次数最多的两位AI研究人员，都获得了AI领域的诺贝尔奖——图灵奖，辛顿还额外获得了诺贝尔奖（物理学）。

[^4]: 在商业激励和几乎零政府监督下构建如此风险的东西，是完全前所未有的。在构建它的人中间甚至没有关于风险的争议！Deepmind、OpenAI和Anthropic的领导者以及许多其他专家都实际签署了一份[声明](https://www.safe.ai/work/statement-on-ai-risk)，表示先进AI对人类构成*灭绝风险*。警钟不能敲得更响了，人们只能得出结论，那些忽视警钟的人根本没有认真对待AGI和超级智能。本文的目标之一就是帮助他们理解为什么应该认真对待。