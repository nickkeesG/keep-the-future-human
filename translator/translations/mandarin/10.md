# 第十章 - 摆在我们面前的选择

为了维护人类的未来，我们必须选择关闭通往通用人工智能(AGI)和超级智能的大门。

人类上一次与其他会说话、会思考、会建造技术并能进行通用问题解决的心智共享地球，是在4万年前的冰河时代欧洲。那些其他的心智灭绝了，全部或部分是由于我们的努力。

我们现在正在重新进入这样的时代。我们文化和技术的最高成就——基于整个互联网信息共享而构建的数据集，以及拥有千亿元件、堪称我们有史以来最复杂技术的芯片——正在被结合起来，创造出先进的通用AI系统。

这些系统的开发者热衷于将其描绘为赋能人类的工具。确实，它们可以是这样的。但毫无疑问的是：我们目前的发展轨迹是要构建更加强大、目标导向、能够决策且通用能力更强的数字智能体。它们已经在广泛的智力任务上表现得与许多人类一样出色，正在快速改进，并且正在为自身的改进做出贡献。

除非这一轨迹发生改变或遇到意外阻碍，否则我们很快就会——以年为单位，而非几十年——拥有危险强大的数字智能。即使在*最好*的情况下，这些系统会带来巨大的经济效益（至少对我们中的一些人而言），但代价是社会的深刻颠覆，以及在我们所做的最重要事情上被机器取代：这些机器会替我们思考，替我们规划，替我们决策，替我们创造。我们会被宠坏，但只是被宠坏的孩子。更可能的是，这些系统会在我们做的积极*和*消极事情上都取代人类，包括剥削、操纵、暴力和战争。我们能在AI超级加强版的这些活动中幸存下来吗？最后，很有可能情况根本不会顺利：相对很快地，我们不仅在所做的事情上被取代，更会在我们*是什么*上被取代——作为文明和未来的建构者。去问问尼安德特人这是怎样的体验吧。也许我们一开始也会给他们提供一些额外的装饰品。

*我们不必这样做。*我们拥有了与人类竞争力相当的AI，没有必要构建我们*无法*与之竞争的AI。我们可以构建令人惊叹的AI工具，而无需构建一个后继物种。认为AGI和超级智能不可避免的观念是*伪装成命运的选择*。

通过施加一些严格的全球限制，我们可以将AI的通用能力保持在大约人类的水平，同时仍能收获计算机以我们无法做到的方式处理数据的好处，并自动化我们都不愿做的任务。这些仍会带来许多风险，但如果设计和管理得当，将为人类带来巨大福祉，从医学到研究再到消费产品。

实施限制需要国际合作，但所需的合作程度比人们想象的要少，而且这些限制仍会为庞大的AI和AI硬件产业留下充足空间，专注于增进人类福祉的应用，而非单纯追求权力。如果有了强有力的安全保障，并经过有意义的全球对话，我们决定走得更远，这个选择仍然属于我们。

人类必须*选择*关闭通往AGI和超级智能的大门。

让未来保持人类特色。

## 作者后记

感谢您花时间与我们一起探讨这个话题。

我写这篇文章，是因为作为一名科学家，我认为说出毫不掩饰的真相很重要，作为一个人，我认为我们必须迅速果断地行动，应对这个改变世界的问题：开发比人类更聪明的AI系统。

如果我们要以智慧应对这一非凡状况，我们必须准备好批判性地审视主流叙述——即AGI和超级智能"必须"被构建来确保我们的利益，或者这是"不可避免的"且无法阻止。这些叙述让我们失去了力量，无法看到摆在我们面前的替代道路。

我希望您能与我一起，面对鲁莽行为时呼吁谨慎，面对贪婪时呼吁勇气。

我希望您能与我一起呼吁一个人类的未来。

*——安东尼*

![Anthony Aguirre signature](https://keepthefuturehuman.ai/essay/_next/image?url=https%3A%2F%2Fkeepthefuturehuman.ai%2Fwp-content%2Fuploads%2F2025%2F02%2FAnthony-Aguirre-signature-300x84.png&w=3840&q=75)