# 第三章 - 现代通用AI系统制作的关键要素

全世界最前沿的AI系统大多采用出人意料地相似的方法制作。以下是基本原理。

要真正理解人类，你需要了解生物学、进化论、育儿等知识；要理解AI，你同样需要了解它的制作过程。在过去五年中，AI系统在能力和复杂性方面都发生了巨大变化。一个关键的促进因素是可获得的巨量算力（在AI领域通俗称为"算力"）。

这些数字令人震惊。GPT系列、Claude、Gemini等模型的训练使用了大约10<sup>25</sup>-10<sup>26</sup>次"浮点运算"（FLOP）[^1]。（相比之下，如果地球上的每个人都不间断地工作，每五秒钟做一次计算，需要大约十亿年才能完成这个计算量。）如此巨大的算力使得能够在TB级数据上训练拥有数万亿参数的模型——这些数据包含了人类历史上大部分优质文本，以及大量的音频、图像和视频库。通过额外的广泛训练来强化人类偏好和良好的任务表现，以这种方式训练的模型在大量基础智力任务上展现出与人类相当的表现，包括推理和问题解决。

我们也知道（非常粗略地）多少算力速度，即每秒运算次数，足以让这种系统的*推理*速度[^3]匹配人类文本处理的*速度*。大约是每秒10<sup>15</sup>-10<sup>16</sup>次FLOP[^4]。

虽然功能强大，但这些模型在关键方面存在天然的局限性，这很像如果强迫一个人只能以固定的每分钟字数输出文本，不能停下来思考或使用任何额外工具时会受到的限制。更新的AI系统通过更复杂的流程和架构来解决这些局限性，结合了几个关键要素：

- 一个或多个神经网络，其中一个模型提供核心认知能力，最多还有几个其他模型执行更狭窄的任务；
- 提供给模型并可供其使用的*工具* ——例如搜索网络、创建或编辑文档、执行程序等能力。
- 连接神经网络输入和输出的*脚手架系统*。一个非常简单的脚手架可能只允许AI模型的两个"实例"相互对话，或者让一个检查另一个的工作[^5]。
- *思维链*和相关的提示技术起到类似作用，使模型能够生成解决问题的多种方法，然后处理这些方法得出综合答案。
- *重新训练*模型以更好地使用工具、脚手架系统和思维链。

由于这些扩展功能可能非常强大（并且包括AI系统本身），这些复合系统可以相当复杂并显著增强AI能力[^6]。最近，脚手架技术，特别是思维链提示技术（以及将结果反馈到重新训练模型中以更好地使用这些技术）已被开发并应用于[o1](https://openai.com/o1/)、[o3](https://openai.com/index/openai-o3-mini/)和[DeepSeek R1](https://api-docs.deepseek.com/news/news250120)中，对给定查询进行多轮推理[^7]。这实际上允许模型对其回应进行"思考"，显著提升了这些模型在科学、数学和编程任务中进行高水平推理的能力[^8]。

对于给定的AI架构，训练算力的增加[可以可靠地转化为](https://arxiv.org/abs/2405.10938)一系列明确定义指标的改进。对于不太明确定义的通用能力（如下文讨论的那些），这种转化不太清晰和可预测，但几乎可以肯定的是，更大的模型和更多的训练算力将拥有新的和更好的能力，即使很难预测这些能力会是什么。

同样，复合系统，特别是"思维链"技术的进步（以及与之配合良好的模型训练），已经释放了*推理*算力的扩展：对于给定的已训练核心模型，至少某些AI系统能力会随着更多算力的应用而提升，使它们能够对复杂问题"更努力更长久地思考"。这带来了陡峭的计算速度成本，需要数百或数千倍的FLOP/s才能匹配人类表现[^9]。

虽然算力只是导致AI快速进步的一部分因素[^10]，但算力的作用和复合系统的可能性对于防止不可控制的AGI和开发更安全的替代方案都将至关重要。

[^1]: 10<sup>27</sup>意味着1后面跟25个零，或十万万亿。FLOP只是对具有一定精度的数字进行算术加法或乘法运算。需要注意的是，AI硬件性能可能因算术精度和计算机架构而相差十倍。计算逻辑门操作（AND、OR、AND NOT）会更基础，但这些通常不可用或不进行基准测试；对于当前目的，标准化为16位运算（FP16）是有用的，不过应该建立适当的转换因子。

[^2]: [Epoch AI](https://epochai.org/data/large-scale-ai-models)提供了一系列估算和确切数据，显示GPT-4大约需要2×10<sup>25</sup>次16位FLOP；这大致匹配[GPT-4的泄露数据](https://mpost.io/gpt-4s-leaked-details-shed-light-on-its-massive-scale-and-impressive-architecture/)。对其他2024年中期模型的估算都在GPT-4的几倍范围内。

[^3]: 推理就是从神经网络生成输出的过程。训练可以被认为是许多推理和模型权重调整的连续过程。

[^4]: 对于文本生成，原始GPT-4每生成一个词元需要560 TFLOP。大约需要7词元/秒来跟上人类思维，因此这给出≈3×10<sup>15</sup> FLOP/s。但效率提升已经降低了这个数字；例如[这份NVIDIA手册](https://developer.nvidia.com/blog/supercharging-llama-3-1-across-nvidia-platforms/)显示，性能相当的Llama 405B模型只需要3×10<sup>14</sup> FLOP/s。

[^5]: 作为一个稍复杂的例子，AI系统可能首先为数学问题生成几个可能的解决方案，然后使用另一个实例检查每个解决方案，最后使用第三个实例将结果综合成清晰的解释。这比单次处理允许更彻底和可靠的问题解决。

[^6]: 例如参见[OpenAI的"Operator"](https://openai.com/index/introducing-operator/)、[Claude的工具能力](https://docs.anthropic.com/en/docs/build-with-claude/computer-use)和[AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)的详细信息。OpenAI的[Deep Research](https://openai.com/index/introducing-deep-research/)可能有相当复杂的架构，但详细信息不可获得。

[^7]: Deepseek R1依赖于迭代训练和提示模型，使最终训练的模型创建广泛的思维链推理。o1或o3的架构细节不可获得，但Deepseek已经透露，释放推理能力扩展并不需要特别的"秘密配方"。但尽管作为颠覆AI"现状"而受到大量媒体关注，这并不影响本文的核心观点。

[^8]: 这些模型在推理基准测试中显著优于标准模型。例如，在GPQA Diamond基准测试——一个严格的博士级科学问题测试中——GPT-4o[得分](https://openai.com/index/learning-to-reason-with-llms/)56%，而o1和o3分别达到78%和88%，远超人类专家70%的平均分数。

[^9]: OpenAI的O3可能花费了约10<sup>21</sup>-10<sup>22</sup>次FLOP[来完成ARC-AGI挑战的每个问题](https://www.interconnects.ai/p/openais-o3-the-2024-finale-of-ai)，而有能力的人类可以在（比如）10-100秒内完成，得出大约10<sup>20</sup> FLOP/s的数字。

[^10]: 虽然算力是AI系统能力的关键衡量标准，但它与数据质量和算法改进都相互作用。更好的数据或算法可以降低计算需求，而更多的算力有时可以补偿较弱的数据或算法。