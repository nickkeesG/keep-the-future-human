# 第五章 - 在门槛前

从今天的AI系统到完全成熟的通用人工智能的道路看起来短得惊人且可以预测。

过去十年来，AI在巨大的[算力](https://epoch.ai/blog/training-compute-of-frontier-ai-models-grows-by-4-5x-per-year)、人力和[财政](https://arxiv.org/abs/2405.21015)资源推动下取得了惊人进展。许多特定领域的AI应用在其指定任务上都超过了人类，而且肯定更快、更便宜。[^1] 还有一些特定领域的超人类智能体能够在诸如[围棋](https://www.nature.com/articles/nature16961)、[国际象棋](https://arxiv.org/abs/1712.01815)和[扑克](https://www.deepstack.ai/)等特定领域游戏中击败所有人类，以及一些能够在简化的模拟环境中像人类一样有效地规划和执行动作的更[通用的智能体](https://deepmind.google/discover/blog/a-generalist-agent/)。

最引人注目的是，来自OpenAI/微软、谷歌/Deepmind、Anthropic/亚马逊、Facebook/Meta、X.ai/特斯拉等公司的当前通用AI系统[^2]自2023年初以来涌现，此后稳步（尽管不均匀地）提高了其能力。所有这些系统都是通过对大规模文本和多媒体数据集进行词元预测，结合来自人类和其他AI系统的大量强化反馈而创建的。其中一些还包括广泛的工具和脚手架系统。

## 当前通用系统的优势和劣势

这些系统在越来越广泛的旨在测量智能和专业知识的测试中表现良好，其进步甚至让该领域的专家都感到惊讶：

- GPT-4首次发布时就在包括SAT、GRE、入学考试和律师资格考试在内的标准学术测试中[达到或超过了典型人类表现](https://arxiv.org/abs/2303.08774)。更新的模型可能表现更好，但结果尚未公开。
- 图灵测试——长期被视为"真正"AI的关键基准——现在已被现代语言模型在某些形式下常规通过，无论是非正式的还是在[正式研究](https://arxiv.org/abs/2405.08007)中。[^3]
- 在涵盖57个学术科目的综合MMLU基准测试中，[最新模型达到了领域专家水平的分数](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu)（约90%）[^4]
- 技术专长有了显著进步：GPQA研究生水平物理基准测试的[表现跃升](https://epoch.ai/data/ai-benchmarking-dashboard)从接近随机猜测（GPT-4，2022年）到专家水平（o1-preview，2024年）。
- 甚至专门设计为抗AI的测试也在失效：据[报告](https://www.nextbigfuture.com/2024/12/openai-releases-o3-model-with-high-performance-and-high-cost.html)，OpenAI的O3在ARC-AGI抽象问题解决基准上达到人类水平，实现了顶级专家编程性能，并在Epoch AI设计来挑战精英数学家的"前沿数学"问题上得分25%。[^5]
- 趋势如此明确，以至于MMLU的开发者现在创建了["人类的最后一次考试"](https://agi.safe.ai/)——这个不祥的名字反映了AI可能很快就会在任何有意义的测试上超越人类表现的可能性。截至本文写作时，有声称AI系统在这个极其困难的考试上取得了27%（根据[Sam Altman](https://x.com/sama/status/1886220281565381078)）和35%（根据[这篇论文](https://arxiv.org/abs/2502.09955)）的成绩。任何个人都不太可能做到这一点。

尽管有这些令人印象深刻的数字（以及与它们交互时明显的智能）[^6]，（至少是已发布版本的）这些神经网络有许多*无法*做到的事情。目前大多数都是无实体的——仅存在于服务器上——最多只能处理文本、声音和静态图像（但不是视频）。关键的是，大多数无法执行需要高准确性的复杂计划活动。[^7] 而且，当前在高级人类认知中很强但在已发布AI系统中较低的其他品质还有很多。

下表基于2024年中期的AI系统（如GPT-4o、Claude 3.5 Sonnet和Google Gemini 1.5）列出了其中许多。[^8] 通用AI变得更强大的速度有多快的关键问题是：仅仅做*更多相同的事情*能在多大程度上产生结果，相对于添加额外但*已知的*技术，相对于开发或实施*真正新的*AI研究方向。我对此的预测在表格中给出，以这些情景中每种能够将该能力提升到并超越人类水平的可能性来表示。

<table><tbody><tr><th>能力</th><th>能力描述</th><th>现状/前景</th><th>扩展/已知/新技术</th></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td colspan="4"><em>核心认知能力</em></td></tr><tr><td>推理</td><td>人类能够进行准确的多步推理，遵循规则并检查准确性。</td><td>使用扩展思维链和重新训练取得显著近期进展</td><td>95/5/5</td></tr><tr><td>规划</td><td>人类展现长期和层次化规划。</td><td>随规模改善；可通过脚手架系统和更好的训练技术得到强力辅助。</td><td>10/85/5</td></tr><tr><td>真实性基础</td><td>通用人工智能会编造无根据的信息来满足查询。</td><td>随规模改善；模型内有校准数据可用；可通过脚手架系统检查/改进。</td><td>30/65/5</td></tr><tr><td>灵活问题解决</td><td>人类能够识别新模式并发明解决复杂问题的新方案；当前机器学习模型在此方面困难。</td><td>随规模改善但微弱；可能通过神经符号或广义"搜索"技术解决。</td><td>15/75/10</td></tr><tr><td colspan="4"><em>学习和知识</em></td></tr><tr><td>学习与记忆</td><td>人类具有工作记忆、短期记忆和长期记忆，它们都是动态且相互关联的。</td><td>所有模型都在训练期间学习；通用人工智能在上下文窗口内学习并在微调期间学习；"持续学习"和其他技术存在但尚未集成到大型通用人工智能中。</td><td>5/80/15</td></tr><tr><td>抽象与递归</td><td>人类能够将关系集映射和转移到更抽象的关系中进行推理和操作，包括递归的"元"推理。</td><td>随规模微弱改善；可能在神经符号系统中出现。</td><td>30/50/20</td></tr><tr><td>世界模型</td><td>人类拥有并持续更新预测性世界模型，在其中可以解决问题和进行物理推理</td><td>随规模改善；更新与学习相关；通用人工智能在现实世界预测方面较弱。</td><td>20/50/30</td></tr><tr><td colspan="4"><em>自我和能动性</em></td></tr><tr><td>能动性</td><td>人类能够基于规划/预测采取行动来追求目标。</td><td>许多机器学习系统具有能动性；大型语言模型可通过包装器成为智能体。</td><td>5/90/5</td></tr><tr><td>自我导向</td><td>人类发展并追求自己的目标，具有内部产生的动机和驱动力。</td><td>主要由能动性加原创性组成；可能在具有抽象目标的复杂能动系统中出现。</td><td>40/45/15</td></tr><tr><td>自我参照</td><td>人类理解并推理自己在环境/情境中的位置。</td><td>随规模改善，可通过训练奖励增强。</td><td>70/15/15</td></tr><tr><td>自我意识</td><td>人类了解并能推理自己的思想和心理状态。</td><td>在通用人工智能中某种意义上存在，它们可以说能通过经典的自我意识"镜子测试"。可通过脚手架系统改进；但不清楚这是否足够。</td><td>20/55/25</td></tr><tr><td colspan="4"><em>接口和环境</em></td></tr><tr><td>具身智能</td><td>人类理解并主动与现实世界环境交互。</td><td>强化学习在模拟和现实世界（机器人）环境中效果良好，可以集成到多模态变换器中。</td><td>5/85/10</td></tr><tr><td>多感官处理</td><td>人类整合并实时处理视觉、音频和其他感官流。</td><td>多模态训练似乎"就是有效"，并随规模改善。实时视频处理困难，但例如自动驾驶系统正在快速改进。</td><td>30/60/10</td></tr><tr><td colspan="4"><em>高阶能力</em></td></tr><tr><td>原创性</td><td>当前机器学习模型在转换和组合现有想法/作品方面具有创造性，但人类能够构建新的框架和结构，有时与其身份相关。</td><td>可能很难与"创造力"区分，后者可能通过规模扩展实现；可能从创造力加自我意识中出现。</td><td>50/40/10</td></tr><tr><td>感知能力</td><td>人类体验感质；这些可以是正面、负面或中性效价；成为一个人是"有感觉的"。</td><td>确定给定系统是否具有此能力非常困难且哲学上复杂。</td><td>5/10/85</td></tr></tbody></table>

现代通用人工智能系统中目前低于人类专家水平的关键能力，按类型分组。第三列总结了当前状态。最后一列显示通过以下方式实现人类水平表现的预测可能性（%）：扩展当前技术/与已知技术结合/开发新技术。这些能力并不独立，任何一个的增加通常伴随着其他能力的增加。请注意，并非所有（特别是感知能力）都是AI系统能够推进AI发展所必需的，这突出了强大但无感知AI的可能性。

以这种方式分解"缺失"的内容，使我们相当清楚地看到，通过扩展现有或已知技术，我们完全有望实现广泛超越人类的智能。[^9]

仍可能有意外。即使抛开"感知能力"不谈，列出的一些核心认知能力可能真的无法用当前技术实现，需要新技术。但请考虑这一点。世界上许多最大公司目前投入的努力相当于阿波罗项目支出的数倍和曼哈顿项目支出的数十倍，[^10] 并且以前所未闻的薪资雇佣了数千名顶尖技术人员。过去几年的动态现在已经为此投入了比历史上任何努力都多的人类智力资源（现在还加上了AI）。我们不应该押注于失败。

## 重大目标：通用自主智能体

过去几年通用AI的发展重点是创造通用且强大但工具型的AI：它主要作为（相当）忠实的助手发挥作用，通常不会自主采取行动。这部分是设计使然，但主要是因为这些系统在相关技能上还不够胜任，无法被委托执行复杂行动。[^11]

然而，AI公司和研究人员正在越来越[转向关注](https://www.axios.com/2025/01/23/davos-2025-ai-agents)*自主的*专家级通用智能体。[^12] 这将使系统能够更像人类助手一样行动，用户可以向其委托真正的行动。[^13] 这需要什么？"缺失内容"表格中的许多能力都有关联，包括强真实性基础、学习和记忆、抽象和递归、世界建模（智能），规划、能动性、原创性、自我导向、自我参照和自我意识（自主性），以及多感官处理、具身智能和灵活问题解决（通用性）。[^14]

高自主性（行动独立性）、高通用性（范围和任务广度）和高智能（认知任务胜任力）的三重交集目前是人类独有的。这隐含地是许多人在想到AGI时可能心中所想的——无论在其价值还是风险方面。

这提供了另一种将A-G-I定义为***自***主-***通***用-***智***能的方式，我们将看到这种三重交集为高能力系统在理解其风险和回报以及AI治理方面提供了非常有价值的视角。

![](https://keepthefuturehuman.ai/essay/_next/image?url=https%3A%2F%2Fkeepthefuturehuman.ai%2Fwp-content%2Fuploads%2F2025%2F02%2FAGI-Venn-Diagram-Simple-1024x1024.png&w=3840&q=75) 变革性的A-G-I力量和风险区域出现在三个关键属性的交集：高自主性、任务高智能和高通用性。

## AI（自我）改进循环

理解AI进展的最后一个关键因素是AI独特的技术反馈循环。在AI开发中，成功——无论是在演示系统还是部署产品中——都会带来额外的投资、人才和竞争，我们目前正处于一个巨大的AI炒作加现实反馈循环中，推动着数千亿甚至数万亿美元的投资。

这种反馈循环可能发生在任何技术上，我们在许多技术中都看到过，其中市场成功带来投资，投资带来改进和更好的市场成功。但AI开发走得更远，现在AI系统正在帮助开发新的、更强大的AI系统。[^15] 我们可以将这个反馈循环想象为五个阶段，每个阶段的时间尺度都比上一个更短，如表中所示。

*AI改进循环在多个时间尺度上运作，每个阶段都可能加速后续阶段。早期阶段已经在进行中，而后期阶段仍是推测性的，但一旦解锁可能进展得非常迅速。*

其中几个阶段已经在进行中，有几个明显开始了。最后阶段，即AI系统自主改进自己，一直是关于极强大AI系统风险文献的主要内容，这是有充分理由的。[^16] 但重要的是要注意，这只是已经开始的反馈循环的最激进形式，可能导致该技术快速发展出现更多意外。

[^1]: 你使用的这种AI比你可能想象的要多得多，它驱动着语音生成和识别、图像处理、新闻推送算法等。

[^2]: 虽然这些公司对之间的关系相当复杂和微妙，但我明确列出它们是为了表明现在参与AI开发的公司的巨大整体市值，以及即使像Anthropic这样的"较小"公司背后也有通过投资和重大合作协议带来的极其深厚的资金支持。

[^3]: 贬低图灵测试已经成为时尚，但它相当强大和通用。在弱版本中，它表明与AI（被训练成像人类一样行动）在典型方式下短时间交互的典型人能否分辨出它是AI。他们不能。其次，高度对抗性的图灵测试可以探测人类能力和智能的本质上任何元素——例如通过将AI系统与人类专家比较，由其他人类专家评估。在某种意义上，AI评估的大部分都是图灵测试的一般化形式。

[^4]: 这是按领域计算的——没有人类可能同时在所有科目上都达到如此高的分数。

[^5]: 这些问题即使是优秀的数学家也需要大量时间来解决，如果他们能解决的话。

[^6]: 如果你持怀疑态度，请保持怀疑但真正试用最新的模型，以及亲自尝试一些它们能通过的测试问题。作为一名物理学教授，我可以近乎肯定地预测，例如，顶级模型会通过我们系的研究生资格考试。

[^7]: 这一点以及编造等其他弱点减缓了市场采用，导致感知能力和声称能力之间存在差距（这也必须通过激烈市场竞争和需要吸引投资的视角来看待）。这让公众和政策制定者对AI进展的实际状态感到困惑。虽然可能不符合炒作，但进展是非常真实的。

[^8]: 此后的主要进展是开发了为高质量推理而训练的系统，在推理过程中利用更多算力和更强的强化学习。由于这些模型是新的，其能力测试较少，除了"推理"（我认为本质上已经解决）之外，我没有完全修改这个表格。但我基于这些系统的经验和报告能力更新了预测。

[^9]: 之前在1960年代和1980年代的AI乐观主义浪潮以"AI寒冬"结束，当时承诺的能力未能实现。然而，当前的浪潮在根本上不同，它已经在许多领域实现了超人类表现，得到了巨大的算力资源和商业成功的支持。

[^10]: 整个阿波罗项目[以2020年美元计约花费2500亿美元](https://www.planetary.org/space-policy/cost-of-apollo)，曼哈顿项目[花费不到其十分之一](https://www.brookings.edu/the-costs-of-the-manhattan-project/)。高盛[预计仅AI数据中心就将花费1万亿美元](https://www.datacenterdynamics.com/en/news/goldman-sachs-1tn-to-be-spent-on-ai-data-centers-chips-and-utility-upgrades-with-little-to-show-for-it-so-far/)在未来几年。

[^11]: 尽管人类会犯很多错误，但我们低估了自己能有多可靠！因为概率是相乘的，需要20个步骤才能正确完成的任务要求每个步骤97%可靠，才能有一半时间做对。我们一直在做这样的任务。

[^12]: 最近朝这个方向迈出的强力一步是OpenAI的["深度研究"](https://openai.com/index/introducing-deep-research/)助手，它能够自主进行一般研究，被描述为"一种新的能动能力，为复杂任务在互联网上进行多步骤研究。"

[^13]: 比如填写那个讨厌的PDF表格，预订航班等。但具有20个领域的博士学位！所以还有：为你写论文，为你谈判合同，为你证明定理，为你创建广告活动等。你做什么？当然是告诉它要做什么。

[^14]: 请注意，感知能力*不是*明确必需的，这种三重交集的AI也不必然意味着感知能力。

[^15]: 这里最接近的类比可能是芯片技术，其中开发已经维持摩尔定律数十年，因为计算机技术帮助人们设计下一代芯片技术。但AI会更加直接。

[^16]: 重要的是要让这一点沉淀一下：AI可能——很快——在几天或几周的时间尺度上改进自己。甚至更短。当有人告诉你某种AI能力绝对还很遥远时，请记住这一点。