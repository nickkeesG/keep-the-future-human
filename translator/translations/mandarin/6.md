# 第6章 - 通用人工智能竞赛

是什么驱动力量推动着公司和国家竞相构建通用人工智能？

AI领域近期的快速进展既源于也导致了非同寻常的关注度和投资规模。这在一定程度上是由AI开发的成功所驱动的，但背后还有更深层的原因。为什么地球上一些最大的公司，甚至是国家，都在竞相构建的不仅仅是AI，而是通用人工智能和超级智能？

## 是什么推动AI研究走向人类水平的智能

直到大约五年前，AI主要还是一个学术和科学研究问题，因此主要由好奇心和对理解智能以及如何在新载体中创造智能的渴望所驱动。

在这一阶段，大多数研究人员对AI的益处或危险相对关注较少。当被问及为什么要开发AI时，常见的回答可能是有些模糊地列出AI可以帮助解决的问题：新药物、新材料、新科学、更智能的流程，以及总体上改善人类生活。[^1]

这些都是令人钦佩的目标！[^2] 尽管我们可以也将质疑实现这些目标是否需要通用人工智能——而不是一般意义上的AI——但它们展现了许多AI研究人员最初的理想主义精神。

然而，在过去五年中，AI已经从一个相对纯粹的研究领域转变为更多的工程和产品领域，主要由世界上一些最大的公司推动。[^3] 研究人员虽然仍然重要，但不再主导这一进程。

## 为什么公司要努力构建通用人工智能？

那么，为什么巨型企业（更不用说投资者）要投入巨大资源来构建通用人工智能？大多数公司对两个驱动因素都相当坦诚：他们将AI视为社会生产力的推动力，以及他们自身利润的来源。由于通用AI本质上是通用的，这里有一个巨大的奖励：与其选择某个特定领域来创造产品和服务，不如尝试*同时涉足所有领域*。大型科技公司通过生产数字商品和服务而变得庞大，至少一些高管肯定将AI视为提供这些服务的下一步，其风险和收益扩展并呼应了搜索、社交媒体、笔记本电脑、手机等所提供的那些。

但为什么是通用人工智能？对此有一个非常简单的答案，但大多数公司和投资者都回避公开讨论。[^4]

那就是通用人工智能可以直接、一对一地*替代工人*。

不是增强，不是赋能，不是提高生产力。甚至不是*取代*。所有这些都可以而且将会由非通用人工智能来完成。通用人工智能特别擅长的是能够完全*替代*脑力工作者（配合机器人技术，也能替代许多体力工作者）。支持这一观点的证据，只需看看OpenAI的[（公开声明的）定义](https://openai.com/our-structure/)，即通用人工智能是"在大多数具有经济价值的工作中超越人类的高度自主系统"。

这里的奖励（对公司而言！）是巨大的。劳动力成本占全球约100万亿美元经济的相当大比例。即使只有一小部分通过AI劳动力替代人类劳动力而被获取，这也是每年数万亿美元的收入。AI公司也清楚谁愿意付费。正如他们所看到的，你不会为生产力工具支付每年数千美元。但如果公司能够替代你的劳动力，他们*愿意*每年支付数千美元。

## 为什么国家感到必须竞相发展通用人工智能

各国发展通用人工智能的公开动机集中在经济和科学领导地位上。这个论证很有说服力：通用人工智能可以大幅加速科学研究、技术发展和经济增长。鉴于利害关系重大，他们论证说，没有哪个主要大国能够承受落后的后果。[^5]

但还有其他基本上未公开的驱动因素。毫无疑问，当某些军事和国家安全领导人闭门讨论一项极其强大且具有灾难性风险的技术时，他们关注的重点不是"我们如何避免这些风险"，而是"我们如何率先获得这项技术？"军事和情报领导人将通用人工智能视为军事事务的潜在革命，可能是自核武器以来最重要的革命。担心的是，第一个开发出通用人工智能的国家可能获得不可逾越的战略优势。这创造了一种典型的军备竞赛动态。

我们将看到，这种"通用人工智能竞赛"思维[^6]虽然令人信服，但存在严重缺陷。这不是因为竞赛是危险和有风险的——尽管确实如此——而是由于技术的本质。未明确表达的假设是，通用人工智能，像其他技术一样，可以被开发它的国家所控制，并且是对拥有最多此类技术的社会的力量增强。正如我们将看到的，它可能两者都不是。

## 为什么是超级智能？

虽然公司公开关注生产力，国家关注经济和技术增长，但对于那些有意追求完整通用人工智能和超级智能的人来说，这些只是开始。他们真正想要什么？虽然很少大声说出来，但包括：

1. 治愈许多或所有疾病；
2. 阻止和逆转衰老；
3. 新的可持续能源，如核聚变；
4. 通过基因工程进行人类升级或设计生物体；
5. 纳米技术和分子制造；
6. 意识上传；
7. 奇异物理学或太空技术；
8. 超人类建议和决策支持；
9. 超人类规划和协调。

前三项主要是"单刃"技术——即可能具有相当强的净正面效应。很难反对治愈疾病或如果选择的话能够活得更长。我们已经承受了核聚变的负面影响（以核武器的形式）；现在能够获得积极的一面将是很好的。这第一类的问题是，更早获得这些技术是否能够补偿风险。

接下来的四项明显是双刃剑：具有潜在巨大好处和巨大风险的变革性技术，很像AI。所有这些，如果明天从黑盒中冒出来并被部署，都将极难管理。[^7]

最后两项涉及超人类AI本身做事情，而不仅仅是发明技术。更确切地说，抛开委婉说法，这些涉及强大的AI系统告诉人们该做什么。如果进行建议的系统比被建议者强大得多，而被建议者无法有意义地理解决策基础（或者即使提供了这些，也不能相信顾问不会为不同的决策提供同样令人信服的理由），那么称其为"建议"是不诚实的。

这指向了上述清单中缺失的一个关键项目：

10. 权力。

很明显，当前超人类AI竞赛的根本动机是*智能=权力*的理念。每个竞赛者都寄希望于成为这种权力的最佳持有者，他们将能够以表面上仁慈的理由行使这种权力，而不会让它滑脱或被人夺取控制权。

也就是说，公司和国家真正追逐的不仅仅是通用人工智能和超级智能的成果，还有控制谁能获得它们以及如何使用它们的权力。公司将自己视为这种权力的负责任管理者，为股东和人类服务；国家将自己视为防止敌对势力获得决定性优势的必要守护者。两者都是危险的错误，未能认识到超级智能本质上无法被任何人类机构可靠地控制。我们将看到，超智能系统的性质和动态使得人类控制极其困难，如果不是不可能的话。

这些竞赛动态——无论是企业的还是地缘政治的——除非被果断打断，否则几乎必然会带来某些风险。我们现在转向审视这些风险，以及为什么它们无法在竞争性[^8]开发模式内得到充分缓解。


[^1]: 更精确的有价值目标清单是联合国[可持续发展目标](https://sdgs.un.org/goals)。从某种意义上说，这些是我们对世界上希望看到改善的事物最接近全球共识目标的集合。AI可以提供帮助。

[^2]: 技术总体上具有促进人类福祉的变革性经济和社会力量，数千年的历史可以证明这一点。在这个意义上，可以在Anthropic创始人Dario Amodei的[这篇文章](https://darioamodei.com/machines-of-loving-grace)中找到对积极通用人工智能愿景的长篇而令人信服的阐释。

[^3]: 私人AI投资[在2018-19年开始繁荣，大约在那时超过了公共投资](https://cset.georgetown.edu/publication/tracking-ai-investment/)，此后大大超过了后者。

[^4]: 我可以证明，在更私密的场合，他们没有这样的顾虑。而且这正变得更加公开；例如参见Y Combinator的新["创业请求"](https://www.ycombinator.com/rfs)，其中许多部分明确要求完全替代人类工作者。引用他们的话，"B2B SaaS的价值主张是让人类工作者逐步提高效率。垂直AI代理的价值主张是完全自动化工作...这个机会完全有可能大到足以创造另外100家独角兽公司。"（对于不熟悉硅谷术语的人，"B2B"是企业对企业，独角兽是价值10亿美元的公司。也就是说，他们在谈论超过一百家价值数十亿美元以上的企业，这些企业为其他企业替代工人。）

[^5]: 例如参见最近的[美中经济与安全审查委员会报告](https://www.uscc.gov/sites/default/files/2024-11/2024_Executive_Summary.pdf)。尽管报告本身内部几乎没有论证，但首要建议是美国"国会建立并资助一个类似曼哈顿项目的计划，专门致力于竞相获得通用人工智能（AGI）能力"。

[^6]: 公司现在采用这种地缘政治框架作为抵御对其AI开发任何约束的盾牌，通常以明目张胆的自利方式，有时甚至以没有基本意义的方式。考虑Meta的[前沿AI方法](https://about.fb.com/news/2025/02/meta-approach-frontier-ai/)，它同时论证美国必须"[巩固其]在技术创新、经济增长和国家安全方面的领导地位"，同时也必须通过公开发布其最强大的AI系统来做到这一点——这包括直接将它们提供给其地缘政治对手和敌手。

[^7]: 因此我们可能不得不将这些技术的管理留给AI。但这将是一种非常有问题的控制权委托，我们将在下面回到这一点。

[^8]: 技术开发中的竞争往往带来重要好处：防止垄断控制、推动创新和成本降低、实现多样化方法，以及创造相互监督。然而，对于通用人工智能，这些好处必须与竞赛动态和减少安全预防措施压力带来的独特风险进行权衡。