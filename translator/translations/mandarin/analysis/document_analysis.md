## Summary

This comprehensive essay argues that humanity stands at a critical juncture in AI development and must choose to prevent the creation of Artificial General Intelligence (AGI) and superintelligence to preserve human civilization. The document is structured as a systematic case across 10 main chapters plus appendices.

**Core argument**: Current AI development trajectories toward AGI and superintelligence pose existential risks to humanity through power concentration, loss of human control, civilizational disruption, and potential human extinction. The essay contends these outcomes are not inevitable but result from corporate and geopolitical racing dynamics.

**Key themes**:
1. **Technical foundation**: Explains how modern AI works, the path from current systems to AGI/superintelligence, and why we're closer than many realize
2. **Risk analysis**: Details how AGI would destabilize society, lead to loss of human control, increase war probability, and ultimately end human civilization
3. **Driving forces**: Examines corporate profit motives (labor replacement) and national security competition fueling the race
4. **Governance solution**: Proposes "closing the Gates" through compute caps, enhanced liability, and international coordination
5. **Alternative path**: Advocates for "Tool AI" that enhances rather than replaces human capability

**Structure**: Moves from technical explanation through risk assessment to concrete policy proposals, concluding with a vision for beneficial AI development under human control.

**Target audience**: Policymakers, technologists, and informed public concerned about AI's societal impact.

## Glossary

- **Source Term**: Artificial General Intelligence (AGI)
- **Target Translation**: 通用人工智能 (AGI)
- **Context**: Central concept throughout the document, defined as AI systems combining high autonomy, generality, and intelligence
- **Notes**: AGI is widely recognized in Chinese AI discourse; using the abbreviation maintains global consistency

- **Source Term**: superintelligence
- **Target Translation**: 超级智能
- **Context**: AI systems far exceeding human cognitive capabilities across all domains
- **Notes**: Direct translation preserves the concept's clarity and matches established Chinese usage

- **Source Term**: compute / computation
- **Target Translation**: 算力
- **Context**: Computational resources used in AI training and inference, central to the governance proposal
- **Notes**: 算力 is the standard term in Chinese AI industry for computational power/resources

- **Source Term**: neural networks
- **Target Translation**: 神经网络
- **Context**: Core AI architecture underlying modern systems
- **Notes**: Established translation widely used in Chinese technical literature

- **Source Term**: training
- **Target Translation**: 训练
- **Context**: Process of developing AI models using data
- **Notes**: Standard translation in machine learning contexts

- **Source Term**: inference
- **Target Translation**: 推理
- **Context**: Process of AI systems generating outputs from trained models
- **Notes**: Established technical term in Chinese AI field

- **Source Term**: alignment
- **Target Translation**: 对齐
- **Context**: Making AI systems do what humans want them to do
- **Notes**: Emerging but increasingly recognized translation in Chinese AI safety discussions

- **Source Term**: Tool AI
- **Target Translation**: 工具型AI
- **Context**: AI systems that enhance rather than replace human capabilities
- **Notes**: Descriptive translation that clearly conveys the instrumental nature of these systems

- **Source Term**: FLOP (floating-point operations)
- **Target Translation**: FLOP (浮点运算)
- **Context**: Technical measure of computational work in AI systems
- **Notes**: FLOP is commonly used as-is in Chinese technical contexts; parenthetical clarification aids understanding

- **Source Term**: autonomous/autonomy
- **Target Translation**: 自主/自主性
- **Context**: AI's ability to act independently without human oversight
- **Notes**: Direct translation maintains the technical precision needed for governance discussions

- **Source Term**: scaffolding
- **Target Translation**: 脚手架系统
- **Context**: Software architecture connecting multiple AI components
- **Notes**: Metaphorical translation that preserves the structural support concept

- **Source Term**: chain-of-thought
- **Target Translation**: 思维链
- **Context**: AI technique for step-by-step reasoning
- **Notes**: Literal translation that's becoming standard in Chinese AI literature

- **Source Term**: multimodal
- **Target Translation**: 多模态
- **Context**: AI systems processing multiple types of data (text, images, etc.)
- **Notes**: Standard translation in Chinese machine learning terminology

- **Source Term**: compute caps
- **Target Translation**: 算力限制
- **Context**: Proposed limits on computational resources for AI development
- **Notes**: Clear translation that conveys the regulatory constraint concept

- **Source Term**: liability framework
- **Target Translation**: 责任框架
- **Context**: Legal structure for holding AI developers accountable
- **Notes**: Standard legal terminology translation

- **Source Term**: Gates (closing the Gates)
- **Target Translation**: 大门 (关闭大门)
- **Context**: Metaphor for preventing development of dangerous AI
- **Notes**: Preserves the metaphorical power while being immediately understandable

- **Source Term**: runaway
- **Target Translation**: 失控
- **Context**: AI systems improving beyond human control
- **Notes**: Captures the loss of control concept more naturally than literal translation

- **Source Term**: provenance tracking
- **Target Translation**: 来源追踪
- **Context**: Systems for tracking the origin and history of AI-generated content
- **Notes**: Clear translation that conveys the traceability concept

- **Source Term**: data dignity
- **Target Translation**: 数据尊严
- **Context**: Concept of fair compensation for human-generated training data
- **Notes**: Direct translation that maintains the dignity/rights framing of the original concept