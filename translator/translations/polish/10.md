# Rozdział 10 - Wybór przed nami

Aby zachować naszą ludzką przyszłość, musimy zdecydować się zamknąć Bramy przed AGI i superinteligencją.

Ostatni raz ludzkość dzieliła Ziemię z innymi umysłami, które mówiły, myślały, budowały technologie i rozwiązywały problemy ogólnego zastosowania, to było 40 000 lat temu w lodowcowej Europie. Te inne umysły wyginęły, w całości lub częściowo z powodu działań naszych.

Teraz wkraczamy ponownie w taki okres. Najbardziej zaawansowane produkty naszej kultury i technologii – zbiory danych zbudowane z całego naszego internetowego dobra wspólnego oraz 100-miliardowe układy scalone będące najzłożonszymi technologiami, jakie kiedykolwiek stworzyliśmy – są łączone, aby powołać do życia zaawansowane systemy AI ogólnego przeznaczenia.

Twórcy tych systemów chętnie przedstawiają je jako narzędzia wzmacniające człowieka. I rzeczywiście mogłyby nimi być. Ale nie mylmy się: nasz obecny kierunek prowadzi do budowy coraz potężniejszych, zorientowanych na cele, podejmujących decyzje i ogólnie zdolnych cyfrowych agentów. Już teraz radzą sobie tak dobrze jak wielu ludzi w szerokim zakresie zadań intelektualnych, szybko się poprawiają i przyczyniają się do własnego rozwoju.

Jeśli ten kierunek się nie zmieni lub nie napotka nieoczekiwanej przeszkody, wkrótce – w ciągu lat, nie dekad – będziemy mieli cyfrowe inteligencje, które będą niebezpiecznie potężne. Nawet w *najlepszych* scenariuszach przyniosłyby one wielkie korzyści ekonomiczne (przynajmniej niektórym z nas), ale tylko kosztem głębokiego zakłócenia naszego społeczeństwa i zastąpienia ludzi w większości najważniejszych rzeczy, które robimy: te maszyny myślałyby za nas, planowałyby za nas, decydowałyby za nas i tworzyły za nas. Bylibyśmy rozpieszczeni, ale jak rozpieszczone dzieci. O wiele bardziej prawdopodobne jest, że te systemy zastąpiłyby ludzi zarówno w pozytywnych, *jak i* negatywnych rzeczach, które robimy, włączając w to wyzysk, manipulację, przemoc i wojnę. Czy możemy przetrwać wersje tych zjawisk napędzane przez AI? Wreszcie, więcej niż prawdopodobne jest, że sprawy wcale nie potoczyłyby się dobrze: że stosunkowo szybko zostalibyśmy zastąpieni nie tylko w tym, co robimy, ale w tym, czym *jesteśmy*, jako architekci cywilizacji i przyszłości. Zapytajcie neandertalczyków, jak to się kończy. Może przez jakiś czas dostarczaliśmy im też dodatkowe błyskotki.

*Nie musimy tego robić.* Mamy AI konkurencyjne z ludźmi i nie ma potrzeby budować AI, z którym *nie możemy* konkurować. Możemy budować niesamowite narzędzia AI bez tworzenia gatunku następcy. Przekonanie, że AGI i superinteligencja są nieuniknione, to *wybór udający przeznaczenie*.

Nakładając pewne twarde, globalne ograniczenia, możemy utrzymać ogólne zdolności AI na mniej więcej ludzkim poziomie, nadal czerpiąc korzyści ze zdolności komputerów do przetwarzania danych w sposób, w jaki my nie potrafimy, i automatyzacji zadań, których nikt z nas nie chce wykonywać. Nadal stwarzałyby one wiele zagrożeń, ale jeśli byłyby dobrze zaprojektowane i zarządzane, stanowiłyby ogromne dobrodziejstwo dla ludzkości, od medycyny przez badania po produkty konsumenckie.

Nałożenie ograniczeń wymagałoby międzynarodowej współpracy, ale mniej niż można by sądzić, a te ograniczenia nadal pozostawiałyby mnóstwo miejsca na ogromny przemysł AI i sprzętu AI skoncentrowany na zastosowaniach wzmacniających ludzkie dobro, a nie na surowym dążeniu do władzy. A jeśli, z silnymi gwarancjami bezpieczeństwa i po znaczącym globalnym dialogu, zdecydujemy się pójść dalej, ta opcja nadal będzie do naszej dyspozycji.

Ludzkość musi *wybrać* zamknięcie Bram przed AGI i superinteligencją.

Aby zachować przyszłość ludzką.

## Notatka od Autora

Dziękuję za poświęcenie czasu na eksplorację tego tematu z nami.

Napisałem ten esej, ponieważ jako naukowiec czuję, że ważne jest mówienie nieprzikraszanej prawdy, a jako człowiek uważam, że kluczowe jest szybkie i zdecydowane działanie w obliczu kwestii zmieniającej świat: rozwoju systemów AI inteligentniejszych niż człowiek.

Jeśli mamy odpowiedzieć mądrze na ten niezwykły stan rzeczy, musimy być gotowi do krytycznego zbadania dominującej narracji, że AGI i superinteligencja "muszą" zostać zbudowane dla zabezpieczenia naszych interesów, lub są "nieuniknione" i nie można ich powstrzymać. Te narracje pozbawiają nas możliwości działania, uniemożliwiając dostrzeżenie alternatywnych ścieżek przed nami.

Mam nadzieję, że dołączysz do mnie w wezwaniu do ostrożności w obliczu lekkomyślności i odwagi w obliczu chciwości.

Mam nadzieję, że dołączysz do mnie w wezwaniu do ludzkiej przyszłości.

*– Anthony*

![Anthony Aguirre signature](https://keepthefuturehuman.ai/essay/_next/image?url=https%3A%2F%2Fkeepthefuturehuman.ai%2Fwp-content%2Fuploads%2F2025%2F02%2FAnthony-Aguirre-signature-300x84.png&w=3840&q=75)