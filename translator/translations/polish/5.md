# Rozdział 5 - U progu

Droga od dzisiejszych systemów AI do w pełni rozwiniętej AGI wydaje się zaskakująco krótka i przewidywalna.

Ostatnie dziesięć lat przyniosło dramatyczne postępy w AI napędzane ogromnymi zasobami [obliczeniowymi](https://epoch.ai/blog/training-compute-of-frontier-ai-models-grows-by-4-5x-per-year), ludzkimi i [finansowymi](https://arxiv.org/abs/2405.21015). Wiele wąskich zastosowań AI przewyższa ludzi w przydzielonych im zadaniach i z pewnością jest znacznie szybszych i tańszych.[^1] Istnieją też wąskie nadludzkie agenty, które mogą pokonać wszystkich ludzi w grach o ograniczonym zakresie, takich jak [Go](https://www.nature.com/articles/nature16961), [szachy](https://arxiv.org/abs/1712.01815) i [poker](https://www.deepstack.ai/), a także bardziej [uniwersalni agenci](https://deepmind.google/discover/blog/a-generalist-agent/), którzy potrafią planować i wykonywać działania w uproszczonych symulowanych środowiskach tak skutecznie jak ludzie.

Najważniejsze są obecne systemy ogólnej AI od OpenAI/Microsoft, Google/Deepmind, Anthropic/Amazon, Facebook/Meta, X.ai/Tesla i innych,[^2] które pojawiły się od początku 2023 roku i od tego czasu systematycznie (choć nierównomiernie) zwiększały swoje możliwości. Wszystkie zostały stworzone poprzez przewidywanie tokenów na ogromnych zbiorach danych tekstowych i multimedialnych, w połączeniu z rozległym wzmocnieniem zwrotnym od ludzi i innych systemów AI. Niektóre z nich zawierają także rozbudowane systemy narzędzi i struktur wspomagających.

## Mocne i słabe strony obecnych systemów ogólnych

Te systemy radzą sobie dobrze w coraz szerszym zakresie testów przeznaczonych do mierzenia inteligencji i wiedzy specjalistycznej, z postępem, który zaskoczył nawet ekspertów w tej dziedzinie:

- Gdy po raz pierwszy został wydany, GPT-4 [dorównał lub przewyższył typowe osiągnięcia ludzkie](https://arxiv.org/abs/2303.08774) w standardowych testach akademickich, w tym SAT, GRE, egzaminach wstępnych i egzaminach adwokackich. Nowsze modele prawdopodobnie radzą sobie znacznie lepiej, choć wyniki nie są publicznie dostępne.
- Test Turinga – długo uważany za kluczowy wskaźnik „prawdziwej" AI – jest teraz rutynowo zdawany w niektórych formach przez nowoczesne modele językowe, zarówno nieformalnie, jak i w [formalnych badaniach](https://arxiv.org/abs/2405.08007).[^3]
- W kompleksowym benchmarku MMLU obejmującym 57 przedmiotów akademickich [najnowsze modele osiągają wyniki na poziomie ekspertów dziedziny](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu) (~90%)[^4]
- Wiedza techniczna dramatycznie się rozwinęła: benchmark GPQA z fizyki na poziomie magisterskim odnotował [skok wydajności](https://epoch.ai/data/ai-benchmarking-dashboard) od niemal losowego zgadywania (GPT-4, 2022) do poziomu eksperckiego (o1-preview, 2024).
- Nawet testy specjalnie zaprojektowane jako odporne na AI upadają: O3 OpenAI [podobno](https://www.nextbigfuture.com/2024/12/openai-releases-o3-model-with-high-performance-and-high-cost.html) rozwiązuje benchmark ARC-AGI abstrakcyjnego rozwiązywania problemów na poziomie ludzkim, osiąga najwyższą ekspercką wydajność w programowaniu i zdobywa 25% punktów w problemach „frontier math" Epoch AI zaprojektowanych dla wyzwania elitarnych matematyków.[^5]
- Trend jest tak wyraźny, że twórca MMLU stworzył teraz [„Ostatni Egzamin Ludzkości"](https://agi.safe.ai/) – złowróżbna nazwa odzwierciedlająca możliwość, że AI wkrótce przewyższy ludzkie osiągnięcia w każdym znaczącym teście. W momencie pisania tego tekstu pojawiają się twierdzenia o systemach AI osiągających 27% (według [Sama Altmana](https://x.com/sama/status/1886220281565381078)) i 35% (według [tego artykułu](https://arxiv.org/abs/2502.09955)) w tym niezwykle trudnym egzaminie. Jest bardzo mało prawdopodobne, aby jakikolwiek pojedynczy człowiek mógł to zrobić.

Pomimo tych imponujących liczb (i ich oczywistej inteligencji podczas interakcji z nimi)[^6] jest wiele rzeczy, których (przynajmniej wydane wersje) te sieci neuronowe *nie potrafią* robić. Obecnie większość z nich jest bezcielesna – istnieje tylko na serwerach – i przetwarza co najwyżej tekst, dźwięk i obrazy statyczne (ale nie wideo). Co kluczowe, większość nie potrafi wykonywać złożonych planowanych działań wymagających wysokiej dokładności.[^7] Istnieje też szereg innych cech silnych w wysokopoziomowej ludzkiej kognicji, które są obecnie słabe w wydanych systemach AI.

Następująca tabela wymienia kilka z nich, opierając się na systemach AI z połowy 2024 roku, takich jak GPT-4o, Claude 3.5 Sonnet i Google Gemini 1.5.[^8] Kluczowe pytanie dotyczące tego, jak szybko ogólna AI stanie się potężniejsza, brzmi: w jakim stopniu samo robienie *więcej tego samego* przyniesie rezultaty, w porównaniu z dodawaniem dodatkowych, ale *znanych* technik, w porównaniu z rozwijaniem lub wdrażaniem *naprawdę nowych* kierunków badań AI. Moje własne przewidywania są podane w tabeli w postaci prawdopodobieństwa każdego z tych scenariuszy osiągnięcia danej zdolności na poziomie ludzkim i powyżej.

<table><tbody><tr><th>Zdolność</th><th>Opis zdolności</th><th>Status/prognoza</th><th>Skalowanie/znane/nowe</th></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td colspan="4"><em>Podstawowe zdolności kognitywne</em></td></tr><tr><td>Rozumowanie</td><td>Ludzie potrafią dokładnie rozumować wieloetapowo, przestrzegając zasad i sprawdzając dokładność.</td><td>Dramatyczny niedawny postęp przy użyciu rozszerzonego łańcucha rozumowania i ponownego treningu</td><td>95/5/5</td></tr><tr><td>Planowanie</td><td>Ludzie wykazują długoterminowe i hierarchiczne planowanie.</td><td>Poprawia się ze skalą; może być silnie wspomagane strukturami wspomagającymi i lepszymi technikami treningu.</td><td>10/85/5</td></tr><tr><td>Ugruntowanie w prawdzie</td><td>GPAI wymyślają nieugruntowane informacje, aby spełnić zapytania.</td><td>Poprawia się ze skalą; dane kalibracyjne dostępne w modelu; można sprawdzać/poprawiać przez struktury wspomagające.</td><td>30/65/5</td></tr><tr><td>Elastyczne rozwiązywanie problemów</td><td>Ludzie potrafią rozpoznawać nowe wzorce i wymyślać nowe rozwiązania złożonych problemów; obecne modele ML mają z tym trudności.</td><td>Poprawia się ze skalą, ale słabo; może być rozwiązywalne technikami neurosymbolicznymi lub uogólnionymi technikami „przeszukiwania".</td><td>15/75/10</td></tr><tr><td colspan="4"><em>Uczenie się i wiedza</em></td></tr><tr><td>Uczenie się i pamięć</td><td>Ludzie mają pamięć roboczą, krótkotrwałą i długotrwałą, wszystkie są dynamiczne i wzajemnie powiązane.</td><td>Wszystkie modele uczą się podczas treningu; GPAI uczą się w oknie kontekstu i podczas dostrojenia; istnieją techniki „ciągłego uczenia" i inne, ale nie są jeszcze zintegrowane z dużymi GPAI.</td><td>5/80/15</td></tr><tr><td>Abstrakcja i rekursja</td><td>Ludzie potrafią mapować i przenosić zestawy relacji do bardziej abstrakcyjnych do rozumowania i manipulacji, w tym rekursywne „meta" rozumowanie.</td><td>Słabo poprawia się ze skalą; może pojawić się w systemach neurosymbolicznych.</td><td>30/50/20</td></tr><tr><td>Model(e) świata</td><td>Ludzie mają i ciągle aktualizują predykcyjny model świata, w którym mogą rozwiązywać problemy i prowadzić rozumowanie fizyczne</td><td>Poprawia się ze skalą; aktualizowanie związane z uczeniem się; GPAI są słabe w przewidywaniu rzeczywistości.</td><td>20/50/30</td></tr><tr><td colspan="4"><em>Jaźń i sprawczość</em></td></tr><tr><td>Sprawczość</td><td>Ludzie potrafią podejmować działania w celu realizacji celów, opierając się na planowaniu/przewidywaniu.</td><td>Wiele systemów ML jest sprawczych; LLM można uczynić agentami przez opakowania.</td><td>5/90/5</td></tr><tr><td>Samoukierunkowanie</td><td>Ludzie rozwijają i realizują własne cele, z wewnętrznie generowaną motywacją i napędem.</td><td>Składa się głównie ze sprawczości plus oryginalności; prawdopodobnie pojawi się w złożonych systemach sprawczych z abstrakcyjnymi celami.</td><td>40/45/15</td></tr><tr><td>Samoodniesienie</td><td>Ludzie rozumieją i rozumują o sobie jako usytuowanych w środowisku/kontekście.</td><td>Poprawia się ze skalą i może być wzmocnione nagrodą treningową.</td><td>70/15/15</td></tr><tr><td>Samoświadomość</td><td>Ludzie mają wiedzę o własnych myślach i stanach psychicznych i potrafią o nich rozumować.</td><td>Istnieje w pewnym sensie w GPAI, które mogą prawdopodobnie przejść klasyczny „test lustra" samoświadomości. Można poprawić strukturami wspomagającymi; ale niejasne, czy to wystarczy.</td><td>20/55/25</td></tr><tr><td colspan="4"><em>Interfejs i środowisko</em></td></tr><tr><td>Inteligencja wcielona</td><td>Ludzie rozumieją i aktywnie wchodzą w interakcję ze swoim rzeczywistym środowiskiem.</td><td>Uczenie się przez wzmacnianie działa dobrze w symulowanych i rzeczywistych (robotycznych) środowiskach i może być zintegrowane z multimodalnymi transformatorami.</td><td>5/85/10</td></tr><tr><td>Przetwarzanie wielozmysłowe</td><td>Ludzie integrują i przetwarzają w czasie rzeczywistym strumienie wizualne, dźwiękowe i inne sensoryczne.</td><td>Trening w wielu modalnościach wydaje się „po prostu działać" i poprawia się ze skalą. Przetwarzanie wideo w czasie rzeczywistym jest trudne, ale np. systemy autonomicznej jazdy szybko się poprawiają.</td><td>30/60/10</td></tr><tr><td colspan="4"><em>Zdolności wyższego rzędu</em></td></tr><tr><td>Oryginalność</td><td>Obecne modele ML są kreatywne w przekształcaniu i łączeniu istniejących pomysłów/dzieł, ale ludzie potrafią budować nowe ramy i struktury, czasem związane z ich tożsamością.</td><td>Może być trudne do odróżnienia od „kreatywności", która może się w to przeskalować; może wyniknąć z kreatywności plus samoświadomości.</td><td>50/40/10</td></tr><tr><td>Doznawanie</td><td>Ludzie doświadczają qualiów; mogą mieć pozytywną, negatywną lub neutralną walencję; „coś znaczy" być człowiekiem.</td><td>Bardzo trudne i filozoficznie problematyczne do określenia, czy dany system to posiada.</td><td>5/10/85</td></tr></tbody></table>

Kluczowe zdolności obecnie poniżej poziomu ekspertów ludzkich w nowoczesnych systemach GPAI, pogrupowane według typu. Trzecia kolumna podsumowuje obecny status. Ostatnia kolumna pokazuje przewidywane prawdopodobieństwo (%), że poziom ludzki zostanie osiągnięty przez: skalowanie obecnych technik / łączenie ze znanymi technikami / rozwijanie nowych technik. Te zdolności nie są niezależne, a wzrost w jednej zazwyczaj idzie wraz ze wzrostami w innych. Należy zauważyć, że nie wszystkie (szczególnie doznawanie) są niezbędne dla systemów AI zdolnych do rozwoju AI, co podkreśla możliwość potężnej, ale niedoznającej AI.

Podział tego, co „brakuje" w ten sposób, sprawia, że jest dość jasne, że jesteśmy całkiem na dobrej drodze do inteligencji szeroko przewyższającej ludzką poprzez skalowanie istniejących lub znanych technik.[^9]

Wciąż mogą być niespodzianki. Nawet pomijając „doznawanie", mogą być niektóre z wymienionych podstawowych zdolności kognitywnych, które naprawdę nie dają się zrobić obecnymi technikami i wymagają nowych. Ale rozważmy to. Obecny wysiłek podejmowany przez wiele z największych światowych firm równa się wielokrotności wydatków projektu Apollo i dziesiątkach razy wydatków projektu Manhattan,[^10] i zatrudnia tysiące najlepszych specjalistów technicznych za niespotykane pensje. Dynamika ostatnich kilku lat przyniosła teraz więcej ludzkiej siły intelektualnej (z AI teraz dodawaną) niż jakiekolwiek przedsięwzięcie w historii. Nie powinniśmy stawiać na porażkę.

## Główny cel: wszechstronni autonomiczni agenci

Rozwój ogólnej AI w ciągu ostatnich kilku lat koncentrował się na tworzeniu ogólnej i potężnej, ale narzędziowej AI: funkcjonuje przede wszystkim jako (dość) lojalny asystent i generalnie nie podejmuje działań samodzielnie. Jest to częściowo zamierzone, ale głównie dlatego, że te systemy po prostu nie były wystarczająco kompetentne w odpowiednich umiejętnościach, aby można im było powierzyć złożone działania.[^11]

Firmy AI i badacze coraz bardziej [przenoszą jednak uwagę](https://www.axios.com/2025/01/23/davos-2025-ai-agents) na *autonomicznych* agentów ogólnego przeznaczenia na poziomie eksperckim.[^12] Pozwoliłoby to systemom działać bardziej jak ludzki asystent, któremu użytkownik może delegować rzeczywiste działania.[^13] Co do tego potrzeba? Szereg zdolności z tabeli „czego brakuje" jest w to zaangażowany, w tym silne ugruntowanie w prawdzie, uczenie się i pamięć, abstrakcja i rekursja oraz modelowanie świata (dla inteligencji), planowanie, sprawczość, oryginalność, samoukierunkowanie, samoodniesienie i samoświadomość (dla autonomii), oraz przetwarzanie wielozmysłowe, inteligencja wcielona i elastyczne rozwiązywanie problemów (dla ogólności).[^14]

To potrójne przecięcie wysokiej autonomii (niezależności działania), wysokiej ogólności (zakresu i szerokości zadań) i wysokiej inteligencji (kompetencji w zadaniach kognitywnych) jest obecnie unikalne dla ludzi. To właśnie prawdopodobnie wielu ma na myśli, myśląc o AGI – zarówno pod względem jej wartości, jak i ryzyka.

To dostarcza innego sposobu definiowania A-G-I jako ***A*** utonomiczna- ***G*** eneralna- ***I*** nteligencja, i zobaczymy, że to potrójne przecięcie zapewnia bardzo wartościową soczewkę dla systemów o wysokich możliwościach, zarówno w zrozumieniu ich ryzyka i korzyści, jak i w zarządzaniu AI.

![](https://keepthefuturehuman.ai/essay/_next/image?url=https%3A%2F%2Fkeepthefuturehuman.ai%2Fwp-content%2Fuploads%2F2025%2F02%2FAGI-Venn-Diagram-Simple-1024x1024.png&w=3840&q=75) Transformacyjna strefa mocy i ryzyka A-G-I wyłania się z przecięcia trzech kluczowych właściwości: wysokiej Autonomii, wysokiej Inteligencji w zadaniach i wysokiej Ogólności.

## Cykl (samo)doskonalenia AI

Ostatnim kluczowym czynnikiem w zrozumieniu postępu AI jest unikalna pętla technologicznego sprzężenia zwrotnego AI. W rozwoju AI sukces – zarówno w demonstrowanych systemach, jak i wdrożonych produktach – przynosi dodatkowe inwestycje, talenty i konkurencję, i obecnie znajdujemy się w środku ogromnej pętli sprzężenia zwrotnego szumu-plus-rzeczywistości AI, która napędza setki miliardów, a nawet biliony dolarów inwestycji.

Ten typ cyklu sprzężenia zwrotnego może zdarzyć się z każdą technologią i widzieliśmy to w wielu, gdzie sukces rynkowy rodzi inwestycję, która rodzi ulepszenie i lepszy sukces rynkowy. Ale rozwój AI idzie dalej, w tym, że teraz systemy AI pomagają rozwijać nowe i potężniejsze systemy AI.[^15] Możemy myśleć o tej pętli sprzężenia zwrotnego w pięciu etapach, każdy z krótszą skalą czasową niż poprzedni, jak pokazano w tabeli.

*Cykl doskonalenia AI działa w wielu skalach czasowych, gdzie każdy etap może potencjalnie przyspieszyć kolejne etapy. Wcześniejsze etapy są już w toku, podczas gdy późniejsze pozostają spekulacyjne, ale mogłyby przebiegać bardzo szybko po odblokowaniu.*

Kilka z tych etapów jest już w toku, a kilka wyraźnie się rozpoczyna. Ostatni etap, w którym systemy AI autonomicznie się doskonalą, był podstawą literatury o ryzyku bardzo potężnych systemów AI, i nie bez powodu.[^16] Ale ważne jest, aby zauważyć, że to tylko najbardziej drastyczna forma cyklu sprzężenia zwrotnego, który już się rozpoczął i może prowadzić do większych niespodzianek w szybkim rozwoju tej technologii.


[^1]: Używasz znacznie więcej tej AI, niż prawdopodobnie myślisz, napędzając generowanie i rozpoznawanie mowy, przetwarzanie obrazów, algorytmy newsfeeda itp.

[^2]: Chociaż relacje między tymi parami firm są dość złożone i zniuansowane, wymieniłem je wyraźnie, aby wskazać zarówno ogromną całkowitą kapitalizację rynkową firm obecnie zaangażowanych w rozwój AI, jak i to, że za nawet „mniejszymi" firmami jak Anthropic stoją niezwykle głębokie kieszenie poprzez inwestycje i główne umowy partnerskie.

[^3]: Stało się modne lekceważenie testu Turinga, ale jest on dość potężny i ogólny. W słabych wersjach wskazuje, czy typowi ludzie wchodząc w interakcję z AI (która jest trenowana do zachowania ludzkiego) w typowy sposób przez krótkie okresy mogą powiedzieć, czy to AI. Nie mogą. Po drugie, wysoce przeciwstawny test Turinga może badać zasadniczo każdy element ludzkiej zdolności i inteligencji – np. przez porównywanie systemu AI z ludzkim ekspertem, ocenianych przez innych ludzkich ekspertów. W pewnym sensie znaczna część oceny AI to uogólniona forma testu Turinga.

[^4]: To jest na domenę – żaden człowiek nie mógłby prawdopodobnie osiągnąć takich wyników we wszystkich przedmiotach jednocześnie.

[^5]: To są problemy, których rozwiązanie zajęłoby nawet doskonałym matematykom znaczny czas, jeśli w ogóle potrafiliby je rozwiązać.

[^6]: Jeśli jesteś sceptycznie nastawiony, zachowaj swój sceptycyzm, ale naprawdę wypróbuj najnowsze modele, a także spróbuj sam niektórych pytań testowych, które potrafią zdać. Jako profesor fizyki przewidziałbym z niemal pewnością, że na przykład najlepsze modele zdałyby egzamin kwalifikacyjny dla absolwentów w naszym wydziale.

[^7]: Ta i inne słabości jak konfabulacja spowolniły adopcję rynkową i doprowadziły do luki między postrzeganymi a deklarowanymi możliwościami (co również musi być widziane przez pryzmat intensywnej konkurencji rynkowej i potrzeby przyciągnięcia inwestycji). To zmyliło zarówno opinię publiczną, jak i decydentów politycznych co do rzeczywistego stanu postępu AI. Chociaż może nie dorównuje szumowi, postęp jest bardzo rzeczywisty.

[^8]: Głównym postępem od tego czasu był rozwój systemów trenowanych dla najwyższej jakości rozumowania, wykorzystujących więcej obliczeń podczas inferencji i większe uczenie się przez wzmacnianie. Ponieważ te modele są nowe i ich zdolności mniej przetestowane, nie przebudowałem całkowicie tej tabeli oprócz „rozumowania", które uważam za zasadniczo rozwiązane. Ale zaktualizowałem przewidywania na podstawie doświadczonych i zgłoszonych możliwości tych systemów.

[^9]: Poprzednie fale optymizmu AI w latach 60. i 80. zakończyły się „zimami AI", gdy obiecane możliwości nie zmaterializowały się. Jednak obecna fala różni się fundamentalnie osiągnięciem nadludzkiej wydajności w wielu domenach, wspieranej masowymi zasobami obliczeniowymi i sukcesem komercyjnym.

[^10]: Pełny projekt Apollo [kosztował około 250 mld USD w dolarach z 2020 roku](https://www.planetary.org/space-policy/cost-of-apollo), a projekt Manhattan [mniej niż jedną dziesiątą tego](https://www.brookings.edu/the-costs-of-the-manhattan-project/). Goldman Sachs [przewiduje bilion dolarów wydatków tylko na centra danych AI](https://www.datacenterdynamics.com/en/news/goldman-sachs-1tn-to-be-spent-on-ai-data-centers-chips-and-utility-upgrades-with-little-to-show-for-it-so-far/) w ciągu najbliższych kilku lat.

[^11]: Chociaż ludzie popełniają mnóstwo błędów, nie doceniamy po prostu tego, jak niezawodni potrafimy być! Ponieważ prawdopodobieństwa się mnożą, zadanie wymagające 20 kroków do prawidłowego wykonania wymaga, aby każdy krok był 97% niezawodny, żeby zrobić to dobrze choćby w połowie przypadków. Robimy takie zadania cały czas.

[^12]: Silny ruch w tym kierunku został bardzo niedawno podjęty przez asystenta [„Deep Research"](https://openai.com/index/introducing-deep-research/) OpenAI, który autonomicznie przeprowadza ogólne badania, opisywany jako „nowa zdolność sprawcza, która prowadzi wieloetapowe badania w internecie dla złożonych zadań".

[^13]: Rzeczy jak wypełnienie tego irytującego formularza PDF, rezerwacja lotów itp. Ale z doktoratem w 20 dziedzinach! Więc także: napisanie tej pracy dyplomowej za ciebie, negocjowanie tej umowy za ciebie, udowodnienie tego twierdzenia za ciebie, stworzenie tej kampanii reklamowej za ciebie itp. Co *ty* robisz? Mówisz mu co robić, oczywiście.

[^14]: Zauważ, że doznawanie *nie* jest wyraźnie wymagane, ani AI w tym potrójnym przecięciu niekoniecznie tego implikuje.

[^15]: Najbliższą analogią jest być może technologia chipów, gdzie rozwój utrzymuje prawo Moore'a od dekad, gdy technologie komputerowe pomagają ludziom projektować następną generację technologii chipów. Ale AI będzie znacznie bardziej bezpośrednie.

[^16]: Ważne jest, aby na chwilę to przemyśleć, że AI mogłaby – wkrótce – doskonalić siebie w skali czasowej dni lub tygodni. Lub mniej. Miej to na uwadze, gdy ktoś mówi ci, że zdolność AI jest definitywnie daleko.