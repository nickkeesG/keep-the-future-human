# Rozdział 6 - Wyścig o AGI

Jakie siły napędowe stoją za wyścigiem o budowę AGI, zarówno dla firm, jak i krajów?

Ostatnie szybkie postępy w dziedzinie AI zaowocowały niezwykłym poziomem uwagi i inwestycji, a jednocześnie z niego wynikają. Wynika to częściowo z sukcesów w rozwoju AI, ale dzieje się coś więcej. Dlaczego niektóre z największych firm na Ziemi, a nawet całe kraje, ścigają się w budowaniu nie tylko AI, ale AGI i superinteligencji?

## Co doprowadziło badania nad AI w kierunku inteligencji na poziomie ludzkim

Przez około pięć ostatnich lat AI była głównie problemem badań akademickich i naukowych, napędzanym więc przede wszystkim przez ciekawość i chęć zrozumienia inteligencji oraz sposobu jej stworzenia w nowym podłożu.

W tej fazie stosunkowo niewiele uwagi poświęcano korzyściom lub zagrożeniom płynącym z AI wśród większości badaczy. Kiedy pytano, dlaczego AI powinno być rozwijane, typową odpowiedzią mogło być wymienienie, w dość ogólny sposób, problemów, z którymi AI mogłoby pomóc: nowe leki, nowe materiały, nowa nauka, mądrzejsze procesy i ogólnie poprawa życia ludzi.[^1]

To szlachetne cele![^2] Choć możemy i będziemy kwestionować, czy AGI – a nie AI w ogóle – jest niezbędne do osiągnięcia tych celów, pokazują one idealizm, z jakim wielu badaczy AI zaczynało.

Jednak w ciągu ostatnich pięciu lat AI przeszła transformację z relatywnie czystej dziedziny badań w znacznie bardziej inżynieryjną i produktową dziedzinę, napędzaną głównie przez niektóre z największych firm świata.[^3] Badacze, choć nadal istotni, nie kierują już tym procesem.

## Dlaczego firmy próbują budować AGI?

Dlaczego więc gigantyczne korporacje (a jeszcze bardziej inwestorzy) przelewają ogromne zasoby na budowę AGI? Istnieją dwie siły napędowe, co do których większość firm jest całkiem szczera: postrzegają AI jako motory produktywności dla społeczeństwa i zysków dla siebie. Ponieważ ogólna AI jest z natury uniwersalna, nagroda jest ogromna: zamiast wybierać sektor, w którym tworzy się produkty i usługi, można próbować *wszystkich na raz.* Firmy Big Tech urosły do ogromnych rozmiarów, produkując dobra i usługi cyfrowe, a przynajmniej niektórzy dyrektorzy z pewnością postrzegają AI po prostu jako kolejny krok w ich dostarczaniu, z ryzykami i korzyściami, które rozszerzają te zapewniane przez wyszukiwarki, media społecznościowe, laptopy, telefony itp., ale są im podobne.

Ale dlaczego AGI? Jest na to bardzo prosta odpowiedź, której większość firm i inwestorów unika omawiania publicznie.[^4]

Chodzi o to, że AGI może bezpośrednio, jeden do jednego, *zastąpić pracowników.*

Nie wspomagać, nie wzmacniać, nie czynić bardziej produktywnymi. Nawet nie *wypierać.* Wszystko to może być i będzie robione przez nie-AGI. AGI to konkretnie to, co może całkowicie *zastąpić* pracowników umysłowych (a z robotyką również wielu fizycznych). Na poparcie tego poglądu wystarczy spojrzeć na [(publicznie ogłoszoną) definicję](https://openai.com/our-structure/) AGI przez OpenAI, która brzmi: "wysoce autonomiczny system przewyższający ludzi w większości ekonomicznie wartościowej pracy".

Nagroda tutaj (dla firm!) jest ogromna. Koszty pracy stanowią znaczący procent światowej gospodarki wartej około 100 bilionów dolarów. Nawet jeśli tylko ułamek tego zostanie przechwycony przez zastąpienie ludzkiej pracy pracą AI, to są to biliony dolarów rocznych przychodów. Firmy AI są również świadome tego, kto jest gotów płacić. Jak to widzą, ty nie zapłacisz tysięcy dolarów rocznie za narzędzia zwiększające produktywność. Ale firma *zapłaci* tysiące dolarów rocznie, aby zastąpić twoją pracę, jeśli będzie mogła.

## Dlaczego kraje czują, że muszą ścigać się o AGI

Oficjalne motywacje krajów dążących do AGI skupiają się na przywództwie ekonomicznym i naukowym. Argument jest przekonujący: AGI mogłoby dramatycznie przyspieszyć badania naukowe, rozwój technologiczny i wzrost gospodarczy. Biorąc pod uwagę stawkę, argumentują, żadne główne mocarstwo nie może sobie pozwolić na pozostawanie w tyle.[^5]

Ale istnieją również dodatkowe i w dużej mierze niewypowiedziane siły napędowe. Nie ma wątpliwości, że kiedy pewni przywódcy wojskowi i bezpieczeństwa narodowego spotykają się za zamkniętymi drzwiami, aby omówić niezwykle potężną i katastrofalnie ryzykowną technologię, ich skupienie nie dotyczy "jak uniknąć tych ryzyk", ale raczej "jak zdobyć to pierwsi?" Przywódcy wojskowi i wywiadowczy postrzegają AGI jako potencjalną rewolucję w sprawach wojskowych, być może najważniejszą od czasów broni nuklearnej. Obawa polega na tym, że pierwszy kraj, który opracuje AGI, może uzyskać nie do pokonania przewagę strategiczną. To tworzy klasyczną dynamikę wyścigu zbrojeń.

Zobaczymy, że to myślenie "wyścigu o AGI",[^6] choć przekonujące, jest głęboko błędne. Nie dlatego, że ściganie się jest niebezpieczne i ryzykowne – choć takie jest – ale ze względu na naturę tej technologii. Niewypowiedziane założenie jest takie, że AGI, jak inne technologie, jest kontrolowane przez państwo, które je rozwija, i stanowi dobrodziejstwo zwiększające potęgę społeczeństwa, które ma go najwięcej. Jak zobaczymy, prawdopodobnie nie będzie ani jednym, ani drugim.

## Dlaczego superinteligencja?

Podczas gdy firmy publicznie koncentrują się na produktywności, a kraje na wzroście gospodarczym i technologicznym, dla tych, którzy świadomie dążą do pełnego AGI i superinteligencji, to dopiero początek. Co naprawdę mają na myśli? Choć rzadko mówione na głos, obejmuje to:

1. Lekarstwa na wiele lub wszystkie choroby;
2. Zatrzymanie i odwrócenie starzenia;
3. Nowe źródła energii odnawialnej, jak fuzja;
4. Ulepszenia człowieka lub organizmy projektowane poprzez inżynierię genetyczną;
5. Nanotechnologia i produkcja molekularna;
6. Przesyłanie umysłów;
7. Egzotyczna fizyka lub technologie kosmiczne;
8. Nadludzkie doradztwo i wsparcie decyzyjne;
9. Nadludzkie planowanie i koordynacja.

Pierwsze trzy to głównie technologie "jednoznacznie pozytywne" – tj. prawdopodobnie dość silnie pozytywne netto. Trudno argumentować przeciwko leczeniu chorób lub możliwości dłuższego życia, jeśli ktoś tego chce. I już zebraliśmy negatywną stronę fuzji (w postaci broni nuklearnej); byłoby miło teraz uzyskać pozytywną stronę. Pytanie dotyczące tej pierwszej kategorii brzmi, czy uzyskanie tych technologii wcześniej kompensuje ryzyko.

Kolejne cztery są wyraźnie obosieczne: technologie transformacyjne z potencjalnie ogromnymi korzyściami i ogromnymi ryzykami, podobnie jak AI. Wszystkie te, gdyby wyskoczyli z czarnej skrzynki jutro i zostały wdrożone, byłyby niezwykle trudne do zarządzania.[^7]

Ostatnie dwie dotyczą nadludzkiej AI robiącej rzeczy sama, a nie tylko wynajdywania technologii. Mówiąc precyzyjniej, odkładając eufemizmy na bok, obejmują one potężne systemy AI mówiące ludziom, co mają robić. Nazywanie tego "doradztwem" jest nieszczere, jeśli system doradzający jest znacznie potężniejszy od doradzanego, który nie może w znaczący sposób zrozumieć podstawy decyzji (lub nawet jeśli jest to zapewnione, zaufać, że doradca nie przedstawi podobnie przekonującego uzasadnienia dla innej decyzji).

To wskazuje na kluczowy element brakujący na powyższej liście:

10. Władza.

Jest jasne, że znaczna część tego, co leży u podstaw obecnego wyścigu o nadludzką AI, to idea, że *inteligencja = władza*. Każdy uczestnik wyścigu liczy na to, że będzie najlepszym posiadaczem tej władzy i że będzie mógł ją wykorzystywać z pozornie dobroczynnych powodów, nie wymykając się lub nie zostając wyrwana spod jego kontroli.

Oznacza to, że firmy i narody naprawdę gonią nie tylko za owocami AGI i superinteligencji, ale za władzą kontrolowania, kto uzyskuje do nich dostęp i jak są używane. Firmy postrzegają siebie jako odpowiedzialnych zarządców tej władzy w służbie akcjonariuszy i ludzkości; narody widzą siebie jako niezbędnych strażników zapobiegających wrogim potęgom uzyskania decydującej przewagi. Oba te poglądy są niebezpiecznie błędne, nie rozpoznając, że superinteligencja, ze swej natury, nie może być niezawodnie kontrolowana przez żadną ludzką instytucję. Zobaczymy, że natura i dynamika superinteligentnych systemów sprawia, że kontrola ludzka jest niezwykle trudna, jeśli nie niemożliwa.

Te dynamiki wyścigu – zarówno korporacyjne, jak i geopolityczne – sprawiają, że pewne ryzyko staje się niemal nieuniknione, chyba że zostanie zdecydowanie przerwane. Przechodzimy teraz do zbadania tych ryzyk i tego, dlaczego nie można ich odpowiednio złagodzić w ramach konkurencyjnego[^8] paradygmatu rozwoju.


[^1]: Bardziej precyzyjna lista godnych celów to [Cele Zrównoważonego Rozwoju](https://sdgs.un.org/goals) ONZ. To są, w pewnym sensie, najbliższe temu, co mamy jako zestaw globalnych celów konsensusowych dla tego, co chcielibyśmy zobaczyć poprawione na świecie. AI mogłaby pomóc.

[^2]: Technologia w ogóle ma transformacyjną moc ekonomiczną i społeczną dla poprawy ludzkości, jak świadczą tysiące lat. W tym duchu, długą i przekonującą wykładnię pozytywnej wizji AGI można znaleźć w [tym eseju](https://darioamodei.com/machines-of-loving-grace) założyciela Anthropic, Dario Amodei.

[^3]: Prywatne inwestycje w AI [zaczęły gwałtownie rosnąć w 2018-19, przewyższając inwestycje publiczne mniej więcej wtedy,](https://cset.georgetown.edu/publication/tracking-ai-investment/) i od tego czasu znacznie je wyprzedzają.

[^4]: Mogę zaświadczyć, że za bardziej zamkniętymi drzwiami nie mają takich skrupułów. I staje się to bardziej publiczne; zobacz na przykład nowy ["wniosek o startupy"](https://www.ycombinator.com/rfs) Y-combinator, którego wiele części jawnie wzywa do hurtowego zastąpienia pracowników ludzkich. Cytując ich: "Propozycja wartości B2B SaaS polegała na stopniowym zwiększaniu wydajności pracowników ludzkich. Propozycja wartości pionowych agentów AI to całkowita automatyzacja pracy... Jest całkiem możliwe, że ta możliwość jest wystarczająco duża, aby stworzyć kolejnych 100 jednorożców." (Dla tych nieobznajomionych z żargonem Doliny Krzemowej, "B2B" to business-to-business, a jednorożec to firma warta miliard dolarów. Oznacza to, że mówią o ponad stu firmach wart miliardy plus dolarów, które zastępują pracowników dla innych firm.)

[^5]: Zobacz na przykład niedawny [raport Komisji ds. Przeglądu Gospodarczego i Bezpieczeństwa USA-Chiny](https://www.uscc.gov/sites/default/files/2024-11/2024_Executive_Summary.pdf). Chociaż w samym raporcie było zaskakująco mało uzasadnienia, główną rekomendacją było, aby Kongres USA "ustanowił i sfinansował program podobny do Projektu Manhattan, poświęcony wyścigowi o zdobycie zdolności Sztucznej Inteligencji Ogólnej (AGI)".

[^6]: Firmy przyjmują teraz to geopolityczne ujęcie jako tarczę przeciwko jakimkolwiek ograniczeniom w rozwoju ich AI, generalnie w sposób rażąco służący własnym interesom, a czasem w sposób, który nawet nie ma podstawowego sensu. Rozważmy [Podejście Meta do Frontowej AI](https://about.fb.com/news/2025/02/meta-approach-frontier-ai/), które jednocześnie argumentuje, że Ameryka musi "\[Umocnić swoją\] pozycję jako lider w innowacjach technologicznych, wzroście gospodarczym i bezpieczeństwie narodowym" i że musi to zrobić poprzez otwarte udostępnianie swoich najpotężniejszych systemów AI – co obejmuje dawanie ich bezpośrednio swoim geopolitycznym rywalom i przeciwnikom.

[^7]: W ten sposób prawdopodobnie musielibyśmy pozostawić zarządzanie tymi technologiami AI. Ale byłoby to bardzo problematyczne przekazanie kontroli, do czego wrócimy poniżej.

[^8]: Konkurencja w rozwoju technologii często przynosi ważne korzyści: zapobieganie kontroli monopolistycznej, napędzanie innowacji i redukcji kosztów, umożliwianie różnorodnych podejść i tworzenie wzajemnego nadzoru. Jednak w przypadku AGI te korzyści muszą być porównane z unikalnymi ryzykami wynikającymi z dynamiki wyścigu i presji na redukcję środków ostrożności bezpieczeństwa.