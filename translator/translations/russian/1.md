# Глава 1 - Введение

То, как мы отреагируем на перспективу появления ИИ умнее человека, является самым насущным вопросом нашего времени. Это эссе предлагает путь вперед.

Возможно, мы находимся в конце человеческой эры.

За последние десять лет началось нечто уникальное в истории нашего вида. Его последствия во многом определят будущее человечества. Примерно с 2015 года исследователи добились успеха в разработке *узкого* искусственного интеллекта (ИИ) — систем, которые могут выигрывать в такие игры, как го, распознавать изображения и речь и так далее, лучше любого человека.[^1]

Это потрясающий успех, который дает чрезвычайно полезные системы и продукты, расширяющие возможности человечества. Но узкий искусственный интеллект никогда не был истинной целью этой области. Скорее, целью было создание ИИ-систем *общего* назначения, особенно тех, которые часто называют «искусственным общим интеллектом» (ИОИ) или «сверхинтеллектом», которые одновременно не уступают людям или превосходят их практически во *всех* задачах, подобно тому, как ИИ сейчас превосходит человека в го, шахматах, покере, гонках дронов и т.д. Это заявленная цель многих крупных ИИ-компаний.[^2]

*Эти усилия также увенчиваются успехом.* Системы ИИ общего назначения, такие как ChatGPT, Gemini, Llama, Grok, Claude и Deepseek, основанные на массивных вычислениях и огромных объемах данных, достигли паритета с обычными людьми в широком спектре задач и даже сравнялись с экспертами-людьми в некоторых областях. Сейчас ИИ-инженеры в некоторых из крупнейших технологических компаний соревнуются в том, чтобы довести эти гигантские эксперименты в области машинного интеллекта до следующих уровней, на которых они сравняются, а затем превзойдут весь спектр человеческих способностей, экспертизы и автономности.

*Это неизбежно.* За последние десять лет экспертные оценки того, сколько времени это займет — если мы продолжим нынешний курс — упали с десятилетий (или столетий) до считанных лет.

Это также имеет эпохальное значение и несет трансцендентный риск. Сторонники ИОИ видят в нем позитивную трансформацию, которая решит научные проблемы, вылечит болезни, разработает новые технологии и автоматизирует рутинную работу. И ИИ, безусловно, может помочь достичь всего этого — более того, он уже это делает. Но на протяжении десятилетий многие вдумчивые мыслители, от Алана Тьюринга до Стивена Хокинга и современных Джеффри Хинтона и Йошуа Бенджио,[^3] выдвигали суровое предупреждение: создание действительно более умного, чем человек, общего, автономного ИИ, как минимум, полностью и безвозвратно перевернет общество, а как максимум — приведет к вымиранию человечества.[^4]

Сверхразумный ИИ быстро приближается на нашем нынешнем пути, но вовсе не неизбежен. Это эссе представляет развернутый аргумент о том, почему и как мы должны *закрыть Врата* этому приближающемуся нечеловеческому будущему, и что нам следует делать вместо этого.


[^1]: Эта [диаграмма](https://time.com/6300942/ai-progress-charts/) показывает набор задач; многие подобные кривые можно было бы добавить к этому графику. Этот быстрый прогресс в узком ИИ удивил даже экспертов в данной области, поскольку бенчмарки были превзойдены на годы раньше предсказаний.

[^2]: Deepmind, OpenAI, Anthropic и X.ai были основаны с конкретной целью разработки ИОИ. Например, устав OpenAI прямо заявляет своей целью разработку «искусственного общего интеллекта, который принесет пользу всему человечеству», в то время как миссия DeepMind — «решить интеллект, а затем использовать это для решения всего остального». Meta, Microsoft и другие теперь следуют по существу схожими путями. Meta заявила, что [планирует разработать ИОИ и сделать его открытым.](https://www.forbes.com/sites/johnkoetsier/2024/01/18/zuckerberg-on-ai-meta-building-agi-for-everyone-and-open-sourcing-it/)

[^3]: Хинтон и Бенджио — два из самых цитируемых исследователей ИИ, оба выиграли Нобелевскую премию области ИИ — премию Тьюринга, а Хинтон к тому же выиграл Нобелевскую премию (по физике).

[^4]: Создание чего-то с таким риском под коммерческими стимулами и практически без государственного надзора — абсолютно беспрецедентно. Среди тех, кто это создает, даже нет разногласий относительно риска! Лидеры Deepmind, OpenAI и Anthropic, среди многих других экспертов, все буквально подписали [заявление](https://www.safe.ai/work/statement-on-ai-risk), что продвинутый ИИ представляет *экзистенциальный риск для человечества.* Тревожные звонки не могли бы звонить громче, и можно лишь заключить, что те, кто их игнорирует, просто не воспринимают ИОИ и сверхинтеллект всерьез. Одна из целей этого эссе — помочь им понять, почему они должны это делать.