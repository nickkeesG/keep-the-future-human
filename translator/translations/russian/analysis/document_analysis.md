## Summary

The document is a comprehensive essay arguing against the development of Artificial General Intelligence (AGI) and superintelligence. The author, Anthony Aguirre, presents a structured case spanning 12 chapters plus appendices, arguing that humanity should "close the gates" to smarter-than-human AI while continuing to develop powerful but controllable "Tool AI."

The essay's core structure moves from technical background (Chapters 2-4) explaining how modern AI works and defining AGI/superintelligence, to timeline analysis (Chapter 5) showing AGI is imminent, to examining the driving forces behind the AGI race (Chapter 6) and catastrophic risks (Chapter 7). The constructive portion outlines concrete governance proposals (Chapter 8) and alternatives through Tool AI (Chapter 9).

The central argument rests on the "A-G-I" framework - that the dangerous intersection occurs when AI systems combine high **A**utonomy, **G**enerality, and **I**ntelligence simultaneously. The author proposes compute-based caps, enhanced liability frameworks, and international governance structures to prevent this convergence while allowing beneficial AI development to continue. The essay emphasizes that AGI development is a choice, not an inevitability, and advocates for maintaining human agency in civilization's future.

## Glossary

- **Source Term**: Artificial General Intelligence (AGI)
- **Target Translation**: искусственный общий интеллект (ИОИ)
- **Context**: Central concept throughout the document, defined as AI combining high autonomy, generality, and intelligence
- **Notes**: Standard translation in Russian AI literature; the Russian acronym ИОИ is sometimes used but AGI is more recognizable

- **Source Term**: superintelligence
- **Target Translation**: сверхинтеллект
- **Context**: AI systems far surpassing human capabilities across all domains
- **Notes**: Direct translation maintains clarity; well-established term in Russian AI safety discussions

- **Source Term**: neural networks
- **Target Translation**: нейронные сети
- **Context**: Technical foundation of modern AI systems described throughout
- **Notes**: Standard technical translation used universally in Russian

- **Source Term**: compute
- **Target Translation**: вычислительные мощности
- **Context**: Key governance mechanism - computational resources needed for AI training/inference
- **Notes**: While "компьют" exists as slang, the full translation is clearer for policy context

- **Source Term**: training
- **Target Translation**: обучение
- **Context**: Process of developing AI models through iterative improvement
- **Notes**: Standard ML terminology; "тренировка" is less precise

- **Source Term**: inference
- **Target Translation**: вывод/инференс
- **Context**: Process of AI generating outputs after training
- **Notes**: "Инференс" is increasingly used in Russian ML; "вывод" for general audiences

- **Source Term**: alignment
- **Target Translation**: выравнивание
- **Context**: Making AI systems do what humans want them to do
- **Notes**: Technical term in AI safety; some texts use "согласование" but "выравнивание" is more established

- **Source Term**: Tool AI
- **Target Translation**: инструментальный ИИ
- **Context**: Author's proposed alternative to AGI - controllable AI that enhances human capabilities
- **Notes**: Literal translation maintains the author's specific conceptual framework

- **Source Term**: autonomous agents
- **Target Translation**: автономные агенты
- **Context**: AI systems that can take actions independently
- **Notes**: Direct translation; well-established in Russian AI literature

- **Source Term**: scaling laws
- **Target Translation**: законы масштабирования
- **Context**: Empirical relationships between computational input and AI capability
- **Notes**: Technical term requiring literal translation for precision

- **Source Term**: FLOP (floating-point operations)
- **Target Translation**: FLOP (операции с плавающей точкой)
- **Context**: Unit for measuring computational work in AI systems
- **Notes**: Acronym commonly used in Russian technical contexts; parenthetical explanation for clarity

- **Source Term**: liability
- **Target Translation**: ответственность
- **Context**: Legal responsibility for AI-caused harms in governance proposals
- **Notes**: "Ответственность" covers both legal liability and broader responsibility concepts

- **Source Term**: hardware security
- **Target Translation**: аппаратная безопасность
- **Context**: Cryptographic features in AI chips for governance and control
- **Notes**: Standard technical translation in cybersecurity contexts

- **Source Term**: chain-of-thought
- **Target Translation**: цепочка рассуждений
- **Context**: AI technique for multi-step reasoning
- **Notes**: Descriptive translation that captures the sequential reasoning concept

- **Source Term**: multimodal models
- **Target Translation**: мультимодальные модели
- **Context**: AI systems processing multiple types of data (text, images, audio)
- **Notes**: Technical term used consistently in Russian ML literature