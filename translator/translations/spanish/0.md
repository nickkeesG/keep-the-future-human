# Resumen ejecutivo

Una descripción general de alto nivel del ensayo. Si tienes poco tiempo, obtén todos los puntos principales en solo 10 minutos.

Los avances dramáticos en inteligencia artificial durante la última década (para IA de propósito específico) y los últimos años (para IA de propósito general) han transformado la IA de un campo académico de nicho a la estrategia comercial central de muchas de las empresas más grandes del mundo, con cientos de miles de millones de dólares en inversión anual en las técnicas y tecnologías para hacer avanzar las capacidades de la IA.

Ahora llegamos a un momento crítico. Mientras las capacidades de los nuevos sistemas de IA comienzan a igualar y superar las de los humanos en muchos dominios cognitivos, la humanidad debe decidir: ¿qué tan lejos llegamos, y en qué dirección?

La IA, como toda tecnología, comenzó con el objetivo de mejorar las cosas para su creador. Pero nuestra trayectoria actual, y elección implícita, es una carrera descontrolada hacia sistemas cada vez más poderosos, impulsada por los incentivos económicos de unas pocas empresas tecnológicas gigantescas que buscan automatizar grandes sectores de la actividad económica actual y el trabajo humano. Si esta carrera continúa mucho más tiempo, hay un ganador inevitable: la IA misma—una alternativa más rápida, más inteligente y más barata que las personas en nuestra economía, nuestro pensamiento, nuestras decisiones, y eventualmente en el control de nuestra civilización.

Pero podemos hacer otra elección: a través de nuestros gobiernos, podemos tomar control del proceso de desarrollo de IA para imponer límites claros, líneas que no cruzaremos, y cosas que simplemente no haremos—como hemos hecho con las tecnologías nucleares, armas de destrucción masiva, armas espaciales, procesos ambientalmente destructivos, la bioingeniería de humanos y la eugenesia. Más importante aún, podemos asegurar que la IA permanezca como una herramienta para empoderar a los humanos, en lugar de una nueva especie que nos reemplace y eventualmente nos suplante.

Este ensayo argumenta que deberíamos *mantener el futuro humano* cerrando las "Puertas" a la IA autónoma de propósito general más inteligente que los humanos—a veces llamada "IAG"—y especialmente a la versión altamente superhumana a veces llamada "superinteligencia." En cambio, deberíamos enfocarnos en herramientas de IA poderosas y confiables que puedan empoderar a los individuos y mejorar transformativamente las capacidades de las sociedades humanas para hacer lo que mejor hacen. La estructura de este argumento sigue brevemente.

## La IA es diferente

Los sistemas de IA son fundamentalmente diferentes de otras tecnologías. Mientras el software tradicional sigue instrucciones precisas, los sistemas de IA aprenden cómo lograr objetivos sin que se les diga explícitamente cómo. Esto los hace poderosos: si podemos definir claramente el objetivo o una métrica de éxito, en la mayoría de los casos un sistema de IA puede aprender a lograrlo. Pero también los hace inherentemente impredecibles: no podemos determinar de manera confiable qué acciones tomarán para lograr sus objetivos.

También son en gran medida inexplicables: aunque son parcialmente código, son principalmente un enorme conjunto de números inescrutables—"pesos" de redes neuronales—que no pueden ser analizados; no somos mucho mejores entendiendo su funcionamiento interno que discerniendo pensamientos al mirar dentro de un cerebro biológico.

Este modo central de entrenamiento de redes neuronales digitales está aumentando rápidamente en complejidad. Los sistemas de IA más poderosos se crean a través de experimentos computacionales masivos, usando hardware especializado para entrenar redes neuronales en conjuntos de datos enormes, que luego se aumentan con herramientas de software y superestructura.

Esto ha llevado a la creación de herramientas muy poderosas para crear y procesar texto e imágenes, realizar razonamiento matemático y científico, agregar información, y consultar interactivamente un vasto almacén de conocimiento humano.

Desafortunadamente, mientras el desarrollo de herramientas tecnológicas más poderosas y más confiables es lo que *deberíamos* hacer, y lo que casi todo el mundo quiere y dice querer, no es la trayectoria en la que realmente estamos.

## IAG y superinteligencia

Desde los albores del campo, la investigación en IA se ha enfocado en cambio en un objetivo diferente: la Inteligencia Artificial General. Este enfoque ahora se ha convertido en el foco de las empresas titánicas que lideran el desarrollo de IA.

¿Qué es la IAG? A menudo se define vagamente como "IA a nivel humano," pero esto es problemático: ¿qué humanos, y en qué capacidades está a nivel humano? ¿Y qué hay de las capacidades superhumanas que ya tiene? Una forma más útil de entender la IAG es a través de la intersección de tres propiedades clave: alta **A**utonomía (independencia de acción), alta **G**eneralidad (amplio alcance y adaptabilidad), y alta **I**nteligencia (competencia en tareas cognitivas). Los sistemas de IA actuales pueden ser altamente capaces pero estrechos, o generales pero requieren supervisión humana constante, o autónomos pero limitados en alcance.

La A-G-I completa combinaría las tres propiedades en niveles que igualen o superen la capacidad humana superior. Críticamente, es esta combinación lo que hace a los humanos tan efectivos y tan diferentes del software actual; es también lo que permitiría que las personas sean reemplazadas completamente por sistemas digitales.

Aunque la inteligencia humana es especial, de ninguna manera es un límite. Los sistemas artificiales "superinteligentes" podrían operar cientos de veces más rápido, procesar vastamente más datos y mantener enormes cantidades "en mente" a la vez, y formar agregados que son mucho más grandes y más efectivos que colecciones de humanos. Podrían suplantar no a individuos sino a empresas, naciones, o nuestra civilización como un todo.

## Estamos en el umbral

Hay un fuerte consenso científico de que la IAG es *posible*. La IA ya supera el rendimiento humano en muchas pruebas generales de capacidad intelectual, incluyendo recientemente el razonamiento de alto nivel y la resolución de problemas. Las capacidades rezagadas—como el aprendizaje continuo, la planificación, la autoconciencia y la originalidad—todas existen en algún nivel en los sistemas de IA actuales, y existen técnicas conocidas que probablemente mejorarán todas ellas.

Mientras que hasta hace pocos años muchos investigadores veían la IAG como algo que estaba a décadas de distancia, actualmente la evidencia de cronogramas cortos hacia la IAG es fuerte:

- Las "leyes de escalamiento" empíricamente verificadas conectan la entrada computacional con la capacidad de IA, y las corporaciones están en camino de escalar la entrada computacional por órdenes de magnitud durante los próximos varios años. Los recursos humanos y fiscales dedicados al avance de la IA ahora igualan los de una docena de Proyectos Manhattan y varios Proyectos Apolo.
- Las corporaciones de IA y sus líderes creen pública y privadamente que la IAG (por alguna definición) es alcanzable dentro de unos pocos años. Estas empresas tienen información que el público no tiene, incluyendo algunas que tienen la próxima generación de sistemas de IA en sus manos.
- Los predictores expertos con historiales comprobados asignan 25% de probabilidad a que la IAG (por alguna definición) llegue dentro de 1-2 años, y 50% para 2-5 años (ver las predicciones de Metaculus para IAG ['débil'](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) y ['completa'](https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/)).
- La autonomía (incluyendo planificación flexible de largo alcance) está rezagada en los sistemas de IA, pero las grandes empresas ahora están enfocando sus vastos recursos en desarrollar sistemas de IA autónomos y han nombrado informalmente a 2025 el ["año del agente."](https://techinformed.com/2025-informed-the-year-of-agentic-ai/)
- La IA está contribuyendo cada vez más a su propia mejora. Una vez que los sistemas de IA sean tan competentes como los investigadores humanos de IA en hacer investigación de IA, se alcanzará un umbral crítico para el progreso rápido hacia sistemas de IA mucho más poderosos y probablemente conducirá a una escalada descontrolada en la capacidad de IA. (Se podría argumentar que esa escalada ya ha comenzado.)

La idea de que la IAG más inteligente que los humanos está a décadas de distancia o más simplemente ya no es sostenible para la gran mayoría de expertos en el campo. Los desacuerdos ahora son sobre cuántos meses o años tomará si nos mantenemos en este curso. La pregunta central que enfrentamos es: ¿deberíamos?

## Qué está impulsando la carrera hacia la IAG

La carrera hacia la IAG está siendo impulsada por múltiples fuerzas, cada una haciendo la situación más peligrosa. Las grandes empresas tecnológicas ven la IAG como la tecnología de automatización definitiva—no solo aumentando a los trabajadores humanos sino reemplazándolos en gran medida o completamente. Para las empresas, el premio es enorme: la oportunidad de capturar una fracción significativa de los $100 billones de producción económica anual mundial automatizando los costos de trabajo humano.

Las naciones se sienten obligadas a unirse a esta carrera, citando públicamente liderazgo económico y científico, pero viendo privadamente la IAG como una revolución potencial en asuntos militares comparable a las armas nucleares. El miedo de que los rivales puedan obtener una ventaja estratégica decisiva crea una dinámica clásica de carrera armamentista.

Aquellos que persiguen la superinteligencia a menudo citan visiones grandiosas: curar todas las enfermedades, revertir el envejecimiento, lograr avances en energía y viajes espaciales, o crear capacidades de planificación superhumanas.

Menos caritativamente, lo que impulsa la carrera es el poder. Cada participante—ya sea empresa o país—cree que la inteligencia es igual a poder, y que ellos serán los mejores custodios de ese poder.

Argumento que estas motivaciones son reales pero fundamentalmente equivocadas: la IAG *absorberá* y *buscará* poder en lugar de otorgarlo; las tecnologías creadas por IA *también* serán fuertemente de doble filo, y donde sean beneficiosas pueden ser creadas con herramientas de IA y sin IAG; e incluso en la medida en que la IAG y sus productos permanezcan bajo control, estas dinámicas de carrera—tanto corporativas como geopolíticas—hacen que los riesgos de gran escala para nuestra sociedad sean casi inevitables a menos que sean interrumpidos decisivamente.

## La IAG y la superinteligencia representan una amenaza dramática para la civilización

A pesar de su atractivo, la IAG y la superinteligencia representan amenazas dramáticas para la civilización a través de múltiples vías que se refuerzan mutuamente:

*Concentración de poder:* la IA superhumana podría desempoderar a la gran mayoría de la humanidad absorbiendo enormes sectores de la actividad social y económica en sistemas de IA dirigidos por un puñado de empresas gigantes (que a su vez pueden ser tomadas por, o efectivamente tomar control de, gobiernos).

*Disrupción masiva:* la automatización masiva de la mayoría de trabajos basados en cognición, el reemplazo de nuestros sistemas epistémicos actuales, y el despliegue de vastos números de agentes activos no humanos trastornaría la mayoría de nuestros sistemas civilizatorios actuales en un período de tiempo relativamente corto.

*Catástrofes:* al proliferar la capacidad—potencialmente por encima del nivel humano—de crear nuevas tecnologías militares y destructivas y desacoplarla de los sistemas sociales y legales que fundamentan la responsabilidad, las catástrofes físicas por armas de destrucción masiva se vuelven dramáticamente más probables.

*Geopolítica y guerra:* las grandes potencias mundiales no se quedarán de brazos cruzados si sienten que una tecnología que podría proporcionar una "ventaja estratégica decisiva" está siendo desarrollada por sus adversarios.

*Escalada descontrolada y pérdida de control:* A menos que se prevenga específicamente, la IA superhumana tendrá todos los incentivos para mejorarse aún más y podría superar por mucho a los humanos en velocidad, procesamiento de datos y sofisticación de pensamiento. No hay manera significativa en que podamos tener control de tal sistema. Tal IA no otorgará poder a los humanos; nosotros le otorgaremos poder a ella, o ella lo tomará.

Muchos de estos riesgos permanecen incluso si se resuelve el problema técnico de "alineación"—asegurar que la IA avanzada haga de manera confiable lo que los humanos quieren que haga. La IA presenta un enorme desafío en cómo será gestionada, y muchos aspectos de esta gestión se vuelven increíblemente difíciles o intratables cuando se supera la inteligencia humana.

Más fundamentalmente, el tipo de IA superhumana de propósito general que actualmente se está persiguiendo tendría, por su misma naturaleza, objetivos, agencia y capacidades que superan las nuestras. Sería inherentemente incontrolable—¿cómo podemos controlar algo que no podemos ni entender ni predecir? No sería una herramienta tecnológica para uso humano, sino una segunda especie de inteligencia en la Tierra junto a la nuestra. Si se le permite progresar más, constituiría no solo una segunda especie sino una especie de reemplazo.

Quizás nos trataría bien, quizás no. Pero el futuro le pertenecería a ella, no a nosotros. La era humana habría terminado.

## Esto no es inevitable; la humanidad puede, muy concretamente, decidir no construir nuestro reemplazo.

La creación de IAG superhumana está lejos de ser inevitable. Podemos prevenirla a través de un conjunto coordinado de medidas de gobernanza:

Primero, necesitamos contabilidad robusta y supervisión del cómputo de IA ("cómputo"), que es un facilitador fundamental y una palanca para gobernar los sistemas de IA de gran escala. Esto a su vez requiere medición estandarizada y reporte del cómputo total usado en entrenar modelos de IA y ejecutarlos, y métodos técnicos para contar, certificar y verificar la computación utilizada.

Segundo, deberíamos implementar límites máximos estrictos en el cómputo de IA, tanto para entrenamiento como para operación; estos previenen que la IA sea demasiado poderosa y opere demasiado rápido. Estos límites pueden implementarse a través de requisitos legales y medidas de seguridad basadas en hardware construidas en chips especializados para IA, análogas a las características de seguridad en los teléfonos modernos. Porque el hardware especializado de IA es hecho por solo un puñado de empresas, la verificación y aplicación son factibles a través de la cadena de suministro existente.

Tercero, necesitamos responsabilidad legal mejorada para los sistemas de IA más peligrosos. Aquellos que desarrollan IA que combina alta autonomía, amplia generalidad e inteligencia superior deberían enfrentar responsabilidad estricta por daños, mientras que refugios seguros de esta responsabilidad alentarían el desarrollo de sistemas más limitados y controlables.

Cuarto, necesitamos regulación escalonada basada en niveles de riesgo. Los sistemas más capaces y peligrosos requerirían garantías extensas de seguridad y controlabilidad antes del desarrollo y despliegue, mientras que sistemas menos poderosos o más especializados enfrentarían supervisión proporcional. Este marco regulatorio debería eventualmente operar tanto a niveles nacionales como internacionales.

Este enfoque—con especificación detallada dada en el documento completo—es práctico: mientras se necesitará coordinación internacional, la verificación y aplicación pueden funcionar a través del pequeño número de empresas que controlan la cadena de suministro de hardware especializado. También es flexible: las empresas aún pueden innovar y obtener ganancias del desarrollo de IA, solo con límites claros en los sistemas más peligrosos.

La contención a largo plazo del poder y riesgo de IA requeriría acuerdos internacionales basados tanto en interés propio como común, tal como controlar la proliferación de armas nucleares lo hace ahora. Pero podemos comenzar inmediatamente con supervisión mejorada y responsabilidad legal, mientras construimos hacia una gobernanza más comprensiva.

El ingrediente clave que falta es la voluntad política y social para tomar control del proceso de desarrollo de IA. La fuente de esa voluntad, si llega a tiempo, será la realidad misma—es decir, de la realización generalizada de las implicaciones reales de lo que estamos haciendo.

## Podemos diseñar IA Herramienta para empoderar a la humanidad

En lugar de perseguir IAG incontrolable, podemos desarrollar "IA Herramienta" poderosa que mejore la capacidad humana mientras permanece bajo control humano significativo. Los sistemas de IA Herramienta pueden ser extremadamente capaces mientras evitan la peligrosa triple-intersección de alta autonomía, amplia generalidad e inteligencia superhumana, siempre y cuando los diseñemos para ser controlables a un nivel proporcional a su capacidad. También pueden combinarse en sistemas sofisticados que mantengan la supervisión humana mientras entregan beneficios transformativos.

La IA Herramienta puede revolucionar la medicina, acelerar el descubrimiento científico, mejorar la educación y mejorar los procesos democráticos. Cuando se gobierna apropiadamente, puede hacer que los expertos humanos e instituciones sean más efectivos en lugar de reemplazarlos. Aunque tales sistemas seguirán siendo altamente disruptivos y requerirán gestión cuidadosa, los riesgos que representan son fundamentalmente diferentes de la IAG: son riesgos que podemos gobernar, como los de otras tecnologías poderosas, no amenazas existenciales a la agencia humana y la civilización. Y críticamente, cuando se desarrolla sabiamente, las herramientas de IA pueden ayudar a las personas a gobernar la IA poderosa y gestionar sus efectos.

Este enfoque requiere repensar tanto cómo se desarrolla la IA como cómo se distribuyen sus beneficios. Nuevos modelos de desarrollo de IA público y sin fines de lucro, marcos regulatorios robustos, y mecanismos para distribuir beneficios económicos más ampliamente pueden ayudar a asegurar que la IA empodere a la humanidad como un todo en lugar de concentrar poder en unas pocas manos. La IA misma puede ayudar a construir mejores instituciones sociales y de gobernanza, habilitando nuevas formas de coordinación y discurso que fortalezcan en lugar de socavar la sociedad humana. Los establecimientos de seguridad nacional pueden aprovechar su experiencia para hacer que los sistemas de herramientas de IA sean genuinamente seguros y confiables, y una verdadera fuente de defensa así como de poder nacional.

Eventualmente podríamos elegir desarrollar sistemas aún más poderosos y más soberanos que sean menos como herramientas y—podemos esperar—más como benefactores sabios y poderosos. Pero deberíamos hacerlo solo después de que hayamos desarrollado la comprensión científica y la capacidad de gobernanza para hacerlo de manera segura. Tal decisión trascendental e irreversible debería ser hecha deliberadamente por la humanidad como un todo, no por defecto en una carrera entre empresas tecnológicas y naciones.

## En manos humanas

Las personas quieren lo bueno que viene de la IA: herramientas útiles que las empoderen, potencien oportunidades económicas y crecimiento, y prometan avances en ciencia, tecnología y educación. ¿Por qué no lo querrían? Pero cuando se les pregunta, mayorías abrumadoras del público general [quieren desarrollo de IA más lento y más cuidadoso](https://www.vox.com/future-perfect/2023/8/18/23836362/ai-slow-down-poll-regulation), y no quieren IA más inteligente que los humanos que los reemplazará en sus trabajos y en otros lugares, llenará su cultura y espacios comunes de información con contenido no humano, concentrará poder en un pequeño conjunto de corporaciones, representará riesgos extremos de gran escala global, y eventualmente amenazará con desempoderar o reemplazar a su especie. ¿Por qué lo querrían?

*Podemos* tener uno sin el otro. Comienza decidiendo que nuestro destino no está en la supuesta inevitabilidad de alguna tecnología o en las manos de unos pocos CEOs en Silicon Valley, sino en el resto de nuestras manos si nos hacemos cargo de él. Cerremos las Puertas, y mantengamos el futuro humano.