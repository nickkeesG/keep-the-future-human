# Capítulo 10 - La elección que tenemos ante nosotros

Para preservar nuestro futuro humano, debemos elegir cerrar las Puertas a la IAG y la superinteligencia.

La última vez que la humanidad compartió la Tierra con otras mentes que hablaban, pensaban, construían tecnología y resolvían problemas de propósito general fue hace 40,000 años en la Europa de la era glacial. Esas otras mentes se extinguieron, en su totalidad o en parte debido a los esfuerzos de las nuestras.

Ahora estamos regresando a ese tipo de época. Los productos más avanzados de nuestra cultura y tecnología —conjuntos de datos construidos a partir de todo nuestro patrimonio informativo de internet, y chips de 100 mil millones de elementos que son las tecnologías más complejas que jamás hemos creado— se están combinando para dar vida a sistemas de IA avanzados de propósito general.

Los desarrolladores de estos sistemas están empeñados en presentarlos como herramientas para el empoderamiento humano. Y de hecho podrían serlo. Pero no nos engañemos: nuestra trayectoria actual consiste en construir agentes digitales cada vez más poderosos, orientados a objetivos, capaces de tomar decisiones y con capacidades generales. Ya se desempeñan tan bien como muchos humanos en una amplia gama de tareas intelectuales, mejoran rápidamente y contribuyen a su propio perfeccionamiento.

A menos que esta trayectoria cambie o se tope con un obstáculo inesperado, pronto —en años, no décadas— tendremos inteligencias digitales peligrosamente poderosas. Incluso en el *mejor* de los escenarios, estas traerían grandes beneficios económicos (al menos para algunos de nosotros), pero solo a costa de una profunda disrupción en nuestra sociedad y el reemplazo de los humanos en la mayoría de las cosas más importantes que hacemos: estas máquinas pensarían por nosotros, planificarían por nosotros, decidirían por nosotros y crearían por nosotros. Estaríamos mimados, pero como niños mimados. Es mucho más probable que estos sistemas reemplazaran a los humanos tanto en las cosas positivas *como* negativas que hacemos, incluyendo la explotación, la manipulación, la violencia y la guerra. ¿Podemos sobrevivir a versiones de estas potenciadas por IA? Finalmente, es más que plausible que las cosas no salieran nada bien: que relativamente pronto fuéramos reemplazados no solo en lo que hacemos, sino en lo que *somos*, como arquitectos de la civilización y el futuro. Pregúntenles a los neandertales cómo resulta eso. Quizás nosotros también les proporcionamos baratijas adicionales durante un tiempo.

*No tenemos que hacer esto.* Tenemos IA que compite con los humanos, y no hay necesidad de construir IA con la que *no podamos* competir. Podemos construir herramientas de IA increíbles sin construir una especie sucesora. La idea de que la IAG y la superinteligencia son inevitables es una *elección que se disfraza de destino*.

Al imponer algunos límites estrictos y globales, podemos mantener la capacidad general de la IA aproximadamente al nivel humano mientras seguimos cosechando los beneficios de la capacidad de las computadoras para procesar datos de maneras que nosotros no podemos, y automatizar tareas que ninguno de nosotros quiere hacer. Estas aún plantearían muchos riesgos, pero si se diseñan y gestionan bien, serían una bendición enorme para la humanidad, desde la medicina hasta la investigación y los productos de consumo.

Imponer límites requeriría cooperación internacional, pero menos de lo que uno podría pensar, y esos límites aún dejarían mucho espacio para una industria de IA y hardware de IA enorme centrada en aplicaciones que mejoren el bienestar humano, en lugar de la búsqueda pura del poder. Y si, con fuertes garantías de seguridad y después de un diálogo global significativo, decidimos ir más allá, esa opción sigue siendo nuestra para perseguirla.

La humanidad debe *elegir* cerrar las Puertas a la IAG y la superinteligencia.

Para mantener el futuro humano.

## Una nota del autor

Gracias por tomarte el tiempo de explorar este tema con nosotros.

Escribí este ensayo porque como científico siento que es importante decir la verdad sin adornos, y porque como persona siento que es crucial que actuemos rápida y decisivamente para abordar un tema que cambia el mundo: el desarrollo de sistemas de IA más inteligentes que los humanos.

Si queremos responder a este estado de cosas extraordinario con sabiduría, debemos estar preparados para examinar críticamente la narrativa predominante de que la IAG y la superinteligencia 'deben' construirse para asegurar nuestros intereses, o son 'inevitables' y no pueden detenerse. Estas narrativas nos dejan sin poder, incapaces de ver los caminos alternativos que tenemos por delante.

Espero que te unas a mí pidiendo cautela ante la imprudencia, y valor ante la codicia.

Espero que te unas a mí pidiendo un futuro humano.

*– Anthony*

![Anthony Aguirre signature](https://keepthefuturehuman.ai/essay/_next/image?url=https%3A%2F%2Fkeepthefuturehuman.ai%2Fwp-content%2Fuploads%2F2025%2F02%2FAnthony-Aguirre-signature-300x84.png&w=3840&q=75)