# Capítulo 5 - En el umbral

El camino desde los sistemas de IA actuales hacia una IAG completamente desarrollada parece sorprendentemente corto y predecible.

Los últimos diez años han visto avances dramáticos en IA impulsados por enormes recursos [computacionales](https://epoch.ai/blog/training-compute-of-frontier-ai-models-grows-by-4-5x-per-year), humanos y [fiscales](https://arxiv.org/abs/2405.21015). Muchas aplicaciones de IA especializada superan a los humanos en sus tareas asignadas, y son ciertamente mucho más rápidas y baratas.[^1] Y también existen agentes especializados sobrehumanos que pueden derrotar a todas las personas en juegos de dominio específico como [Go](https://www.nature.com/articles/nature16961), [ajedrez](https://arxiv.org/abs/1712.01815) y [póker](https://www.deepstack.ai/), así como [agentes más generales](https://deepmind.google/discover/blog/a-generalist-agent/) que pueden planificar y ejecutar acciones en entornos simulados simplificados tan eficazmente como los humanos.

Más prominentemente, los sistemas actuales de IA general de OpenAI/Microsoft, Google/Deepmind, Anthropic/Amazon, Facebook/Meta, X.ai/Tesla y otros [^2] han surgido desde principios de 2023 y han aumentado constantemente (aunque de manera desigual) sus capacidades desde entonces. Todos estos han sido creados mediante predicción de tokens en enormes conjuntos de datos de texto y multimedia, combinados con retroalimentación de refuerzo extensiva de humanos y otros sistemas de IA. Algunos de ellos también incluyen sistemas extensos de herramientas y andamiaje.

## Fortalezas y debilidades de los sistemas generales actuales

Estos sistemas funcionan bien en una gama cada vez más amplia de pruebas diseñadas para medir inteligencia y experiencia, con un progreso que ha sorprendido incluso a los expertos en el campo:

- Cuando se lanzó por primera vez, GPT-4 [igualó o superó el rendimiento humano típico](https://arxiv.org/abs/2303.08774) en exámenes académicos estándar incluyendo SATs, GRE, exámenes de ingreso y exámenes de colegiación. Los modelos más recientes probablemente funcionan significativamente mejor, aunque los resultados no están disponibles públicamente.
- La prueba de Turing – considerada durante mucho tiempo como un punto de referencia clave para la IA "verdadera" – ahora es rutinariamente superada en algunas formas por los modelos de lenguaje modernos, tanto informalmente como en [estudios formales](https://arxiv.org/abs/2405.08007).[^3]
- En el exhaustivo punto de referencia MMLU que abarca 57 materias académicas, [los modelos recientes logran puntuaciones a nivel de experto en el dominio](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu) (~90%) [^4]
- La experiencia técnica ha avanzado dramáticamente: El punto de referencia GPQA de física de nivel posgrado vio [saltar el rendimiento](https://epoch.ai/data/ai-benchmarking-dashboard) de casi adivinación aleatoria (GPT-4, 2022) a nivel experto (o1-preview, 2024).
- Incluso las pruebas específicamente diseñadas para ser resistentes a la IA están cayendo: O3 de OpenAI [supuestamente](https://www.nextbigfuture.com/2024/12/openai-releases-o3-model-with-high-performance-and-high-cost.html) resuelve el punto de referencia ARC-AGI de resolución abstracta de problemas a nivel humano, logra rendimiento de codificación de experto superior, y obtiene 25% en los problemas de "matemáticas de frontera" de Epoch AI diseñados para desafiar a matemáticos de élite.[^5]
- La tendencia es tan clara que el desarrollador de MMLU ahora ha creado ["El Último Examen de la Humanidad"](https://agi.safe.ai/) – un nombre ominoso que refleja la posibilidad de que la IA pronto supere el rendimiento humano en cualquier prueba significativa. Al momento de escribir esto, hay afirmaciones de sistemas de IA que logran 27% (según [Sam Altman](https://x.com/sama/status/1886220281565381078)) y 35% (según [este artículo](https://arxiv.org/abs/2502.09955)) en este examen extremadamente difícil. Es muy poco probable que cualquier humano individual pueda hacerlo.

A pesar de estos números impresionantes (y su obvia inteligencia cuando uno interactúa con ellos) [^6] hay muchas cosas que (al menos las versiones lanzadas de) estas redes neuronales *no pueden* hacer. Actualmente la mayoría son incorpóreas – existiendo solo en servidores – y procesan como máximo texto, sonido e imágenes fijas (pero no video). Crucialmente, la mayoría no puede llevar a cabo actividades planificadas complejas que requieren alta precisión.[^7] Y hay una serie de otras cualidades fuertes en la cognición humana de alto nivel que actualmente son bajas en los sistemas de IA lanzados.

La siguiente tabla enumera varias de estas, basadas en sistemas de IA de mediados de 2024 como GPT-4o, Claude 3.5 Sonnet y Google Gemini 1.5.[^8] La pregunta clave para qué tan rápidamente la IA general se volverá más poderosa es: ¿hasta qué grado simplemente hacer *más de lo mismo* producirá resultados, versus agregar técnicas adicionales pero *conocidas*, versus desarrollar o implementar direcciones de investigación en IA *realmente nuevas*? Mis propias predicciones para esto se dan en la tabla, en términos de qué tan probable es que cada uno de estos escenarios obtenga esa capacidad a nivel humano y más allá.

<table><tbody><tr><th>Capacidad</th><th>Descripción de la capacidad</th><th>Estado/pronóstico</th><th>Escalamiento/conocido/nuevo</th></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td colspan="4"><em>Capacidades Cognitivas Centrales</em></td></tr><tr><td>Razonamiento</td><td>Las personas pueden hacer razonamiento preciso, de múltiples pasos, siguiendo reglas y verificando precisión.</td><td>Progreso reciente dramático usando cadena de razonamiento extendida y reentrenamiento</td><td>95/5/5</td></tr><tr><td>Planificación</td><td>Las personas exhiben planificación a largo plazo y jerárquica.</td><td>Mejorando con escala; puede ser fuertemente ayudado usando andamiaje y mejores técnicas de entrenamiento.</td><td>10/85/5</td></tr><tr><td>Anclaje en la verdad</td><td>Las IAPG confabulan información no fundamentada para satisfacer consultas.</td><td>Mejorando con escala; datos de calibración disponibles dentro del modelo; puede ser verificado/mejorado vía andamiaje.</td><td>30/65/5</td></tr><tr><td>Resolución flexible de problemas</td><td>Los humanos pueden reconocer nuevos patrones e inventar nuevas soluciones a problemas complejos; los modelos de AM actuales luchan.</td><td>Mejora con escala pero débilmente; puede ser solucionable con técnicas neurosimbólicas o de "búsqueda" generalizadas.</td><td>15/75/10</td></tr><tr><td colspan="4"><em>Aprendizaje y Conocimiento</em></td></tr><tr><td>Aprendizaje y memoria</td><td>Las personas tienen memoria de trabajo, a corto y largo plazo, todas las cuales son dinámicas e interrelacionadas.</td><td>Todos los modelos aprenden durante el entrenamiento; las IAPG aprenden dentro de la ventana de contexto y durante el ajuste fino; "aprendizaje continuo" y otras técnicas existen pero aún no integradas en IAPG grandes.</td><td>5/80/15</td></tr><tr><td>Abstracción y recursión</td><td>Las personas pueden mapear y transferir conjuntos de relaciones a otros más abstractos para razonamiento y manipulación, incluyendo razonamiento "meta" recursivo.</td><td>Mejorando débilmente con escala; podría emerger en sistemas neurosimbólicos.</td><td>30/50/20</td></tr><tr><td>Modelo(s) del mundo</td><td>Las personas tienen y continuamente actualizan un modelo predictivo del mundo dentro del cual pueden resolver problemas y hacer razonamiento físico</td><td>Mejorando con escala; actualización ligada al aprendizaje; IAPG débiles en predicción del mundo real.</td><td>20/50/30</td></tr><tr><td colspan="4"><em>Yo y Agencia</em></td></tr><tr><td>Agencia</td><td>Las personas pueden tomar acciones para perseguir objetivos, basándose en planificación/predicción.</td><td>Muchos sistemas de AM son agénticos; los LLM pueden convertirse en agentes vía envoltorios.</td><td>5/90/5</td></tr><tr><td>Autodirección</td><td>Las personas desarrollan y persiguen sus propios objetivos, con motivación e impulso generados internamente.</td><td>Compuesto en gran medida de agencia más originalidad; probablemente emerja en sistemas agénticos complejos con objetivos abstractos.</td><td>40/45/15</td></tr><tr><td>Autorreferencia</td><td>Las personas entienden y razonan sobre sí mismas como situadas dentro de un ambiente/contexto.</td><td>Mejorando con escala y podría ser aumentado con recompensa de entrenamiento.</td><td>70/15/15</td></tr><tr><td>Autoconciencia</td><td>Las personas tienen conocimiento de y pueden razonar respecto a sus propios pensamientos y estados mentales.</td><td>Existe en algún sentido en IAPG, que pueden decirse que pasan la "prueba del espejo" clásica para autoconciencia. Puede ser mejorado con andamiaje; pero no está claro si esto es suficiente.</td><td>20/55/25</td></tr><tr><td colspan="4"><em>Interfaz y Ambiente</em></td></tr><tr><td>Inteligencia encarnada</td><td>Las personas entienden e interactúan activamente con su ambiente del mundo real.</td><td>El aprendizaje por refuerzo funciona bien en ambientes simulados y del mundo real (robóticos) y puede ser integrado en transformadores multimodales.</td><td>5/85/10</td></tr><tr><td>Procesamiento multisensorial</td><td>Las personas integran y procesan en tiempo real flujos visuales, auditivos y de otros sensores.</td><td>El entrenamiento en múltiples modalidades parece "simplemente funcionar," y mejorar con escala. El procesamiento de video en tiempo real es difícil pero e.g. los sistemas de conducción autónoma están mejorando rápidamente.</td><td>30/60/10</td></tr><tr><td colspan="4"><em>Capacidades de Orden Superior</em></td></tr><tr><td>Originalidad</td><td>Los modelos de AM actuales son creativos en transformar y combinar ideas/obras existentes, pero las personas pueden construir nuevos marcos y estructuras, a veces ligados a su identidad.</td><td>Puede ser difícil de discernir de "creatividad," que puede escalar hacia ella; puede emerger de creatividad más autoconciencia.</td><td>50/40/10</td></tr><tr><td>Sensibilidad</td><td>Las personas experimentan qualia; estos pueden ser de valencia positiva, negativa o neutral; es "como algo" ser una persona.</td><td>Muy difícil y filosóficamente complejo determinar si un sistema dado tiene esto.</td><td>5/10/85</td></tr></tbody></table>

Capacidades clave actualmente por debajo del nivel de experto humano en sistemas de IAPG modernos, agrupadas por tipo. La tercera columna resume el estado actual. La columna final muestra la probabilidad predicha (%) de que el rendimiento a nivel humano se logrará mediante: escalamiento de técnicas actuales / combinación con técnicas conocidas / desarrollo de técnicas nuevas. Estas capacidades no son independientes, y el aumento en cualquiera típicamente va junto con aumentos en otras. Nótese que no todas (particularmente la sensibilidad) son necesarias para sistemas de IA capaces de avanzar el desarrollo de IA, destacando la posibilidad de IA poderosa pero no sensible.

Desglosar lo que está "faltando" de esta manera deja bastante claro que estamos muy encaminados hacia inteligencia ampliamente superior a la humana mediante el escalamiento de técnicas existentes o conocidas.[^9]

Aún podrían haber sorpresas. Incluso dejando de lado la "sensibilidad," podría haber algunas de las capacidades cognitivas centrales listadas que realmente no se pueden hacer con técnicas actuales y requieren nuevas. Pero considere esto. El esfuerzo presente que están poniendo muchas de las compañías más grandes del mundo equivale a múltiples veces el gasto del proyecto Apollo y decenas de veces el del proyecto Manhattan,[^10] y está empleando miles de las personas técnicas más destacadas con salarios inauditos. Las dinámicas de los últimos años ahora han traído a esto más poder intelectual humano (con IA ahora siendo agregada) que cualquier empresa en la historia. No deberíamos apostar al fracaso.

## El gran objetivo: agentes autónomos generalistas

El desarrollo de IA general durante los últimos años se ha enfocado en crear IA general y poderosa pero similar a herramientas: funciona principalmente como un asistente (bastante) leal, y generalmente no toma acciones por sí misma. Esto es parcialmente por diseño, pero en gran medida porque estos sistemas simplemente no han sido lo suficientemente competentes en las habilidades relevantes para ser confiados con acciones complejas.[^11]

Sin embargo, las compañías de IA e investigadores están [cambiando su enfoque](https://www.axios.com/2025/01/23/davos-2025-ai-agents) cada vez más hacia agentes *autónomos* de propósito general a nivel experto.[^12] Esto permitiría que los sistemas actúen más como un asistente humano al cual el usuario puede delegar acciones reales.[^13] ¿Qué requerirá eso? Varias de las capacidades en la tabla de "lo que falta" están implicadas, incluyendo fuerte anclaje en la verdad, aprendizaje y memoria, abstracción y recursión, y modelado del mundo (para inteligencia), planificación, agencia, originalidad, autodirección, autorreferencia y autoconciencia (para autonomía), y procesamiento multisensorial, inteligencia encarnada, y resolución flexible de problemas (para generalidad).[^14]

Esta triple intersección de alta autonomía (independencia de acción), alta generalidad (alcance y amplitud de tareas) y alta inteligencia (competencia en tareas cognitivas) es actualmente única de los humanos. Es implícitamente lo que muchos probablemente tienen en mente cuando piensan en IAG – tanto en términos de su valor como de sus riesgos.

Esto proporciona otra manera de definir I-A-G como ***I*** nteligencia- ***A*** utónoma- ***G*** eneral, y veremos que esta triple intersección proporciona una lente muy valiosa para sistemas de alta capacidad tanto en entender sus riesgos y recompensas, como en la gobernanza de la IA.

![](https://keepthefuturehuman.ai/essay/_next/image?url=https%3A%2F%2Fkeepthefuturehuman.ai%2Fwp-content%2Fuploads%2F2025%2F02%2FAGI-Venn-Diagram-Simple-1024x1024.png&w=3840&q=75) La zona transformacional de poder y riesgo de I-A-G emerge de la intersección de tres propiedades clave: alta Autonomía, alta Inteligencia en tareas, y alta Generalidad.

## El ciclo de (auto-)mejoramiento de la IA

Un factor crucial final en entender el progreso de la IA es el ciclo único de retroalimentación tecnológica de la IA. En el desarrollo de IA, el éxito – tanto en sistemas demostrados como en productos desplegados – trae inversión adicional, talento y competencia, y actualmente estamos en medio de un enorme ciclo de retroalimentación de exageración-más-realidad de IA que está impulsando cientos de miles de millones, o incluso billones, de dólares en inversión.

Este tipo de ciclo de retroalimentación podría suceder con cualquier tecnología, y lo hemos visto en muchas, donde el éxito de mercado genera inversión, que genera mejoramiento y mejor éxito de mercado. Pero el desarrollo de IA va más lejos, en que ahora los sistemas de IA están ayudando a desarrollar sistemas de IA nuevos y más poderosos.[^15] Podemos pensar en este ciclo de retroalimentación en cinco etapas, cada una con una escala de tiempo más corta que la anterior, como se muestra en la tabla.

*El ciclo de mejoramiento de IA opera a través de múltiples escalas de tiempo, con cada etapa potencialmente acelerando las etapas subsecuentes. Las etapas anteriores están bien en marcha, mientras que las etapas posteriores permanecen especulativas pero podrían proceder muy rápidamente una vez desbloqueadas.*

Varias de estas etapas ya están en marcha, y un par claramente comenzando. La última etapa, en la cual los sistemas de IA se mejoran autónomamente a sí mismos, ha sido un elemento básico de la literatura sobre el riesgo de sistemas de IA muy poderosos, y por buena razón.[^16] Pero es importante notar que es solo la forma más drástica de un ciclo de retroalimentación que ya ha comenzado y podría llevar a más sorpresas en el avance rápido de la tecnología.


[^1]: Usted usa mucho más de esta IA de lo que probablemente piensa, impulsando generación y reconocimiento de voz, procesamiento de imágenes, algoritmos de feeds de noticias, etc.

[^2]: Aunque las relaciones entre estos pares de compañías son bastante complejas y matizadas, las he listado explícitamente para indicar tanto la vasta capitalización de mercado general de firmas ahora involucradas en desarrollo de IA, como también que detrás incluso de compañías "más pequeñas" como Anthropic se encuentran bolsillos enormemente profundos vía inversiones y acuerdos de asociación importantes.

[^3]: Se ha vuelto de moda menospreciar la prueba de Turing, pero es bastante poderosa y general. En versiones débiles indica si las personas típicas interactuando con una IA (que está entrenada para actuar humana) de maneras típicas por períodos breves pueden distinguir si es una IA. No pueden. Segundo, una prueba de Turing altamente adversarial puede sondear esencialmente cualquier elemento de capacidad e inteligencia humana – por ej. comparando un sistema de IA con un experto humano, evaluado por otros expertos humanos. Hay un sentido en el cual mucha de la evaluación de IA es una forma generalizada de prueba de Turing.

[^4]: Esto es por dominio – ningún humano podría plausiblemente lograr tales puntuaciones a través de todas las materias simultáneamente.

[^5]: Estos son problemas que tomarían incluso a excelentes matemáticos tiempo sustancial resolver, si pudieran resolverlos del todo.

[^6]: Si usted es de inclinación escéptica, mantenga su escepticismo pero realmente pruebe los modelos más actuales, así como trate por usted mismo algunas de las preguntas de prueba que pueden pasar. Como profesor de física, predigo con casi certeza que, por ejemplo, los mejores modelos pasarían el examen de calificación de posgrado en nuestro departamento.

[^7]: Esta y otras debilidades como la confabulación han ralentizado la adopción del mercado y llevado a una brecha entre capacidades percibidas y reclamadas (que también debe ser vista a través de la lente de intensa competencia de mercado y la necesidad de atraer inversión). Esto ha confundido tanto al público como a los formuladores de políticas sobre el estado real del progreso de IA. Aunque quizás no igualando la exageración, el progreso es muy real.

[^8]: El avance mayor desde entonces ha sido el desarrollo de sistemas entrenados para razonamiento de alta calidad, aprovechando más computación durante la inferencia y mayor aprendizaje por refuerzo. Porque estos modelos son nuevos y sus capacidades menos probadas, no he reelaborado completamente esta tabla excepto por "razonamiento," que considero esencialmente resuelto. Pero he actualizado predicciones basadas en capacidades experimentadas y reportadas de esos sistemas.

[^9]: Ondas previas de optimismo de IA en los 1960s y 1980s terminaron en "inviernos de IA" cuando las capacidades prometidas fallaron en materializarse. Sin embargo, la onda actual difiere fundamentalmente en haber logrado rendimiento sobrehumano en muchos dominios, respaldado por recursos computacionales masivos y éxito comercial.

[^10]: El proyecto Apollo completo [costó cerca de $250 mil millones USD en dólares de 2020](https://www.planetary.org/space-policy/cost-of-apollo), y el proyecto Manhattan [menos de una décima parte de eso](https://www.brookings.edu/the-costs-of-the-manhattan-project/). Goldman Sachs [proyecta un billón de dólares de gasto solo en centros de datos de IA](https://www.datacenterdynamics.com/en/news/goldman-sachs-1tn-to-be-spent-on-ai-data-centers-chips-and-utility-upgrades-with-little-to-show-for-it-so-far/) durante los próximos años.

[^11]: Aunque los humanos cometemos muchos errores, ¡subestimamos qué tan confiables podemos ser! Porque las probabilidades se multiplican, una tarea que requiere 20 pasos para hacerse correctamente requiere que cada paso sea 97% confiable solo para hacerla bien la mitad del tiempo. Hacemos tales tareas todo el tiempo.

[^12]: Un movimiento fuerte en esta dirección se ha tomado muy recientemente con el asistente ["Deep Research"](https://openai.com/index/introducing-deep-research/) de OpenAI que autónomamente realiza investigación general, descrito como "una nueva capacidad agéntica que conduce investigación de múltiples pasos en internet para tareas complejas."

[^13]: Cosas como llenar ese formulario PDF molesto, reservar vuelos, etc. ¡Pero con un doctorado en 20 campos! Así que también: escribir esa tesis para usted, negociar ese contrato para usted, demostrar ese teorema para usted, crear esa campaña publicitaria para usted, etc. ¿Qué hace *usted*? Le dice qué hacer, por supuesto.

[^14]: Nótese que la sensibilidad *no* es claramente requerida, ni la IA en esta triple intersección necesariamente la implica.

[^15]: La analogía más cercana aquí es quizás la tecnología de chips, donde el desarrollo ha mantenido la ley de Moore por décadas, mientras las tecnologías computacionales ayudan a las personas a diseñar la siguiente generación de tecnología de chips. Pero la IA será mucho más directa.

[^16]: Es importante dejar que se asiente por un momento que la IA podría – pronto – estar mejorándose a sí misma en una escala de tiempo de días o semanas. O menos. Tenga esto en mente cuando alguien le diga que una capacidad de IA está definitivamente muy lejos.