# Capítulo 6 - La carrera hacia la IAG

¿Cuáles son las fuerzas impulsoras detrás de la carrera para construir IAG, tanto para empresas como para países?

El rápido progreso reciente en IA ha resultado tanto de como en un nivel extraordinario de atención e inversión. Esto se debe en parte al éxito en el desarrollo de IA, pero hay más factores en juego. ¿Por qué algunas de las empresas más grandes de la Tierra, e incluso países enteros, compiten para construir no solo IA, sino IAG y superinteligencia?

## Qué ha llevado la investigación en IA hacia la IA de nivel humano

Hasta hace aproximadamente cinco años, la IA había sido principalmente un problema de investigación académica y científica, impulsado en gran medida por la curiosidad y el impulso de entender la inteligencia y cómo crearla en un nuevo sustrato.

En esta fase, había relativamente poca atención prestada a los beneficios o peligros de la IA entre la mayoría de los investigadores. Cuando se les preguntaba por qué debería desarrollarse la IA, una respuesta común podría ser enumerar, de manera algo vaga, problemas con los que la IA podría ayudar: nuevas medicinas, nuevos materiales, nueva ciencia, procesos más inteligentes, y en general mejorar las cosas para la gente.[^1]

¡Estos son objetivos admirables![^2] Aunque podemos y vamos a cuestionar si la IAG —en lugar de la IA en general— es necesaria para estos objetivos, exhiben el idealismo con el que muchos investigadores de IA comenzaron.

Sin embargo, durante la última media década, la IA se ha transformado de un campo de investigación relativamente puro en más bien un campo de ingeniería y productos, impulsado en gran medida por algunas de las empresas más grandes del mundo.[^3] Los investigadores, aunque relevantes, ya no están a cargo del proceso.

## ¿Por qué las empresas están tratando de construir IAG?

Entonces, ¿por qué las corporaciones gigantes (y aún más los inversionistas) están volcando vastos recursos en construir IAG? Hay dos impulsores sobre los que la mayoría de empresas son bastante honestas: ven la IA como impulsores de productividad para la sociedad, y de ganancias para ellas. Debido a que la IA general es por naturaleza de propósito general, hay un premio enorme: en lugar de elegir un sector en el cual crear productos y servicios, uno puede intentar *todos ellos a la vez.* Las grandes empresas tecnológicas han crecido enormemente produciendo bienes y servicios digitales, y al menos algunos ejecutivos seguramente ven la IA como simplemente el siguiente paso en proporcionárselos bien, con riesgos y beneficios que se expanden sobre pero hacen eco de aquellos proporcionados por la búsqueda, redes sociales, laptops, teléfonos, etc.

Pero ¿por qué IAG? Hay una respuesta muy simple a esto, que la mayoría de empresas e inversionistas evitan discutir públicamente.[^4]

Es que la IAG puede directamente, uno por uno, *reemplazar trabajadores.*

No aumentar, no empoderar, no hacer más productivo. Ni siquiera *desplazar.* Todo esto puede y será hecho por IA que no sea IAG. La IAG es específicamente lo que puede *reemplazar* completamente a los trabajadores del conocimiento (y con robótica, también muchos físicos). Como apoyo a esta perspectiva uno no necesita mirar más allá de la [definición (declarada públicamente)](https://openai.com/our-structure/) de IAG de OpenAI, que es "un sistema altamente autónomo que supera a los humanos en la mayoría del trabajo económicamente valioso."

El premio aquí (¡para las empresas!) es enorme. Los costos laborales son un porcentaje sustancial de los ∼$100 billones de la economía global mundial. Incluso si solo una fracción de esto es capturada por el reemplazo del trabajo humano por trabajo de IA, esto son billones de dólares de ingresos anuales. Las empresas de IA también son conscientes de quién está dispuesto a pagar. Como ellas lo ven, tú no vas a pagar miles de dólares al año por herramientas de productividad. Pero una empresa *sí* pagará miles de dólares por año para reemplazar tu trabajo, si pueden.

## Por qué los países sienten que tienen que competir hacia la IAG

Las motivaciones declaradas de los países para perseguir IAG se enfocan en el liderazgo económico y científico. El argumento es convincente: la IAG podría acelerar dramáticamente la investigación científica, el desarrollo tecnológico y el crecimiento económico. Dados los riesgos en juego, argumentan, ninguna potencia mayor puede permitirse quedarse atrás.[^5]

Pero también hay impulsores adicionales y en gran medida no declarados. No hay duda de que cuando ciertos líderes militares y de seguridad nacional se reúnen a puerta cerrada para discutir una tecnología extraordinariamente potente y catastróficamente riesgosa, su enfoque no es en "¿cómo evitamos esos riesgos?" sino más bien "¿cómo obtenemos esto primero?" Los líderes militares y de inteligencia ven la IAG como una revolución potencial en asuntos militares, quizás la más significativa desde las armas nucleares. El temor es que el primer país en desarrollar IAG podría ganar una ventaja estratégica insuperable. Esto crea una dinámica clásica de carrera armamentista.

Veremos que este pensamiento de "carrera hacia la IAG",[^6] aunque convincente, está profundamente defectuoso. Esto no es porque competir sea peligroso y riesgoso —aunque lo es— sino debido a la naturaleza de la tecnología. La suposición no declarada es que la IAG, como otras tecnologías, es controlable por el estado que la desarrolla, y es una bendición que otorga poder a la sociedad que tiene más de ella. Como veremos, probablemente no será ninguna de las dos cosas.

## ¿Por qué superinteligencia?

Mientras las empresas se enfocan públicamente en la productividad, y los países en el crecimiento económico y tecnológico, para aquellos que deliberadamente persiguen IAG completa y superinteligencia estos son solo el comienzo. ¿Qué tienen realmente en mente? Aunque rara vez se dice en voz alta, incluyen:

1. Curas para muchas o todas las enfermedades;
2. Detener y revertir el envejecimiento;
3. Nuevas fuentes de energía sostenible como la fusión;
4. Mejoras humanas, u organismos diseñados mediante ingeniería genética;
5. Nanotecnología y manufactura molecular;
6. Cargas de mente;
7. Física exótica o tecnologías espaciales;
8. Consejo y apoyo de decisiones sobrehumanos;
9. Planificación y coordinación sobrehumanas.

Las primeras tres son en gran medida tecnologías de "filo único" —es decir, probablemente bastante fuertemente positivas netas. Es difícil argumentar contra curar enfermedades o poder vivir más tiempo si uno elige. Y ya hemos cosechado el lado negativo de la fusión (en forma de armas nucleares); sería encantador ahora obtener el lado positivo. La pregunta con esta primera categoría es si obtener estas tecnologías antes compensa el riesgo.

Las siguientes cuatro son claramente de doble filo: tecnologías transformativas con tanto ventajas potencialmente enormes como riesgos inmensos, muy parecido a la IA. Todas estas, si brotaran de una caja negra mañana y fueran desplegadas, serían increíblemente difíciles de manejar.[^7]

Las dos finales conciernen a la IA sobrehumana haciendo cosas ella misma en lugar de solo inventar tecnología. Más precisamente, dejando los eufemismos de lado, estas involucran sistemas de IA poderosos diciéndole a la gente qué hacer. Llamar a esto "consejo" es deshonesto si el sistema que aconseja es mucho más poderoso que el aconsejado, quien no puede entender significativamente la base de la decisión (o incluso si esto es proporcionado, confiar en que el consejero no proporcionaría una justificación similarmente convincente para una decisión diferente).

Esto apunta a un elemento clave que falta en la lista anterior:

10. Poder.

Es abundantemente claro que mucho de lo que subyace la carrera actual por IA sobrehumana es la idea de que *inteligencia = poder*. Cada competidor está apostando a ser el mejor poseedor de ese poder, y que serán capaces de ejercerlo por razones ostensiblemente benevolentes sin que se les escape o sea tomado de su control.

Es decir, lo que las empresas y naciones están realmente persiguiendo no son solo los frutos de la IAG y superinteligencia, sino el poder de controlar quién tiene acceso a ellos y cómo se usan. Las empresas se ven como administradores responsables de este poder al servicio de los accionistas y la humanidad; las naciones se ven como guardianes necesarios previniendo que poderes hostiles ganen ventaja decisiva. Ambos están peligrosamente equivocados, fallando en reconocer que la superinteligencia, por su naturaleza, no puede ser confiablemente controlada por ninguna institución humana. Veremos que la naturaleza y dinámicas de los sistemas superinteligentes hacen el control humano extremadamente difícil, si no imposible.

Estas dinámicas de carrera —tanto corporativas como geopolíticas— hacen ciertos riesgos casi inevitables a menos que sean decisivamente interrumpidas. Ahora nos volvemos a examinar estos riesgos y por qué no pueden ser adecuadamente mitigados dentro de un paradigma de desarrollo competitivo.[^8]


[^1]: Una lista más precisa de objetivos dignos son los [Objetivos de Desarrollo Sostenible](https://sdgs.un.org/goals) de la ONU. Estos son, en cierto sentido, lo más cercano que tenemos a un conjunto de objetivos de consenso global para lo que nos gustaría ver mejorado en el mundo. La IA podría ayudar.

[^2]: La tecnología en general tiene un poder transformativo económico y social para el mejoramiento humano, como miles de años atestiguan. En esta línea, una explicación larga y convincente de una visión positiva de IAG puede encontrarse en [este ensayo](https://darioamodei.com/machines-of-loving-grace) del fundador de Anthropic, Dario Amodei.

[^3]: La inversión privada en IA [comenzó a dispararse en 2018-19, cruzando la inversión pública alrededor de entonces,](https://cset.georgetown.edu/publication/tracking-ai-investment/) y la ha superado enormemente desde entonces.

[^4]: Puedo atestiguar que detrás de puertas más cerradas, no tienen tal escrúpulo. Y se está volviendo más público; ver por ejemplo la nueva ["solicitud de startups"](https://www.ycombinator.com/rfs) de Y-combinator, muchas partes de la cual explícitamente piden el reemplazo al por mayor de trabajadores humanos. Para citarlos, "La propuesta de valor del SaaS B2B era hacer a los trabajadores humanos incrementalmente más eficientes. La propuesta de valor de los agentes de IA verticales es automatizar el trabajo completamente... Es completamente posible que esta oportunidad sea lo suficientemente grande para acuñar otros 100 unicornios." (Para aquellos no versados en la jerga del Silicon Valley, "B2B" es negocio a negocio y un unicornio es una empresa de $1 billón. Es decir, están hablando de más de cien negocios de billones-más-dólares que reemplazan trabajadores para otros negocios.)

[^5]: Ver por ejemplo un [reporte reciente de la Comisión de Revisión Económica y de Seguridad Estados Unidos-China](https://www.uscc.gov/sites/default/files/2024-11/2024_Executive_Summary.pdf). Aunque había sorprendentemente poca justificación dentro del reporte mismo, la recomendación principal fue que Estados Unidos "El Congreso establezca y financie un programa tipo Proyecto Manhattan dedicado a competir hacia y adquirir una capacidad de Inteligencia Artificial General (IAG)."

[^6]: Las empresas ahora están adoptando este encuadre geopolítico como un escudo contra cualquier restricción en su desarrollo de IA, generalmente de maneras que son descaradamente egoístas, y a veces de maneras que ni siquiera tienen sentido básico. Considerar el [Enfoque hacia la IA Frontera](https://about.fb.com/news/2025/02/meta-approach-frontier-ai/) de Meta, que simultáneamente argumenta que América debe "Cimentar su posición como líder en innovación tecnológica, crecimiento económico y seguridad nacional" y también que debe hacerlo liberando abiertamente sus sistemas de IA más poderosos — lo que incluye dárselos directamente a sus rivales y adversarios geopolíticos.

[^7]: Así que probablemente tendríamos que dejar el manejo de estas tecnologías a las IA. Pero esta sería una delegación de control muy problemática, a la que regresaremos más abajo.

[^8]: La competencia en el desarrollo tecnológico a menudo trae beneficios importantes: prevenir el control monopolístico, impulsar la innovación y reducción de costos, habilitar enfoques diversos, y crear supervisión mutua. Sin embargo, con la IAG estos beneficios deben ser sopesados contra riesgos únicos de las dinámicas de carrera y la presión para reducir precauciones de seguridad.