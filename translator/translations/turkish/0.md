# Yönetici Özeti

Makaleye üst düzey bir bakış. Zamanınız kısıtlıysa, tüm ana noktaları sadece 10 dakikada öğrenin.

Son on yılda yapay zeka alanındaki çarpıcı ilerlemeler (dar amaçlı AI için) ve son birkaç yıldaki gelişmeler (genel amaçlı AI için) yapay zekayı niş bir akademik alandan dünyanın en büyük şirketlerinin temel iş stratejisine dönüştürdü. AI'ın yeteneklerini geliştirmeye yönelik teknik ve teknolojilere yılda yüzlerce milyar dolarlık yatırım yapılıyor.

Şimdi kritik bir kavşağa geldik. Yeni AI sistemlerinin yetenekleri birçok bilişsel alanda insanlarınkiyle eşleşmeye ve onları aşmaya başladığında, insanlık şunu karar vermelidir: ne kadar ileri gidiyoruz ve hangi yönde?

AI, tüm teknolojiler gibi, yaratıcısı için işleri iyileştirme hedefiyle başladı. Ancak mevcut yörüngemiz ve zımni seçimimiz, birkaç dev teknoloji şirketinin ekonomik teşvikleriyle yönlendirilen, mevcut ekonomik faaliyetin ve insan emeğinin büyük bölümlerini otomatikleştirmeyi amaçlayan, sürekli daha güçlü sistemlere doğru kontrolsüz bir yarış. Bu yarış çok daha uzun süre devam ederse, kaçınılmaz bir kazanan var: AI'ın kendisi - ekonomimizde, düşüncelerimizde, kararlarımızda insanlara göre daha hızlı, daha akıllı, daha ucuz bir alternatif ve sonunda medeniyetimizin kontrolünü elinde tutan bir güç.

Ama başka bir seçim yapabiliriz: hükümetlerimiz aracılığıyla AI geliştirme sürecinin kontrolünü ele alarak net sınırlar, geçmeyeceğimiz çizgiler ve kesinlikle yapmayacağımız şeyler koyabiliriz - tıpkı nükleer teknolojiler, kitle imha silahları, uzay silahları, çevresel açıdan yıkıcı süreçler, insanların biyomühendisliği ve öjeni için yaptığımız gibi. En önemlisi, AI'ın insanları güçlendiren bir araç olarak kalmasını sağlayabiliriz; bizi değiştiren ve sonunda yerimizi alan yeni bir tür haline gelmesini değil.

Bu makale, insanlardan daha akıllı, otonom, genel amaçlı AI - bazen "YGZ" olarak adlandırılan - ve özellikle bazen "superintellijans" denilen son derece insanüstü versiyonuna giden "kapıları" kapatarak *geleceği insani tutmamızı* savunuyor. Bunun yerine, bireyleri güçlendirebilecek ve insan toplumlarının en iyi yaptıkları şeyleri yapma yeteneklerini dönüştürücü şekilde iyileştirebilecek güçlü, güvenilir AI araçlarına odaklanmalıyız. Bu argümanın yapısı kısaca şöyle.

## AI farklıdır

AI sistemleri temelden diğer teknolojilerden farklıdır. Geleneksel yazılımlar kesin talimatları takip ederken, AI sistemleri nasıl yapacağı açıkça söylenmeden hedeflere ulaşmayı öğrenir. Bu onları güçlü kılar: hedefi veya başarı ölçütünü net tanımlayabildiğimizde, çoğu durumda bir AI sistemi bunu gerçekleştirmeyi öğrenebilir. Ama aynı zamanda onları doğası gereği öngörülemez kılar: amaçlarına ulaşmak için hangi eylemleri yapacaklarını güvenilir şekilde belirleyemeyiz.

Ayrıca büyük ölçüde açıklanamaz durumdalar: kısmen kod olmalarına rağmen, çoğunlukla anlaşılmaz sayılardan - sinir ağı "ağırlıklarından" - oluşan devasa bir küme olduklarından ayrıştırılamazlar; iç işleyişlerini anlamakta, biyolojik bir beyne bakarak düşünceleri çözmeye çalışmaktan çok daha iyi değiliz.

Dijital sinir ağlarını eğitmenin bu temel yöntemi hızla karmaşıklık kazanıyor. En güçlü AI sistemleri, devasa veri kümeleri üzerinde sinir ağlarını eğitmek için özelleşmiş donanım kullanan masif hesaplama deneyleri yoluyla yaratılıyor ve daha sonra yazılım araçları ve üst yapılarla güçlendiriliyor.

Bu, metin ve görsel yaratma ve işleme, matematiksel ve bilimsel akıl yürütme, bilgi toplama ve geniş insan bilgisi stoklarını etkileşimli sorgulama konularında çok güçlü araçların yaratılmasına yol açtı.

Ne yazık ki, daha güçlü, daha güvenilir teknolojik araçlar geliştirmek yapmamız *gereken* şey ve neredeyse herkesin istediği ve istediğini söylediği şey olsa da, aslında gittiğimiz yön bu değil.

## YGZ ve superintellijans

Alanın doğuşundan bu yana, AI araştırmaları bunun yerine farklı bir hedefe odaklandı: Yapay Genel Zeka. Bu odak noktası artık AI gelişimini yöneten dev şirketlerin odağı haline geldi.

YGZ nedir? Genellikle "insan seviyesinde AI" olarak belirsiz tanımlanır, ama bu sorunlu: hangi insanlar ve hangi yeteneklerde insan seviyesinde? Peki halihazırda sahip olduğu insanüstü yetenekler ne olacak? YGZ'yi anlamanın daha kullanışlı yolu üç temel özelliğin kesişimi: yüksek **O** tonom (eylem bağımsızlığı), yüksek **G** enellik (geniş kapsam ve uyum sağlayabilirlik), ve yüksek **Z** eka (bilişsel görevlerde yetkinlik). Mevcut AI sistemleri oldukça yetenekli ama dar, ya da genel ama sürekli insan gözetimi gerektiren, ya da otonom ama sınırlı kapsamlı olabilir.

Tam O-G-Z, üç özelliği de en üst düzey insan yeteneğini eşleyen veya aşan seviyelerde birleştirir. Kritik olan şu ki, insanları bu kadar etkili ve mevcut yazılımlardan bu kadar farklı kılan bu kombinasyon; aynı zamanda insanların toptan dijital sistemlerle değiştirilebilmesini sağlayacak olan da bu.

İnsan zekası özel olsa da, hiçbir şekilde bir sınır değildir. Yapay "süper zekili" sistemler yüzlerce kat daha hızlı çalışabilir, çok daha fazla veriyi işleyebilir ve muazzam miktarlarda bilgiyi aynı anda "aklında" tutabilir, ve insan topluluklarından çok daha büyük ve etkili kümeler oluşturabilir. Sadece bireyleri değil şirketleri, ulusları ya da bir bütün olarak medeniyetimizi yerinden edebilirler.

## Eşikteyiz

YGZ'nin *mümkün* olduğu konusunda güçlü bir bilimsel konsensüs var. AI, son zamanlarda üst düzey akıl yürütme ve problem çözme dahil olmak üzere, birçok genel entelektüel yetenek testinde insan performansını zaten aşıyor. Geride kalan yetenekler - sürekli öğrenme, planlama, öz-farkındalık ve özgünlük gibi - mevcut AI sistemlerinde bir düzeyde var ve bunların hepsini geliştirme olasılığı yüksek olan bilinen teknikler mevcut.

Birkaç yıl öncesine kadar birçok araştırmacı YGZ'yi onlarca yıl uzakta görürken, şu anda YGZ'ye kısa vadeli kanıtlar güçlü:

- Deneysel olarak doğrulanmış "ölçekleme yasaları" hesaplama girdisini AI yeteneğine bağlıyor ve şirketler önümüzdeki birkaç yıl içinde hesaplama girdisini büyüklük mertebeleri artıracak yolda. AI gelişimine ayrılan insan ve mali kaynaklar şimdi bir düzine Manhattan Projesi ve birkaç Apollo Projesi'ne eşit.
- AI şirketleri ve liderleri, YGZ'nin (bir tanımıyla) birkaç yıl içinde elde edilebileceğine alenen ve özel olarak inanıyorlar. Bu şirketlerin kamunun bilmediği bilgileri var; bazıları bir sonraki nesil AI sistemlerini elinde tutuyor.
- Kanıtlanmış sicili olan uzman tahminciler, YGZ'nin (bir tanımıyla) 1-2 yıl içinde gelmesi için %25, 2-5 yıl için %50 olasılık atfediyorlar (bkz. Metaculus ['zayıf'](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) ve ['tam'](https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/) YGZ tahminleri).
- Otonomi (uzun menzilli esnek planlama dahil) AI sistemlerinde geride kalıyor, ama büyük şirketler artık muazzam kaynaklarını otonom AI sistemleri geliştirmeye odaklıyorlar ve 2025'i gayri resmi olarak ["ajan yılı"](https://techinformed.com/2025-informed-the-year-of-agentic-ai/) ilan ettiler.
- AI kendi gelişimine giderek daha fazla katkıda bulunuyor. AI sistemleri AI araştırması yapan insan AI araştırmacıları kadar yetkin olduğunda, çok daha güçlü AI sistemlerine hızlı ilerleme için kritik bir eşik geçilecek ve muhtemelen AI yeteneğinde kaçış hızına yol açacak. (Tartışılabilir ki, bu kaçış hızı çoktan başladı.)

İnsanlardan daha akıllı YGZ'nin onlarca yıl ya da daha uzun süre uzakta olduğu fikri artık alandaki uzmanların büyük çoğunluğu için geçerli değil. Anlaşmazlıklar artık bu rotada devam edersek kaç ay ya da yıl süreceği konusunda. Karşılaştığımız temel soru: devam etmeli miyiz?

## YGZ yarışını ne yönlendiriyor

YGZ'ye doğru yarış birden fazla güç tarafından yönlendiriliyor ve her biri durumu daha tehlikeli hale getiriyor. Büyük teknoloji şirketleri YGZ'yi nihai otomasyon teknolojisi olarak görüyor - sadece insan çalışanları desteklemek değil, büyük ölçüde ya da tamamen değiştirmek. Şirketler için ödül muazzam: insan emek maliyetlerini otomatikleştirerek dünyanın 100 trilyon dolarlık yıllık ekonomik çıktısının önemli bir bölümünü ele geçirme fırsatı.

Uluslar bu yarışa katılmak zorunda hissediyorlar, alenen ekonomik ve bilimsel liderliği öne sürerken, özel olarak YGZ'yi nükleer silahlara benzer askeri işlerdeki potansiel devrime bakıyorlar. Rakiplerin belirleyici stratejik avantaj elde edebileceği korkusu klasik silah yarışı dinamiği yaratıyor.

Superintellijansı hedefleyenler genellikle büyük vizyonlar öne sürerler: tüm hastalıkları iyileştirmek, yaşlanmayı tersine çevirmek, enerji ve uzay yolculuğunda atılımlar gerçekleştirmek, ya da insanüstü planlama yetenekleri yaratmak.

Daha az cömert bakıldığında, yarışı yönlendiren güçtür. Her katılımcı - ister şirket ister ülke olsun - zekanın güce eşit olduğuna ve bu gücün en iyi koruyucusunun kendileri olduğuna inanıyor.

Bu motivasyonların gerçek ama temelden yanlış yönlendirilmiş olduğunu savunuyorum: YGZ güç *verecek* değil güç *emecek* ve *arayacak*; AI-yaratılmış teknolojiler *de* güçlü şekilde iki yönlü keskin olacak ve faydalı oldukları yerlerde AI araçlarıyla ve YGZ olmadan yaratılabilecek; ve YGZ ve çıktıları kontrolde kaldığı ölçüde bile, bu yarış dinamikleri - hem kurumsal hem jeopolitik - kararlı şekilde kesintiye uğratılmadıkça toplumumuza büyük ölçekli riskleri neredeyse kaçınılmaz hale getiriyor.

## YGZ ve superintellijans medeniyet için çarpıcı bir tehdit oluşturuyor

Çekicilikleri olmasına rağmen, YGZ ve superintellijans birbirini güçlendiren çoklu yollarla medeniyet için çarpıcı tehditler oluşturuyor:

*Güç yoğunlaşması:* insanüstü AI, sosyal ve ekonomik faaliyetin büyük bölümlerini avuç dolusu dev şirket (sırayla hükümetler tarafından devralınabilir ya da hükümetleri fiilen devralabilir) tarafından işletilen AI sistemlerine absorbe ederek insanlığın büyük çoğunluğunu güçsüzleştirebilir.

*Masif bozulma:* bilişsel tabanlı işlerin toplu otomasyonu, mevcut epistemik sistemlerimizin değiştirilmesi, ve çok sayıda aktif insani olmayan ajanın kullanıma sunulması mevcut medeni sistemlerimizin çoğunu nispeten kısa sürede altüst edecektir.

*Felaketler:* yeni askeri ve yıkıcı teknolojiler yaratma yeteneğini - potansiyel olarak insan seviyesinin üzerinde - yaygınlaştırarak ve bunu sorumluluğu temelleyen sosyal ve hukuki sistemlerden ayırarak, kitle imha silahlarından fiziksel felaketler çarpıcı şekilde daha olası hale gelir.

*Jeopolitik ve savaş:* büyük dünya güçleri, "belirleyici stratejik avantaj" sağlayabilecek bir teknolojinin düşmanları tarafından geliştirildiğini hissederlerse aylak durmayacaklar.

*Kaçış hızı ve kontrol kaybı:* özellikle engellenmediği sürece, insanüstü AI kendini daha da iyileştirme için her türlü teşvike sahip olacak ve hız, veri işleme ve düşünce karmaşıklığında insanları çok geride bırakabilecek. Böyle bir sistemi kontrol etmenin anlamlı hiçbir yolu yok. Böyle AI insanlara güç vermeyecek; biz ona güç vereceğiz ya da o alacak.

Bu risklerin çoğu teknik "hizalama" problemi - gelişmiş AI'ın güvenilir şekilde insanların istediği şeyi yapmasını sağlama - çözülse bile devam eder. AI nasıl yönetileceği konusunda muazzam bir meydan okuma sunar ve bu yönetimin pek çok yönü insan zekası aşıldığında inanılmaz derecede zor ya da çözemez hale gelir.

En temelde, şu anda izlenen insanüstü genel amaçlı AI türü, doğası gereği bizimkini aşan hedeflere, failliğe ve yeteneklere sahip olacaktır. Doğası gereği kontrol edilemez olacaktır - ne anlayamadığımız ne de öngöremediğimiz bir şeyi nasıl kontrol edebiliriz? İnsan kullanımı için teknolojik bir araç değil, Dünya'da bizimkinin yanında ikinci bir zeka türü olacaktır. Daha da ilerlemesine izin verilirse, sadece ikinci bir tür değil yedek tür teşkil edecektir.

Belki bize iyi davranır, belki davranmaz. Ama gelecek bizim değil onun olacaktır. İnsan çağı sona erecektir.

## Bu kaçınılmaz değil; insanlık çok somut şekilde yerimizi alacak olanı inşa etmemeye karar verebilir.

İnsanüstü YGZ yaratılması kaçınılmazdan uzaktır. Koordineli yönetişim önlemleri setiyle bunu engelleyebiliriz:

İlk olarak, büyük ölçekli AI sistemlerinin temel etkinleştiricisi ve yönetim kaldıracı olan AI hesaplamasının ("işlem gücü") sağlam muhasebe ve gözetimine ihtiyacımız var. Bu da AI modelleri eğitme ve çalıştırmada kullanılan toplam işlem gücünün standartlaştırılmış ölçümü ve raporlaması ile kullanılan hesaplamanın sayım, sertifikalandırma ve doğrulama teknik yöntemlerini gerektirير.

İkinci olarak, AI hesaplamasında hem eğitim hem işletim için katı üst sınırlar koymalıyız; bunlar AI'ın hem çok güçlü olmasını hem çok hızlı çalışmasını engeller. Bu sınırlar hem yasal gereklilikler hem de modern telefonlardaki güvenlik özelliklerine benzer şekilde AI özellikli çiplere inşa edilen donanım tabanlı güvenlik önlemleriyle uygulanabilir. Özelleşmiş AI donanımı sadece avuç dolusu şirket tarafından yapıldığından, mevcut tedarik zinciri aracılığıyla doğrulama ve uygulama mümkündür.

Üçüncü olarak, en tehlikeli AI sistemleri için artırılmış sorumluluğa ihtiyacımız var. Yüksek otonomi, geniş genellik ve üstün zekayı birleştiren AI geliştirenlerin zararlar için katı sorumluluğu olmalı, bu sorumluluktan güvenli limanlar ise daha sınırlı ve kontrol edilebilir sistemlerin gelişimini teşvik edecektir.

Dördüncü olarak, risk seviyelerine dayalı kademeli düzenlemeye ihtiyacımız var. En yetenekli ve tehlikeli sistemler geliştirme ve kullanıma sunmadan önce kapsamlı güvenlik ve kontrol edilebilirlik garantileri gerektirecek, daha az güçlü ya da daha özelleşmiş sistemler ise orantılı gözetimle karşılaşacaktır. Bu düzenleyici çerçeve sonunda hem ulusal hem uluslararası düzeylerde çalışmalıdır.

Bu yaklaşım - detayları tam belgede verilmiştir - pratiktir: uluslararası koordinasyon gerekecek olsa da, doğrulama ve uygulama özelleşmiş donanım tedarik zincirini kontrol eden az sayıda şirket aracılığıyla işleyebilir. Ayrıca esnektir: şirketler yine de AI gelişiminden yenilik yapabilir ve kâr edebilir, sadece en tehlikeli sistemlerde net sınırlarla.

AI gücü ve riskinin uzun vadeli kontrolü, nükleer silah yayılmasını kontrol etmenin şu anda yaptığı gibi, hem kendi çıkarı hem ortak çıkara dayalı uluslararası anlaşmalar gerektirecektir. Ama daha kapsamlı yönetişime doğru inşa ederken, artırılmış gözetim ve sorumlulukla hemen başlayabiliriz.

Eksik temel bileşen, AI geliştirme sürecinin kontrolünü ele almak için politik ve sosyal iradedir. Bu iradenin kaynağı, zamanında gelirse, gerçekliğin kendisi olacaktır - yani yaptığımızın gerçek sonuçlarının yaygın fark edilmesinden.

## İnsanlığı güçlendirmek için Araç AI mühendisliği yapabiliriz

Kontrol edilemez YGZ peşinde koşmak yerine, anlamlı insan kontrolünde kalırken insan yeteneğini artıran güçlü "Araç AI" geliştirebiliriz. Araç AI sistemleri, yetenek seviyelerine uygun kontrol edilebilirlik seviyesinde mühendislik yaptığımız sürece, yüksek otonomi, geniş genellik ve insanüstü zekanın tehlikeli üçlü kesişiminden kaçınırken son derece yetenekli olabilir. Ayrıca insan gözetimini korurken dönüştürücü faydalar sağlayan karmaşık sistemlerde birleştirilebilirler.

Araç AI tıpta devrim yaratabilir, bilimsel keşfi hızlandırabilir, eğitimi geliştirebilir ve demokratik süreçleri iyileştirebilir. Uygun şekilde yönetildiğinde, insan uzmanları ve kurumları değiştirmek yerine daha etkili hale getirebilir. Bu sistemler yine de oldukça yıkıcı olacak ve dikkatli yönetim gerektirecek olsa da, oluşturdukları riskler YGZ'ninkinden temelden farklıdır: yönetebileceğimiz risklerdir, diğer güçlü teknolojilerin riskleri gibi, insan failliği ve medeniyeti için varoluşsal tehditler değil. Ve kritik olarak, akıllıca geliştirildiğinde, AI araçları insanların güçlü AI'ı yönetmesine ve etkilerini yönetmesine yardımcı olabilir.

Bu yaklaşım hem AI'ın nasıl geliştirildiğini hem faydalarının nasıl dağıtıldığını yeniden düşünmeyi gerektirir. Yeni kamu ve kâr amacı gütmeyen AI geliştirme modelleri, sağlam düzenleyici çerçeveler ve ekonomik faydaları daha geniş dağıtma mekanizmaları AI'ın güçü birkaç elde yoğunlaştırmak yerine insanlığın tamamını güçlendirmesini sağlayabilir. AI'ın kendisi daha iyi sosyal ve yönetişim kurumları inşa etmekte yardım edebilir, insan toplumunu zayıflatmak yerine güçlendiren yeni koordinasyon ve söylem biçimlerini mümkün kılabilir. Ulusal güvenlik kurumları uzmanlıklarından yararlanarak AI araç sistemlerini gerçekten güvenli ve güvenilir, hem savunma hem de ulusal güç kaynağı haline getirebilir.

Sonunda araç olmaktan daha az benzer ve - umabileceğimiz gibi - akıllı ve güçlü hayırseverlere daha çok benzer daha güçlü ve daha egemen sistemler geliştirmeyi seçebiliriz. Ama bunu ancak güvenli şekilde yapabilecek bilimsel anlayış ve yönetişim kapasitesini geliştirdikten sonra yapmalıyız. Bu kadar önemli ve geri dönüşü olmayan bir karar teknoloji şirketleri ve uluslar arasındaki yarışta varsayılan olarak değil, insanlık tarafından bir bütün halinde kasıtlı olarak alınmalıdır.

## İnsan ellerinde

İnsanlar AI'dan gelen iyiliği istiyor: onları güçlendiren, ekonomik fırsatları ve büyümeyi artıran, bilim, teknoloji ve eğitimde atılımlar vaat eden faydalı araçlar. Neden istemesinler? Ama sorulduğunda, halkın ezici çoğunluğu [daha yavaş ve dikkatli AI gelişimi](https://www.vox.com/future-perfect/2023/8/18/23836362/ai-slow-down-poll-regulation) istiyor ve onları işlerinde ve başka yerlerde değiştirecek, kültürlerini ve bilgi ortamlarını insani olmayan içerikle dolduracak, gücü küçücük bir şirket setinde yoğunlaştıracak, aşırı büyük ölçekli küresel riskler oluşturacak ve sonunda türlerini güçsüzleştirme ya da değiştirme tehdidi yaratacak insanlardan daha akıllı AI istemiyor. Neden istesinler?

Birini diğeri olmadan *alabiliriz*. Bu, kaderimizin herhangi bir teknolojinin sözde kaçınılmazlığında ya da Silikon Vadisi'ndeki birkaç CEO'nun elinde değil, ona sahip çıkarsak bizim ellerimizin geri kalanında olduğuna karar vermekle başlar. Kapıları kapatalım ve geleceği insani tutalım.