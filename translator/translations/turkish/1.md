# Bölüm 1 - Giriş

İnsandan daha akıllı yapay zeka ihtimaline nasıl tepki vereceğimiz, çağımızın en acil meselesidir. Bu makale, ileriye dönük bir yol sunmaktadır.

İnsan çağının sonuna gelmiş olabiliriz.

Son on yılda türümüzün tarihinde eşi benzeri görülmemiş bir şey başladı. Bunun sonuçları büyük ölçüde insanlığın geleceğini belirleyecek. 2015 civarından itibaren araştırmacılar *dar kapsamlı* yapay zeka (AI) geliştirmeyi başardılar – Go gibi oyunlarda kazanabilen, görüntü ve konuşmayı herhangi bir insandan daha iyi tanıyabilen sistemler.[^1]

Bu harika bir başarı ve insanlığı güçlendirecek son derece yararlı sistemler ve ürünler ortaya çıkarıyor. Ancak dar kapsamlı yapay zeka hiçbir zaman alanın gerçek hedefi olmadı. Bunun yerine amaç, özellikle "yapay genel zeka" (YGZ) veya "süper zeka" olarak adlandırılan, yapay zekanın şu anda Go, satranç, poker, drone yarışı vb. alanlarda insanüstü olduğu gibi, *tüm* görevlerde aynı anda insanlar kadar iyi veya daha iyi olan *genel* amaçlı yapay zeka sistemleri yaratmaktı. Bu, birçok büyük yapay zeka şirketinin açık hedefidir.[^2]

*Bu çabalar da başarılı oluyor.* ChatGPT, Gemini, Llama, Grok, Claude ve Deepseek gibi büyük hesaplamalar ve dağlar dolusu veriye dayanan genel amaçlı yapay zeka sistemleri, çok çeşitli görevlerde tipik insanlarla eşitliğe ulaştı ve hatta bazı alanlarda insan uzmanlarıyla boy ölçüştü. Şimdi en büyük teknoloji şirketlerinden bazılarındaki yapay zeka mühendisleri, bu dev makine zekası deneylerini insan kapasitelerinin, uzmanlığının ve özerkliğinin tüm alanlarında önce eşitleyen, sonra da aşan seviyelere taşımak için yarışıyorlar.

*Bu çok yakın bir gelecekte gerçekleşecek.* Son on yılda uzmanların bunun ne kadar süreceğine dair tahminleri – mevcut rotamızda devam edersek – on yıllardan (veya yüzyıllardan) tek haneli yıllara düştü.

Bu aynı zamanda çağ açıcı öneme sahip ve aşkın bir risk taşıyor. YGZ savunucuları bunu bilimsel problemleri çözecek, hastalıkları iyileştirecek, yeni teknolojiler geliştirecek ve sıkıcı işleri otomatikleştirecek pozitif bir dönüşüm olarak görüyorlar. Yapay zeka kesinlikle tüm bunları başarmaya yardım edebilir – nitekim şimdiden ediyor. Ancak on yıllar boyunca Alan Turing'den Stephen Hawking'e, günümüzün Geoffrey Hinton ve Yoshua Bengio'suna[^3] kadar pek çok dikkatli düşünür sert bir uyarı yaptı: gerçekten insandan daha akıllı, genel, otonom yapay zeka inşa etmek en azından toplumu tamamen ve geri döndürülemez şekilde alt üst edecek, en kötü ihtimalle ise insan türünün yok olmasına yol açacaktır.[^4]

Süper zekâlı yapay zeka mevcut yolumuzda hızla yaklaşıyor, ancak kaçınılmaz olmaktan çok uzak. Bu makale, bu yaklaşan insandışı geleceğe giden *Kapıları* neden ve nasıl kapatmamız gerektiği ve bunun yerine ne yapmamız gerektiği konusunda genişletilmiş bir argümandır.


[^1]: Bu [çizelge](https://time.com/6300942/ai-progress-charts/) bir dizi görevi gösteriyor; bu grafiğe benzer pek çok eğri eklenebilir. Dar kapsamlı yapay zekadaki bu hızlı ilerleme alandaki uzmanları bile şaşırtmış, kriterler tahminlerin yıllar öncesinde aşılmıştır.

[^2]: Deepmind, OpenAI, Anthropic ve X.ai'nin hepsi YGZ geliştirme özel amacıyla kuruldu. Örneğin OpenAI'ın tüzüğünde açıkça "tüm insanlığa fayda sağlayan yapay genel zeka" geliştirme hedefi belirtilirken, DeepMind'ın misyonu "zekayı çözmek, sonra da bunu kullanarak her şeyi çözmek"tir. Meta, Microsoft ve diğerleri artık büyük ölçüde benzer yolları izliyor. Meta, [YGZ geliştirmeyi ve bunu açık kaynak olarak yayınlamayı planladığını](https://www.forbes.com/sites/johnkoetsier/2024/01/18/zuckerberg-on-ai-meta-building-agi-for-everyone-and-open-sourcing-it/) söyledi.

[^3]: Hinton ve Bengio en çok atıf alan yapay zeka araştırmacıları arasında yer alır, ikisi de yapay zeka alanının Nobeli olan Turing Ödülü'nü kazanmışlar ve Hinton ayrıca (fizik) Nobel Ödülü'ne de sahiptir.

[^4]: Bu düzeyde risk taşıyan bir şeyi ticari teşvikler altında ve neredeyse sıfır devlet gözetimi ile inşa etmek tamamen emsalsizdir. Bunu inşa edenler arasında risk konusunda tartışma bile yok! Deepmind, OpenAI ve Anthropic'in liderleri ile diğer birçok uzman, gelişmiş yapay zekanın *insanlık için varoluşsal risk* oluşturduğuna dair bir [bildirgeyi](https://www.safe.ai/work/statement-on-ai-risk) resmen imzaladılar. Alarm zilleri daha yüksek sesle çalamaz ve bunları görmezden gelenlerin YGZ ve süper zekayı ciddiye almadıkları sonucuna varabiliriz. Bu makalenin amaçlarından biri, onların neden ciddiye alması gerektiğini anlamalarına yardım etmektir.