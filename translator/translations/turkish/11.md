# Ekler

YGZ güvenliği ve güvenlik standartları için katmanlı yaklaşım, hesaplama muhasebesi teknik detayları, 'kapı kapatma' örnek uygulaması ve katı YGZ sorumluluk rejimi detayları dahil olmak üzere ek bilgiler.

## Ek A: Hesaplama muhasebesi teknik detayları

Anlamlı hesaplama tabanlı kontroller için hem "gerçek değer" hem de eğitim ve çıkarımda kullanılan toplam işlem gücü için iyi yaklaşımlar içeren detaylı bir yöntem gereklidir. İşte "gerçek değerin" teknik düzeyde nasıl hesaplanabileceğine dair bir örnek.

**Tanımlar:**

*Hesaplama nedensel grafiği:* Bir AI modelinin belirli bir çıktısı O için, o hesaplamanın sonucunu değiştirmenin potansiyel olarak O'yu değiştirebileceği bir dizi dijital hesaplama vardır. (Bu muhafazakar olarak varsayılmalıdır, yani bir hesaplamanın hem zamanda daha önce gerçekleşen hem de fiziksel olarak potansiyel nedensel etki yolu olan bir öncülden bağımsız olduğuna inanmak için açık bir neden olmalıdır.) Bu, çıkarım sırasında AI modeli tarafından yapılan hesaplamayı ve ayrıca modelin girdi, veri hazırlama ve eğitimine giren hesaplamaları içerir. Bunların herhangi biri bir AI modelinden gelen çıktı olabileceği için, bu özyinelemeli olarak hesaplanır ve bir insanın girdide önemli bir değişiklik sağladığı yerde kesilir.

*Eğitim İşlem Gücü:* Bir sinir ağının hesaplama nedensel grafiğinde yer alan toplam işlem gücü (FLOP veya diğer birimlerle), (veri hazırlama, eğitim ve ince ayar ve diğer tüm hesaplamalar dahil.)

*Çıktı İşlem Gücü:* Belirli bir AI çıktısının hesaplama nedensel grafiğindeki toplam işlem gücü, tüm sinir ağları (ve Eğitim İşlem Gücü dahil) ve o çıktıya giren diğer hesaplamalar dahil.

*Çıkarım İşlem Gücü Oranı:* Bir dizi çıktıda, çıktılar arasındaki Çıktı İşlem Gücünün değişim oranı (FLOP/s veya diğer birimlerle), yani bir sonraki çıktıyı üretmek için kullanılan işlem gücünün çıktılar arasındaki zaman aralığına bölünmesi.

**Örnekler ve yaklaşımlar:**

- İnsan tarafından oluşturulan veriler üzerinde eğitilmiş tek bir sinir ağı için, Eğitim İşlem Gücü geleneksel olarak rapor edildiği şekliyle toplam eğitim işlem gücüdür.
- Sabit bir hızda çıkarım yapan böyle bir sinir ağı için, Çıkarım İşlem Gücü Oranı yaklaşık olarak çıkarımı gerçekleştiren hesaplama kümesinin FLOP/s cinsinden toplam hesaplama hızıdır.
- Model ince ayarı için, tamamlanmış modelin Eğitim İşlem Gücü, ince ayar yapılmamış modelin Eğitim İşlem Gücü artı ince ayar sırasında yapılan hesaplama ve ince ayarda kullanılan verileri hazırlamak için yapılan hesaplamadır.
- Damıtılmış bir model için, tamamlanmış modelin Eğitim İşlem Gücü hem damıtılmış modelin hem de sentetik veri veya diğer eğitim girdisi sağlamak için kullanılan daha büyük modelin eğitimini içerir.
- Birkaç model eğitilir ancak birçok "deneme" insan yargısına dayanarak atılırsa, bunlar tutulan modelin Eğitim veya Çıktı İşlem Gücüne sayılmaz.

## Ek B: Kapı kapatma örnek uygulaması

**Uygulama Örneği:** İşte eğitim için 10<sup>27</sup> FLOP ve çıkarım için 10<sup>20</sup> FLOP/s (AI'yı çalıştırma) sınırı verildiğinde bir kapı kapatmanın nasıl işleyebileceğine dair bir örnek:

**1. Duraklama:** Ulusal güvenlik gerekçeleriyle, ABD Yürütme organı ABD merkezli, ABD'de iş yapan veya ABD'de üretilen çipler kullanan tüm şirketlerden 10<sup>27</sup> FLOP Eğitim İşlem Gücü sınırını aşabilecek yeni AI eğitim çalışmalarını durdurmasını talep eder. ABD, AI geliştirme faaliyeti yürüten diğer ülkelerle görüşmelere başlamalı, onları benzer adımlar atmaya güçlü bir şekilde teşvik etmeli ve uymamaları durumunda ABD duraksatmasının kaldırılabileceğini belirtmelidir.

**2. ABD gözetimi ve lisanslama:** Yürütme emri veya mevcut bir düzenleyici kurumun eylemiyle, ABD (diyelim ki) bir yıl içinde şunları gerektirir:

- ABD'de faaliyet gösteren şirketler tarafından yapılan 10<sup>25</sup> FLOP üzerindeki tüm AI eğitim çalışmalarının bir ABD düzenleyici kurumu tarafından tutulan bir veritabanına kaydedilmesi. (Not: Bunun biraz daha zayıf bir versiyonu, 10<sup>26</sup> FLOP üzerindeki modeller için kayıt gerektiren, artık yürürlükten kaldırılmış 2023 ABD AI yürütme emrinde zaten yer almıştı.)
- ABD'de faaliyet gösteren veya ABD hükümetiyle iş yapan tüm AI ilgili donanım üreticilerinin, özel donanımları ve onu çalıştıran yazılım üzerinde bir dizi gerekliliğe uyması. (Bu gerekliliklerin çoğu mevcut donanıma yazılım ve aygıt yazılımı güncellemeleri ile dahil edilebilir, ancak uzun vadeli ve sağlam çözümler sonraki donanım nesillerde değişiklikler gerektirir.) Bunlar arasında, donanım 10<sup>18</sup> FLOP/s hesaplama yürütme kapasitesine sahip yüksek hızlı birbirine bağlı bir kümenin parçasıysa, hem telemetri alan hem de ek hesaplama gerçekleştirme talepleri alan uzaktan bir "yönetici"den düzenli izin içeren daha yüksek bir doğrulama seviyesi gerektirir.
- Sorumlu taraf, donanımında gerçekleştirilen toplam hesaplamayı ABD veritabanını tutan kuruma bildirir.
- Hem daha güvenli hem de daha esnek gözetim ve izin vermeye olanak sağlamak için daha güçlü gereklilikler aşamalı olarak devreye girer.

**3. Uluslararası gözetim:**

- ABD, Çin ve gelişmiş çip üretim kapasitesine sahip diğer ülkeler uluslararası bir anlaşma müzakere eder.
- Bu anlaşma, Uluslararası Atom Enerjisi Ajansına benzer şekilde AI eğitimi ve yürütmesini denetlemekle görevli yeni bir uluslararası ajans oluşturur.
- İmzacı ülkeler, yerel AI donanım üreticilerinin ABD'de uygulananlar kadar güçlü bir dizi gereklilik ile uyum sağlamasını zorunlu kılmalıdır.
- Sorumlu taraflar artık AI hesaplama sayılarını hem kendi ülkelerindeki ajanslara hem de uluslararası ajans içindeki yeni ofise bildirmek zorundadır.
- Ek ülkeler mevcut uluslararası anlaşmaya katılmaya güçlü bir şekilde teşvik edilir: imzacı ülkeler tarafından ihracat kontrolleri imzacı olmayanlara yüksek kaliteli donanım erişimini kısıtlarken imzacılar AI sistemlerini yönetmede teknik destek alabilir.

**4. Uluslararası doğrulama ve yaptırım:**

- Donanım doğrulama sistemi, hesaplama kullanımını hem orijinal sorumlu tarafa hem de doğrudan uluslararası ajans ofisine bildirecek şekilde güncellenir.
- Ajans, uluslararası anlaşma imzacıları ile görüşme yoluyla, imzacı ülkelerde hukuki güç kazanan hesaplama sınırları üzerinde anlaşmaya varır.
- Paralel olarak, bir hesaplama eşiğinin üzerinde (ancak sınırın altında) AI eğitimi ve çalıştırılmasının bu standartlara uymasının gerekli olacağı bir dizi uluslararası standart geliştirilebilir.
- Ajans, gerekirse daha iyi algoritmalar vb. için tazmin etmek üzere hesaplama sınırını düşürebilir. Veya güvenli ve tavsiye edilir görülürse (ispatlanabilir güvenlik garantileri düzeyinde) hesaplama sınırını yükseltebilir.

## Ek C: Katı YGZ sorumluluk rejimi detayları

**Katı YGZ sorumluluk rejimi detayları**

- Son derece genel, yetenekli ve otonom olan gelişmiş bir AI sisteminin oluşturulması ve işletilmesi "anormal derecede tehlikeli" bir faaliyet olarak kabul edilir.
- Bu nedenle, bu tür sistemleri eğitme ve işletme için varsayılan sorumluluk, model veya çıktıları/eylemleri tarafından yapılan herhangi bir zarar için katı, müşterek ve müteselsil sorumluluktur (veya ABD dışı eşdeğeri).
- Ağır ihmal veya kasıtlı suistimal durumlarında yönetici ve yönetim kurulu üyeleri için kişisel sorumluluk uygulanacaktır. Bu, en ağır durumlar için cezai yaptırımları içermelidir.
- Sorumluluğun insanların ve şirketlerin normal olarak tabi olacağı varsayılan (ABD'de kusur temelli) sorumluluğa döndüğü çok sayıda güvenli liman vardır.
	- Bazı hesaplama eşiğinin altında eğitilmiş ve işletilen modeller (bu, yukarıda açıklanan üst sınırlardan en az 10 kat daha düşük olacaktır.)
	- "Zayıf" olan AI (kabaca, amaçlandığı görevlerde insan uzman seviyesinin altında) ve/veya
	- "Dar" olan AI (özel olarak tasarlandığı ve eğitildiği sabit ve oldukça sınırlı görev ve işlem kapsamına sahip) ve/veya
	- "Pasif" olan AI (mütevazi değişiklik altında bile - doğrudan insan katılımı ve kontrolü olmadan eylemler gerçekleştirme veya karmaşık çok adımlı görevler yapma yeteneği çok sınırlı.)
	- Güvenli, emniyetli ve kontrol edilebilir olması garanti edilen AI (kanıtlanabilir şekilde güvenli veya risk analizi ihmal edilebilir düzeyde beklenen zarar gösterir.)
- Güvenli limanlar, AI geliştiricisi tarafından hazırlanan ve bir ajans tarafından yetkilendirilmiş bir ajans veya denetçi tarafından onaylanan [güvenlik vakası](https://arxiv.org/abs/2410.21572) temelinde talep edilebilir. Hesaplamaya dayalı güvenli liman talep etmek için geliştirici sadece toplam Eğitim İşlem Gücü ve maksimal Çıkarım Oranı için güvenilir tahminler sunmalıdır.
- Mevzuat, yüksek kamu zararı riski olan AI sistemlerinin geliştirilmesinden ihtiyati tedbir kararının uygun olacağı durumları açıkça belirtecektir.
- Şirket konsorsiyumları, STK'lar ve devlet kurumları ile çalışarak, bu terimleri, düzenleyicilerin güvenli limanları nasıl vereceğini, AI geliştiricilerinin güvenlik vakalarını nasıl geliştireceğini ve mahkemelerin güvenli limanların proaktif olarak talep edilmediği durumlarda sorumluluğu nasıl yorumlayacağını tanımlayan standartlar ve normlar geliştirmelidir.

## Ek D: YGZ güvenliği ve güvenlik standartları için katmanlı yaklaşım

**YGZ güvenliği ve güvenlik standartları için katmanlı yaklaşım**

| Risk Katmanı | Tetikleyici(ler) | Eğitim gereklilikleri | Dağıtım gerekliliği |
| --- | --- | --- | --- |
| RT-0 | Otonomi, genellik ve zeka açısından zayıf AI | hiçbiri | hiçbiri |
| RT-1 | Otonomi, genellik ve zeka açısından birinde güçlü AI | hiçbiri | Risk ve kullanıma dayalı, potansiyel olarak modelin kullanılabileceği yerlerde ulusal otoriteler tarafından onaylanmış güvenlik vakaları |
| RT-2 | Otonomi, genellik ve zeka açısından ikisinde güçlü AI | Geliştirici üzerinde yargı yetkisi olan ulusal otoriteye kayıt | Büyük zarar riskini yetkili seviyeler altında sınırlayan güvenlik vakası artı modelin kullanılabileceği yerlerde ulusal otoriteler tarafından onaylanmış bağımsız güvenlik denetimleri (black-box ve white-box red teaming dahil) |
| RT-3 | Otonomi, genellik ve zeka açısından güçlü YGZ | Geliştirici üzerinde yargı yetkisi olan ulusal otorite tarafından güvenlik ve emniyet planının ön onayı | Büyük zarar riskini yetkili seviyeler altında sınırlayan güvenlik vakası ve siber güvenlik, kontrol edilebilirlik, çıkarılamaz öldürme anahtarı, insan değerleriyle hizalama ve kötüye kullanıma karşı sağlamlık dahil gerekli spesifikasyonların garanti edilmesi. |
| RT-4 | 10<sup>27</sup> FLOP Eğitim veya 10<sup>20</sup> FLOP/s Çıkarımı aşan herhangi bir model | Uluslararası olarak kararlaştırılan hesaplama üst sınırının kaldırılması beklenene kadar yasak | Uluslararası olarak kararlaştırılan hesaplama üst sınırının kaldırılması beklenene kadar yasak |

Yüksek otonomi, genellik ve zeka kombinasyonlarının yanı sıra hesaplama eşiklerine dayalı katmanlar içeren risk sınıflandırmaları ve güvenlik/emniyet standartları:

- *Güçlü otonomi*, sistem önemli insan gözetimi veya müdahalesi olmadan gerçek dünyada alakalı olan çok adımlı görevleri yapabiliyorsa ve/veya karmaşık eylemleri gerçekleştirebiliyorsa veya kolayca bunu yapmak için hazırlanabiliyorsa geçerlidir. Örnekler: otonom araçlar ve robotlar; finansal ticaret botları. Olmayan örnekler: GPT-4; görüntü sınıflandırıcıları
- *Güçlü genellik* geniş uygulama kapsamını, modelin kasıtlı ve spesifik olarak eğitilmediği görevleri yapmasını ve önemli yeni görev öğrenme yeteneğini gösterir. Örnekler: GPT-4; mu-zero. Olmayan örnekler: AlphaFold; otonom araçlar; görüntü üreticileri
- *Güçlü zeka*, modelin en iyi performans gösterdiği görevlerde insan uzman seviyesi performansına eşlik etmeye karşılık gelir (ve genel bir model için geniş görev yelpazesinde.) Örnekler: AlphaFold; mu-zero; o3. Olmayan örnekler: GPT-4; Siri