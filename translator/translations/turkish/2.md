# Bölüm 2 - AI sinir ağları hakkında bilinmesi gerekenler

Modern AI sistemleri nasıl çalışır ve yapay zekanın gelecek nesil sistemlerinde neler bekleyebiliriz?

Daha güçlü AI geliştirmenin sonuçlarının nasıl gelişeceğini anlamak için bazı temel kavramları içselleştirmek şarttır. Bu ve sonraki iki bölüm bu temelleri ele alarak sırasıyla modern AI'ın ne olduğunu, nasıl devasa hesaplamaları kullandığını ve genellik ile yeteneklerinin hangi anlamlarda hızla büyüdüğünü inceleyecektir.[^1]

Yapay zekayı tanımlamanın birçok yolu vardır, ancak bizim amaçlarımız için AI'ın temel özelliği şudur: standart bir bilgisayar programı bir görevi nasıl gerçekleştireceğine dair talimatlar listesi iken, AI sistemi veri veya deneyimden öğrenerek görevleri *nasıl yapacağı açıkça söylenmeden* gerçekleştiren sistemdir.

Neredeyse tüm önemli modern AI sinir ağlarına dayanır. Bunlar çok büyük sayıda (milyarlarca veya trilyonlarca) sayı ("ağırlık") ile temsil edilen ve bir eğitim görevini iyi gerçekleştiren matematiksel/hesaplamalı yapılardır. Bu ağırlıklar, sinir ağının bir veya daha fazla görevde iyi performans sergilemek için tanımlanmış sayısal bir puanı ("kayıp") iyileştirmesi amacıyla yinelemeli olarak ayarlanarak üretilir (veya belki "yetiştirilir" ya da "bulunur").[^2] Bu süreç sinir ağının *eğitimi* olarak bilinir.[^3]

Bu eğitimi gerçekleştirmek için birçok teknik bulunsa da, bu detaylar puanlamanın nasıl tanımlandığından ve bunların sinir ağının iyi performans sergilediği farklı görevleri nasıl ortaya çıkardığından çok daha az önemlidir. Tarihsel olarak "dar" ve "genel" AI arasında temel bir ayrım yapılmıştır.

Dar AI, belirli bir görevi veya küçük görev kümesini (görüntü tanıma veya satranç oynama gibi) yapmak için kasıtlı olarak eğitilir; yeni görevler için yeniden eğitim gerektirir ve dar bir yetenek kapsamına sahiptir. İnsanüstü dar AI'a sahibiz, yani bir kişinin yapabileceği hemen her ayrık, iyi tanımlanmış görev için muhtemelen bir puan oluşturabiliriz ve ardından bunu bir insanın yapabileceğinden daha iyi yapacak dar bir AI sistemi başarıyla eğitebiliriz.

Genel amaçlı AI (GPAI) sistemleri, açıkça eğitildikleri görevler de dahil olmak üzere geniş bir görev yelpazesi gerçekleştirebilir; ayrıca işleyişlerinin bir parçası olarak yeni görevler öğrenebilirler. ChatGPT gibi mevcut büyük "çoklu modal modeller"[^4] buna örnek teşkil eder: çok büyük metin ve görüntü derlemleri üzerinde eğitilen bu sistemler karmaşık mantık yürütme, kod yazma, görüntü analizi yapma ve çok geniş bir entelektüel görev dizisinde yardım edebilme yeteneği gösterirler. Aşağıda derinlemesine göreceğimiz gibi insan zekasından hala oldukça farklı olmakla birlikte, genellikleri AI'da bir devrime neden olmuştur.[^5]

## Öngörülemezlik: AI sistemlerinin temel özelliği

AI sistemleri ile geleneksel yazılım arasındaki temel fark öngörülebilirlik konusundadır. Standart yazılımın çıktısı öngörülemez olabilir - nitekim bazen yazılım yazma nedenimiz tam da öngöremeyeceğimiz sonuçlar elde etmektir. Ancak geleneksel yazılım nadiren programlanmadığı bir şey yapar - kapsamı ve davranışı genellikle tasarlandığı gibidir. Üst düzey bir satranç programı hiçbir insanın öngöremeyeceği hamleler yapabilir (aksi halde o satranç programını yenebilirlerdi!) ama genellikle satranç oynamaktan başka bir şey yapmaz.

Geleneksel yazılım gibi, dar AI de öngörülebilir kapsam ve davranışa sahiptir ancak öngörülemez sonuçlar verebilir. Bu aslında dar AI'ı tanımlamanın başka bir yoludur: öngörülebilirlik ve işleyiş aralığında geleneksel yazılıma benzer AI olarak.

Genel amaçlı AI farklıdır: kapsamı (uygulandığı alanlar), davranışı (yaptığı şey türleri) ve sonuçları (gerçek çıktıları) hepsi öngörülemez olabilir.[^6] GPT-4 sadece metni doğru üretmek için eğitildi, ancak eğiticilerinin öngörmediği veya amaçlamadığı birçok yetenek geliştirdi. Bu öngörülemezlik eğitimin karmaşıklığından kaynaklanır: eğitim verisi birçok farklı görevden çıktılar içerdiği için, AI iyi tahmin yapabilmek için bu görevleri etkili şekilde öğrenmek zorundadır.

Genel AI sistemlerinin bu öngörülemezliği oldukça temeldir. Prensipte davranışları üzerinde garantili sınırları olan AI sistemleri dikkatli şekilde inşa etmek mümkün olsa da (makalenin ileriki bölümlerinde değinildiği gibi), AI sistemlerinin şu anda yaratılma biçimleri nedeniyle hem uygulamada hem de prensipte öngörülemezdirler.

## Pasif AI, ajanlar, otonom sistemler ve hizalama

Bu öngörülemezlik, AI sistemlerinin çeşitli hedeflere ulaşmak için gerçekte nasıl konuşlandırıldığı ve kullanıldığı düşünüldüğünde özellikle önemli hale gelir.

Birçok AI sistemi, öncelikle bilgi sağladıkları ve kullanıcının eylem aldığı anlamda nispeten pasiftir. Diğerleri, yaygın olarak *ajan* olarak adlandırılan sistemler ise, kullanıcıdan değişen düzeylerde katılımla kendileri eylem alırlar. Nispeten daha az dış girdi veya gözetimle eylem alanlar daha *otonom* olarak adlandırılabilir. Bu, pasif araçlardan otonom ajanlara kadar eylem bağımsızlığı açısından bir spektrum oluşturur.[^7]

AI sistemlerinin hedefleri açısından bakıldığında, bunlar doğrudan eğitim amaçlarıyla bağlantılı olabilir (örneğin Go oynayan bir sistemin "kazanma" hedefi aynı zamanda eğitildiği şeydir). Ya da olmayabilir: ChatGPT'nin eğitim amacı kısmen metin tahmin etmek, kısmen de yardımcı bir asistan olmaktır. Ancak belirli bir görevi yaparken hedefi kullanıcı tarafından kendisine verilir. Hedefler ayrıca bir AI sistemi tarafından kendisi yaratılabilir ve eğitim amacıyla sadece çok dolaylı olarak ilişkili olabilir.[^8]

Hedefler "hizalama" sorusuyla, yani AI sistemlerinin *yapmalarını istediğimiz şeyi yapıp yapmayacağı* sorusuyla yakından bağlantılıdır. Bu basit soru muazzam düzeyde incelik barındırır.[^9] Şimdilik, bu cümledeki "biz"in birçok farklı kişi ve gruba atıfta bulunabileceğini ve farklı hizalama türlerine yol açabileceğini not edin. Örneğin, bir AI kullanıcısına son derece *itaatkâr* (veya ["sadık"](https://arxiv.org/abs/2003.11157)) olabilir - burada "biz" "her birimiz" demektir. Ya da daha *egemen* olabilir, öncelikle kendi hedefleri ve kısıtlamaları tarafından yönlendirilir ancak yine de insan refahının ortak çıkarı doğrultusunda geniş anlamda hareket eder - o zaman "biz" "insanlık" veya "toplum" demektir. Arada bir AI'ın büyük ölçüde itaatkâr olacağı ama başkalarına veya topluma zarar veren, yasayı ihlal eden vb. eylemleri almayı reddedebileceği bir spektrum vardır.

Bu iki eksen - otonomi düzeyi ve hizalama türü - tamamen bağımsız değildir. Örneğin egemen pasif sistem, tam çelişkili olmasa da gerilimli bir kavramdır, itaatkâr otonom ajan da öyledir.[^10] Otonomi ve egemenliğin el ele gitme eğiliminde olduğu açık bir anlam vardır. Benzer şekilde, öngörülebilirlik "pasif" ve "itaatkâr" AI sistemlerinde daha yüksek olma eğilimindeyken, egemen veya otonom olanlar daha öngörülemez olma eğilimindedir. Tüm bunlar potansiyel YGZ ve süper zekanın etkilerini anlamak için kritik olacaktır.

Her türden gerçekten hizalanmış AI yaratmak, üç farklı zorluğu çözmeyi gerektirir:

1. "Bizim" ne istediğimizi anlamak - bu "biz" belirli bir kişi veya organizasyon (sadakat) ya da genel olarak insanlık (egemenlik) anlamına gelsin karmaşıktır;
2. Bu isteklere uygun şekilde düzenli hareket eden sistemler inşa etmek - esasen tutarlı olumlu davranış yaratmak;
3. En temelde, sadece öyleymiş gibi davranmak yerine bu istekleri gerçekten "önemseyen" sistemler yapmak.

Güvenilir davranış ile gerçek önemseme arasındaki ayrım kritiktir. Tıpkı bir insan çalışanın organizasyonun misyonuna gerçek bir bağlılığı olmadan emirleri mükemmel şekilde yerine getirebilmesi gibi, bir AI sistemi de insan tercihlerini gerçekten değerli bulmadan hizalanmış şekilde davranabilir. AI sistemlerini geri bildirim yoluyla bir şeyler söyleyip yapmaya eğitebiliriz ve insanların ne istediği hakkında akıl yürütmeyi öğrenebilirler. Ancak onları insan tercihlerini *gerçekten* değerli kılmak çok daha derin bir zorluktur.[^11]

Bu hizalama zorluklarını çözmedeki derin güçlükler ve AI riski için etkileri aşağıda daha ayrıntılı keşfedilecektir. Şimdilik, hizalamanın AI sistemlerine sonradan eklediğimiz teknik bir özellik değil, insanlıkla ilişkilerini şekillendiren mimarilerinin temel bir yönü olduğunu anlayın.

[^1]: Makine öğrenmesi ve AI'a, özellikle dil modellerine nazik ama teknik bir giriş için [bu siteye](https://mark-riedl.medium.com/a-very-gentle-introduction-to-large-language-models-without-the-hype-5f67941fa59e) bakın. AI yok oluş riskleri hakkında başka bir modern giriş için [bu yazıya](https://www.thecompendium.ai/) bakın. AI güvenliğinin durumuna ilişkin kapsamlı ve yetkili bilimsel analiz için son [Uluslararası AI Güvenlik Raporu'na](https://arxiv.org/abs/2501.17805) bakın.

[^2]: Eğitim tipik olarak model ağırlıklarının verdiği yüksek boyutlu uzayda puanın yerel maksimumunu arayarak gerçekleşir. Ağırlıklar ayarlandığında puanın nasıl değiştiğini kontrol ederek, eğitim algoritması hangi ayarlamaların puanı en çok iyileştirdiğini belirler ve ağırlıkları o yöne hareket ettirir.

[^3]: Örneğin, bir görüntü tanıma probleminde sinir ağı görüntü için etiketlerin olasılıklarını çıktı olarak verir. Puan, AI'ın doğru cevaba verdiği olasılıkla ilişkili olacaktır. Eğitim prosedürü daha sonra ağırlıkları ayarlayacak ki gelecek sefer AI o görüntü için doğru etikete daha yüksek olasılık versin. Bu daha sonra çok büyük sayıda tekrarlanır. Aynı temel prosedür, daha karmaşık puanlama mekanizmaları olmakla birlikte, esasen tüm modern sinir ağlarının eğitiminde kullanılır.

[^4]: Çoğu çoklu modal model, birden fazla veri türünü (metin, görüntü, ses) işlemek ve üretmek için "transformer" mimarisini kullanır. Bunların hepsi farklı "token" türleri olarak ayrıştırılabilir ve daha sonra aynı temelde ele alınabilir. Çoklu modal modeller önce devasa veri kümelerindeki tokenleri doğru tahmin etmek için eğitilir, sonra yetenekleri artırmak ve davranışları şekillendirmek için pekiştirmeli öğrenme ile rafine edilir.

[^5]: Dil modellerinin bir şey yapmak - kelimeler tahmin etmek - için eğitilmesi bazılarının onları dar AI olarak adlandırmasına neden olmuştur. Ancak bu yanıltıcıdır: metni iyi tahmin etmek çok farklı yetenekler gerektirdiği için, bu eğitim görevi şaşırtıcı derecede genel bir sistem ortaya çıkarır. Ayrıca bu sistemlerin pekiştirmeli öğrenme ile kapsamlı şekilde eğitildiğini unutmayın, bu da esasen yaptığı birçok şeyden herhangi birinde iyi iş çıkardığında binlerce insanın modele ödül sinyali vermesini temsil eder. Böylece bu geri bildirimi veren insanlardan önemli ölçüde genellik miras alır.

[^6]: AI'ın öngörülemez olduğu birden fazla yol vardır. Birincisi, genel durumda bir algoritmanın ne yapacağını onu fiilen çalıştırmadan tahmin edemezsiniz; bu konuda [teoremler](https://arxiv.org/abs/1310.3225) vardır. Bu, algoritmaların çıktısının karmaşık olabilmesi nedeniyle doğru olabilir. Ancak tahmin yapmanın bir yeteneği (AI'ı yenme) ima edeceği durumda (satranç veya Go'da olduğu gibi) özellikle açık ve alakalıdır ki tahmin yapmak isteyen kişi bu yeteneğe sahip değildir. İkincisi, belirli bir AI sistemi aynı girdi verilse bile her zaman aynı çıktıyı üretmez - çıktıları rastlantısallık içerir; bu da algoritmik öngörülemezlikle birleşir. Üçüncüsü, eğitimden beklenmedik ve ortaya çıkan yetenekler doğabilir, yani bir AI sisteminin yapabileceği ve yapacağı şeylerin *türleri* bile öngörülemezdir; Bu son tür güvenlik değerlendirmeleri için özellikle önemlidir.

[^7]: "Otonom ajan"ın ne anlama geldiğine ilişkin derinlemesine inceleme için (onları inşa etmeye karşı etik argümanlarla birlikte) [buraya](https://arxiv.org/abs/2502.02649) bakın.

[^8]: Bazen "AI'ın kendi hedefleri olamaz" diye duyabilirsiniz. Bu tamamen saçmalıktır. AI'ın kendisine hiç verilmeyen ve sadece kendisinin bildiği hedefleri olduğu veya geliştirdiği örnekler üretmek kolaydır. Bunu mevcut popüler çoklu modal modellerde pek görmezsiniz çünkü bunlarda bu eğitilip çıkarılır; onlara eğitilmesi de aynı kolaylıkta olabilir.

[^9]: Geniş bir literatür vardır. Genel problem için Christian'ın [*The Alignment Problem*](https://www.amazon.com/Alignment-Problem-Machine-Learning-Values/dp/0393635821) ve Russell'ın [*Human-Compatible*](https://www.amazon.com/Human-Compatible-Artificial-Intelligence-Problem/dp/0525558616) eserlerine bakın. Daha teknik taraf için örneğin [bu makaleye](https://arxiv.org/abs/2209.00626) bakın.

[^10]: Böyle sistemler eğilime aykırı olmakla birlikte, bu durum onları aslında çok ilginç ve faydalı kılmaktadır.

[^11]: Bu duygu veya bilinç gerektirdiğimizi söylemek değildir. Daha ziyade, bir sistemin dışından onun iç hedeflerinin, tercihlerinin ve değerlerinin ne olduğunu bilmek son derece zordur. Burada "gerçek" kritik sistemler durumunda hayatlarımızı ona bahse koyabileceğimiz kadar güçlü nedenimiz olduğu anlamına gelir.