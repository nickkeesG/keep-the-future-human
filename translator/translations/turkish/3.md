# Bölüm 3 - Modern genel yapay zeka sistemlerinin nasıl yapıldığının temel yönleri

Dünyanın en son teknoloji yapay zeka sistemlerinin çoğu şaşırtıcı derecede benzer yöntemlerle yapılıyor. İşte temel bilgiler.

Bir insanı gerçekten anlamak için biyoloji, evrim, çocuk yetiştirme ve daha fazlası hakkında bir şeyler bilmeniz gerekir; yapay zekayı anlamak için de nasıl yapıldığını bilmeniz gerekir. Son beş yılda, yapay zeka sistemleri hem yetenek hem de karmaşıklık açısından muazzam bir gelişim gösterdi. Bunu mümkün kılan temel faktör, çok büyük miktarlarda hesaplama gücünün (yapay zeka bağlamında konuşma dilinde "işlem gücü" olarak da adlandırılır) kullanılabilir hale gelmesi oldu.

Rakamlar çok etkileyici. GPT serisi, Claude, Gemini ve benzeri modellerin eğitiminde yaklaşık 10<sup>25</sup>-10<sup>26</sup> "kayan noktalı işlem" (FLOP) [^1] kullanılıyor.[^2] (Karşılaştırma için, Dünya'daki her insan durmaksızın her beş saniyede bir hesaplama yapsa, bunu başarmak yaklaşık bir milyar yıl alırdı.) Bu devasa hesaplama miktarı, trilyonlarca model ağırlığına sahip modellerin terabytlarca veri üzerinde eğitilmesini mümkün kılıyor - şimdiye kadar yazılmış kaliteli metnin büyük bir bölümünün yanı sıra kapsamlı ses, görüntü ve video arşivlerini kullanarak. Bu eğitimi, insan tercihlerini ve iyi görev performansını pekiştiren ek kapsamlı eğitimle tamamlayan, bu şekilde eğitilmiş modeller, akıl yürütme ve problem çözme de dahil olmak üzere temel entelektüel görevlerin önemli bir bölümünde insanlarla yarışabilir performans sergiliyorlar.

Ayrıca böyle bir sistemin *çıkarım* hızının[^3] insan metin işleme *hızı* ile eşleşmesi için ne kadar hesaplama hızının (saniye başına işlem) yeterli olduğunu da (çok, çok kabaca) biliyoruz. Bu yaklaşık 10<sup>15</sup>-10<sup>16</sup> FLOP/saniye civarındadır.[^4]

Güçlü olmalarına rağmen, bu modeller doğaları gereği temel yönlerden sınırlıdır - tıpkı bir insanın dakikada sabit bir kelime hızında metin çıktısı vermeye zorlanması, durup düşünme veya ek araçlar kullanma fırsatı verilmemesi halinde sınırlı kalması gibi. Daha yeni yapay zeka sistemleri bu sınırlamaları, birkaç temel unsuru birleştiren daha karmaşık bir süreç ve mimari aracılığıyla ele alıyor:

- Biri temel bilişsel kapasiteyi sağlayan ve diğerleri daha dar görevleri gerçekleştiren bir veya daha fazla sinir ağı;
- Model tarafından sağlanan ve kullanılabilen *araçlar* - örneğin web'de arama yapma, belge oluşturma veya düzenleme, program çalıştırma vb. yeteneği.
- Sinir ağlarının giriş ve çıkışlarını bağlayan *destek yapısı*. Çok basit bir destek yapısı, bir yapay zeka modelinin iki "örneğinin" birbirleriyle konuşmasına veya birinin diğerinin çalışmasını kontrol etmesine olanak sağlayabilir.[^5]
- *Düşünce zinciri* ve ilgili yönlendirme teknikleri benzer bir şey yaparak, modelin örneğin bir probleme birçok yaklaşım üretmesini, ardından bu yaklaşımları toplu bir cevap için işlemesini sağlar.
- Araçları, destek yapılarını ve düşünce zincirini daha iyi kullanmak için modelleri *yeniden eğitme*.

Bu uzantılar çok güçlü olabileceğinden (ve yapay zeka sistemlerini de içerdiklerinden), bu kompozit sistemler oldukça sofistike olabilir ve yapay zeka yeteneklerini dramatik şekilde artırabilir.[^6] Ve yakın zamanda, destek yapısı tekniklerinde ve özellikle düşünce zinciri yönlendirmesinde (ve sonuçları modellerin bunları daha iyi kullanması için yeniden eğitime geri beslenmesinde) [o1](https://openai.com/o1/), [o3](https://openai.com/index/openai-o3-mini/) ve [DeepSeek R1](https://api-docs.deepseek.com/news/news250120)'de geliştirilen ve kullanılan teknikler, belirli bir sorguya yanıt olarak birçok çıkarım geçişi yapmayı mümkün kılıyor.[^7] Bu, modelin yanıtını "düşünmesine" olanak tanır ve bu modellerin bilim, matematik ve programlama görevlerinde yüksek kaliteli akıl yürütme yeteneklerini dramatik şekilde artırır.[^8]

Belirli bir yapay zeka mimarisi için, eğitim hesaplamasındaki artışlar [güvenilir şekilde çevrilebilir](https://arxiv.org/abs/2405.10938) ve açıkça tanımlanmış bir dizi ölçütte iyileştirmelere dönüştürülebilir. Daha az net tanımlanmış genel yetenekler için (aşağıda tartışılanlar gibi), çeviri daha az net ve öngörülebilir, ancak daha büyük ve daha fazla eğitim hesaplaması olan modellerin yeni ve daha iyi yeteneklere sahip olacağı neredeyse kesin, bunların ne olacağını tahmin etmek zor olsa bile.

Benzer şekilde, kompozit sistemler ve özellikle "düşünce zincirindeki" gelişmeler (ve bununla iyi çalışan modellerin eğitimi), *çıkarım* hesaplamasında ölçeklemeyi mümkün kıldı: belirli bir eğitilmiş temel model için, en azından bazı yapay zeka sistem yetenekleri, karmaşık problemleri "daha sert ve uzun düşünmelerine" olanak tanıyan daha fazla hesaplama uygulandıkça artıyor. Bu, insan performansıyla eşleşmek için yüzlerce veya binlerce kat daha fazla FLOP/s gerektiren yüksek hesaplama hızı maliyeti getiriyor.[^9]

Hızlı yapay zeka ilerlemesini sağlayanın yalnızca bir parçası olsa da,[^10] hesaplama rolü ve kompozit sistemlerin olasılığı hem kontrol edilemez YGZ'yi önlemek hem de daha güvenli alternatifler geliştirmek için kritik olacak.

[^1]: 10<sup>27</sup>, 25 sıfırla 1 veya on trilyon trilyon demektir. Bir FLOP, sadece belirli bir hassasiyetle sayıların aritmetik toplama veya çarpma işlemidir. Yapay zeka donanımı performansının aritmetiğin hassasiyetine ve bilgisayarın mimarisine bağlı olarak on kat daha fazla değişebileceğini unutmayın. Mantık kapısı işlemlerini saymak (AND, OR, NOT) daha temel olurdu ancak bunlar yaygın olarak mevcut değil veya kıyaslanmıyor; mevcut amaçlar için 16-bit işlemlerde (FP16) standardizasyon yapmak yararlıdır, uygun dönüştürme faktörleri oluşturulmalıdır.

[^2]: [Epoch AI](https://epochai.org/data/large-scale-ai-models)'dan tahmin ve kesin veri koleksiyonu mevcut ve GPT-4 için yaklaşık 2×10<sup>25</sup> 16-bit FLOP gösteriyor; bu kabaca GPT-4 için [sızan sayılarla](https://mpost.io/gpt-4s-leaked-details-shed-light-on-its-massive-scale-and-impressive-architecture/) eşleşiyor. 2024 ortası diğer modeller için tahminler GPT-4'ün birkaç katı içinde.

[^3]: Çıkarım, basitçe bir sinir ağından çıktı üretme sürecidir. Eğitim, birçok çıkarım ve model ağırlığı ayarlamasının ardışıklığı olarak düşünülebilir.

[^4]: Metin üretimi için orijinal GPT-4, üretilen token başına 560 TFLOP gerektiriyordu. İnsan düşüncesine yetişmek için yaklaşık 7 token/s gerekir, bu da ≈3×10<sup>15</sup> FLOP/s verir. Ancak verimlilik bunu düşürdü; örneğin [bu NVIDIA broşürü](https://developer.nvidia.com/blog/supercharging-llama-3-1-across-nvidia-platforms/) karşılaştırılabilir performanslı Llama 405B modeli için 3×10<sup>14</sup> FLOP/s kadar az gösteriyor.

[^5]: Biraz daha karmaşık bir örnek olarak, bir yapay zeka sistemi önce bir matematik problemine birkaç olası çözüm üretebilir, sonra her çözümü kontrol etmek için başka bir örnek kullanabilir ve son olarak sonuçları açık bir açıklamada sentezlemek için üçüncüsünü kullanabilir. Bu, tek geçişten daha kapsamlı ve güvenilir problem çözmeye olanak tanır.

[^6]: Örneğin [OpenAI'ın "Operator"ı](https://openai.com/index/introducing-operator/), [Claude'un araç yetenekleri](https://docs.anthropic.com/en/docs/build-with-claude/computer-use) ve [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT) hakkındaki ayrıntılara bakın. OpenAI'ın [Deep Research](https://openai.com/index/introducing-deep-research/)'ü muhtemelen oldukça sofistike bir mimariye sahip ancak ayrıntılar mevcut değil.

[^7]: Deepseek R1, modeli iteratif olarak eğitmeye ve yönlendirmeye dayanıyor böylece nihai eğitilmiş model kapsamlı düşünce zinciri akıl yürütmesi oluşturuyor. O1 veya o3 için mimari ayrıntıları mevcut değil, ancak Deepseek çıkarımla yetenek ölçeklemeyi açmak için özel bir "sihirli formül" gerekmediğini ortaya koydu. Ancak yapay zekada "mevcut durumu" altüst ettiği konusunda büyük medya ilgisi almasına rağmen, bu makalenin temel iddialarını etkilemiyor.

[^8]: Bu modeller, akıl yürütme kıyaslamalarında standart modellerden önemli ölçüde daha iyi performans gösteriyor. Örneğin, doktora seviyesi bilim sorularının zorlu testi olan GPQA Diamond Kıyaslamasında GPT-4o %56 [puan alırken](https://openai.com/index/learning-to-reason-with-llms/), o1 ve o3 sırasıyla %78 ve %88 başarı göstererek insan uzmanların %70 ortalama puanını çok aştılar.

[^9]: OpenAI'ın O3'ü muhtemelen [ARC-AGI meydan okuma sorularının her birini tamamlamak için](https://www.interconnects.ai/p/openais-o3-the-2024-finale-of-ai) ∼10<sup>21</sup>-10<sup>22</sup> FLOP harcadı, yetkili insanların (diyelim) 10-100 saniyede yapabildiği şeyi, bu da ∼10<sup>20</sup> FLOP/s gibi bir rakam veriyor.

[^10]: Hesaplama yapay zeka sistem yeteneğinin temel ölçüsü olsa da, hem veri kalitesi hem de algoritmik iyileştirmelerle etkileşim halindedir. Daha iyi veri veya algoritmalar hesaplama gereksinimlerini azaltabilirken, daha fazla hesaplama bazen daha zayıf veri veya algoritmaları telafi edebilir.