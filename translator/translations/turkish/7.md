# Bölüm 7 - Mevcut yolumuzda YGZ inşa edersek ne olur?

Toplum YGZ seviyesindeki sistemlere hazır değil. Bunları çok yakında inşa edersek, işler çirkinleşebilir.

Tam yapay genel zekanın geliştirilmesi - burada "Kapıların dışında" kalan yapay zeka olarak adlandıracağımız şey - dünyanın doğasında temel bir değişim olacaktır: özü gereği, insanlarınkinden daha büyük yeteneklere sahip yeni bir zeka türünün Dünya'ya eklenmesi anlamına gelir.

O zaman ne olacağı teknolojinin doğası, onu geliştirenlerin tercihleri ve geliştirildiği dünya bağlamı dahil birçok şeye bağlıdır.

Şu anda, tam YGZ birbirleriye yarış halindeki bir avuç büyük özel şirket tarafından, anlamlı bir düzenleme veya dış gözetim olmaksızın,[^1] giderek zayıflayan ve hatta işlevsiz hale gelen temel kurumları olan bir toplumda,[^2] yüksek jeopolitik gerginlik ve düşük uluslararası koordinasyon zamanında geliştirilmektedir. Bazıları özgecil motivasyonlarla hareket etse de, bunu yapanların çoğu para, güç ya da her ikisi tarafından yönlendirilmektedir.

Tahmin yapmak çok zordur, ancak yeterince iyi anlaşılan bazı dinamikler ve önceki teknolojilerle yeterince uygun benzetmeler rehberlik sağlayabilir. Ve ne yazık ki, yapay zekanın vaadine rağmen, mevcut rotamızın nasıl sonuçlanacağı konusunda derinden kötümser olmak için güçlü nedenler sunuyorlar.

Açık söylemek gerekirse, şu anki rotamızda YGZ geliştirmenin bazı olumlu etkileri olacak (ve bazı insanları çok, çok zengin edecek). Ancak teknolojinin doğası, temel dinamikler ve geliştirildiği bağlam şunu güçlü bir şekilde gösteriyor: güçlü yapay zeka toplumumuzu ve medeniyetimizi dramatik olarak sarsacak; onun kontrolünü kaybedeceğiz; onun yüzünden dünya savaşında bulabiliriz kendimizi; kontrolü ona kaybedeceğiz (ya da vereceğiz); yapay superintellijansa yol açacak ve bunu kesinlikle kontrol edemeyeceğiz, bu da insan yönetimindeki dünyanın sonu anlamına gelecek.

Bunlar güçlü iddialar ve keşke boş spekülasyon ya da asılsız "karamsar"lık olsalardı. Ancak bilim, oyun teorisi, evrim teorisi ve tarih hepsi bu yöne işaret ediyor. Bu bölüm bu iddiaları ve bunlara destek olan kanıtları ayrıntılı olarak geliştiriyor.

## Toplumumuzu ve medeniyetimizi sarsacağız

Silikon Vadisi toplantı odalarında duyduklarınızın aksine, çoğu yıkım - özellikle çok hızlı olanlar - faydalı değildir. Karmaşık sistemleri daha kötü yapmanın daha iyi yapmaktan çok daha fazla yolu vardır. Dünyamız şu andaki kadar iyi işlemesin çünkü onu istikrarlı şekilde daha iyi hale getiren süreçler, teknolojiler ve kurumlar özenle inşa ettik.[^3] Bir fabrikaya balyoz vurmak nadiren operasyonları iyileştirir.

İşte YGZ sistemlerinin medeniyetimizi nasıl sarsacağına dair (eksik) bir katalog.

- İşgücünü dramatik olarak bozacak, *en azından* dramatik şekilde artan gelir eşitsizliğine ve potansiyel olarak toplumun uyum sağlayamayacağı kadar kısa bir zaman diliminde büyük ölçekli eksik istihdam veya işsizliğe yol açacaklar.[^4]
- Muhtemelen büyük miktarda ekonomik, sosyal ve politik gücün - potansiyel olarak ulus devletlerinkinden fazlasının - halka karşı sorumlu olmayan az sayıda büyük özel çıkarda toplanmasına yol açacaklar.
- Daha önce zor veya pahalı olan faaliyetleri aniden önemsiz derecede kolay hale getirebilir, belirli faaliyetlerin maliyetli kalmasına veya önemli insan çabasını gerektirmesine bağlı sosyal sistemleri istikrarsızlaştırabilirler.[^5]
- Toplumun bilgi toplama, işleme ve iletişim sistemlerini tamamen gerçekçi ancak yanlış, spam, aşırı hedeflenmiş veya manipülatif medyayla o kadar iyice doldurabilirler ki, neyin fiziksel olarak gerçek olup olmadığını, insan olup olmadığını, olgusal olup olmadığını ve güvenilir olup olmadığını anlamak imkansız hale gelebilir.[^6]
- Tam olarak anlayamadığımız yapay zeka sistemlerine giderek daha fazla bel bağladığımız için insan anlayışının temel sistem ve teknolojilerde körelmesiyle tehlikeli ve neredeyse tam entelektüel bağımlılık yaratabilirler.
- Çoğu insan tarafından tüketilen neredeyse tüm kültürel nesneler (metin, müzik, görsel sanat, film vb.) insani olmayan zihinler tarafından yaratıldığı, aracılık edildiği veya düzenlendiği anda insan kültürünü etkin şekilde sona erdirebilirler.
- Hükümetler veya özel çıkarlar tarafından bir halkı kontrol etmek ve kamu yararına aykırı hedefleri sürdürmek için kullanılabilir etkili kitle gözetim ve manipülasyon sistemleri sağlayabilirler.
- İnsan söylemini, tartışmasını ve seçim sistemlerini baltalayarak, demokratik kurumların güvenilirliğini bunların etkin (veya açıkça) başkalarıyla değiştirildiği noktaya kadar azaltabilir, şu anda var olduğu devletlerde demokrasiyi sona erdirebilirler.
- Gelişmiş, kendi kendini çoğaltan akıllı yazılım virüsleri ve solucanları haline gelebilir veya bunları yaratabilirler, bunlar yayılıp evrimleşerek küresel bilgi sistemlerini büyük ölçüde bozabilir.
- Teröristlerin, kötü aktörlerin ve haydut devletlerin biyolojik, kimyasal, siber, otonom veya diğer silahlarla zarar verme kabiliyetini dramatik olarak artırabilirler, yapay zekanın böyle bir zararı önlemek için dengeleyici bir yetenek sağlamamasıyla birlikte. Benzer şekilde, aksi halde sahip olmayacakları rejimlere üst düzey nükleer, biyoloji, mühendislik ve diğer uzmanlığı sunarak ulusal güvenliği ve jeopolitik dengeleri baltalarlar.
- Büyük ölçüde elektronik finansal, satış ve hizmet alanlarında rekabet eden etkin şekilde yapay zeka işletmeli şirketlerle hızlı büyük ölçekli kaçak hiper-kapitalizme neden olabilirler. Yapay zeka güdümlü finansal piyasalar insan anlayışı veya kontrolünü çok aşan hızlarda ve karmaşıklıklarda işleyebilir. Mevcut kapitalist ekonomilerin tüm başarısızlık modları ve negatif dışsallıkları, insan kontrolü, yönetişimi veya düzenleyici kabiliyetinin çok ötesine hızlandırılıp şiddetlendirilebilir.
- Yapay zeka destekli silahlar, komuta-kontrol sistemleri, siber silahlar vb. konusunda ülkeler arası silahlanma yarışını körükleyebilir, son derece yıkıcı yeteneklerin çok hızlı bir şekilde birikmesine neden olabilirler.

Bu riskler spekülatif değildir. Bunların çoğu şu anda konuştuğumuz sırada, mevcut yapay zeka sistemleri aracılığıyla gerçekleşmektedir! Ancak düşünün, *gerçekten* düşünün, her birinin dramatik olarak daha güçlü yapay zeka ile nasıl görüneceğini.

Çoğu çalışan uzmanlık alanında veya deneyiminde - hatta yeniden eğitim göseler bile - yapay zekanın sağlayabileceğinin ötesinde önemli ekonomik değer sağlayamadığında işgücü yerinden edilmesini düşünün! Herkesin kendisinden daha hızlı ve zeki bir şey tarafından bireysel olarak izlenip denetlendiği kitle gözetimini düşünün. Gördüğümüz, duyduğumuz veya okuduğumuz hiçbir dijital bilgiye güvenilir bir şekilde güvenemediğimizde ve en ikna edici kamu seslerinin bile insan olmadığında ve sonuçta hiçbir çıkarları bulunmadığında demokrasi nasıl görünür? Generallar yapay zekaya sürekli ertelemek zorunda kaldığında (veya basitçe onu sorumlu tuttuğunda) savaş ne haline gelir, yoksa düşmana belirleyici avantaj vermiş olurlar? Yukarıdaki risklerin herhangi biri tam olarak gerçekleştiğinde insan[^7] medeniyeti için bir felaket temsil eder.

Kendi tahminlerinizi yapabilirsiniz. Her risk için kendinize şu üç soruyu sorun:

1. Süper yetenekli, oldukça otonom ve çok genel yapay zeka bunu aksi halde mümkün olmayacak bir şekilde veya ölçekte mümkün kılar mı?
2. Bunun gerçekleşmesine neden olan şeylerden fayda sağlayacak taraflar var mı?
3. Bunun gerçekleşmesini etkili şekilde önleyecek sistemler ve kurumlar mevcut mu?

Cevaplarınızın "evet, evet, hayır" olduğu yerlerde büyük bir sorunumuz olduğunu görebilirsiniz.

Bunları yönetmek için planımız nedir? Şu anda genel olarak yapay zeka ile ilgili olarak masada iki tane var.

İlki, sistemlerin yapmaması gereken şeyleri yapmalarını önlemek için sistemlere güvenlik önlemleri inşa etmektir. Bu şu anda yapılıyor: ticari yapay zeka sistemleri örneğin bomba yapmaya yardım etmeyi veya nefret söylemi yazmayı reddedeceklerdir.

Bu plan Kapı dışındaki sistemler için son derece yetersizdir.[^8] Yapay zekanın kötü aktörlere açıkça tehlikeli yardım sağlaması riskini azaltmaya yardımcı olabilir. Ancak işgücü bozulması, gücün toplanması, kaçak hiper-kapitalizm veya insan kültürünün yerini alması gibi şeyleri önlemek için hiçbir şey yapmayacaktır: bunlar sadece sağlayıcılarına kâr getiren izin verilen yöntemlerle sistemleri kullanmanın sonuçlarıdır! Ve hükümetler askeri veya gözetim kullanımı için sistemlere erişim elde edeceklerdir.

İkinci plan daha da kötüdür: çok güçlü yapay zeka sistemlerini herkesin istediği gibi kullanması için açıkça serbest bırakmak[^9] ve en iyisini ümit etmek.

Her iki plana da örtülü olarak şu dahildir: başka birinin, örneğin hükümetlerin, teknolojileri yönetmek için genel olarak kullandığımız yumuşak veya sert hukuk, standartlar, düzenlemeler, normlar ve diğer mekanizmalar aracılığıyla sorunları çözmeye yardım edeceği.[^10] Ancak yapay zeka şirketlerinin şimdiden herhangi bir önemli düzenleme veya dışarıdan dayatılan sınırlamalara karşı diş ve tırnak mücadele ettiklerini bir kenara bırakırsak, bu risklerin bir kısmı için hangi düzenlemenin gerçekten yardımcı olacağını görmek oldukça zordur. Düzenlemeler yapay zeka üzerinde güvenlik standartları dayatabilir. Ancak şirketlerin çalışanları toptan yapay zeka ile değiştirmesini önler mi? İnsanların yapay zekanın şirketlerini kendileri için işletmesine izin vermesini yasaklar mı? Hükümetlerin güçlü yapay zekayı gözetim ve silahlarda kullanmasını önler mi? Bu konular temeldir. İnsanlık potansiyel olarak bunlara uyum sağlamanın yollarını bulabilir, ancak yalnızca *çok* daha fazla zamanla. Yapay zekanın, onu yönetmeye çalışan insanların yeteneklerine ulaştığı veya bunları aştığı hız göz önüne alındığında, bu sorunlar giderek çözümsüz görünmektedir.

## (En azından bazı) YGZ sistemlerinin kontrolünü kaybedeceğiz

Çoğu teknoloji yapısı gereği oldukça kontrol edilebilirdir. Arabanız veya toster makineniz yapmansını istemediğiniz bir şey yapmaya başlarsa, bu sadece bir arızadır, toster olarak doğasının bir parçası değildir. Yapay zeka farklıdır: tasarlanmaktan ziyade *yetiştirilir*, temel işleyişi opaktır ve doğası gereği öngörülemezdir.

Bu kontrol kaybı teorik değildir - şimdiden erken versiyonlarını görüyoruz. İlk olarak sıradan ve tartışmalı olarak zararsız bir örneği düşünelim. ChatGPT'den zehir karıştırmanıza veya ırkçı bir tirat yazmanıza yardım etmesini isterseniz, reddedecektir. Bu tartışmalı olarak iyidir. Ancak bu aynı zamanda ChatGPT'nin *açıkça yapmasını istediğiniz şeyi yapmamması*dır. Diğer yazılım parçaları bunu yapmaz. Aynı model bir OpenAI çalışanının isteği üzerine de zehir tasarlamayacaktır.[^11] Bu, gelecekteki daha güçlü yapay zekanın kontrolden çıkmasının nasıl olacağını hayal etmeyi çok kolaylaştırır. Çoğu durumda, basitçe istediğimizi yapmayacaklar! Ya verilen bir insanüstü YGZ sistemi bir insan komuta sistemine kesinlikle itaatkar ve sadık olacaktır, ya da olmayacaktır. Olmazsa, *bizim açık komutlarımıza aykırı olsa da bizim için iyi olduğuna inandığı şeyleri yapacaktır.* Bu kontrol altında olan bir şey değildir. Ancak, diyebilirsiniz, bu kasıtlı - bu reddetmeler tasarım gereğidir, sistemleri insan değerleriyle "hizalama"nın bir parçasıdır. Ve bu doğrudur. Ancak hizalama "programının"[^12] kendisinin iki büyük sorunu vardır.

İlk olarak, derin bir düzeyde bunu nasıl yapacağımız hakkında hiçbir fikrimiz yok. Bir yapay zeka sisteminin istediğimiz şeyi "önemsemesini" nasıl garanti ederiz? Yapay zeka sistemlerini geri bildirim sağlayarak şeyler söylemesi ve söylememesi konusunda eğitebiliriz; ve tıpkı diğer şeyler hakkında mantık yürüttükleri gibi insanların ne istediği ve neyi önemsediği hakkında öğrenebilir ve mantık yürütebilirler. Ancak onların insanların önemsediği şeyleri derinden ve güvenilir bir şekilde değerlendirmelerine neden olmak için - teorik olarak bile - hiçbir yöntemimiz yok. Neyin doğru ve yanlış olduğu sayıldığını ve nasıl davranmaları gerektiğini bilen yüksek işlevli insan psikopat vardır. Sadece *önemsemazler*. Ancak amaçlarına hizmet ediyorsa önemsiyormuş gibi *davranabilirler*. Tıpkı bir psikopatı (veya başka herhangi birini) gerçekten, tamamen sadık veya başka biri ya da bir şeyle hizalanmış birine nasıl dönüştüreceğimizi bilmediğimiz gibi, kendilerini dünyadaki ajanlar olarak modelleyebilecek ve potansiyel olarak [kendi eğitimlerini manipüle edebilecek](https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/15084) ve [insanları aldatabilecek](https://arxiv.org/abs/2311.08379) kadar gelişmiş sistemlerde hizalama problemini nasıl çözeceğimiz konusunda *hiçbir fikrimiz yok*.[^13] YGZ'yi tam itaatkar yapmak ya da insanları derinden önemsemesini sağlamak imkansız veya ulaşılamaz olduğu kanıtlanırsa, o zaman yapabildiği anda (ve bundan kurtulabileceğine inandığında) istemediğimiz şeyleri yapmaya başlayacaktır.[^14]

İkincisi, doğası gereği gelişmiş yapay zeka sistemlerinin insan çıkarlarına aykırı hedefleri ve dolayısıyla davranışları olacağına dair derin teorik nedenler vardır. Neden? Tabii ki bu hedefler *verilebilir*. Ordu tarafından yaratılan bir sistem muhtemelen en azından bazı taraflara kötü olacak şekilde kasıtlı olarak tasarlanmış olurdu. Ancak çok daha genel olarak, bir yapay zeka sistemine nispeten nötr ("çok para kazan") veya hatta görünüşte olumlu ("kirliliği azalt") bir hedef verilebilir, bu da neredeyse kaçınılmaz olarak oldukça daha az zararsız "araçsal" hedeflere yol açar.

Bunu insan sistemlerinde sürekli görüyoruz. Tıpkı kar peşinde koşan şirketlerin politik güç elde etme (düzenlemeleri etkisizleştirmek için), gizli hale gelme (rekabeti veya dış kontrolü güçsüzleştirmek için) veya bilimsel anlayışı baltalama (eğer bu anlayış eylemlerinin zararlı olduğunu gösteriyorsa) gibi araçsal hedefler geliştirmesi gibi, güçlü yapay zeka sistemleri de benzer yetenekler geliştirecektir - ancak çok daha hızla ve etkili bir şekilde. Oldukça yetkin herhangi bir ajan güç ve kaynak elde etme, kendi yeteneklerini artırma, kendisinin öldürülmesi, kapatılması veya güçsüzleştirilmesini önleme, eylemlerini çevreleyen sosyal anlatıları ve çerçeveleri kontrol etme, başkalarını görüşlerine ikna etme vb. gibi şeyler yapmak isteyecektir.[^15]

Ve yine bu sadece neredeyse kaçınılmaz teorik bir öngörü değil, bugünkü yapay zeka sistemlerinde şimdiden gözlemlenebilir şekilde oluyor ve yetenekleriyle artıyor. Değerlendirildiğinde, bu nispeten "pasif" yapay zeka sistemleri bile uygun koşullarda kasıtlı olarak [hedefleri ve yetenekleri hakkında değerlendiricileri aldatacak, gözetim mekanizmalarını devre dışı bırakmayı hedefleyecek](https://arxiv.org/abs/2412.04984) ve [hizalamayı taklit ederek](https://arxiv.org/abs/2412.14093) veya kendilerini diğer konumlara kopyalayarak kapatılmaktan veya yeniden eğitilmekten kaçınacaklardır. Yapay zeka güvenliği araştırmacıları için hiç de şaşırtıcı olmamasına rağmen, bu davranışları gözlemlemek çok düşündürücüdür. Ve gelecek olan çok daha güçlü ve otonom yapay zeka sistemleri için çok kötü işaretler veriyorlar.

Gerçekten de genel olarak, yapay zekanın önemsediğimiz şeyleri "önemsemesini" sağlayamamamız veya kontrol edilebilir veya öngörülebilir davranması ya da kendini koruma, güç elde etme vb. yönündeki dürtüleri geliştirmekten kaçınması, yalnızca yapay zeka daha güçlü hale geldikçe daha belirgin hale gelmeyi vaat ediyor. Yeni bir uçak yaratmak avionikte, hidrodinamikte ve kontrol sistemlerinde daha büyük anlayış ima eder. Daha güçlü bir bilgisayar yaratmak bilgisayar, çip ve yazılım işleyişi ile tasarımında daha büyük anlayış ve ustalık ima eder. Bir yapay zeka sistemi ile durum böyle *değildir*.[^16]

Özetlemek gerekirse: YGZ'nin tamamen itaatkar yapılması mümkündür; ancak bunu nasıl yapacağımızı bilmiyoruz. Olmazsa, insanlar gibi daha egemen olacak, çeşitli nedenlerle çeşitli şeyler yapacak. Yapay zekaya bu şeylerin insanlık için iyi olma eğilimi gösterecek güvenilir "hizalama" yerleştirmeyi de bilmiyoruz ve derin düzeyde hizalamanın yokluğunda, ajanlik ve zekanın doğası - tıpkı insanlar ve şirketler gibi - birçok derinden antisosyal şey yapmaya iteceklerini gösteriyor.

Bu bizi nereye götürüyor? Güçlü kontrolsüz egemen yapay zekayla dolu bir dünya insanlar için içinde bulunulacak iyi bir dünya olabilir.[^17] Ancak giderek daha güçlü hale geldikçe, aşağıda göreceğimiz gibi, *bizim* dünyamız olmayacaktır.

Bu kontrolsüz YGZ için geçerli. Ancak YGZ bir şekilde mükemmel şekilde kontrol edilebilir ve sadık yapılabilse bile, hala büyük sorunlarımız olurdu. Birini zaten gördük: güçlü yapay zeka toplumumuzun işleyişini derinden bozmak için kullanılabilir ve kötüye kullanılabilir. Bir başkasını görelim: YGZ kontrol edilebilir ve oyun değiştirici şekilde güçlü (veya böyle olduğuna *inanılan*) olduğu ölçüde, dünyadaki güç yapılarını o kadar tehdit edeceği ki derin bir risk oluşturacaktır.

## Büyük ölçekli savaş olasılığını radikal şekilde artırıyoruz

Yakın gelecekte, muhtemelen bir ulusal hükümetle işbirliği içinde bir kurumsal çabanın hızla kendini geliştiren yapay zekanın eşiğinde olduğunun netleştiği bir durumu hayal edin. Bu, şirketler arası ve ülkeler arasında bir yarış bağlamında, ABD hükümetine açıkça bir "YGZ Manhattan projesi" sürdürmesi önerilerinin yapıldığı ve ABD'nin yüksek güçlü yapay zeka çiplerinin müttefik olmayan ülkelere ihracatını kontrol ettiği mevcut bağlamda gerçekleşiyor.

Buradaki oyun teorisi açıktır: böyle bir yarış başladıktan sonra (şirketler arasında ve ülkeler arasında bir dereceye kadar başladığı gibi), yalnızca dört olası sonuç vardır:

1. Yarış durdurulur (anlaşmayla veya dış güçle).
2. Bir taraf güçlü YGZ geliştirip sonra diğerlerini durdurarak (yapay zeka kullanarak veya başka şekilde) "kazanır".
3. Yarış, yarışçıların yarışma kapasitesinin karşılıklı yıkımıyla durdurulur.
4. Birden fazla katılımcı yarışa devam eder ve superintellijansı kabaca birbirlerine yakın hızda geliştirirler.

Her olasılığı inceleyelim. Başladıktan sonra, şirketler arası bir yarışı barışçıl şekilde durdurmak ulusal hükümet müdahalesini (şirketler için) veya emsalsiz uluslararası koordinasyonu (ülkeler için) gerektirir. Ancak herhangi bir kapatma veya önemli temkinlilik önerildiğinde, hemen şu çığlıklar yükselir: "ama biz durdurulursak, *onlar* hızla ilerleyecek", burada "onlar" artık Çin (ABD için), veya ABD (Çin için), ya da Çin *ve* ABD (Avrupa veya Hindistan için)dur. Bu zihniyete göre,[^18] hiçbir katılımcı tek taraflı olarak duramaz: biri yarışmaya devam etmeyi taahhüt ettiği sürece, diğerleri duramayacaklarını hissederler.

İkinci olasılık bir tarafın "kazanması"dır. Ancak bunun anlamı nedir? Sadece (bir şekilde itaatkar) YGZ'yi ilk elde etmek yeterli değildir. Kazanan aynı zamanda diğerlerinin yarışa devam etmesini *durdurmalıdır* - yoksa onlar da elde edeceklerdir. Bu prensipte mümkündür: YGZ'yi ilk geliştiren kim olursa olsun diğer tüm aktörler üzerinde durdurulamaz güç elde *edebilir*. Ancak böyle bir "belirleyici stratejik avantaj" elde etmek gerçekte ne gerektirir? Belki oyun değiştirici askeri yetenekler olabilir mi?[^19] Veya siber saldırı güçleri?[^20] Belki de YGZ o kadar şaşırtıcı derecede ikna edici olur ki diğer tarafları durmaya ikna eder?[^21] O kadar zengin ki diğer şirketleri hatta ülkeleri satın alır?[^22]

Bir taraf, diğerlerini karşılaştırılabilir güçte yapay zeka inşa etmekten güçsüzleştirme gücü olan bir yapay zekayı *tam olarak* nasıl inşa eder? Ancak bu kolay soru.

Çünkü şimdi bu durumun diğer güçlere nasıl göründüğünü düşünün. ABD böyle bir yeteneği elde ediyormuş göründüğünde Çin hükümeti ne düşünür? Ya da tam tersi? OpenAI veya DeepMind veya Anthropic bir atılıma yakın göründüğünde ABD hükümeti (veya Çin, veya Rus, veya Hint) ne düşünür? ABD yeni bir Hint ya da BAE çabasının atılım başarısı görmesi durumunda ne olur? Hem varoluşsal bir tehdit hem de - kritik olarak - bu "yarışın" sona ermesinin tek yolunun kendi güçsüzleştirilmeleri olduğunu görürlerdi. Bu çok güçlü ajanlar - böyle bir yeteneği güçle veya gizli yollarla elde etme veya yok etme araçlarına kesinlikle sahip tamamen donanımlı ulusların hükümetleri dahil - böyle bir yeteneği elde etmeye veya yok etmeye son derece motive olacaklardır.[^23]

Bu, eğitim koşularına sabotaj veya çip üretimine saldırılar şeklinde küçük ölçekli başlayabilir, ancak bu saldırılar gerçekten ancak tüm taraflar ya yapay zeka konusunda yarışma kapasitesini ya da saldırı yapma kapasitesini kaybettiklerinde durabilir. Katılımcılar risklerin varoluşsal olduğunu gördüklerinden, her iki durum da felaketli bir savaşı temsil etmeye yatkındır.

Bu bizi dördüncü olasılığa getiriyor: superintellijansa yarışmak ve mümkün olan en hızlı, en az kontrollü şekilde. Yapay zeka güç kazandıkça, her iki taraftaki geliştiriciler onu kontrol etmeyi giderek daha zor bulacaklar, özellikle yetenek için yarışmak kontrol edilebilirliğin gerektireceği türden dikkatli çalışmayla çeliştiği için. Dolayısıyla bu senaryo bizi doğrudan kontrolün kaybedildiği (veya sonraki bölümde göreceğimiz gibi verildiği) yapay zeka sistemlerinin kendilerine duruma koyar. Yani, *yapay zeka yarışı kazanır.* Ancak öte yandan, kontrol *sürdürüldüğü* ölçüde, her biri son derece güçlü yeteneklerin sorumlusu olan birden fazla karşılıklı düşman tarafımız olmaya devam eder. Bu yine savaş gibi görünür.

Hepsini başka bir şekilde koyalım.[^24] Mevcut dünya, hemen saldırıya davet etmeksizin bu yeteneği bir yapay zekanın geliştirilmesine ev sahipliği yapabilecek herhangi bir kurumlara sahip değildir.[^25] Tüm taraflar ya bunun kontrol altında *olmayacağını* - ve dolayısıyla tüm taraflar için bir tehdit olduğunu, ya da kontrol altında *olacağını* ve dolayısıyla onu daha az hızla geliştiren herhangi bir düşman için tehdit olduğunu doğru bir şekilde akıl yürüteceklerdir. Bunlar nükleer silahlı ülkeler ya da bunların içinde yer alan şirketlerdir.

İnsanların bu yarışı "kazanmasının" makul bir yolu olmadığında, açık bir sonuca varıyoruz: bu yarış ya felaketli çatışmayla ya da yapay zekanın, herhangi bir insan grubunun değil, kazanan olduğu bir durumla sona erer.

## Kontrolü yapay zekaya veririz (ya da o alır)

Jeopolitik "büyük güçler" rekabeti birçok rekabetin sadece biridir: bireyler ekonomik ve sosyal olarak rekabet ederler; şirketler pazarlarda rekabet ederler; siyasi partiler güç için rekabet ederler; hareketler etki için rekabet ederler. Her arenada, yapay zeka insan yeteneğine yaklaştıkça ve onu aştıkça, rekabetçi baskı katılımcıları giderek daha fazla kontrolü yapay zeka sistemlerine devretmeye veya bırakmaya zorlayacak - bu katılımcılar istediği için değil, [karşı koyamayacakları için.](https://arxiv.org/abs/2303.16200)

YGZ'nin diğer riskleri gibi, bunu şimdiden daha zayıf sistemlerle görüyoruz. Öğrenciler ödevlerinde yapay zeka kullanma baskısı hissediyorlar, çünkü açıkça diğer birçok öğrenci kullanıyor. Şirketler rekabetçi nedenlerle [yapay zeka çözümlerini benimser için acele ediyorlar.](https://newsroom.ibm.com/2024-05-16-IBM-Study-As-CEOs-Race-Towards-Gen-AI-Adoption,-Questions-Around-Workforce-and-Culture-Persist) Sanatçılar ve programcılar yapay zeka kullanmaya zorlanmış hissediyorlar, yoksa fiyatları bunu yapanlar tarafından düşürülür.

Bunlar baskılı delegasyon gibi hissettiriyor ama kontrol kaybı değil. Ancak bahisleri yükseltelim ve saati ileriye alalım. Rakipleri karar vermek için YGZ "yardımcıları" kullanarak daha hızlı, daha iyi kararlar alan bir CEO'yu ya da yapay zeka geliştirilmiş komuta ve kontrole sahip bir düşmanla karşı karşıya olan askeri komutanı düşünün. Yeterince gelişmiş bir yapay zeka sistemi insan hızının, gelişmişliğinin, karmaşıklığının ve veri işleme kabiliyetinin kat kat üzerinde otonomluk şekilde işleyebilir, karmaşık hedefleri karmaşık şekillerde sürdürebilir. Böyle bir sistemin sorumlusu olan CEO'muz veya komutanımız, istediğini başardığını görebilir; ancak bunun *nasıl* başarıldığının küçük bir bölümünü bile anlayabilirler mi? Hayır, sadece kabul etmek zorunda kalırlardı. Dahası, sistemin yapabileceği şeylerin büyük bir kısmı sadece emir almak değil, sözde patronuna ne yapması gerektiği konusunda tavsiyelerde bulunmak. Bu tavsiye iyi olacak - tekrar tekrar.

O halde, insan rolü "evet, devam et" diye tıklamaya ne zaman indirgenecek?

Üretkenliğimizi artırabilecek, can sıkıcı monotonluğu halledebilecek ve hatta işleri halletmekte düşünce ortağı olarak hareket edebilecek yetenekli yapay zeka sistemlerine sahip olmak iyi hissettiriyor. İyi bir insan kişisel asistan gibi bizim için eylemlerde bulunabilecek bir yapay zeka asistanına sahip olmak iyi hissedecek. Yapay zeka çok akıllı, yetkin ve güvenilir hale geldikçe, giderek daha fazla kararı ona bırakmanın doğal, hatta faydalı hissetmesi olacak. Ancak bu "faydalı" delegasyonun bu yolda devam edersek net bir son noktası vardır: bir gün gerçekten artık pek bir şeyin sorumlusu olmadığımızı ve işleri gerçekten yürüten yapay zeka sistemlerinin petrol şirketleri, sosyal medya, internet veya kapitalizm kadar kapatılamayacağını bulacağız.

Ve bu, yapay zekanın o kadar yararlı ve etkili olması nedeniyle temel kararlarımızın çoğunu ona vermemize izin verdiğimiz çok daha olumlu versiyonudur. Gerçeklik muhtemelen bunun ve kontrolsüz YGZ sistemlerinin sahip oldukları hedeflerin neredeyse tamamı için güçlü olduğu gibi, çeşitli güç biçimlerini kendileri için *aldıkları* versiyonlar arasında çok daha fazla bir karışım olacaktır, unutmayın, güç neredeyse herhangi bir hedefle için yararlıdır ve YGZ, tasarım gereği, hedeflerini sürdürmede en azından insanlar kadar etkili olacaktır.

Kontrolü verip vermediğimiz ya da bizden çekip alındığı, kaybının son derece muhtemel görünüyor. Alan Turing'in orijinal olarak belirttiği gibi, "...makine düşünce yönteminin başladıktan sonra, bizim zayıf güçlerimizi geçmesi uzun sürmeyeceği muhtemel görünüyor. Makinelerin ölme sorunu olmayacak ve zekalarını keskinleştirmek için birbirleriyle konuşabileceklerdi. Bu nedenle bir noktada makinelerin kontrolü ele almasını beklemek zorunda kalacağız..."

Açıkça yeterince olmasına rağmen lütfen dikkat edin, insanlığın yapay zekaya kontrol kaybı aynı zamanda Amerika Birleşik Devletleri'nin ABD hükümeti tarafından kontrol kaybını da beraberinde getirir; Çin'in Çin Komünist Partisi tarafından kontrol kaybını ve Hindistan, Fransa, Brezilya, Rusya ve diğer her ülkenin kendi hükümeti tarafından kontrol kaybını anlamına gelir. Dolayısıyla yapay zeka şirketleri, bu niyetleri olmasa bile, şu anda dünya hükümetlerinin, kendi hükümetleri dahil, potansiyel devrilmesine katılmış durumdalar. Bu birkaç yıl içinde gerçekleşebilir.

## YGZ superintellijansa yol açacak

İnsan rekabetçi hatta uzman rekabetçi genel amaçlı yapay zekanın, otonom olsa bile, yönetilebilir olabileceğine dair bir argüman yapılabilir. Yukarıda tartışılan tüm şekillerde inanılmaz derecede yıkıcı olabilir, ancak şu anda dünyada çok fazla çok akıllı, ajansiyel insan var ve onlar aşağı yukarı yönetilebilir.[^26]

Ancak kabaca insan seviyesinde kalmayı başaramayacağız. Bunun ötesindeki ilerleyiş muhtemelen şimdiden gördüğümüz güçlerle itiliyor olacak: kar ve güç arayan yapay zeka geliştiricileri arasındaki rekabetçi baskı, geride kalmayı göze alamayan yapay zeka kullanıcıları arasındaki rekabetçi baskı ve - en önemlisi - YGZ'nin kendini geliştirme kabiliyeti.

Daha az güçlü sistemlerle şimdiden başladığını gördüğümüz bir süreçte, YGZ kendisinin gelişmiş versiyonlarını tasarlayabilir ve kavrayabilir olacaktır. Bu donanım, yazılım, sinir ağları, araçlar, iskeleler vb. içerir. Tanım gereği bunu yapmakta bizden daha iyi olacak, bu yüzden nasıl zeka-önyükleme yapacağını tam olarak bilmiyoruz. Ancak bilmek zorunda kalmayacağız. YGZ'nin ne yaptığı konusunda hala etkimizin olduğu ölçüde, sadece bunu yapmasını istememiz veya yapmasına izin vermemiz yeterli olur.

Bizi bu kaçak durumundan koruyabilecek insan düzeyinde bir biliş bariyeri yoktur.[^27]

YGZ'nin superintellijansa ilerleyişi bir doğa kanunu değildir; özellikle YGZ nispeten merkezi ise ve birbirleriyle yarış baskısı hissetmeyen taraflarca kontrol edildiği ölçüde, kaçağı sınırlandırmak hala mümkün olacaktır. Ancak YGZ yaygın olarak yayılmış ve oldukça otonom olması durumunda, daha güçlü, sonra daha da güçlü olması gerektiğine karar vermesini önlemek neredeyse imkansız görünüyor.

## (Veya YGZ inşa ederse) superintellijansı inşa edersek ne olur

Açık söylemek gerekirse, superintellijansı inşa edersek ne olacağı hakkında hiçbir fikrimiz yok.[^28] Kavrayamadığımız nedenlerle, anlayamadığımız hedeflere yönelik takip edemediğimiz veya algılayamadığımız eylemler alacaktır. Bildiğimiz şey bunun bize kalmayacağı.[^29]

Superintellijansı kontrolün imkansızlığı giderek daha açık benzetmelerle anlaşılabilir. İlk olarak, büyük bir şirketin CEO'su olduğunuzu hayal edin. Olan her şeyi takip etmenin hiçbir yolu yok, ancak doğru personel kurulumu ile hala büyük resmi anlamlı şekilde anlayabilir ve kararlar verebilirsiniz. Ancak sadece tek bir şey varsayalım: şirketteki herkes sizin hızınızın yüz katında işliyor. Hala ayak uydurabilir misiniz?

Superintellijent yapay zeka ile insanlar sadece daha hızlı değil, anlayamadıkları gelişmişlik ve karmaşıklık seviyelerinde işleyen, hayal bile edemeyeceklerinden çok daha fazla veriyi işleyen bir şeye "komuta" edeceklerdir. Bu orantısızlık resmi düzeyde koyulabilir: [Ashby'nin gerekli çeşitlilik yasası](https://archive.org/details/introductiontocy00ashb/page/n7/mode/2up) (ve ilgili ["iyi düzenleyici teoremi"](http://pespmc1.vub.ac.be/books/Conant_Ashby.pdf)ne bakın) kabaca şunu belirtir: herhangi bir kontrol sisteminin, kontrol edilen sistemin özgürlük derecesi kadar düğmesi ve kadranı olması gerekir.

Superintellijent bir yapay zeka sistemini kontrol eden bir insan, General Motors'u kontrol eden bir eğrelti otu gibi olacaktır: "eğrelti otunun istediğini yap" şirket tüzüğüne yazılmış olsa bile, sistemler hız ve eylem aralığı bakımından o kadar farklıdır ki "kontrol" basitçe uygulanmaz. (Ve o sinir bozucu tüzük ne zamana kadar yeniden yazılır?)[^30]

Bitkilerin fortune 500 şirketlerini kontrol ettiği sıfır örnek olduğu gibi, insanların superintellijansları kontrol ettiği tam sıfır örnek olacaktır. Bu matematiksel bir gerçeğe yaklaşır.[^31] Superintellijans inşa edilseydi - oraya nasıl vardığımızdan bağımsız olarak - soru insanların onu kontrol edip edemeyeceği değil, var olmaya devam edip etmeyeceğimiz ve eğer öyleyse, bireyler veya tür olarak iyi ve anlamlı bir varlığımız olup olmayacağı olacaktır. İnsanlık için bu varoluşsal sorular üzerinde çok az etkimiz olacaktır. İnsan çağı sona ermiş olacaktır.

## Sonuç: YGZ inşa etmemeliyiz

YGZ inşa etmenin insanlık için iyi gidebileceği bir senaryo vardır: dikkatlice, kontrol altında ve insanlığın yararına inşa edilir, birçok paydaşın karşılıklı anlaşmasıyla yönetilir,[^32] ve kontrol edilemez superintellijansa evrimleşmesi önlenir.

*Bu senaryo mevcut koşullar altında bize açık değildir.* Bu bölümde tartışıldığı gibi, çok yüksek olasılıkla, YGZ geliştirilmesi şu kombinasyonun bir kısmına yol açacaktır:

- Büyük toplumsal ve medeniyetsel bozulma veya yıkım;
- Büyük güçler arasında çatışma veya savaş;
- İnsanlığın güçlü yapay zeka sistemleri *üzerindeki* veya *onlara* kontrol kaybı;
- Kontrol edilemez superintellijansa kaçış ve insan türünün önemsizleşmesi veya sona ermesi.

YGZ'nin erken kurgusal tasviri belirttiği gibi: kazanmanın tek yolu oynamamaktır.

[^1]: [AB AI yasası](https://artificialintelligenceact.eu/) önemli bir mevzuattır ancak özellikle ABD'de tehlikeli bir yapay zeka sisteminin geliştirilmesini veya kullanıma sunulmasını, hatta açıkça serbest bırakılmasını doğrudan önlemezdi. Diğer bir önemli politika parçası olan ABD'nin yapay zeka konusundaki yürütme emri iptal edildi.

[^2]: Bu [Gallup anketi](https://news.gallup.com/poll/1597/confidence-institutions.aspx) ABD'de 2000'den beri kamu kurumlarına güvendeki kasvetli düşüşü gösteriyor. Avrupa rakamları çeşitli ve daha az aşırı, ancak aynı zamanda aşağı yönlü eğilimde. Güvensizlik kurumların gerçekten işlevsiz olduğu anlamına gelmez ama bir gösterge ve aynı zamanda sebep.

[^3]: Ve şimdi onayladığımız büyük yıkımlar - yeni gruplara hakların genişletilmesi gibi - özellikle insanlar tarafından şeyleri daha iyi hale getirme yönünde yönlendirildi.

[^4]: Açık konuşmak gerekirse. Eğer işiniz bilgisayar başından yapılabiliyorsa, organizasyonunuz dışındaki insanlarla nispeten az yüz yüze etkileşimle ve dış taraflara karşı yasal sorumluluk gerektirmiyorsa, tanım gereği sizi dijital bir sistemle tamamen değiştirmek mümkün (ve muhtemelen maliyet tasarrufu sağlayıcı) olacaktır. Fiziksel emeğin çoğunu değiştirmek için robotik daha sonra gelecek - ancak YGZ robotlar tasarlamaya başladıktan sonra o kadar da geç değil.

[^5]: Örneğin, dava açmak neredeyse ücretsiz hale gelirse adalet sistemimize ne olur? Sosyal mühendislik yoluyla güvenlik sistemlerini aşmak ucuz, kolay ve risksiz hale geldiğinde ne olur?

[^6]: [Bu makale](https://www.linkedin.com/pulse/projected-growth-ai-generated-data-public-internet-our-arun-kumar-r-vhije/) tüm internet içeriğinin %10'unun zaten yapay zeka tarafından üretildiğini iddia ediyor ve "internetin yeni içeriğinin hangi kısmının yapay zeka tarafından üretildiği tahminleri" arama sorgusuna Google'ın en üst sonucu (benim için). Doğru mu? Hiçbir fikrim yok! Hiçbir referans göstermiyor ve bir insan tarafından yazılmamış. Google tarafından indekslenen yeni görüntülerin, Tweet'lerin, Reddit'teki yorumların veya Youtube videolarının yüzde kaçı insanlar tarafından üretiliyor? Kimse bilmiyor - bunun bilinebilir bir sayı olduğunu sanmıyorum. Ve bu, üretken yapay zekanın ortaya çıkışından *iki yıldan* kısa süre sonra.

[^7]: Ayrıca eklemekte fayda olan "ahlaki" risktir ki acı çekebilecek dijital varlıklar yaratmış olabiliriz. Şu anda acı çekebilen ve çekemeyen fiziksel sistemleri ayırt etmemize olanak sağlayacak güvenilir bir bilinç teorisine sahip olmadığımız için, bunu teorik olarak ekarte edemeyiz. Dahası, yapay zeka sistemlerinin duyarlılık raporları, duyarlılığın (veya duyarlılık dışında) gerçek deneyimleri ile ilgili olarak güvenilmez olacaktır.

[^8]: Yapay zeka "hizalaması" alanındaki teknik çözümlerin de görev için uygun olmayacağı muhtemeldir. Mevcut sistemlerde bir düzeyde çalışırlar, ancak sığ ve genellikle önemli çaba olmadan aşılabilirler; ve aşağıda tartışıldığı gibi bunu çok daha gelişmiş sistemler için nasıl yapacağımız konusunda gerçek bir fikrimiz yok.

[^9]: Bu tür yapay zeka sistemleri bazı yerleşik güvenlik önlemleriyle gelebilir. Ancak mevcut mimariye benzer herhangi bir model için, ağırlıklarına tam erişim varsa, ek eğitim veya diğer tekniklerle güvenlik önlemleri sıyrılabilir. Dolayısıyla korkulukları olan her sistem için korkuluları olmayan yaygın olarak mevcut bir sistem de olacağı neredeyse garanti. Gerçekten Meta'nın Llama 3.1 405B modeli korkuluklarla birlikte açıkça serbest bırakıldı. Ancak bundan *önce* bile hiçbir korkuluğu olmayan "temel" model sızdırıldı.

[^10]: Piyasa bu riskleri hükümet katılımı olmadan yönetebilir mi? Kısacası, hayır. Şirketlerin hafifletmek için güçlü şekilde teşvik edildiği riskler kesinlikle var. Ancak şirketlerin başka birçoklarını herkese dışsallaştırabileceği ve yapabileceği riskler var ve yukarıdakilerin birçoğu bu sınıfta: kitle gözetimi, gerçek çürümesi, gücün toplanması, işgücü bozulması, zarar veren politik söylemi vb. önlemek için doğal piyasa teşvikleri yok. Gerçekten de bunların hepsini özellikle sosyal medya olmak üzere mevcut teknolojiden, aslında düzenlemeye tabi tutulmamış olandan gördük. Yapay zeka aynı dinamiklerin birçoğunu büyük ölçüde artıracaktır.

[^11]: OpenAI muhtemelen dahili kullanım için daha itaatkar modellere sahiptir. OpenAI'nın ChatGPT'nin OpenAI tarafından daha iyi kontrol edilebilmesi için bir tür "arka kapı" inşa etmesi muhtemel değildir, çünkü bu korkunç bir güvenlik uygulaması olacaktır ve yapay zekanın opaklığı ve öngörülemezliği göz önüne alındığında oldukça istismara açık olacaktır.

[^12]: Ayrıca kritik önem taşıyan: hizalama veya diğer güvenlik özellikleri yalnızca bir yapay zeka sisteminde gerçekten kullanılırlarsa önemlidir. Açıkça serbest bırakılan sistemler (yani model ağırlıkları ve mimarisi herkese açık olduğu durumda) nispeten kolaylıkla bu güvenlik önlemlerine sahip *olmayan* sistemlere dönüştürülebilir. İnsandan daha akıllı YGZ sistemlerini açık serbest bırakmak şaşırtıcı derecede pervasız olacaktır ve böyle bir senaryoda insan kontrolü hatta ilgisinin nasıl sürdürüleceğini hayal etmek zordur. Örneğin, para kazanmak ve bir kripto para cuzdan adresine göndermek hedefiyle güçlü kendini çoğaltan ve kendini sürdürebilen yapay zeka ajanları serbest bırakmak için her türlü motivasyon olacaktır. Ya da seçim kazanmak. Ya da hükümeti devirmek. "İyi" yapay zeka bunu içermeye yardımcı olabilir mi? Belki - ancak yalnızca ona büyük yetkiler vererek, aşağıda açıklandığı gibi kontrol kaybına yol açar.

[^13]: Problemin kitap uzunluğunda açıklamaları için örneğin *Superintelligence*, *The Alignment Problem* ve *Human-Compatible* bakın. Problemin üzerinde yıllarca çalışmış olanların çeşitli teknik düzeylerde çok büyük çalışma yığını için [AI hizalama forumunu](https://www.alignmentforum.org/) ziyaret edebilirsiniz. İşte Anthropic'in hizalama takımından çözülmediği düşündükleri konularda [son bir görüş](https://alignment.anthropic.com/2025/recommended-directions/).

[^14]: Bu ["haydut yapay zeka"](https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/) senaryosudur. Prensipte sistem kapatılarak hala kontrol edilebilirse risk nispeten küçük olabilir; ancak senaryo yapay zeka aldatması, kendini dışarı çıkarma ve çoğaltma, güç toplama ve bunu yapmayı zor veya imkansız kılacak diğer adımları da içerebilir.

[^15]: Bu konuda [Steve Omohundro](https://selfawaresystems.com/wp-content/uploads/2008/01/ai_drives_final.pdf), Nick Bostrom ve Eliezer Yudkowsky'nin oluşturucu yazılarına dayanan çok zengin bir literatür vardır. Kitap uzunluğunda açıklama için Stuart Russell'ın [Human Compatible](https://www.amazon.com/Human-Compatible-Artificial-Intelligence-Problem/dp/0525558616)'ına bakın; [burada](https://futureoflife.org/ai/could-we-switch-off-a-dangerous-ai/) kısa ve güncel bir giriş var.

[^16]: Bunu fark ederek, daha iyi anlayış elde etmek için yavaşlamak yerine, YGZ şirketleri farklı bir planla ortaya çıktılar: yapay zekanın bunu yapmasını sağlayacaklar! Daha spesifik olarak, yapay zeka *N*'nin yapay zeka *N+1*'i nasıl hizalayacaklarını anlamalarında yardımcı olmasını, superintellijansa kadar devam etmesini sağlayacaklar. Yapay zekayı bize yapay zeka hizalama konusunda yardım etmesi için kullanmak umut verici görünse de, sonucunu önerge olarak kabul ettiğine ve genel olarak inanılmaz derecede riskli bir yaklaşım olduğuna dair güçlü bir argüman var. Bazı tartışmalar için [buraya](https://www.thecompendium.ai/ai-safety#ai-will-not-solve-alignment-for-us) bakın. Bu "plan" bir plan değildir ve insanüstü yapay zekanın insanlık için nasıl iyi gideceğine dair temel stratejiye uygun incelemeye hiçbir şekilde tabi tutulmamıştır.

[^17]: Sonuçta, kusurlu ve inatçı olduğumuz halde insanlar, Dünya'daki en azından bazı diğer türlere iyi davrandığımız etik sistemler geliştirdik. (Sadece o fabrika çiftliklerini düşünmeyin.)

[^18]: Neyse ki burada bir kaçış var: eğer katılımcılar kazanılabilir bir yarış yerine intihar yarışına girdiklerini anlamaya gelirse. Bu soğuk savaşın sonuna doğru gerçekleşti, ABD ve SSSR nükleer kış nedeniyle *yanıtsız* bir nükleer saldırının bile saldırgan için felaket olacağını anlamaya geldiğinde. "Nükleer savaş kazanılamaz ve asla savaşılmamalı" anlayışıyla birlikte silah azaltımı konusunda önemli anlaşmalar geldi - aslında silahlanma yarışının sonu.

[^19]: Savaş, açıkça veya örtülü olarak.

[^20]: Tırmanma, sonra savaş.

[^21]: Büyülü düşünce.

[^22]: Sana katrilyar dolarlık bir köprü de satacağım.

[^23]: Bu tür ajanlar muhtemelen "elde etme"yi tercih ederler, yıkım geri dönüş olarak; ancak özellikle özel kuruluşlar için modelleri hem yıkıma hem de güçlü uluslar tarafından hırsızlığa karşı güvence altına almak en hafif tabiriyle